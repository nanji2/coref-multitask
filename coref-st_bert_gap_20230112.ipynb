{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5544d3ec-a275-43af-9704-32cfe4747c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da81ce68-01b4-45ee-96f2-5ccd272d97aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a97e1236-837f-461b-8dec-57273845ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99309099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.legacy import data\n",
    "#from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "#from transformers import RobertaTokenizer, RobertaModel\n",
    "#from transformers import BertTokenizer, BertModel\n",
    "#from transformers import LongformerTokenizer, LongformerModel\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import statistics\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random\n",
    "import functools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf54be0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters & setup\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "DROPOUT = 0.2\n",
    "N_EPOCHS = 610\n",
    "BATCH_SIZE = 4\n",
    "# batch accumulation parameter\n",
    "accum_iter = 4\n",
    "LEARNING_RATE = 2e-6\n",
    "NO_HEAD_TRANS = 16\n",
    "\n",
    "TAG_LOSS_WEIGTH = 0.5\n",
    "CLS_LOSS_WEIGTH = 0.5\n",
    "\n",
    "BERT_PATH = './bert-large-uncased' # the path of your downloaded pre-trained language model\n",
    "DATA_PATH = './gap/'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_PATH)\n",
    "bert = AutoModel.from_pretrained(BERT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "681d50c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pre-processing\n",
    "\n",
    "def read_token_idx_list_n_cut_to_max_length(tokens, max_input_length):\n",
    "    \n",
    "    tokens =  tokens[:max_input_length-1]\n",
    "    tokens_list = []\n",
    "    for i in tokens:\n",
    "        tokens_list.append(int(i))\n",
    "    return torch.tensor(tokens_list)\n",
    "\n",
    "def cut_to_max_length(tokens, max_input_length):\n",
    "    tokens = tokens[:max_input_length-1]\n",
    "    return tokens\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "pad_token = tokenizer.pad_token\n",
    "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
    "max_input_length = tokenizer.max_model_input_sizes['bert-large-cased']\n",
    "text_id_preprocessor = functools.partial(read_token_idx_list_n_cut_to_max_length,max_input_length = max_input_length)\n",
    "tag_preprocessor = functools.partial(cut_to_max_length, max_input_length = max_input_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e0231b7-347d-401b-80f2-18c1cf067f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert-base-uncased': 512,\n",
       " 'bert-large-uncased': 512,\n",
       " 'bert-base-cased': 512,\n",
       " 'bert-large-cased': 512,\n",
       " 'bert-base-multilingual-uncased': 512,\n",
       " 'bert-base-multilingual-cased': 512,\n",
       " 'bert-base-chinese': 512,\n",
       " 'bert-base-german-cased': 512,\n",
       " 'bert-large-uncased-whole-word-masking': 512,\n",
       " 'bert-large-cased-whole-word-masking': 512,\n",
       " 'bert-large-uncased-whole-word-masking-finetuned-squad': 512,\n",
       " 'bert-large-cased-whole-word-masking-finetuned-squad': 512,\n",
       " 'bert-base-cased-finetuned-mrpc': 512,\n",
       " 'bert-base-german-dbmdz-cased': 512,\n",
       " 'bert-base-german-dbmdz-uncased': 512,\n",
       " 'TurkuNLP/bert-base-finnish-cased-v1': 512,\n",
       " 'TurkuNLP/bert-base-finnish-uncased-v1': 512,\n",
       " 'wietsedv/bert-base-dutch-cased': 512}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.max_model_input_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db3a44be-f250-4727-b2f1-a75d8c7482e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b13fb8a6-446f-4e68-a1d9-7d026df063cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-large-uncased'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT_PATH[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2778ba5-e654-43f2-96b9-d0aa7cf2529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "\n",
    "TOKEN = data.Field(batch_first = True)\n",
    "TOKEN_ID = data.Field(batch_first = True,\n",
    "                     use_vocab = False,\n",
    "                     dtype=torch.int64,\n",
    "                     pad_token = pad_token_idx,\n",
    "                     preprocessing = text_id_preprocessor)\n",
    "LABEL1 = data.Field(batch_first = True,\n",
    "                    unk_token = None,\n",
    "                    preprocessing = tag_preprocessor)\n",
    "MASK_AB = data.Field(batch_first = True,\n",
    "                     use_vocab = False,\n",
    "                     dtype=torch.int64,\n",
    "                     pad_token = pad_token_idx,\n",
    "                     preprocessing = text_id_preprocessor)\n",
    "MASK_P = data.Field(batch_first = True,\n",
    "                     use_vocab = False,\n",
    "                     dtype=torch.int64,\n",
    "                     pad_token = pad_token_idx,\n",
    "                     preprocessing = text_id_preprocessor)\n",
    "FT_TAGS = data.Field(batch_first = True,\n",
    "                     use_vocab = False,\n",
    "                     dtype=torch.int64,\n",
    "                     pad_token = pad_token_idx,\n",
    "                     preprocessing = text_id_preprocessor)\n",
    "SEQ = data.Field(batch_first = True)\n",
    "LABEL2 = data.Field(batch_first = True,\n",
    "                    unk_token = None,\n",
    "                    #pad_token = None,\n",
    "                    preprocessing = tag_preprocessor)\n",
    "\n",
    "fields = ((\"token\", TOKEN),\n",
    "          ('token_id', TOKEN_ID),\n",
    "          ('label1', LABEL1),\n",
    "          ('mask_ab', MASK_AB),\n",
    "          ('mask_p', MASK_P),\n",
    "          ('first_token', FT_TAGS),\n",
    "          ('seq', SEQ),\n",
    "          ('label2', LABEL2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "201d6f0a-9b53-49d1-b8fd-a8f21513de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data.TabularDataset.splits(\n",
    "                                    path = DATA_PATH,\n",
    "                                    train = 'gap_train_bert_2mask.csv',\n",
    "                                    validation = None,\n",
    "                                    test = 'gap_test_bert_2mask.csv',\n",
    "                                    format = 'csv',\n",
    "                                    fields = fields,\n",
    "                                    skip_header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a188fd46-c10e-481b-bba6-29a8fff620ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN.build_vocab(train_data, test_data)\n",
    "LABEL1.build_vocab(train_data, test_data)\n",
    "FT_TAGS.build_vocab(train_data, test_data)\n",
    "SEQ.build_vocab(train_data, test_data)\n",
    "LABEL2.build_vocab(train_data, test_data)\n",
    "\n",
    "# if you want to prepare a big vocabulary that covers words that never appear in your dataset:\n",
    "\n",
    "#word_list = [['<unk>', '<pad>', 'I', 'great', \"it's\", 'like', 'swimming', '.', ',', 'BBBBBBB']]\n",
    "#TOKEN.build_vocab(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4454779e-ee86-4d6e-a264-bcf14b48571f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.legacy.data.dataset.TabularDataset'>\n",
      "<torchtext.legacy.data.dataset.TabularDataset object at 0x0000019E89764790>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09b8cde6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: {'token': ['[CLS]', 'between', 'the', 'years', '1979', '-', '1981', ',', 'river', 'won', 'four', 'local', 'titles', ',', 'and', 'became', 'one', 'of', 'the', 'most', 'expensive', 'teams', 'in', 'the', 'world', ',', 'with', 'a', 'first', 'team', '(', 'alonso', '-', 'lu', '##que', ')', 'playing', 'in', 'league', 'games', 'and', 'an', 'equally', 'prestigious', 'second', 'team', '(', 'carr', '##asco', '-', 'ram', '*', 'n', 'd', '*', 'az', ')', 'used', 'mostly', 'in', 'copa', 'libertadores', 'matches', '.', 'during', 'the', '1981', '`', '`', 'nacional', \"'\", \"'\", 'tournament', '(', 'which', 'river', 'would', 'eventually', 'win', ')', ',', 'alonso', 'often', 'clashed', 'with', 'then', 'coach', 'alfredo', 'di', 'st', '*', 'fan', '##o', '(', 'who', 'seldom', 'selected', 'him', 'for', 'the', 'first', 'team', 'and', 'instead', 'put', 'younger', 'players', 'such', 'as', 'carlos', 'daniel', 'tap', '##ia', 'and', 'jose', 'maria', 'viet', '##a', 'in', 'his', 'position', ')', '.', '[SEP]'], 'token_id': tensor([  101,  2090,  1996,  2086,  3245,  1011,  3261,  1010,  2314,  2180,\n",
      "         2176,  2334,  4486,  1010,  1998,  2150,  2028,  1997,  1996,  2087,\n",
      "         6450,  2780,  1999,  1996,  2088,  1010,  2007,  1037,  2034,  2136,\n",
      "         1006, 17649,  1011, 11320,  4226,  1007,  2652,  1999,  2223,  2399,\n",
      "         1998,  2019,  8053,  8919,  2117,  2136,  1006, 12385, 28187,  1011,\n",
      "         8223,  1008,  1050,  1040,  1008, 17207,  1007,  2109,  3262,  1999,\n",
      "        10613, 27968,  3503,  1012,  2076,  1996,  3261,  1036,  1036, 10718,\n",
      "         1005,  1005,  2977,  1006,  2029,  2314,  2052,  2776,  2663,  1007,\n",
      "         1010, 17649,  2411, 22600,  2007,  2059,  2873, 19423,  4487,  2358,\n",
      "         1008,  5470,  2080,  1006,  2040, 15839,  3479,  2032,  2005,  1996,\n",
      "         2034,  2136,  1998,  2612,  2404,  3920,  2867,  2107,  2004,  5828,\n",
      "         3817, 11112,  2401,  1998,  4560,  3814, 19710,  2050,  1999,  2010,\n",
      "         2597,  1007,  1012,   102]), 'label1': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'mask_ab': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0]), 'mask_p': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0]), 'first_token': tensor([0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 0, 0, 0]), 'seq': ['Between', 'the', 'years', '1979-1981,', 'River', 'won', 'four', 'local', 'titles,', 'and', 'became', 'one', 'of', 'the', 'most', 'expensive', 'teams', 'in', 'the', 'world,', 'with', 'a', 'first', 'team', '(Alonso-', 'Luque)', 'playing', 'in', 'league', 'games', 'and', 'an', 'equally', 'prestigious', 'second', 'team', '(Carrasco-', 'Ram*n', 'D*az)', 'used', 'mostly', 'in', 'Copa', 'Libertadores', 'matches.', 'During', 'the', '1981', \"``Nacional''\", 'tournament', '(which', 'River', 'would', 'eventually', 'win),', 'Alonso', 'often', 'clashed', 'with', 'then', 'coach', 'Alfredo', 'Di', 'St*fano', '(who', 'seldom', 'selected', 'him', 'for', 'the', 'first', 'team', 'and', 'instead', 'put', 'younger', 'players', 'such', 'as', 'Carlos', 'Daniel', 'Tapia', 'and', 'Jose', 'Maria', 'Vieta', 'in', 'his', 'position).'], 'label2': ['1']}\n",
      "Label1 vocab ['<pad>', '0', '1']\n",
      "Label2 vocab ['<pad>', '0', '1']\n"
     ]
    }
   ],
   "source": [
    "print('Example:', vars(test_data.examples[2]))\n",
    "print('Label1 vocab', LABEL1.vocab.itos)\n",
    "print('Label2 vocab', LABEL2.vocab.itos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9491f7ad-bd7e-42c1-954b-7c08e137de3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: {'token': ['[CLS]', 'between', 'the', 'years', '1979', '-', '1981', ',', 'river', 'won', 'four', 'local', 'titles', ',', 'and', 'became', 'one', 'of', 'the', 'most', 'expensive', 'teams', 'in', 'the', 'world', ',', 'with', 'a', 'first', 'team', '(', 'alonso', '-', 'lu', '##que', ')', 'playing', 'in', 'league', 'games', 'and', 'an', 'equally', 'prestigious', 'second', 'team', '(', 'carr', '##asco', '-', 'ram', '*', 'n', 'd', '*', 'az', ')', 'used', 'mostly', 'in', 'copa', 'libertadores', 'matches', '.', 'during', 'the', '1981', '`', '`', 'nacional', \"'\", \"'\", 'tournament', '(', 'which', 'river', 'would', 'eventually', 'win', ')', ',', 'alonso', 'often', 'clashed', 'with', 'then', 'coach', 'alfredo', 'di', 'st', '*', 'fan', '##o', '(', 'who', 'seldom', 'selected', 'him', 'for', 'the', 'first', 'team', 'and', 'instead', 'put', 'younger', 'players', 'such', 'as', 'carlos', 'daniel', 'tap', '##ia', 'and', 'jose', 'maria', 'viet', '##a', 'in', 'his', 'position', ')', '.', '[SEP]'], 'token_id': tensor([  101,  2090,  1996,  2086,  3245,  1011,  3261,  1010,  2314,  2180,\n",
      "         2176,  2334,  4486,  1010,  1998,  2150,  2028,  1997,  1996,  2087,\n",
      "         6450,  2780,  1999,  1996,  2088,  1010,  2007,  1037,  2034,  2136,\n",
      "         1006, 17649,  1011, 11320,  4226,  1007,  2652,  1999,  2223,  2399,\n",
      "         1998,  2019,  8053,  8919,  2117,  2136,  1006, 12385, 28187,  1011,\n",
      "         8223,  1008,  1050,  1040,  1008, 17207,  1007,  2109,  3262,  1999,\n",
      "        10613, 27968,  3503,  1012,  2076,  1996,  3261,  1036,  1036, 10718,\n",
      "         1005,  1005,  2977,  1006,  2029,  2314,  2052,  2776,  2663,  1007,\n",
      "         1010, 17649,  2411, 22600,  2007,  2059,  2873, 19423,  4487,  2358,\n",
      "         1008,  5470,  2080,  1006,  2040, 15839,  3479,  2032,  2005,  1996,\n",
      "         2034,  2136,  1998,  2612,  2404,  3920,  2867,  2107,  2004,  5828,\n",
      "         3817, 11112,  2401,  1998,  4560,  3814, 19710,  2050,  1999,  2010,\n",
      "         2597,  1007,  1012,   102]), 'label1': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'mask_ab': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0]), 'mask_p': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0]), 'first_token': tensor([0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 0, 0, 0]), 'seq': ['Between', 'the', 'years', '1979-1981,', 'River', 'won', 'four', 'local', 'titles,', 'and', 'became', 'one', 'of', 'the', 'most', 'expensive', 'teams', 'in', 'the', 'world,', 'with', 'a', 'first', 'team', '(Alonso-', 'Luque)', 'playing', 'in', 'league', 'games', 'and', 'an', 'equally', 'prestigious', 'second', 'team', '(Carrasco-', 'Ram*n', 'D*az)', 'used', 'mostly', 'in', 'Copa', 'Libertadores', 'matches.', 'During', 'the', '1981', \"``Nacional''\", 'tournament', '(which', 'River', 'would', 'eventually', 'win),', 'Alonso', 'often', 'clashed', 'with', 'then', 'coach', 'Alfredo', 'Di', 'St*fano', '(who', 'seldom', 'selected', 'him', 'for', 'the', 'first', 'team', 'and', 'instead', 'put', 'younger', 'players', 'such', 'as', 'Carlos', 'Daniel', 'Tapia', 'and', 'Jose', 'Maria', 'Vieta', 'in', 'his', 'position).'], 'label2': ['1']}\n"
     ]
    }
   ],
   "source": [
    "print('Example:', vars(test_data.examples[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "601a08eb-25da-4717-8cca-a36accc7ef88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.legacy.data.dataset.TabularDataset"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "770e518b-8b92-4f39-8703-e8eeb68154ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3978"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5d813a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# train_iterator, test_iterator = data.BucketIterator.splits(\n",
    "#     (train_data, test_data), \n",
    "#     batch_size = BATCH_SIZE,\n",
    "#     device = device,\n",
    "#     shuffle = True,\n",
    "#     sort=False)\n",
    "train_iterator = data.BucketIterator(\n",
    "    train_data, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    shuffle = True,\n",
    "    sort=False)\n",
    "test_iterator = data.BucketIterator(\n",
    "    test_data, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    shuffle = False,\n",
    "    sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebd6678c-1ab6-4ff6-98cc-034f1f400fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.config.to_dict()['hidden_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "868bef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTL(nn.Module):\n",
    "    def __init__(self,bert,label1_output_dim,label2_output_dim,dropout,no_head_trans):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        #self.tag_layer1 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        self.cls_layer1 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        #self.tag_layer2 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        self.cls_layer2 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        #self.tag_layer3 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        self.cls_layer3 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        #self.tag_layer4 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        self.cls_layer4 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        \n",
    "        #self.fc_tag = nn.Linear(embedding_dim, label1_output_dim)\n",
    "        self.fc_cls = nn.Linear(embedding_dim, label2_output_dim)\n",
    "        # self.fc_cls = nn.Linear(embedding_dim*2, label2_output_dim)\n",
    "        self.fc_layernorm_cls = nn.LayerNorm(label2_output_dim)\n",
    "        \n",
    "    def forward(self, token_id, mask_ab, mask_p):\n",
    "        #mask_ab [batch size, seq len]\n",
    "        emb_share = self.dropout(self.bert(token_id)[0]) # [batch size, seq len, emb dim]\n",
    "        \n",
    "        \n",
    "        #tag1 = self.dropout(self.tag_layer1(emb_share))  # [batch size, seq len, emb dim]\n",
    "        # cls1_mask_ab = emb_share*mask_ab.unsqueeze(2)  # [batch size, seq len, emb dim]\n",
    "        # cls1_mask_p = emb_share*mask_p.unsqueeze(2)  # [batch size, seq len, emb dim]\n",
    "        # cls1_mask = cls1_mask_ab+cls1_mask_p  # [batch size, seq len, emb dim]\n",
    "        # cls1 = self.dropout(self.cls_layer1(cls1_mask))    # [batch size, seq len, emb dim]\n",
    "        cls1 = self.dropout(self.cls_layer1(emb_share))    # [batch size, seq len, emb dim]\n",
    "        #tag2 = self.dropout(self.tag_layer2(tag1))  # [batch size, seq len, emb dim]\n",
    "        cls2 = self.dropout(self.cls_layer2(cls1))    # [batch size, seq len, emb dim]\n",
    "        #tag3 = self.dropout(self.tag_layer3(tag2))  # [batch size, seq len, emb dim]\n",
    "        cls3 = self.dropout(self.cls_layer3(cls2))    # [batch size, seq len, emb dim]\n",
    "        #tag4 = self.dropout(self.tag_layer4(tag2))  # [batch size, seq len, emb dim]\n",
    "        cls4 = self.dropout(self.cls_layer4(cls3))    # [batch size, seq len, emb dim]\n",
    "        \n",
    "        #tag_pred = self.fc_tag(tag2) # [batch size, seq len, output dim 1]\n",
    "        # get the average for candidate\n",
    "        cls_mask_ab = torch.sum(cls2*mask_ab.unsqueeze(2),1)/torch.sum(mask_ab.unsqueeze(2),1) # [batch size, emb dim]\n",
    "        # cls_mask_ab = torch.sum(cls4*mask_ab.unsqueeze(2),1) # [batch size, emb dim]\n",
    "        # get the average for pronoun\n",
    "        cls_mask_p = torch.sum(cls2*mask_p.unsqueeze(2),1)/torch.sum(mask_p.unsqueeze(2),1) # [batch size, emb dim]\n",
    "        \n",
    "        # element wise product\n",
    "        cls_fusion= cls_mask_ab * cls_mask_p # [batch size, emb dim]\n",
    "        \n",
    "        # # element-wise addition\n",
    "        # cls_fusion= torch.add(cls_mask_ab, cls_mask_p) # [batch size, emb dim]\n",
    "        \n",
    "        # # element-wise square of difference\n",
    "        # cls_fusion= torch.square(torch.sub(cls_mask_ab, cls_mask_p)) # [batch size, emb dim]\n",
    "        \n",
    "        # # concatenation\n",
    "        # cls_fusion= torch.cat((cls_mask_ab,cls_mask_p),dim=1) # [batch size, emb dim*2]\n",
    "                               \n",
    "        cls_pred = self.fc_layernorm_cls(self.fc_cls(cls_fusion)) # [batch size, output dim 2]\n",
    "        \n",
    "        # cls_mask_out = torch.sum(cls4*mask.unsqueeze(2),1) # [batch size, output dim]\n",
    "        # cls_pred = self.fc_layernorm_cls(self.fc_cls(cls_mask_out))\n",
    "        \n",
    "        return  cls_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2f2566a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 368,744,457 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIM_TAGGING = len(LABEL1.vocab)\n",
    "OUTPUT_DIM_CLASSIFICATION = len(LABEL2.vocab)\n",
    "\n",
    "model = MTL(bert,\n",
    "            OUTPUT_DIM_TAGGING, \n",
    "            OUTPUT_DIM_CLASSIFICATION, \n",
    "            DROPOUT,\n",
    "            NO_HEAD_TRANS)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e89581b7-4e6d-4f2c-8afe-b53543b9f54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(OUTPUT_DIM_TAGGING)\n",
    "print(OUTPUT_DIM_CLASSIFICATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cff96df-2b10-45dd-835d-8ab3cbeb316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_params = []\n",
    "other_params = []\n",
    "for name, param in model.named_parameters():\n",
    "  if name.startswith(\"bert\"):\n",
    "    bert_params.append(param)\n",
    "  else:\n",
    "    other_params.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88a34620-9de1-4681-974a-4466b7bdc3b6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66678321-1cb9-4e0c-bb8e-5ac474707dd4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(other_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8323a48a-8550-457e-9add-670b264ecc59",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight\n",
      "bert.embeddings.position_embeddings.weight\n",
      "bert.embeddings.token_type_embeddings.weight\n",
      "bert.embeddings.LayerNorm.weight\n",
      "bert.embeddings.LayerNorm.bias\n",
      "bert.encoder.layer.0.attention.self.query.weight\n",
      "bert.encoder.layer.0.attention.self.query.bias\n",
      "bert.encoder.layer.0.attention.self.key.weight\n",
      "bert.encoder.layer.0.attention.self.key.bias\n",
      "bert.encoder.layer.0.attention.self.value.weight\n",
      "bert.encoder.layer.0.attention.self.value.bias\n",
      "bert.encoder.layer.0.attention.output.dense.weight\n",
      "bert.encoder.layer.0.attention.output.dense.bias\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.0.intermediate.dense.weight\n",
      "bert.encoder.layer.0.intermediate.dense.bias\n",
      "bert.encoder.layer.0.output.dense.weight\n",
      "bert.encoder.layer.0.output.dense.bias\n",
      "bert.encoder.layer.0.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.attention.self.query.weight\n",
      "bert.encoder.layer.1.attention.self.query.bias\n",
      "bert.encoder.layer.1.attention.self.key.weight\n",
      "bert.encoder.layer.1.attention.self.key.bias\n",
      "bert.encoder.layer.1.attention.self.value.weight\n",
      "bert.encoder.layer.1.attention.self.value.bias\n",
      "bert.encoder.layer.1.attention.output.dense.weight\n",
      "bert.encoder.layer.1.attention.output.dense.bias\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.intermediate.dense.weight\n",
      "bert.encoder.layer.1.intermediate.dense.bias\n",
      "bert.encoder.layer.1.output.dense.weight\n",
      "bert.encoder.layer.1.output.dense.bias\n",
      "bert.encoder.layer.1.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.attention.self.query.weight\n",
      "bert.encoder.layer.2.attention.self.query.bias\n",
      "bert.encoder.layer.2.attention.self.key.weight\n",
      "bert.encoder.layer.2.attention.self.key.bias\n",
      "bert.encoder.layer.2.attention.self.value.weight\n",
      "bert.encoder.layer.2.attention.self.value.bias\n",
      "bert.encoder.layer.2.attention.output.dense.weight\n",
      "bert.encoder.layer.2.attention.output.dense.bias\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.intermediate.dense.weight\n",
      "bert.encoder.layer.2.intermediate.dense.bias\n",
      "bert.encoder.layer.2.output.dense.weight\n",
      "bert.encoder.layer.2.output.dense.bias\n",
      "bert.encoder.layer.2.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.attention.self.query.weight\n",
      "bert.encoder.layer.3.attention.self.query.bias\n",
      "bert.encoder.layer.3.attention.self.key.weight\n",
      "bert.encoder.layer.3.attention.self.key.bias\n",
      "bert.encoder.layer.3.attention.self.value.weight\n",
      "bert.encoder.layer.3.attention.self.value.bias\n",
      "bert.encoder.layer.3.attention.output.dense.weight\n",
      "bert.encoder.layer.3.attention.output.dense.bias\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.intermediate.dense.weight\n",
      "bert.encoder.layer.3.intermediate.dense.bias\n",
      "bert.encoder.layer.3.output.dense.weight\n",
      "bert.encoder.layer.3.output.dense.bias\n",
      "bert.encoder.layer.3.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.attention.self.query.weight\n",
      "bert.encoder.layer.4.attention.self.query.bias\n",
      "bert.encoder.layer.4.attention.self.key.weight\n",
      "bert.encoder.layer.4.attention.self.key.bias\n",
      "bert.encoder.layer.4.attention.self.value.weight\n",
      "bert.encoder.layer.4.attention.self.value.bias\n",
      "bert.encoder.layer.4.attention.output.dense.weight\n",
      "bert.encoder.layer.4.attention.output.dense.bias\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.intermediate.dense.weight\n",
      "bert.encoder.layer.4.intermediate.dense.bias\n",
      "bert.encoder.layer.4.output.dense.weight\n",
      "bert.encoder.layer.4.output.dense.bias\n",
      "bert.encoder.layer.4.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.attention.self.query.weight\n",
      "bert.encoder.layer.5.attention.self.query.bias\n",
      "bert.encoder.layer.5.attention.self.key.weight\n",
      "bert.encoder.layer.5.attention.self.key.bias\n",
      "bert.encoder.layer.5.attention.self.value.weight\n",
      "bert.encoder.layer.5.attention.self.value.bias\n",
      "bert.encoder.layer.5.attention.output.dense.weight\n",
      "bert.encoder.layer.5.attention.output.dense.bias\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.intermediate.dense.weight\n",
      "bert.encoder.layer.5.intermediate.dense.bias\n",
      "bert.encoder.layer.5.output.dense.weight\n",
      "bert.encoder.layer.5.output.dense.bias\n",
      "bert.encoder.layer.5.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.attention.self.query.weight\n",
      "bert.encoder.layer.6.attention.self.query.bias\n",
      "bert.encoder.layer.6.attention.self.key.weight\n",
      "bert.encoder.layer.6.attention.self.key.bias\n",
      "bert.encoder.layer.6.attention.self.value.weight\n",
      "bert.encoder.layer.6.attention.self.value.bias\n",
      "bert.encoder.layer.6.attention.output.dense.weight\n",
      "bert.encoder.layer.6.attention.output.dense.bias\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.intermediate.dense.weight\n",
      "bert.encoder.layer.6.intermediate.dense.bias\n",
      "bert.encoder.layer.6.output.dense.weight\n",
      "bert.encoder.layer.6.output.dense.bias\n",
      "bert.encoder.layer.6.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.attention.self.query.weight\n",
      "bert.encoder.layer.7.attention.self.query.bias\n",
      "bert.encoder.layer.7.attention.self.key.weight\n",
      "bert.encoder.layer.7.attention.self.key.bias\n",
      "bert.encoder.layer.7.attention.self.value.weight\n",
      "bert.encoder.layer.7.attention.self.value.bias\n",
      "bert.encoder.layer.7.attention.output.dense.weight\n",
      "bert.encoder.layer.7.attention.output.dense.bias\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.intermediate.dense.weight\n",
      "bert.encoder.layer.7.intermediate.dense.bias\n",
      "bert.encoder.layer.7.output.dense.weight\n",
      "bert.encoder.layer.7.output.dense.bias\n",
      "bert.encoder.layer.7.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.attention.self.query.weight\n",
      "bert.encoder.layer.8.attention.self.query.bias\n",
      "bert.encoder.layer.8.attention.self.key.weight\n",
      "bert.encoder.layer.8.attention.self.key.bias\n",
      "bert.encoder.layer.8.attention.self.value.weight\n",
      "bert.encoder.layer.8.attention.self.value.bias\n",
      "bert.encoder.layer.8.attention.output.dense.weight\n",
      "bert.encoder.layer.8.attention.output.dense.bias\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.intermediate.dense.weight\n",
      "bert.encoder.layer.8.intermediate.dense.bias\n",
      "bert.encoder.layer.8.output.dense.weight\n",
      "bert.encoder.layer.8.output.dense.bias\n",
      "bert.encoder.layer.8.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.attention.self.query.weight\n",
      "bert.encoder.layer.9.attention.self.query.bias\n",
      "bert.encoder.layer.9.attention.self.key.weight\n",
      "bert.encoder.layer.9.attention.self.key.bias\n",
      "bert.encoder.layer.9.attention.self.value.weight\n",
      "bert.encoder.layer.9.attention.self.value.bias\n",
      "bert.encoder.layer.9.attention.output.dense.weight\n",
      "bert.encoder.layer.9.attention.output.dense.bias\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.intermediate.dense.weight\n",
      "bert.encoder.layer.9.intermediate.dense.bias\n",
      "bert.encoder.layer.9.output.dense.weight\n",
      "bert.encoder.layer.9.output.dense.bias\n",
      "bert.encoder.layer.9.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.attention.self.query.weight\n",
      "bert.encoder.layer.10.attention.self.query.bias\n",
      "bert.encoder.layer.10.attention.self.key.weight\n",
      "bert.encoder.layer.10.attention.self.key.bias\n",
      "bert.encoder.layer.10.attention.self.value.weight\n",
      "bert.encoder.layer.10.attention.self.value.bias\n",
      "bert.encoder.layer.10.attention.output.dense.weight\n",
      "bert.encoder.layer.10.attention.output.dense.bias\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.intermediate.dense.weight\n",
      "bert.encoder.layer.10.intermediate.dense.bias\n",
      "bert.encoder.layer.10.output.dense.weight\n",
      "bert.encoder.layer.10.output.dense.bias\n",
      "bert.encoder.layer.10.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.attention.self.query.weight\n",
      "bert.encoder.layer.11.attention.self.query.bias\n",
      "bert.encoder.layer.11.attention.self.key.weight\n",
      "bert.encoder.layer.11.attention.self.key.bias\n",
      "bert.encoder.layer.11.attention.self.value.weight\n",
      "bert.encoder.layer.11.attention.self.value.bias\n",
      "bert.encoder.layer.11.attention.output.dense.weight\n",
      "bert.encoder.layer.11.attention.output.dense.bias\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.intermediate.dense.weight\n",
      "bert.encoder.layer.11.intermediate.dense.bias\n",
      "bert.encoder.layer.11.output.dense.weight\n",
      "bert.encoder.layer.11.output.dense.bias\n",
      "bert.encoder.layer.11.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.output.LayerNorm.bias\n",
      "bert.encoder.layer.12.attention.self.query.weight\n",
      "bert.encoder.layer.12.attention.self.query.bias\n",
      "bert.encoder.layer.12.attention.self.key.weight\n",
      "bert.encoder.layer.12.attention.self.key.bias\n",
      "bert.encoder.layer.12.attention.self.value.weight\n",
      "bert.encoder.layer.12.attention.self.value.bias\n",
      "bert.encoder.layer.12.attention.output.dense.weight\n",
      "bert.encoder.layer.12.attention.output.dense.bias\n",
      "bert.encoder.layer.12.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.12.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.12.intermediate.dense.weight\n",
      "bert.encoder.layer.12.intermediate.dense.bias\n",
      "bert.encoder.layer.12.output.dense.weight\n",
      "bert.encoder.layer.12.output.dense.bias\n",
      "bert.encoder.layer.12.output.LayerNorm.weight\n",
      "bert.encoder.layer.12.output.LayerNorm.bias\n",
      "bert.encoder.layer.13.attention.self.query.weight\n",
      "bert.encoder.layer.13.attention.self.query.bias\n",
      "bert.encoder.layer.13.attention.self.key.weight\n",
      "bert.encoder.layer.13.attention.self.key.bias\n",
      "bert.encoder.layer.13.attention.self.value.weight\n",
      "bert.encoder.layer.13.attention.self.value.bias\n",
      "bert.encoder.layer.13.attention.output.dense.weight\n",
      "bert.encoder.layer.13.attention.output.dense.bias\n",
      "bert.encoder.layer.13.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.13.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.13.intermediate.dense.weight\n",
      "bert.encoder.layer.13.intermediate.dense.bias\n",
      "bert.encoder.layer.13.output.dense.weight\n",
      "bert.encoder.layer.13.output.dense.bias\n",
      "bert.encoder.layer.13.output.LayerNorm.weight\n",
      "bert.encoder.layer.13.output.LayerNorm.bias\n",
      "bert.encoder.layer.14.attention.self.query.weight\n",
      "bert.encoder.layer.14.attention.self.query.bias\n",
      "bert.encoder.layer.14.attention.self.key.weight\n",
      "bert.encoder.layer.14.attention.self.key.bias\n",
      "bert.encoder.layer.14.attention.self.value.weight\n",
      "bert.encoder.layer.14.attention.self.value.bias\n",
      "bert.encoder.layer.14.attention.output.dense.weight\n",
      "bert.encoder.layer.14.attention.output.dense.bias\n",
      "bert.encoder.layer.14.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.14.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.14.intermediate.dense.weight\n",
      "bert.encoder.layer.14.intermediate.dense.bias\n",
      "bert.encoder.layer.14.output.dense.weight\n",
      "bert.encoder.layer.14.output.dense.bias\n",
      "bert.encoder.layer.14.output.LayerNorm.weight\n",
      "bert.encoder.layer.14.output.LayerNorm.bias\n",
      "bert.encoder.layer.15.attention.self.query.weight\n",
      "bert.encoder.layer.15.attention.self.query.bias\n",
      "bert.encoder.layer.15.attention.self.key.weight\n",
      "bert.encoder.layer.15.attention.self.key.bias\n",
      "bert.encoder.layer.15.attention.self.value.weight\n",
      "bert.encoder.layer.15.attention.self.value.bias\n",
      "bert.encoder.layer.15.attention.output.dense.weight\n",
      "bert.encoder.layer.15.attention.output.dense.bias\n",
      "bert.encoder.layer.15.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.15.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.15.intermediate.dense.weight\n",
      "bert.encoder.layer.15.intermediate.dense.bias\n",
      "bert.encoder.layer.15.output.dense.weight\n",
      "bert.encoder.layer.15.output.dense.bias\n",
      "bert.encoder.layer.15.output.LayerNorm.weight\n",
      "bert.encoder.layer.15.output.LayerNorm.bias\n",
      "bert.encoder.layer.16.attention.self.query.weight\n",
      "bert.encoder.layer.16.attention.self.query.bias\n",
      "bert.encoder.layer.16.attention.self.key.weight\n",
      "bert.encoder.layer.16.attention.self.key.bias\n",
      "bert.encoder.layer.16.attention.self.value.weight\n",
      "bert.encoder.layer.16.attention.self.value.bias\n",
      "bert.encoder.layer.16.attention.output.dense.weight\n",
      "bert.encoder.layer.16.attention.output.dense.bias\n",
      "bert.encoder.layer.16.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.16.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.16.intermediate.dense.weight\n",
      "bert.encoder.layer.16.intermediate.dense.bias\n",
      "bert.encoder.layer.16.output.dense.weight\n",
      "bert.encoder.layer.16.output.dense.bias\n",
      "bert.encoder.layer.16.output.LayerNorm.weight\n",
      "bert.encoder.layer.16.output.LayerNorm.bias\n",
      "bert.encoder.layer.17.attention.self.query.weight\n",
      "bert.encoder.layer.17.attention.self.query.bias\n",
      "bert.encoder.layer.17.attention.self.key.weight\n",
      "bert.encoder.layer.17.attention.self.key.bias\n",
      "bert.encoder.layer.17.attention.self.value.weight\n",
      "bert.encoder.layer.17.attention.self.value.bias\n",
      "bert.encoder.layer.17.attention.output.dense.weight\n",
      "bert.encoder.layer.17.attention.output.dense.bias\n",
      "bert.encoder.layer.17.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.17.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.17.intermediate.dense.weight\n",
      "bert.encoder.layer.17.intermediate.dense.bias\n",
      "bert.encoder.layer.17.output.dense.weight\n",
      "bert.encoder.layer.17.output.dense.bias\n",
      "bert.encoder.layer.17.output.LayerNorm.weight\n",
      "bert.encoder.layer.17.output.LayerNorm.bias\n",
      "bert.encoder.layer.18.attention.self.query.weight\n",
      "bert.encoder.layer.18.attention.self.query.bias\n",
      "bert.encoder.layer.18.attention.self.key.weight\n",
      "bert.encoder.layer.18.attention.self.key.bias\n",
      "bert.encoder.layer.18.attention.self.value.weight\n",
      "bert.encoder.layer.18.attention.self.value.bias\n",
      "bert.encoder.layer.18.attention.output.dense.weight\n",
      "bert.encoder.layer.18.attention.output.dense.bias\n",
      "bert.encoder.layer.18.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.18.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.18.intermediate.dense.weight\n",
      "bert.encoder.layer.18.intermediate.dense.bias\n",
      "bert.encoder.layer.18.output.dense.weight\n",
      "bert.encoder.layer.18.output.dense.bias\n",
      "bert.encoder.layer.18.output.LayerNorm.weight\n",
      "bert.encoder.layer.18.output.LayerNorm.bias\n",
      "bert.encoder.layer.19.attention.self.query.weight\n",
      "bert.encoder.layer.19.attention.self.query.bias\n",
      "bert.encoder.layer.19.attention.self.key.weight\n",
      "bert.encoder.layer.19.attention.self.key.bias\n",
      "bert.encoder.layer.19.attention.self.value.weight\n",
      "bert.encoder.layer.19.attention.self.value.bias\n",
      "bert.encoder.layer.19.attention.output.dense.weight\n",
      "bert.encoder.layer.19.attention.output.dense.bias\n",
      "bert.encoder.layer.19.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.19.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.19.intermediate.dense.weight\n",
      "bert.encoder.layer.19.intermediate.dense.bias\n",
      "bert.encoder.layer.19.output.dense.weight\n",
      "bert.encoder.layer.19.output.dense.bias\n",
      "bert.encoder.layer.19.output.LayerNorm.weight\n",
      "bert.encoder.layer.19.output.LayerNorm.bias\n",
      "bert.encoder.layer.20.attention.self.query.weight\n",
      "bert.encoder.layer.20.attention.self.query.bias\n",
      "bert.encoder.layer.20.attention.self.key.weight\n",
      "bert.encoder.layer.20.attention.self.key.bias\n",
      "bert.encoder.layer.20.attention.self.value.weight\n",
      "bert.encoder.layer.20.attention.self.value.bias\n",
      "bert.encoder.layer.20.attention.output.dense.weight\n",
      "bert.encoder.layer.20.attention.output.dense.bias\n",
      "bert.encoder.layer.20.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.20.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.20.intermediate.dense.weight\n",
      "bert.encoder.layer.20.intermediate.dense.bias\n",
      "bert.encoder.layer.20.output.dense.weight\n",
      "bert.encoder.layer.20.output.dense.bias\n",
      "bert.encoder.layer.20.output.LayerNorm.weight\n",
      "bert.encoder.layer.20.output.LayerNorm.bias\n",
      "bert.encoder.layer.21.attention.self.query.weight\n",
      "bert.encoder.layer.21.attention.self.query.bias\n",
      "bert.encoder.layer.21.attention.self.key.weight\n",
      "bert.encoder.layer.21.attention.self.key.bias\n",
      "bert.encoder.layer.21.attention.self.value.weight\n",
      "bert.encoder.layer.21.attention.self.value.bias\n",
      "bert.encoder.layer.21.attention.output.dense.weight\n",
      "bert.encoder.layer.21.attention.output.dense.bias\n",
      "bert.encoder.layer.21.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.21.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.21.intermediate.dense.weight\n",
      "bert.encoder.layer.21.intermediate.dense.bias\n",
      "bert.encoder.layer.21.output.dense.weight\n",
      "bert.encoder.layer.21.output.dense.bias\n",
      "bert.encoder.layer.21.output.LayerNorm.weight\n",
      "bert.encoder.layer.21.output.LayerNorm.bias\n",
      "bert.encoder.layer.22.attention.self.query.weight\n",
      "bert.encoder.layer.22.attention.self.query.bias\n",
      "bert.encoder.layer.22.attention.self.key.weight\n",
      "bert.encoder.layer.22.attention.self.key.bias\n",
      "bert.encoder.layer.22.attention.self.value.weight\n",
      "bert.encoder.layer.22.attention.self.value.bias\n",
      "bert.encoder.layer.22.attention.output.dense.weight\n",
      "bert.encoder.layer.22.attention.output.dense.bias\n",
      "bert.encoder.layer.22.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.22.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.22.intermediate.dense.weight\n",
      "bert.encoder.layer.22.intermediate.dense.bias\n",
      "bert.encoder.layer.22.output.dense.weight\n",
      "bert.encoder.layer.22.output.dense.bias\n",
      "bert.encoder.layer.22.output.LayerNorm.weight\n",
      "bert.encoder.layer.22.output.LayerNorm.bias\n",
      "bert.encoder.layer.23.attention.self.query.weight\n",
      "bert.encoder.layer.23.attention.self.query.bias\n",
      "bert.encoder.layer.23.attention.self.key.weight\n",
      "bert.encoder.layer.23.attention.self.key.bias\n",
      "bert.encoder.layer.23.attention.self.value.weight\n",
      "bert.encoder.layer.23.attention.self.value.bias\n",
      "bert.encoder.layer.23.attention.output.dense.weight\n",
      "bert.encoder.layer.23.attention.output.dense.bias\n",
      "bert.encoder.layer.23.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.23.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.23.intermediate.dense.weight\n",
      "bert.encoder.layer.23.intermediate.dense.bias\n",
      "bert.encoder.layer.23.output.dense.weight\n",
      "bert.encoder.layer.23.output.dense.bias\n",
      "bert.encoder.layer.23.output.LayerNorm.weight\n",
      "bert.encoder.layer.23.output.LayerNorm.bias\n",
      "bert.pooler.dense.weight\n",
      "bert.pooler.dense.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if param.requires_grad:\n",
    "        if name.startswith(\"bert\"):\n",
    "            print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa8face5-f407-4596-bba9-13b73adec0ec",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_layer1.self_attn.in_proj_weight\n",
      "cls_layer1.self_attn.in_proj_bias\n",
      "cls_layer1.self_attn.out_proj.weight\n",
      "cls_layer1.self_attn.out_proj.bias\n",
      "cls_layer1.linear1.weight\n",
      "cls_layer1.linear1.bias\n",
      "cls_layer1.linear2.weight\n",
      "cls_layer1.linear2.bias\n",
      "cls_layer1.norm1.weight\n",
      "cls_layer1.norm1.bias\n",
      "cls_layer1.norm2.weight\n",
      "cls_layer1.norm2.bias\n",
      "cls_layer2.self_attn.in_proj_weight\n",
      "cls_layer2.self_attn.in_proj_bias\n",
      "cls_layer2.self_attn.out_proj.weight\n",
      "cls_layer2.self_attn.out_proj.bias\n",
      "cls_layer2.linear1.weight\n",
      "cls_layer2.linear1.bias\n",
      "cls_layer2.linear2.weight\n",
      "cls_layer2.linear2.bias\n",
      "cls_layer2.norm1.weight\n",
      "cls_layer2.norm1.bias\n",
      "cls_layer2.norm2.weight\n",
      "cls_layer2.norm2.bias\n",
      "cls_layer3.self_attn.in_proj_weight\n",
      "cls_layer3.self_attn.in_proj_bias\n",
      "cls_layer3.self_attn.out_proj.weight\n",
      "cls_layer3.self_attn.out_proj.bias\n",
      "cls_layer3.linear1.weight\n",
      "cls_layer3.linear1.bias\n",
      "cls_layer3.linear2.weight\n",
      "cls_layer3.linear2.bias\n",
      "cls_layer3.norm1.weight\n",
      "cls_layer3.norm1.bias\n",
      "cls_layer3.norm2.weight\n",
      "cls_layer3.norm2.bias\n",
      "cls_layer4.self_attn.in_proj_weight\n",
      "cls_layer4.self_attn.in_proj_bias\n",
      "cls_layer4.self_attn.out_proj.weight\n",
      "cls_layer4.self_attn.out_proj.bias\n",
      "cls_layer4.linear1.weight\n",
      "cls_layer4.linear1.bias\n",
      "cls_layer4.linear2.weight\n",
      "cls_layer4.linear2.bias\n",
      "cls_layer4.norm1.weight\n",
      "cls_layer4.norm1.bias\n",
      "cls_layer4.norm2.weight\n",
      "cls_layer4.norm2.bias\n",
      "fc_cls.weight\n",
      "fc_cls.bias\n",
      "fc_layernorm_cls.weight\n",
      "fc_layernorm_cls.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if param.requires_grad:\n",
    "        if not name.startswith(\"bert\"):\n",
    "            print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a75a5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606645\n",
      "12.0\n"
     ]
    }
   ],
   "source": [
    "from transformers.optimization import (\n",
    "    get_linear_schedule_with_warmup, get_constant_schedule, get_constant_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup,\n",
    "get_cosine_schedule_with_warmup)\n",
    "\n",
    "TAG_PAD_IDX = LABEL1.vocab.stoi[LABEL1.pad_token]\n",
    "\n",
    "criterion_tag = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
    "criterion_cls = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
    "\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "criterion_tag = criterion_tag.to(device)\n",
    "criterion_cls = criterion_cls.to(device)\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    [\n",
    "        {\"params\": bert_params, \"lr\": 0.5*LEARNING_RATE},\n",
    "        {\"params\": other_params}\n",
    "    ],\n",
    "    lr=LEARNING_RATE,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "num_train_steps = int(\n",
    "            len(train_data) / BATCH_SIZE  * N_EPOCHS)\n",
    "\n",
    "print(num_train_steps)\n",
    "num_cycles=(N_EPOCHS-10)/50\n",
    "print(num_cycles)\n",
    "\n",
    "# scheduler = get_constant_schedule_with_warmup(\n",
    "#                 optimizer,\n",
    "#                 num_warmup_steps = 15)\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "#                 optimizer,\n",
    "#                 num_warmup_steps = 15,\n",
    "#                 num_training_steps = num_train_steps*2)\n",
    "\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "#                 optimizer,\n",
    "#                 num_warmup_steps = num_train_steps*0.1,\n",
    "#                 num_training_steps = num_train_steps*2)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer,\n",
    "                num_warmup_steps = 10,\n",
    "                num_training_steps = num_train_steps,\n",
    "                num_cycles = num_cycles)\n",
    "\n",
    "# scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(\n",
    "#                 optimizer,\n",
    "#                 num_warmup_steps = num_train_steps*0.2,\n",
    "#                 num_training_steps = num_train_steps,\n",
    "#                 num_cycles = 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f916de3-69e4-499f-af5d-32cb19956d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.bert.named_parameters():                \n",
    "#     if name.startswith('embeddings'):\n",
    "#         param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdfb3735-b997-4630-a493-8880fa71ea15",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight\n",
      "bert.embeddings.position_embeddings.weight\n",
      "bert.embeddings.token_type_embeddings.weight\n",
      "bert.embeddings.LayerNorm.weight\n",
      "bert.embeddings.LayerNorm.bias\n",
      "bert.encoder.layer.0.attention.self.query.weight\n",
      "bert.encoder.layer.0.attention.self.query.bias\n",
      "bert.encoder.layer.0.attention.self.key.weight\n",
      "bert.encoder.layer.0.attention.self.key.bias\n",
      "bert.encoder.layer.0.attention.self.value.weight\n",
      "bert.encoder.layer.0.attention.self.value.bias\n",
      "bert.encoder.layer.0.attention.output.dense.weight\n",
      "bert.encoder.layer.0.attention.output.dense.bias\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.0.intermediate.dense.weight\n",
      "bert.encoder.layer.0.intermediate.dense.bias\n",
      "bert.encoder.layer.0.output.dense.weight\n",
      "bert.encoder.layer.0.output.dense.bias\n",
      "bert.encoder.layer.0.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.attention.self.query.weight\n",
      "bert.encoder.layer.1.attention.self.query.bias\n",
      "bert.encoder.layer.1.attention.self.key.weight\n",
      "bert.encoder.layer.1.attention.self.key.bias\n",
      "bert.encoder.layer.1.attention.self.value.weight\n",
      "bert.encoder.layer.1.attention.self.value.bias\n",
      "bert.encoder.layer.1.attention.output.dense.weight\n",
      "bert.encoder.layer.1.attention.output.dense.bias\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.intermediate.dense.weight\n",
      "bert.encoder.layer.1.intermediate.dense.bias\n",
      "bert.encoder.layer.1.output.dense.weight\n",
      "bert.encoder.layer.1.output.dense.bias\n",
      "bert.encoder.layer.1.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.attention.self.query.weight\n",
      "bert.encoder.layer.2.attention.self.query.bias\n",
      "bert.encoder.layer.2.attention.self.key.weight\n",
      "bert.encoder.layer.2.attention.self.key.bias\n",
      "bert.encoder.layer.2.attention.self.value.weight\n",
      "bert.encoder.layer.2.attention.self.value.bias\n",
      "bert.encoder.layer.2.attention.output.dense.weight\n",
      "bert.encoder.layer.2.attention.output.dense.bias\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.intermediate.dense.weight\n",
      "bert.encoder.layer.2.intermediate.dense.bias\n",
      "bert.encoder.layer.2.output.dense.weight\n",
      "bert.encoder.layer.2.output.dense.bias\n",
      "bert.encoder.layer.2.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.attention.self.query.weight\n",
      "bert.encoder.layer.3.attention.self.query.bias\n",
      "bert.encoder.layer.3.attention.self.key.weight\n",
      "bert.encoder.layer.3.attention.self.key.bias\n",
      "bert.encoder.layer.3.attention.self.value.weight\n",
      "bert.encoder.layer.3.attention.self.value.bias\n",
      "bert.encoder.layer.3.attention.output.dense.weight\n",
      "bert.encoder.layer.3.attention.output.dense.bias\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.intermediate.dense.weight\n",
      "bert.encoder.layer.3.intermediate.dense.bias\n",
      "bert.encoder.layer.3.output.dense.weight\n",
      "bert.encoder.layer.3.output.dense.bias\n",
      "bert.encoder.layer.3.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.attention.self.query.weight\n",
      "bert.encoder.layer.4.attention.self.query.bias\n",
      "bert.encoder.layer.4.attention.self.key.weight\n",
      "bert.encoder.layer.4.attention.self.key.bias\n",
      "bert.encoder.layer.4.attention.self.value.weight\n",
      "bert.encoder.layer.4.attention.self.value.bias\n",
      "bert.encoder.layer.4.attention.output.dense.weight\n",
      "bert.encoder.layer.4.attention.output.dense.bias\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.intermediate.dense.weight\n",
      "bert.encoder.layer.4.intermediate.dense.bias\n",
      "bert.encoder.layer.4.output.dense.weight\n",
      "bert.encoder.layer.4.output.dense.bias\n",
      "bert.encoder.layer.4.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.attention.self.query.weight\n",
      "bert.encoder.layer.5.attention.self.query.bias\n",
      "bert.encoder.layer.5.attention.self.key.weight\n",
      "bert.encoder.layer.5.attention.self.key.bias\n",
      "bert.encoder.layer.5.attention.self.value.weight\n",
      "bert.encoder.layer.5.attention.self.value.bias\n",
      "bert.encoder.layer.5.attention.output.dense.weight\n",
      "bert.encoder.layer.5.attention.output.dense.bias\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.intermediate.dense.weight\n",
      "bert.encoder.layer.5.intermediate.dense.bias\n",
      "bert.encoder.layer.5.output.dense.weight\n",
      "bert.encoder.layer.5.output.dense.bias\n",
      "bert.encoder.layer.5.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.attention.self.query.weight\n",
      "bert.encoder.layer.6.attention.self.query.bias\n",
      "bert.encoder.layer.6.attention.self.key.weight\n",
      "bert.encoder.layer.6.attention.self.key.bias\n",
      "bert.encoder.layer.6.attention.self.value.weight\n",
      "bert.encoder.layer.6.attention.self.value.bias\n",
      "bert.encoder.layer.6.attention.output.dense.weight\n",
      "bert.encoder.layer.6.attention.output.dense.bias\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.intermediate.dense.weight\n",
      "bert.encoder.layer.6.intermediate.dense.bias\n",
      "bert.encoder.layer.6.output.dense.weight\n",
      "bert.encoder.layer.6.output.dense.bias\n",
      "bert.encoder.layer.6.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.attention.self.query.weight\n",
      "bert.encoder.layer.7.attention.self.query.bias\n",
      "bert.encoder.layer.7.attention.self.key.weight\n",
      "bert.encoder.layer.7.attention.self.key.bias\n",
      "bert.encoder.layer.7.attention.self.value.weight\n",
      "bert.encoder.layer.7.attention.self.value.bias\n",
      "bert.encoder.layer.7.attention.output.dense.weight\n",
      "bert.encoder.layer.7.attention.output.dense.bias\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.intermediate.dense.weight\n",
      "bert.encoder.layer.7.intermediate.dense.bias\n",
      "bert.encoder.layer.7.output.dense.weight\n",
      "bert.encoder.layer.7.output.dense.bias\n",
      "bert.encoder.layer.7.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.attention.self.query.weight\n",
      "bert.encoder.layer.8.attention.self.query.bias\n",
      "bert.encoder.layer.8.attention.self.key.weight\n",
      "bert.encoder.layer.8.attention.self.key.bias\n",
      "bert.encoder.layer.8.attention.self.value.weight\n",
      "bert.encoder.layer.8.attention.self.value.bias\n",
      "bert.encoder.layer.8.attention.output.dense.weight\n",
      "bert.encoder.layer.8.attention.output.dense.bias\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.intermediate.dense.weight\n",
      "bert.encoder.layer.8.intermediate.dense.bias\n",
      "bert.encoder.layer.8.output.dense.weight\n",
      "bert.encoder.layer.8.output.dense.bias\n",
      "bert.encoder.layer.8.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.attention.self.query.weight\n",
      "bert.encoder.layer.9.attention.self.query.bias\n",
      "bert.encoder.layer.9.attention.self.key.weight\n",
      "bert.encoder.layer.9.attention.self.key.bias\n",
      "bert.encoder.layer.9.attention.self.value.weight\n",
      "bert.encoder.layer.9.attention.self.value.bias\n",
      "bert.encoder.layer.9.attention.output.dense.weight\n",
      "bert.encoder.layer.9.attention.output.dense.bias\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.intermediate.dense.weight\n",
      "bert.encoder.layer.9.intermediate.dense.bias\n",
      "bert.encoder.layer.9.output.dense.weight\n",
      "bert.encoder.layer.9.output.dense.bias\n",
      "bert.encoder.layer.9.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.attention.self.query.weight\n",
      "bert.encoder.layer.10.attention.self.query.bias\n",
      "bert.encoder.layer.10.attention.self.key.weight\n",
      "bert.encoder.layer.10.attention.self.key.bias\n",
      "bert.encoder.layer.10.attention.self.value.weight\n",
      "bert.encoder.layer.10.attention.self.value.bias\n",
      "bert.encoder.layer.10.attention.output.dense.weight\n",
      "bert.encoder.layer.10.attention.output.dense.bias\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.intermediate.dense.weight\n",
      "bert.encoder.layer.10.intermediate.dense.bias\n",
      "bert.encoder.layer.10.output.dense.weight\n",
      "bert.encoder.layer.10.output.dense.bias\n",
      "bert.encoder.layer.10.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.attention.self.query.weight\n",
      "bert.encoder.layer.11.attention.self.query.bias\n",
      "bert.encoder.layer.11.attention.self.key.weight\n",
      "bert.encoder.layer.11.attention.self.key.bias\n",
      "bert.encoder.layer.11.attention.self.value.weight\n",
      "bert.encoder.layer.11.attention.self.value.bias\n",
      "bert.encoder.layer.11.attention.output.dense.weight\n",
      "bert.encoder.layer.11.attention.output.dense.bias\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.intermediate.dense.weight\n",
      "bert.encoder.layer.11.intermediate.dense.bias\n",
      "bert.encoder.layer.11.output.dense.weight\n",
      "bert.encoder.layer.11.output.dense.bias\n",
      "bert.encoder.layer.11.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.output.LayerNorm.bias\n",
      "bert.encoder.layer.12.attention.self.query.weight\n",
      "bert.encoder.layer.12.attention.self.query.bias\n",
      "bert.encoder.layer.12.attention.self.key.weight\n",
      "bert.encoder.layer.12.attention.self.key.bias\n",
      "bert.encoder.layer.12.attention.self.value.weight\n",
      "bert.encoder.layer.12.attention.self.value.bias\n",
      "bert.encoder.layer.12.attention.output.dense.weight\n",
      "bert.encoder.layer.12.attention.output.dense.bias\n",
      "bert.encoder.layer.12.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.12.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.12.intermediate.dense.weight\n",
      "bert.encoder.layer.12.intermediate.dense.bias\n",
      "bert.encoder.layer.12.output.dense.weight\n",
      "bert.encoder.layer.12.output.dense.bias\n",
      "bert.encoder.layer.12.output.LayerNorm.weight\n",
      "bert.encoder.layer.12.output.LayerNorm.bias\n",
      "bert.encoder.layer.13.attention.self.query.weight\n",
      "bert.encoder.layer.13.attention.self.query.bias\n",
      "bert.encoder.layer.13.attention.self.key.weight\n",
      "bert.encoder.layer.13.attention.self.key.bias\n",
      "bert.encoder.layer.13.attention.self.value.weight\n",
      "bert.encoder.layer.13.attention.self.value.bias\n",
      "bert.encoder.layer.13.attention.output.dense.weight\n",
      "bert.encoder.layer.13.attention.output.dense.bias\n",
      "bert.encoder.layer.13.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.13.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.13.intermediate.dense.weight\n",
      "bert.encoder.layer.13.intermediate.dense.bias\n",
      "bert.encoder.layer.13.output.dense.weight\n",
      "bert.encoder.layer.13.output.dense.bias\n",
      "bert.encoder.layer.13.output.LayerNorm.weight\n",
      "bert.encoder.layer.13.output.LayerNorm.bias\n",
      "bert.encoder.layer.14.attention.self.query.weight\n",
      "bert.encoder.layer.14.attention.self.query.bias\n",
      "bert.encoder.layer.14.attention.self.key.weight\n",
      "bert.encoder.layer.14.attention.self.key.bias\n",
      "bert.encoder.layer.14.attention.self.value.weight\n",
      "bert.encoder.layer.14.attention.self.value.bias\n",
      "bert.encoder.layer.14.attention.output.dense.weight\n",
      "bert.encoder.layer.14.attention.output.dense.bias\n",
      "bert.encoder.layer.14.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.14.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.14.intermediate.dense.weight\n",
      "bert.encoder.layer.14.intermediate.dense.bias\n",
      "bert.encoder.layer.14.output.dense.weight\n",
      "bert.encoder.layer.14.output.dense.bias\n",
      "bert.encoder.layer.14.output.LayerNorm.weight\n",
      "bert.encoder.layer.14.output.LayerNorm.bias\n",
      "bert.encoder.layer.15.attention.self.query.weight\n",
      "bert.encoder.layer.15.attention.self.query.bias\n",
      "bert.encoder.layer.15.attention.self.key.weight\n",
      "bert.encoder.layer.15.attention.self.key.bias\n",
      "bert.encoder.layer.15.attention.self.value.weight\n",
      "bert.encoder.layer.15.attention.self.value.bias\n",
      "bert.encoder.layer.15.attention.output.dense.weight\n",
      "bert.encoder.layer.15.attention.output.dense.bias\n",
      "bert.encoder.layer.15.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.15.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.15.intermediate.dense.weight\n",
      "bert.encoder.layer.15.intermediate.dense.bias\n",
      "bert.encoder.layer.15.output.dense.weight\n",
      "bert.encoder.layer.15.output.dense.bias\n",
      "bert.encoder.layer.15.output.LayerNorm.weight\n",
      "bert.encoder.layer.15.output.LayerNorm.bias\n",
      "bert.encoder.layer.16.attention.self.query.weight\n",
      "bert.encoder.layer.16.attention.self.query.bias\n",
      "bert.encoder.layer.16.attention.self.key.weight\n",
      "bert.encoder.layer.16.attention.self.key.bias\n",
      "bert.encoder.layer.16.attention.self.value.weight\n",
      "bert.encoder.layer.16.attention.self.value.bias\n",
      "bert.encoder.layer.16.attention.output.dense.weight\n",
      "bert.encoder.layer.16.attention.output.dense.bias\n",
      "bert.encoder.layer.16.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.16.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.16.intermediate.dense.weight\n",
      "bert.encoder.layer.16.intermediate.dense.bias\n",
      "bert.encoder.layer.16.output.dense.weight\n",
      "bert.encoder.layer.16.output.dense.bias\n",
      "bert.encoder.layer.16.output.LayerNorm.weight\n",
      "bert.encoder.layer.16.output.LayerNorm.bias\n",
      "bert.encoder.layer.17.attention.self.query.weight\n",
      "bert.encoder.layer.17.attention.self.query.bias\n",
      "bert.encoder.layer.17.attention.self.key.weight\n",
      "bert.encoder.layer.17.attention.self.key.bias\n",
      "bert.encoder.layer.17.attention.self.value.weight\n",
      "bert.encoder.layer.17.attention.self.value.bias\n",
      "bert.encoder.layer.17.attention.output.dense.weight\n",
      "bert.encoder.layer.17.attention.output.dense.bias\n",
      "bert.encoder.layer.17.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.17.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.17.intermediate.dense.weight\n",
      "bert.encoder.layer.17.intermediate.dense.bias\n",
      "bert.encoder.layer.17.output.dense.weight\n",
      "bert.encoder.layer.17.output.dense.bias\n",
      "bert.encoder.layer.17.output.LayerNorm.weight\n",
      "bert.encoder.layer.17.output.LayerNorm.bias\n",
      "bert.encoder.layer.18.attention.self.query.weight\n",
      "bert.encoder.layer.18.attention.self.query.bias\n",
      "bert.encoder.layer.18.attention.self.key.weight\n",
      "bert.encoder.layer.18.attention.self.key.bias\n",
      "bert.encoder.layer.18.attention.self.value.weight\n",
      "bert.encoder.layer.18.attention.self.value.bias\n",
      "bert.encoder.layer.18.attention.output.dense.weight\n",
      "bert.encoder.layer.18.attention.output.dense.bias\n",
      "bert.encoder.layer.18.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.18.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.18.intermediate.dense.weight\n",
      "bert.encoder.layer.18.intermediate.dense.bias\n",
      "bert.encoder.layer.18.output.dense.weight\n",
      "bert.encoder.layer.18.output.dense.bias\n",
      "bert.encoder.layer.18.output.LayerNorm.weight\n",
      "bert.encoder.layer.18.output.LayerNorm.bias\n",
      "bert.encoder.layer.19.attention.self.query.weight\n",
      "bert.encoder.layer.19.attention.self.query.bias\n",
      "bert.encoder.layer.19.attention.self.key.weight\n",
      "bert.encoder.layer.19.attention.self.key.bias\n",
      "bert.encoder.layer.19.attention.self.value.weight\n",
      "bert.encoder.layer.19.attention.self.value.bias\n",
      "bert.encoder.layer.19.attention.output.dense.weight\n",
      "bert.encoder.layer.19.attention.output.dense.bias\n",
      "bert.encoder.layer.19.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.19.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.19.intermediate.dense.weight\n",
      "bert.encoder.layer.19.intermediate.dense.bias\n",
      "bert.encoder.layer.19.output.dense.weight\n",
      "bert.encoder.layer.19.output.dense.bias\n",
      "bert.encoder.layer.19.output.LayerNorm.weight\n",
      "bert.encoder.layer.19.output.LayerNorm.bias\n",
      "bert.encoder.layer.20.attention.self.query.weight\n",
      "bert.encoder.layer.20.attention.self.query.bias\n",
      "bert.encoder.layer.20.attention.self.key.weight\n",
      "bert.encoder.layer.20.attention.self.key.bias\n",
      "bert.encoder.layer.20.attention.self.value.weight\n",
      "bert.encoder.layer.20.attention.self.value.bias\n",
      "bert.encoder.layer.20.attention.output.dense.weight\n",
      "bert.encoder.layer.20.attention.output.dense.bias\n",
      "bert.encoder.layer.20.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.20.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.20.intermediate.dense.weight\n",
      "bert.encoder.layer.20.intermediate.dense.bias\n",
      "bert.encoder.layer.20.output.dense.weight\n",
      "bert.encoder.layer.20.output.dense.bias\n",
      "bert.encoder.layer.20.output.LayerNorm.weight\n",
      "bert.encoder.layer.20.output.LayerNorm.bias\n",
      "bert.encoder.layer.21.attention.self.query.weight\n",
      "bert.encoder.layer.21.attention.self.query.bias\n",
      "bert.encoder.layer.21.attention.self.key.weight\n",
      "bert.encoder.layer.21.attention.self.key.bias\n",
      "bert.encoder.layer.21.attention.self.value.weight\n",
      "bert.encoder.layer.21.attention.self.value.bias\n",
      "bert.encoder.layer.21.attention.output.dense.weight\n",
      "bert.encoder.layer.21.attention.output.dense.bias\n",
      "bert.encoder.layer.21.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.21.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.21.intermediate.dense.weight\n",
      "bert.encoder.layer.21.intermediate.dense.bias\n",
      "bert.encoder.layer.21.output.dense.weight\n",
      "bert.encoder.layer.21.output.dense.bias\n",
      "bert.encoder.layer.21.output.LayerNorm.weight\n",
      "bert.encoder.layer.21.output.LayerNorm.bias\n",
      "bert.encoder.layer.22.attention.self.query.weight\n",
      "bert.encoder.layer.22.attention.self.query.bias\n",
      "bert.encoder.layer.22.attention.self.key.weight\n",
      "bert.encoder.layer.22.attention.self.key.bias\n",
      "bert.encoder.layer.22.attention.self.value.weight\n",
      "bert.encoder.layer.22.attention.self.value.bias\n",
      "bert.encoder.layer.22.attention.output.dense.weight\n",
      "bert.encoder.layer.22.attention.output.dense.bias\n",
      "bert.encoder.layer.22.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.22.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.22.intermediate.dense.weight\n",
      "bert.encoder.layer.22.intermediate.dense.bias\n",
      "bert.encoder.layer.22.output.dense.weight\n",
      "bert.encoder.layer.22.output.dense.bias\n",
      "bert.encoder.layer.22.output.LayerNorm.weight\n",
      "bert.encoder.layer.22.output.LayerNorm.bias\n",
      "bert.encoder.layer.23.attention.self.query.weight\n",
      "bert.encoder.layer.23.attention.self.query.bias\n",
      "bert.encoder.layer.23.attention.self.key.weight\n",
      "bert.encoder.layer.23.attention.self.key.bias\n",
      "bert.encoder.layer.23.attention.self.value.weight\n",
      "bert.encoder.layer.23.attention.self.value.bias\n",
      "bert.encoder.layer.23.attention.output.dense.weight\n",
      "bert.encoder.layer.23.attention.output.dense.bias\n",
      "bert.encoder.layer.23.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.23.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.23.intermediate.dense.weight\n",
      "bert.encoder.layer.23.intermediate.dense.bias\n",
      "bert.encoder.layer.23.output.dense.weight\n",
      "bert.encoder.layer.23.output.dense.bias\n",
      "bert.encoder.layer.23.output.LayerNorm.weight\n",
      "bert.encoder.layer.23.output.LayerNorm.bias\n",
      "bert.pooler.dense.weight\n",
      "bert.pooler.dense.bias\n",
      "cls_layer1.self_attn.in_proj_weight\n",
      "cls_layer1.self_attn.in_proj_bias\n",
      "cls_layer1.self_attn.out_proj.weight\n",
      "cls_layer1.self_attn.out_proj.bias\n",
      "cls_layer1.linear1.weight\n",
      "cls_layer1.linear1.bias\n",
      "cls_layer1.linear2.weight\n",
      "cls_layer1.linear2.bias\n",
      "cls_layer1.norm1.weight\n",
      "cls_layer1.norm1.bias\n",
      "cls_layer1.norm2.weight\n",
      "cls_layer1.norm2.bias\n",
      "cls_layer2.self_attn.in_proj_weight\n",
      "cls_layer2.self_attn.in_proj_bias\n",
      "cls_layer2.self_attn.out_proj.weight\n",
      "cls_layer2.self_attn.out_proj.bias\n",
      "cls_layer2.linear1.weight\n",
      "cls_layer2.linear1.bias\n",
      "cls_layer2.linear2.weight\n",
      "cls_layer2.linear2.bias\n",
      "cls_layer2.norm1.weight\n",
      "cls_layer2.norm1.bias\n",
      "cls_layer2.norm2.weight\n",
      "cls_layer2.norm2.bias\n",
      "cls_layer3.self_attn.in_proj_weight\n",
      "cls_layer3.self_attn.in_proj_bias\n",
      "cls_layer3.self_attn.out_proj.weight\n",
      "cls_layer3.self_attn.out_proj.bias\n",
      "cls_layer3.linear1.weight\n",
      "cls_layer3.linear1.bias\n",
      "cls_layer3.linear2.weight\n",
      "cls_layer3.linear2.bias\n",
      "cls_layer3.norm1.weight\n",
      "cls_layer3.norm1.bias\n",
      "cls_layer3.norm2.weight\n",
      "cls_layer3.norm2.bias\n",
      "cls_layer4.self_attn.in_proj_weight\n",
      "cls_layer4.self_attn.in_proj_bias\n",
      "cls_layer4.self_attn.out_proj.weight\n",
      "cls_layer4.self_attn.out_proj.bias\n",
      "cls_layer4.linear1.weight\n",
      "cls_layer4.linear1.bias\n",
      "cls_layer4.linear2.weight\n",
      "cls_layer4.linear2.bias\n",
      "cls_layer4.norm1.weight\n",
      "cls_layer4.norm1.bias\n",
      "cls_layer4.norm2.weight\n",
      "cls_layer4.norm2.bias\n",
      "fc_cls.weight\n",
      "fc_cls.bias\n",
      "fc_layernorm_cls.weight\n",
      "fc_layernorm_cls.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a491051-4c10-4b28-8878-e78baa48e52f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight\n",
      "embeddings.position_embeddings.weight\n",
      "embeddings.token_type_embeddings.weight\n",
      "embeddings.LayerNorm.weight\n",
      "embeddings.LayerNorm.bias\n",
      "encoder.layer.0.attention.self.query.weight\n",
      "encoder.layer.0.attention.self.query.bias\n",
      "encoder.layer.0.attention.self.key.weight\n",
      "encoder.layer.0.attention.self.key.bias\n",
      "encoder.layer.0.attention.self.value.weight\n",
      "encoder.layer.0.attention.self.value.bias\n",
      "encoder.layer.0.attention.output.dense.weight\n",
      "encoder.layer.0.attention.output.dense.bias\n",
      "encoder.layer.0.attention.output.LayerNorm.weight\n",
      "encoder.layer.0.attention.output.LayerNorm.bias\n",
      "encoder.layer.0.intermediate.dense.weight\n",
      "encoder.layer.0.intermediate.dense.bias\n",
      "encoder.layer.0.output.dense.weight\n",
      "encoder.layer.0.output.dense.bias\n",
      "encoder.layer.0.output.LayerNorm.weight\n",
      "encoder.layer.0.output.LayerNorm.bias\n",
      "encoder.layer.1.attention.self.query.weight\n",
      "encoder.layer.1.attention.self.query.bias\n",
      "encoder.layer.1.attention.self.key.weight\n",
      "encoder.layer.1.attention.self.key.bias\n",
      "encoder.layer.1.attention.self.value.weight\n",
      "encoder.layer.1.attention.self.value.bias\n",
      "encoder.layer.1.attention.output.dense.weight\n",
      "encoder.layer.1.attention.output.dense.bias\n",
      "encoder.layer.1.attention.output.LayerNorm.weight\n",
      "encoder.layer.1.attention.output.LayerNorm.bias\n",
      "encoder.layer.1.intermediate.dense.weight\n",
      "encoder.layer.1.intermediate.dense.bias\n",
      "encoder.layer.1.output.dense.weight\n",
      "encoder.layer.1.output.dense.bias\n",
      "encoder.layer.1.output.LayerNorm.weight\n",
      "encoder.layer.1.output.LayerNorm.bias\n",
      "encoder.layer.2.attention.self.query.weight\n",
      "encoder.layer.2.attention.self.query.bias\n",
      "encoder.layer.2.attention.self.key.weight\n",
      "encoder.layer.2.attention.self.key.bias\n",
      "encoder.layer.2.attention.self.value.weight\n",
      "encoder.layer.2.attention.self.value.bias\n",
      "encoder.layer.2.attention.output.dense.weight\n",
      "encoder.layer.2.attention.output.dense.bias\n",
      "encoder.layer.2.attention.output.LayerNorm.weight\n",
      "encoder.layer.2.attention.output.LayerNorm.bias\n",
      "encoder.layer.2.intermediate.dense.weight\n",
      "encoder.layer.2.intermediate.dense.bias\n",
      "encoder.layer.2.output.dense.weight\n",
      "encoder.layer.2.output.dense.bias\n",
      "encoder.layer.2.output.LayerNorm.weight\n",
      "encoder.layer.2.output.LayerNorm.bias\n",
      "encoder.layer.3.attention.self.query.weight\n",
      "encoder.layer.3.attention.self.query.bias\n",
      "encoder.layer.3.attention.self.key.weight\n",
      "encoder.layer.3.attention.self.key.bias\n",
      "encoder.layer.3.attention.self.value.weight\n",
      "encoder.layer.3.attention.self.value.bias\n",
      "encoder.layer.3.attention.output.dense.weight\n",
      "encoder.layer.3.attention.output.dense.bias\n",
      "encoder.layer.3.attention.output.LayerNorm.weight\n",
      "encoder.layer.3.attention.output.LayerNorm.bias\n",
      "encoder.layer.3.intermediate.dense.weight\n",
      "encoder.layer.3.intermediate.dense.bias\n",
      "encoder.layer.3.output.dense.weight\n",
      "encoder.layer.3.output.dense.bias\n",
      "encoder.layer.3.output.LayerNorm.weight\n",
      "encoder.layer.3.output.LayerNorm.bias\n",
      "encoder.layer.4.attention.self.query.weight\n",
      "encoder.layer.4.attention.self.query.bias\n",
      "encoder.layer.4.attention.self.key.weight\n",
      "encoder.layer.4.attention.self.key.bias\n",
      "encoder.layer.4.attention.self.value.weight\n",
      "encoder.layer.4.attention.self.value.bias\n",
      "encoder.layer.4.attention.output.dense.weight\n",
      "encoder.layer.4.attention.output.dense.bias\n",
      "encoder.layer.4.attention.output.LayerNorm.weight\n",
      "encoder.layer.4.attention.output.LayerNorm.bias\n",
      "encoder.layer.4.intermediate.dense.weight\n",
      "encoder.layer.4.intermediate.dense.bias\n",
      "encoder.layer.4.output.dense.weight\n",
      "encoder.layer.4.output.dense.bias\n",
      "encoder.layer.4.output.LayerNorm.weight\n",
      "encoder.layer.4.output.LayerNorm.bias\n",
      "encoder.layer.5.attention.self.query.weight\n",
      "encoder.layer.5.attention.self.query.bias\n",
      "encoder.layer.5.attention.self.key.weight\n",
      "encoder.layer.5.attention.self.key.bias\n",
      "encoder.layer.5.attention.self.value.weight\n",
      "encoder.layer.5.attention.self.value.bias\n",
      "encoder.layer.5.attention.output.dense.weight\n",
      "encoder.layer.5.attention.output.dense.bias\n",
      "encoder.layer.5.attention.output.LayerNorm.weight\n",
      "encoder.layer.5.attention.output.LayerNorm.bias\n",
      "encoder.layer.5.intermediate.dense.weight\n",
      "encoder.layer.5.intermediate.dense.bias\n",
      "encoder.layer.5.output.dense.weight\n",
      "encoder.layer.5.output.dense.bias\n",
      "encoder.layer.5.output.LayerNorm.weight\n",
      "encoder.layer.5.output.LayerNorm.bias\n",
      "encoder.layer.6.attention.self.query.weight\n",
      "encoder.layer.6.attention.self.query.bias\n",
      "encoder.layer.6.attention.self.key.weight\n",
      "encoder.layer.6.attention.self.key.bias\n",
      "encoder.layer.6.attention.self.value.weight\n",
      "encoder.layer.6.attention.self.value.bias\n",
      "encoder.layer.6.attention.output.dense.weight\n",
      "encoder.layer.6.attention.output.dense.bias\n",
      "encoder.layer.6.attention.output.LayerNorm.weight\n",
      "encoder.layer.6.attention.output.LayerNorm.bias\n",
      "encoder.layer.6.intermediate.dense.weight\n",
      "encoder.layer.6.intermediate.dense.bias\n",
      "encoder.layer.6.output.dense.weight\n",
      "encoder.layer.6.output.dense.bias\n",
      "encoder.layer.6.output.LayerNorm.weight\n",
      "encoder.layer.6.output.LayerNorm.bias\n",
      "encoder.layer.7.attention.self.query.weight\n",
      "encoder.layer.7.attention.self.query.bias\n",
      "encoder.layer.7.attention.self.key.weight\n",
      "encoder.layer.7.attention.self.key.bias\n",
      "encoder.layer.7.attention.self.value.weight\n",
      "encoder.layer.7.attention.self.value.bias\n",
      "encoder.layer.7.attention.output.dense.weight\n",
      "encoder.layer.7.attention.output.dense.bias\n",
      "encoder.layer.7.attention.output.LayerNorm.weight\n",
      "encoder.layer.7.attention.output.LayerNorm.bias\n",
      "encoder.layer.7.intermediate.dense.weight\n",
      "encoder.layer.7.intermediate.dense.bias\n",
      "encoder.layer.7.output.dense.weight\n",
      "encoder.layer.7.output.dense.bias\n",
      "encoder.layer.7.output.LayerNorm.weight\n",
      "encoder.layer.7.output.LayerNorm.bias\n",
      "encoder.layer.8.attention.self.query.weight\n",
      "encoder.layer.8.attention.self.query.bias\n",
      "encoder.layer.8.attention.self.key.weight\n",
      "encoder.layer.8.attention.self.key.bias\n",
      "encoder.layer.8.attention.self.value.weight\n",
      "encoder.layer.8.attention.self.value.bias\n",
      "encoder.layer.8.attention.output.dense.weight\n",
      "encoder.layer.8.attention.output.dense.bias\n",
      "encoder.layer.8.attention.output.LayerNorm.weight\n",
      "encoder.layer.8.attention.output.LayerNorm.bias\n",
      "encoder.layer.8.intermediate.dense.weight\n",
      "encoder.layer.8.intermediate.dense.bias\n",
      "encoder.layer.8.output.dense.weight\n",
      "encoder.layer.8.output.dense.bias\n",
      "encoder.layer.8.output.LayerNorm.weight\n",
      "encoder.layer.8.output.LayerNorm.bias\n",
      "encoder.layer.9.attention.self.query.weight\n",
      "encoder.layer.9.attention.self.query.bias\n",
      "encoder.layer.9.attention.self.key.weight\n",
      "encoder.layer.9.attention.self.key.bias\n",
      "encoder.layer.9.attention.self.value.weight\n",
      "encoder.layer.9.attention.self.value.bias\n",
      "encoder.layer.9.attention.output.dense.weight\n",
      "encoder.layer.9.attention.output.dense.bias\n",
      "encoder.layer.9.attention.output.LayerNorm.weight\n",
      "encoder.layer.9.attention.output.LayerNorm.bias\n",
      "encoder.layer.9.intermediate.dense.weight\n",
      "encoder.layer.9.intermediate.dense.bias\n",
      "encoder.layer.9.output.dense.weight\n",
      "encoder.layer.9.output.dense.bias\n",
      "encoder.layer.9.output.LayerNorm.weight\n",
      "encoder.layer.9.output.LayerNorm.bias\n",
      "encoder.layer.10.attention.self.query.weight\n",
      "encoder.layer.10.attention.self.query.bias\n",
      "encoder.layer.10.attention.self.key.weight\n",
      "encoder.layer.10.attention.self.key.bias\n",
      "encoder.layer.10.attention.self.value.weight\n",
      "encoder.layer.10.attention.self.value.bias\n",
      "encoder.layer.10.attention.output.dense.weight\n",
      "encoder.layer.10.attention.output.dense.bias\n",
      "encoder.layer.10.attention.output.LayerNorm.weight\n",
      "encoder.layer.10.attention.output.LayerNorm.bias\n",
      "encoder.layer.10.intermediate.dense.weight\n",
      "encoder.layer.10.intermediate.dense.bias\n",
      "encoder.layer.10.output.dense.weight\n",
      "encoder.layer.10.output.dense.bias\n",
      "encoder.layer.10.output.LayerNorm.weight\n",
      "encoder.layer.10.output.LayerNorm.bias\n",
      "encoder.layer.11.attention.self.query.weight\n",
      "encoder.layer.11.attention.self.query.bias\n",
      "encoder.layer.11.attention.self.key.weight\n",
      "encoder.layer.11.attention.self.key.bias\n",
      "encoder.layer.11.attention.self.value.weight\n",
      "encoder.layer.11.attention.self.value.bias\n",
      "encoder.layer.11.attention.output.dense.weight\n",
      "encoder.layer.11.attention.output.dense.bias\n",
      "encoder.layer.11.attention.output.LayerNorm.weight\n",
      "encoder.layer.11.attention.output.LayerNorm.bias\n",
      "encoder.layer.11.intermediate.dense.weight\n",
      "encoder.layer.11.intermediate.dense.bias\n",
      "encoder.layer.11.output.dense.weight\n",
      "encoder.layer.11.output.dense.bias\n",
      "encoder.layer.11.output.LayerNorm.weight\n",
      "encoder.layer.11.output.LayerNorm.bias\n",
      "encoder.layer.12.attention.self.query.weight\n",
      "encoder.layer.12.attention.self.query.bias\n",
      "encoder.layer.12.attention.self.key.weight\n",
      "encoder.layer.12.attention.self.key.bias\n",
      "encoder.layer.12.attention.self.value.weight\n",
      "encoder.layer.12.attention.self.value.bias\n",
      "encoder.layer.12.attention.output.dense.weight\n",
      "encoder.layer.12.attention.output.dense.bias\n",
      "encoder.layer.12.attention.output.LayerNorm.weight\n",
      "encoder.layer.12.attention.output.LayerNorm.bias\n",
      "encoder.layer.12.intermediate.dense.weight\n",
      "encoder.layer.12.intermediate.dense.bias\n",
      "encoder.layer.12.output.dense.weight\n",
      "encoder.layer.12.output.dense.bias\n",
      "encoder.layer.12.output.LayerNorm.weight\n",
      "encoder.layer.12.output.LayerNorm.bias\n",
      "encoder.layer.13.attention.self.query.weight\n",
      "encoder.layer.13.attention.self.query.bias\n",
      "encoder.layer.13.attention.self.key.weight\n",
      "encoder.layer.13.attention.self.key.bias\n",
      "encoder.layer.13.attention.self.value.weight\n",
      "encoder.layer.13.attention.self.value.bias\n",
      "encoder.layer.13.attention.output.dense.weight\n",
      "encoder.layer.13.attention.output.dense.bias\n",
      "encoder.layer.13.attention.output.LayerNorm.weight\n",
      "encoder.layer.13.attention.output.LayerNorm.bias\n",
      "encoder.layer.13.intermediate.dense.weight\n",
      "encoder.layer.13.intermediate.dense.bias\n",
      "encoder.layer.13.output.dense.weight\n",
      "encoder.layer.13.output.dense.bias\n",
      "encoder.layer.13.output.LayerNorm.weight\n",
      "encoder.layer.13.output.LayerNorm.bias\n",
      "encoder.layer.14.attention.self.query.weight\n",
      "encoder.layer.14.attention.self.query.bias\n",
      "encoder.layer.14.attention.self.key.weight\n",
      "encoder.layer.14.attention.self.key.bias\n",
      "encoder.layer.14.attention.self.value.weight\n",
      "encoder.layer.14.attention.self.value.bias\n",
      "encoder.layer.14.attention.output.dense.weight\n",
      "encoder.layer.14.attention.output.dense.bias\n",
      "encoder.layer.14.attention.output.LayerNorm.weight\n",
      "encoder.layer.14.attention.output.LayerNorm.bias\n",
      "encoder.layer.14.intermediate.dense.weight\n",
      "encoder.layer.14.intermediate.dense.bias\n",
      "encoder.layer.14.output.dense.weight\n",
      "encoder.layer.14.output.dense.bias\n",
      "encoder.layer.14.output.LayerNorm.weight\n",
      "encoder.layer.14.output.LayerNorm.bias\n",
      "encoder.layer.15.attention.self.query.weight\n",
      "encoder.layer.15.attention.self.query.bias\n",
      "encoder.layer.15.attention.self.key.weight\n",
      "encoder.layer.15.attention.self.key.bias\n",
      "encoder.layer.15.attention.self.value.weight\n",
      "encoder.layer.15.attention.self.value.bias\n",
      "encoder.layer.15.attention.output.dense.weight\n",
      "encoder.layer.15.attention.output.dense.bias\n",
      "encoder.layer.15.attention.output.LayerNorm.weight\n",
      "encoder.layer.15.attention.output.LayerNorm.bias\n",
      "encoder.layer.15.intermediate.dense.weight\n",
      "encoder.layer.15.intermediate.dense.bias\n",
      "encoder.layer.15.output.dense.weight\n",
      "encoder.layer.15.output.dense.bias\n",
      "encoder.layer.15.output.LayerNorm.weight\n",
      "encoder.layer.15.output.LayerNorm.bias\n",
      "encoder.layer.16.attention.self.query.weight\n",
      "encoder.layer.16.attention.self.query.bias\n",
      "encoder.layer.16.attention.self.key.weight\n",
      "encoder.layer.16.attention.self.key.bias\n",
      "encoder.layer.16.attention.self.value.weight\n",
      "encoder.layer.16.attention.self.value.bias\n",
      "encoder.layer.16.attention.output.dense.weight\n",
      "encoder.layer.16.attention.output.dense.bias\n",
      "encoder.layer.16.attention.output.LayerNorm.weight\n",
      "encoder.layer.16.attention.output.LayerNorm.bias\n",
      "encoder.layer.16.intermediate.dense.weight\n",
      "encoder.layer.16.intermediate.dense.bias\n",
      "encoder.layer.16.output.dense.weight\n",
      "encoder.layer.16.output.dense.bias\n",
      "encoder.layer.16.output.LayerNorm.weight\n",
      "encoder.layer.16.output.LayerNorm.bias\n",
      "encoder.layer.17.attention.self.query.weight\n",
      "encoder.layer.17.attention.self.query.bias\n",
      "encoder.layer.17.attention.self.key.weight\n",
      "encoder.layer.17.attention.self.key.bias\n",
      "encoder.layer.17.attention.self.value.weight\n",
      "encoder.layer.17.attention.self.value.bias\n",
      "encoder.layer.17.attention.output.dense.weight\n",
      "encoder.layer.17.attention.output.dense.bias\n",
      "encoder.layer.17.attention.output.LayerNorm.weight\n",
      "encoder.layer.17.attention.output.LayerNorm.bias\n",
      "encoder.layer.17.intermediate.dense.weight\n",
      "encoder.layer.17.intermediate.dense.bias\n",
      "encoder.layer.17.output.dense.weight\n",
      "encoder.layer.17.output.dense.bias\n",
      "encoder.layer.17.output.LayerNorm.weight\n",
      "encoder.layer.17.output.LayerNorm.bias\n",
      "encoder.layer.18.attention.self.query.weight\n",
      "encoder.layer.18.attention.self.query.bias\n",
      "encoder.layer.18.attention.self.key.weight\n",
      "encoder.layer.18.attention.self.key.bias\n",
      "encoder.layer.18.attention.self.value.weight\n",
      "encoder.layer.18.attention.self.value.bias\n",
      "encoder.layer.18.attention.output.dense.weight\n",
      "encoder.layer.18.attention.output.dense.bias\n",
      "encoder.layer.18.attention.output.LayerNorm.weight\n",
      "encoder.layer.18.attention.output.LayerNorm.bias\n",
      "encoder.layer.18.intermediate.dense.weight\n",
      "encoder.layer.18.intermediate.dense.bias\n",
      "encoder.layer.18.output.dense.weight\n",
      "encoder.layer.18.output.dense.bias\n",
      "encoder.layer.18.output.LayerNorm.weight\n",
      "encoder.layer.18.output.LayerNorm.bias\n",
      "encoder.layer.19.attention.self.query.weight\n",
      "encoder.layer.19.attention.self.query.bias\n",
      "encoder.layer.19.attention.self.key.weight\n",
      "encoder.layer.19.attention.self.key.bias\n",
      "encoder.layer.19.attention.self.value.weight\n",
      "encoder.layer.19.attention.self.value.bias\n",
      "encoder.layer.19.attention.output.dense.weight\n",
      "encoder.layer.19.attention.output.dense.bias\n",
      "encoder.layer.19.attention.output.LayerNorm.weight\n",
      "encoder.layer.19.attention.output.LayerNorm.bias\n",
      "encoder.layer.19.intermediate.dense.weight\n",
      "encoder.layer.19.intermediate.dense.bias\n",
      "encoder.layer.19.output.dense.weight\n",
      "encoder.layer.19.output.dense.bias\n",
      "encoder.layer.19.output.LayerNorm.weight\n",
      "encoder.layer.19.output.LayerNorm.bias\n",
      "encoder.layer.20.attention.self.query.weight\n",
      "encoder.layer.20.attention.self.query.bias\n",
      "encoder.layer.20.attention.self.key.weight\n",
      "encoder.layer.20.attention.self.key.bias\n",
      "encoder.layer.20.attention.self.value.weight\n",
      "encoder.layer.20.attention.self.value.bias\n",
      "encoder.layer.20.attention.output.dense.weight\n",
      "encoder.layer.20.attention.output.dense.bias\n",
      "encoder.layer.20.attention.output.LayerNorm.weight\n",
      "encoder.layer.20.attention.output.LayerNorm.bias\n",
      "encoder.layer.20.intermediate.dense.weight\n",
      "encoder.layer.20.intermediate.dense.bias\n",
      "encoder.layer.20.output.dense.weight\n",
      "encoder.layer.20.output.dense.bias\n",
      "encoder.layer.20.output.LayerNorm.weight\n",
      "encoder.layer.20.output.LayerNorm.bias\n",
      "encoder.layer.21.attention.self.query.weight\n",
      "encoder.layer.21.attention.self.query.bias\n",
      "encoder.layer.21.attention.self.key.weight\n",
      "encoder.layer.21.attention.self.key.bias\n",
      "encoder.layer.21.attention.self.value.weight\n",
      "encoder.layer.21.attention.self.value.bias\n",
      "encoder.layer.21.attention.output.dense.weight\n",
      "encoder.layer.21.attention.output.dense.bias\n",
      "encoder.layer.21.attention.output.LayerNorm.weight\n",
      "encoder.layer.21.attention.output.LayerNorm.bias\n",
      "encoder.layer.21.intermediate.dense.weight\n",
      "encoder.layer.21.intermediate.dense.bias\n",
      "encoder.layer.21.output.dense.weight\n",
      "encoder.layer.21.output.dense.bias\n",
      "encoder.layer.21.output.LayerNorm.weight\n",
      "encoder.layer.21.output.LayerNorm.bias\n",
      "encoder.layer.22.attention.self.query.weight\n",
      "encoder.layer.22.attention.self.query.bias\n",
      "encoder.layer.22.attention.self.key.weight\n",
      "encoder.layer.22.attention.self.key.bias\n",
      "encoder.layer.22.attention.self.value.weight\n",
      "encoder.layer.22.attention.self.value.bias\n",
      "encoder.layer.22.attention.output.dense.weight\n",
      "encoder.layer.22.attention.output.dense.bias\n",
      "encoder.layer.22.attention.output.LayerNorm.weight\n",
      "encoder.layer.22.attention.output.LayerNorm.bias\n",
      "encoder.layer.22.intermediate.dense.weight\n",
      "encoder.layer.22.intermediate.dense.bias\n",
      "encoder.layer.22.output.dense.weight\n",
      "encoder.layer.22.output.dense.bias\n",
      "encoder.layer.22.output.LayerNorm.weight\n",
      "encoder.layer.22.output.LayerNorm.bias\n",
      "encoder.layer.23.attention.self.query.weight\n",
      "encoder.layer.23.attention.self.query.bias\n",
      "encoder.layer.23.attention.self.key.weight\n",
      "encoder.layer.23.attention.self.key.bias\n",
      "encoder.layer.23.attention.self.value.weight\n",
      "encoder.layer.23.attention.self.value.bias\n",
      "encoder.layer.23.attention.output.dense.weight\n",
      "encoder.layer.23.attention.output.dense.bias\n",
      "encoder.layer.23.attention.output.LayerNorm.weight\n",
      "encoder.layer.23.attention.output.LayerNorm.bias\n",
      "encoder.layer.23.intermediate.dense.weight\n",
      "encoder.layer.23.intermediate.dense.bias\n",
      "encoder.layer.23.output.dense.weight\n",
      "encoder.layer.23.output.dense.bias\n",
      "encoder.layer.23.output.LayerNorm.weight\n",
      "encoder.layer.23.output.LayerNorm.bias\n",
      "pooler.dense.weight\n",
      "pooler.dense.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.bert.named_parameters():                \n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "833977a2-0571-4843-9883-e079d7fea105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_tagging_pred_n_true(preds, y, tag_pad_idx, org_shap, fist_tokens, FT_TAGS):\n",
    "\n",
    "    max_preds_p = preds.argmax(dim = 1, keepdim = True).view(org_shap)\n",
    "    y_p = y.view(org_shap)\n",
    "    fist_tokens_p = fist_tokens.view(org_shap)\n",
    "   \n",
    "    preds_list = []\n",
    "    true_list = []\n",
    "    for i in range(len(y_p)):\n",
    "        seq_pred = []\n",
    "        seq_true = []\n",
    "        for j in range(len(y_p[i])):\n",
    "\n",
    "            if y_p[i][j].item() != tag_pad_idx and fist_tokens_p[i][j] == 1:\n",
    "                seq_pred.append(max_preds_p[i][j].item()-1)\n",
    "                seq_true.append(y_p[i][j].item()-1)\n",
    "\n",
    "        preds_list.append(seq_pred)\n",
    "        true_list.append(seq_true)\n",
    "\n",
    "    return preds_list, true_list\n",
    "\n",
    "def obtain_classification_pred_n_true(preds, y):\n",
    "\n",
    "    max_preds = preds.argmax(dim = 1)\n",
    "   \n",
    "    preds_list = []\n",
    "    true_list = []\n",
    "    for i in range(len(y)):\n",
    "        preds_list.append(max_preds[i].item()-1)\n",
    "        true_list.append(y[i].item()-1)\n",
    "\n",
    "    return preds_list, true_list\n",
    "\n",
    "def f1_score_tag(preds_list, true_list):\n",
    "    tp,tn,fp,fn = 0,0,0,0\n",
    "    for i in range(len(true_list)):\n",
    "        for j in range(len(true_list[i])):\n",
    "            if true_list[i][j] == 1:\n",
    "                if preds_list[i][j] == 1:\n",
    "                    tp+=1\n",
    "                elif preds_list[i][j] == 0:\n",
    "                    fn += 1\n",
    "            elif true_list[i][j] == 0:\n",
    "                if preds_list[i][j] == 0:\n",
    "                    tn += 1\n",
    "                elif preds_list[i][j] == 1:\n",
    "                    fp += 1\n",
    "               \n",
    "    recall = tp/(tp+fn+1e-9)\n",
    "    precision = tp/(tp+fp+1e-9)\n",
    "    f1 = 2*recall*precision/(recall+precision+1e-9)\n",
    "    acc = (tp+tn)/(tp+tn+fp+fn+1e-9)\n",
    "    return round(precision,4), round(recall,4), round(f1,4), round(acc,4)\n",
    "\n",
    "def f1_score_cls(preds_list, true_list):\n",
    "    tp,tn,fp,fn = 0,0,0,0\n",
    "    for i in range(len(true_list)):\n",
    "        if true_list[i] == 1:\n",
    "            if preds_list[i] == true_list[i]:\n",
    "                tp+=1\n",
    "            elif preds_list[i] != true_list[i]:\n",
    "                fn += 1\n",
    "        elif true_list[i] == 0:\n",
    "            if preds_list[i] == true_list[i]:\n",
    "                tn += 1\n",
    "            elif preds_list[i] != true_list[i]:\n",
    "                fp += 1\n",
    "               \n",
    "    print(\"tp: \",tp)\n",
    "    print(\"fn: \",fn)\n",
    "    print(\"tn: \",tn)\n",
    "    print(\"fp: \",fp)\n",
    "    \n",
    "    recall = tp/(tp+fn+1e-9)\n",
    "    precision = tp/(tp+fp+1e-9)\n",
    "    f1 = 2*recall*precision/(recall+precision+1e-9)\n",
    "    acc = (tp+tn)/(tp+tn+fp+fn+1e-9)\n",
    "    return round(precision,4), round(recall,4), round(f1,4), round(acc,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c708cb4-2da4-4c33-b967-c1193058172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, scheduler, criterion_label, criterion_pos, tag_pad_idx, ori_tag_loss_weight, ori_cls_loss_weight):\n",
    "    \n",
    "    loss_label1 = 0\n",
    "    loss_label2 = 0\n",
    "    \n",
    "    #tag_loss_weight = ori_tag_loss_weight\n",
    "    cls_loss_weight = ori_cls_loss_weight\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    pred_label1_list=[]\n",
    "    true_label1_list=[]\n",
    "    pred_label2_list=[]\n",
    "    true_label2_list=[]\n",
    "    \n",
    "    #first_batch_loss_tag = None\n",
    "    first_batch_loss_cls = None\n",
    "    batch_number = 0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(iterator):\n",
    "        \n",
    "        #org_label1_shap = batch.label1.size() # [batch size, seq len]\n",
    "        org_label2_shap = batch.label2.size() # [batch size, 1]\n",
    "        \n",
    "        token_idx_ = batch.token_id # [batch size, seq len]\n",
    "        mask_ab = batch.mask_ab # [batch size, seq len]\n",
    "        mask_p = batch.mask_p # [batch size, seq len]\n",
    "        ft_tags = batch.first_token.view(-1) # [batch size * seq len]\n",
    "        #tag_true = batch.label1.view(-1) # [batch size * seq len]\n",
    "        cls_true = batch.label2.view(-1) # [batch size]\n",
    "        \n",
    "        \n",
    "        \n",
    "        # tag_pred:[batch size, seq len, label1 dim]\n",
    "        # cls_pred:[batch size, label2 dim]\n",
    "        cls_pred = model(token_idx_,mask_ab, mask_p)\n",
    "\n",
    "        #tag_pred = tag_pred.view(-1, tag_pred.shape[-1]) # [batch size * seq len, label1 dim]\n",
    "\n",
    "        #loss_tag = criterion_tag(tag_pred, tag_true)\n",
    "        loss_cls = criterion_cls(cls_pred, cls_true)\n",
    "        \n",
    "        # if first_batch_loss_tag is not None:\n",
    "        #     tag_loss_weight = (loss_tag.item()/first_batch_loss_tag)**2\n",
    "        if first_batch_loss_cls is not None:\n",
    "            cls_loss_weight = (loss_cls.item()/first_batch_loss_cls)**2\n",
    "        \n",
    "        # if first_batch_loss_tag is None:\n",
    "        #     first_batch_loss_tag = loss_tag.item()\n",
    "        if first_batch_loss_cls is None:\n",
    "            first_batch_loss_cls = loss_cls.item()\n",
    "        \n",
    "        # loss_label1 += loss_tag.item()\n",
    "        loss_label2 += loss_cls.item()\n",
    "        \n",
    "        # loss_tag is larger than loss_cls, so the overall loss is weighted summed up.\n",
    "        # if loss_cls > loss_tag*10:\n",
    "        #     cls_loss_weight=0.1\n",
    "        # elif loss_cls > loss_tag*5:\n",
    "        #     cls_loss_weight=0.2\n",
    "        # elif loss_cls > loss_tag*2:\n",
    "        #     cls_loss_weight=0.5\n",
    "        # elif loss_cls < loss_tag*0.5:\n",
    "        #     cls_loss_weight=2\n",
    "        \n",
    "        # tag_loss_weight=1\n",
    "        # cls_loss_weight=tag_loss_weight*loss_tag/loss_cls\n",
    "        \n",
    "        \n",
    "        # if loss_label2 < 500 and loss_label2 > 100 and loss_label2 > loss_label1*2:\n",
    "        #     tag_loss_weight=0\n",
    "        \n",
    "        #weight = F.softmax(torch.randn(2), dim=-1)\n",
    "        \n",
    "        \n",
    "        # if batch_number%100==0: \n",
    "        #     # first_batch_loss_tag = loss_tag.item()\n",
    "        #     # first_batch_loss_cls = loss_cls.item()\n",
    "        #     print(\"batch number: \",batch_number)\n",
    "        #     print(\"tag loss weight: \",tag_loss_weight)\n",
    "        #     print(\"cls loss weight: \",cls_loss_weight)\n",
    "        #     print(\"tag loss: \",loss_tag.item())\n",
    "        #     print(\"cls loss: \",loss_cls.item())\n",
    "        # batch_number+=1\n",
    "        \n",
    "        \n",
    "        #loss = tag_loss_weight*loss_tag + cls_loss_weight*loss_cls\n",
    "        #loss = weight[0]*loss_tag + weight[1]*loss_cls\n",
    "        loss = ori_cls_loss_weight*loss_cls\n",
    "        \n",
    "        # normalize loss to account for batch accumulation\n",
    "        loss = loss / accum_iter\n",
    "        \n",
    "        # backward pass, The gradients are computed when we call loss.backward() and are stored by PyTorch until we call optimizer.zero_grad().\n",
    "        loss.backward()\n",
    "        \n",
    "        # weights update. It is important to also update weights on the last batch when batch_idx + 1 == len(data_loader) - \n",
    "        # this makes sure that data from the last batches are not discarded and used for optimizing the network.\n",
    "        if ((batch_idx + 1) % accum_iter == 0) or (batch_idx + 1 == len(iterator)):\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # pred_label1, true_label1 = obtain_tagging_pred_n_true(tag_pred, tag_true, tag_pad_idx, org_label1_shap, ft_tags, FT_TAGS)\n",
    "        pred_label2, true_label2 = obtain_classification_pred_n_true(cls_pred, cls_true)\n",
    "        \n",
    "        \n",
    "        # pred_label1_list.extend(pred_label1)\n",
    "        # true_label1_list.extend(true_label1)\n",
    "        pred_label2_list.extend(pred_label2)\n",
    "        true_label2_list.extend(true_label2)\n",
    "            \n",
    "            \n",
    "    # p_label1, r_label1, f_label1, acc_label1 = f1_score_tag(pred_label1_list, true_label1_list)\n",
    "    p_label2, r_label2, f_label2, acc_label2 = f1_score_cls(pred_label2_list, true_label2_list)\n",
    "    \n",
    "    print(\"train set pred label2 length: \",len(pred_label2_list))\n",
    "    print(\"train set true label2 length: \",len(true_label2_list))\n",
    "    match_number=0\n",
    "    for i in range(len(pred_label2_list)):\n",
    "        if pred_label2_list[i] == true_label2_list[i]:\n",
    "            match_number+=1\n",
    "    print(\"match number: \",match_number)   \n",
    "    \n",
    "      \n",
    "        \n",
    "    return round(loss_label2,4),  p_label2, r_label2, f_label2, acc_label2\n",
    "\n",
    "def evaluate(model, iterator, criterion_label, criterion_pos, tag_pad_idx):\n",
    "    \n",
    "    loss_label1 = 0\n",
    "    loss_label2 = 0\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        pred_label1_list=[]\n",
    "        true_label1_list=[]\n",
    "        pred_label2_list=[]\n",
    "        true_label2_list=[]\n",
    "        \n",
    "        for batch in iterator:\n",
    "\n",
    "            # org_label1_shap = batch.label1.size() # [batch size, seq len]\n",
    "            org_label2_shap = batch.label2.size() # [batch size, 1]\n",
    "\n",
    "            token_idx_ = batch.token_id # [batch size, seq len]\n",
    "            mask_ab = batch.mask_ab # [batch size, seq len]\n",
    "            mask_p = batch.mask_p # [batch size, seq len]\n",
    "            ft_tags = batch.first_token.view(-1) # [batch size * seq len]\n",
    "            # tag_true = batch.label1.view(-1) # [batch size * seq len]\n",
    "            cls_true = batch.label2.view(-1) # [batch size]\n",
    "\n",
    "            # tag_pred:[batch size, seq len, label1 dim]\n",
    "            # cls_pred:[batch size, label2 dim]\n",
    "            cls_pred = model(token_idx_,mask_ab,mask_p)\n",
    "\n",
    "            # tag_pred = tag_pred.view(-1, tag_pred.shape[-1]) # [batch size * seq len, label1 dim]\n",
    "\n",
    "            # loss_tag = criterion_tag(tag_pred, tag_true)\n",
    "            loss_cls = criterion_cls(cls_pred, cls_true)\n",
    "\n",
    "            # loss_label1 += loss_tag.item()\n",
    "            loss_label2 += loss_cls.item()\n",
    "\n",
    "            # pred_label1, true_label1 = obtain_tagging_pred_n_true(tag_pred, tag_true, tag_pad_idx, org_label1_shap, ft_tags, FT_TAGS)\n",
    "            pred_label2, true_label2 = obtain_classification_pred_n_true(cls_pred, cls_true)\n",
    "            \n",
    "            # pred_label1_list.extend(pred_label1)\n",
    "            # true_label1_list.extend(true_label1)\n",
    "            pred_label2_list.extend(pred_label2)\n",
    "            true_label2_list.extend(true_label2)\n",
    "            \n",
    "            \n",
    "        # p_label1, r_label1, f_label1, acc_label1 = f1_score_tag(pred_label1_list, true_label1_list)\n",
    "        p_label2, r_label2, f_label2, acc_label2 = f1_score_cls(pred_label2_list, true_label2_list)\n",
    "        \n",
    "        print(\"pred label2 length: \",len(pred_label2_list))\n",
    "        print(\"true label2 length: \",len(true_label2_list))\n",
    "        match_number=0\n",
    "        for i in range(len(pred_label2_list)):\n",
    "            if pred_label2_list[i] == true_label2_list[i]:\n",
    "                match_number+=1\n",
    "        print(\"match number: \",match_number)   \n",
    "        \n",
    "    return  round(loss_label2,4), p_label2, r_label2, f_label2, acc_label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31736127-1666-4727-9871-4f4d0be936e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = F.softmax(torch.randn(2), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9dfb11e-fb5f-4e21-b989-d19832f3a2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5016)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13f38094-0574-46d3-a726-3c69537015bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_output_difference(model, iterator, criterion_label, criterion_pos, tag_pad_idx):\n",
    "    \n",
    "    loss_label1 = 0\n",
    "    loss_label2 = 0\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        pred_label1_list=[]\n",
    "        true_label1_list=[]\n",
    "        pred_label2_list=[]\n",
    "        true_label2_list=[]\n",
    "        token_idx_list=[]\n",
    "        \n",
    "        for batch in iterator:\n",
    "\n",
    "            # org_label1_shap = batch.label1.size() # [batch size, seq len]\n",
    "            org_label2_shap = batch.label2.size() # [batch size, 1]\n",
    "\n",
    "            token_idx_ = batch.token_id # [batch size, seq len]\n",
    "            mask_ab = batch.mask_ab # [batch size, seq len]\n",
    "            mask_p = batch.mask_p # [batch size, seq len]\n",
    "            ft_tags = batch.first_token.view(-1) # [batch size * seq len]\n",
    "            # tag_true = batch.label1.view(-1) # [batch size * seq len]\n",
    "            cls_true = batch.label2.view(-1) # [batch size]\n",
    "            #seq = batch.seq.view(-1) # [batch size]\n",
    "\n",
    "            # tag_pred:[batch size, seq len, label1 dim]\n",
    "            # cls_pred:[batch size, label2 dim]\n",
    "            cls_pred = model(token_idx_,mask_ab,mask_p)\n",
    "\n",
    "            # tag_pred = tag_pred.view(-1, tag_pred.shape[-1]) # [batch size * seq len, label1 dim]\n",
    "\n",
    "            # loss_tag = criterion_tag(tag_pred, tag_true)\n",
    "            loss_cls = criterion_cls(cls_pred, cls_true)\n",
    "\n",
    "            # loss_label1 += loss_tag.item()\n",
    "            loss_label2 += loss_cls.item()\n",
    "\n",
    "            # pred_label1, true_label1 = obtain_tagging_pred_n_true(tag_pred, tag_true, tag_pad_idx, org_label1_shap, ft_tags, FT_TAGS)\n",
    "            pred_label2, true_label2 = obtain_classification_pred_n_true(cls_pred, cls_true)\n",
    "            \n",
    "            # pred_label1_list.extend(pred_label1)\n",
    "            # true_label1_list.extend(true_label1)\n",
    "            pred_label2_list.extend(pred_label2)\n",
    "            true_label2_list.extend(true_label2)\n",
    "            \n",
    "            for i in range(len(batch.token_id.tolist())):\n",
    "                token_idx_list.append(batch.token_id.tolist()[i])\n",
    "            \n",
    "            \n",
    "        # p_label1, r_label1, f_label1, acc_label1 = f1_score_tag(pred_label1_list, true_label1_list)\n",
    "        p_label2, r_label2, f_label2, acc_label2 = f1_score_cls(pred_label2_list, true_label2_list)\n",
    "        \n",
    "        print(\"pred label2 length: \",len(pred_label2_list))\n",
    "        print(\"true label2 length: \",len(true_label2_list))\n",
    "        match_number=0\n",
    "        comparison_df = pd.DataFrame(columns=['index', 'token_idx','pred_label2', 'true_label2'])\n",
    "        for i in range(len(pred_label2_list)):\n",
    "            if pred_label2_list[i] == true_label2_list[i]:\n",
    "                match_number+=1\n",
    "            elif pred_label2_list[i] != true_label2_list[i]:\n",
    "                df2={'index': i, 'token_idx':' '.join(str(e) for e in token_idx_list[i]), 'pred_label2': pred_label2_list[i], 'true_label2': true_label2_list[i]}\n",
    "                comparison_df = comparison_df.append(df2, ignore_index = True)\n",
    "        print(\"match number: \",match_number)   \n",
    "        \n",
    "    return round(loss_label2,4),  p_label2, r_label2, f_label2, acc_label2, comparison_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5d0749a-ae40-45c1-a76b-f2736d2322f1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for batch in test_iterator:\n",
    "#     print(batch.token_id.tolist()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c788175-2128-46a3-a2a6-e28e6d5aa1a0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-28 09:51:16.070499\n",
      "EPOCH 0\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  534\n",
      "fn:  1232\n",
      "tn:  1511\n",
      "fp:  701\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  2045\n",
      "tp:  0\n",
      "fn:  1750\n",
      "tn:  2234\n",
      "fp:  0\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  2234\n",
      "    TRAIN | Label 2 loss: 964.8946 ; P: 0.4324 ; R: 0.3024 ; F1: 0.3559 ; Acc: 0.5141\n",
      "    TEST | Label 2 loss: 883.8224 ; P: 0.0 ; R: 0.0 ; F1: 0.0 ; Acc: 0.5607\n",
      "2023-01-28 09:54:25.823524\n",
      "counter:  0\n",
      "2023-01-28 09:54:27.545559\n",
      "EPOCH 1\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  597\n",
      "fn:  1169\n",
      "tn:  1566\n",
      "fp:  646\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  2163\n",
      "tp:  100\n",
      "fn:  1650\n",
      "tn:  2154\n",
      "fp:  80\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  2254\n",
      "    TRAIN | Label 2 loss: 796.0746 ; P: 0.4803 ; R: 0.3381 ; F1: 0.3968 ; Acc: 0.5437\n",
      "    TEST | Label 2 loss: 753.5455 ; P: 0.5556 ; R: 0.0571 ; F1: 0.1036 ; Acc: 0.5658\n",
      "2023-01-28 09:57:35.002596\n",
      "counter:  0\n",
      "2023-01-28 09:57:36.864770\n",
      "EPOCH 2\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  551\n",
      "fn:  1215\n",
      "tn:  1624\n",
      "fp:  588\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  2175\n",
      "tp:  81\n",
      "fn:  1669\n",
      "tn:  2216\n",
      "fp:  18\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  2297\n",
      "    TRAIN | Label 2 loss: 756.3317 ; P: 0.4838 ; R: 0.312 ; F1: 0.3793 ; Acc: 0.5468\n",
      "    TEST | Label 2 loss: 730.3351 ; P: 0.8182 ; R: 0.0463 ; F1: 0.0876 ; Acc: 0.5766\n",
      "2023-01-28 10:00:46.231112\n",
      "counter:  1\n",
      "2023-01-28 10:00:46.232108\n",
      "EPOCH 3\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  489\n",
      "fn:  1277\n",
      "tn:  1792\n",
      "fp:  420\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  2281\n",
      "tp:  168\n",
      "fn:  1582\n",
      "tn:  2201\n",
      "fp:  33\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  2369\n",
      "    TRAIN | Label 2 loss: 737.4082 ; P: 0.538 ; R: 0.2769 ; F1: 0.3656 ; Acc: 0.5734\n",
      "    TEST | Label 2 loss: 721.334 ; P: 0.8358 ; R: 0.096 ; F1: 0.1722 ; Acc: 0.5946\n",
      "2023-01-28 10:03:54.167716\n",
      "counter:  0\n",
      "2023-01-28 10:03:55.939107\n",
      "EPOCH 4\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  510\n",
      "fn:  1256\n",
      "tn:  1815\n",
      "fp:  397\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  2325\n",
      "tp:  176\n",
      "fn:  1574\n",
      "tn:  2219\n",
      "fp:  15\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  2395\n",
      "    TRAIN | Label 2 loss: 732.3766 ; P: 0.5623 ; R: 0.2888 ; F1: 0.3816 ; Acc: 0.5845\n",
      "    TEST | Label 2 loss: 712.8554 ; P: 0.9215 ; R: 0.1006 ; F1: 0.1813 ; Acc: 0.6012\n",
      "2023-01-28 10:07:04.273699\n",
      "counter:  0\n",
      "2023-01-28 10:07:06.116811\n",
      "EPOCH 5\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  571\n",
      "fn:  1195\n",
      "tn:  1840\n",
      "fp:  372\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  2411\n",
      "tp:  438\n",
      "fn:  1312\n",
      "tn:  2157\n",
      "fp:  77\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  2595\n",
      "    TRAIN | Label 2 loss: 721.0667 ; P: 0.6055 ; R: 0.3233 ; F1: 0.4216 ; Acc: 0.6061\n",
      "    TEST | Label 2 loss: 702.009 ; P: 0.8505 ; R: 0.2503 ; F1: 0.3868 ; Acc: 0.6514\n",
      "2023-01-28 10:10:11.628901\n",
      "counter:  0\n",
      "2023-01-28 10:10:13.427878\n",
      "EPOCH 6\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  697\n",
      "fn:  1069\n",
      "tn:  1794\n",
      "fp:  418\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  2491\n",
      "tp:  507\n",
      "fn:  1243\n",
      "tn:  2169\n",
      "fp:  65\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  2676\n",
      "    TRAIN | Label 2 loss: 711.3831 ; P: 0.6251 ; R: 0.3947 ; F1: 0.4839 ; Acc: 0.6262\n",
      "    TEST | Label 2 loss: 682.1135 ; P: 0.8864 ; R: 0.2897 ; F1: 0.4367 ; Acc: 0.6717\n",
      "2023-01-28 10:13:17.313261\n",
      "counter:  0\n",
      "2023-01-28 10:13:19.166955\n",
      "EPOCH 7\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  811\n",
      "fn:  955\n",
      "tn:  1779\n",
      "fp:  433\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  2590\n",
      "tp:  1255\n",
      "fn:  495\n",
      "tn:  1499\n",
      "fp:  735\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  2754\n",
      "    TRAIN | Label 2 loss: 687.8829 ; P: 0.6519 ; R: 0.4592 ; F1: 0.5389 ; Acc: 0.6511\n",
      "    TEST | Label 2 loss: 658.5718 ; P: 0.6307 ; R: 0.7171 ; F1: 0.6711 ; Acc: 0.6913\n",
      "2023-01-28 10:16:24.150673\n",
      "counter:  0\n",
      "2023-01-28 10:16:25.957524\n",
      "EPOCH 8\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  966\n",
      "fn:  800\n",
      "tn:  1757\n",
      "fp:  455\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  2723\n",
      "tp:  1013\n",
      "fn:  737\n",
      "tn:  1975\n",
      "fp:  259\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  2988\n",
      "    TRAIN | Label 2 loss: 656.805 ; P: 0.6798 ; R: 0.547 ; F1: 0.6062 ; Acc: 0.6845\n",
      "    TEST | Label 2 loss: 603.1992 ; P: 0.7964 ; R: 0.5789 ; F1: 0.6704 ; Acc: 0.75\n",
      "2023-01-28 10:19:30.925652\n",
      "counter:  1\n",
      "2023-01-28 10:19:30.925652\n",
      "EPOCH 9\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1028\n",
      "fn:  738\n",
      "tn:  1826\n",
      "fp:  386\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  2854\n",
      "tp:  1110\n",
      "fn:  640\n",
      "tn:  1945\n",
      "fp:  289\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3055\n",
      "    TRAIN | Label 2 loss: 625.8519 ; P: 0.727 ; R: 0.5821 ; F1: 0.6465 ; Acc: 0.7174\n",
      "    TEST | Label 2 loss: 571.1682 ; P: 0.7934 ; R: 0.6343 ; F1: 0.705 ; Acc: 0.7668\n",
      "2023-01-28 10:22:36.090708\n",
      "counter:  0\n",
      "2023-01-28 10:22:37.982163\n",
      "EPOCH 10\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1128\n",
      "fn:  638\n",
      "tn:  1849\n",
      "fp:  363\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  2977\n",
      "tp:  1191\n",
      "fn:  559\n",
      "tn:  1908\n",
      "fp:  326\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3099\n",
      "    TRAIN | Label 2 loss: 589.0774 ; P: 0.7565 ; R: 0.6387 ; F1: 0.6927 ; Acc: 0.7484\n",
      "    TEST | Label 2 loss: 551.915 ; P: 0.7851 ; R: 0.6806 ; F1: 0.7291 ; Acc: 0.7779\n",
      "2023-01-28 10:25:42.360176\n",
      "counter:  0\n",
      "2023-01-28 10:25:44.241843\n",
      "EPOCH 11\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1157\n",
      "fn:  609\n",
      "tn:  1849\n",
      "fp:  363\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3006\n",
      "tp:  1213\n",
      "fn:  537\n",
      "tn:  1924\n",
      "fp:  310\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3137\n",
      "    TRAIN | Label 2 loss: 571.0806 ; P: 0.7612 ; R: 0.6552 ; F1: 0.7042 ; Acc: 0.7557\n",
      "    TEST | Label 2 loss: 532.1085 ; P: 0.7965 ; R: 0.6931 ; F1: 0.7412 ; Acc: 0.7874\n",
      "2023-01-28 10:28:48.993729\n",
      "counter:  0\n",
      "2023-01-28 10:28:50.805458\n",
      "EPOCH 12\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1208\n",
      "fn:  558\n",
      "tn:  1881\n",
      "fp:  331\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3089\n",
      "tp:  1352\n",
      "fn:  398\n",
      "tn:  1788\n",
      "fp:  446\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3140\n",
      "    TRAIN | Label 2 loss: 548.3574 ; P: 0.7849 ; R: 0.684 ; F1: 0.731 ; Acc: 0.7765\n",
      "    TEST | Label 2 loss: 528.6229 ; P: 0.7519 ; R: 0.7726 ; F1: 0.7621 ; Acc: 0.7882\n",
      "2023-01-28 10:31:54.995251\n",
      "counter:  0\n",
      "2023-01-28 10:31:56.689517\n",
      "EPOCH 13\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1230\n",
      "fn:  536\n",
      "tn:  1869\n",
      "fp:  343\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3099\n",
      "tp:  1315\n",
      "fn:  435\n",
      "tn:  1896\n",
      "fp:  338\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3211\n",
      "    TRAIN | Label 2 loss: 527.5902 ; P: 0.7819 ; R: 0.6965 ; F1: 0.7367 ; Acc: 0.779\n",
      "    TEST | Label 2 loss: 504.9504 ; P: 0.7955 ; R: 0.7514 ; F1: 0.7728 ; Acc: 0.806\n",
      "2023-01-28 10:35:01.391446\n",
      "counter:  0\n",
      "2023-01-28 10:35:03.285293\n",
      "EPOCH 14\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1298\n",
      "fn:  468\n",
      "tn:  1908\n",
      "fp:  304\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3206\n",
      "tp:  1312\n",
      "fn:  438\n",
      "tn:  1942\n",
      "fp:  292\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3254\n",
      "    TRAIN | Label 2 loss: 510.4093 ; P: 0.8102 ; R: 0.735 ; F1: 0.7708 ; Acc: 0.8059\n",
      "    TEST | Label 2 loss: 486.8968 ; P: 0.818 ; R: 0.7497 ; F1: 0.7823 ; Acc: 0.8168\n",
      "2023-01-28 10:38:08.401785\n",
      "counter:  0\n",
      "2023-01-28 10:38:10.161277\n",
      "EPOCH 15\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1332\n",
      "fn:  434\n",
      "tn:  1938\n",
      "fp:  274\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3270\n",
      "tp:  1452\n",
      "fn:  298\n",
      "tn:  1832\n",
      "fp:  402\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3284\n",
      "    TRAIN | Label 2 loss: 483.6361 ; P: 0.8294 ; R: 0.7542 ; F1: 0.79 ; Acc: 0.822\n",
      "    TEST | Label 2 loss: 481.7659 ; P: 0.7832 ; R: 0.8297 ; F1: 0.8058 ; Acc: 0.8243\n",
      "2023-01-28 10:41:13.871566\n",
      "counter:  0\n",
      "2023-01-28 10:41:15.667032\n",
      "EPOCH 16\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1352\n",
      "fn:  414\n",
      "tn:  1935\n",
      "fp:  277\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3287\n",
      "tp:  1428\n",
      "fn:  322\n",
      "tn:  1884\n",
      "fp:  350\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3312\n",
      "    TRAIN | Label 2 loss: 475.8985 ; P: 0.83 ; R: 0.7656 ; F1: 0.7965 ; Acc: 0.8263\n",
      "    TEST | Label 2 loss: 466.8641 ; P: 0.8031 ; R: 0.816 ; F1: 0.8095 ; Acc: 0.8313\n",
      "2023-01-28 10:44:20.408780\n",
      "counter:  0\n",
      "2023-01-28 10:44:22.215591\n",
      "EPOCH 17\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1394\n",
      "fn:  372\n",
      "tn:  1921\n",
      "fp:  291\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3315\n",
      "tp:  1480\n",
      "fn:  270\n",
      "tn:  1874\n",
      "fp:  360\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3354\n",
      "    TRAIN | Label 2 loss: 461.4895 ; P: 0.8273 ; R: 0.7894 ; F1: 0.8079 ; Acc: 0.8333\n",
      "    TEST | Label 2 loss: 454.6753 ; P: 0.8043 ; R: 0.8457 ; F1: 0.8245 ; Acc: 0.8419\n",
      "2023-01-28 10:47:26.828616\n",
      "counter:  0\n",
      "2023-01-28 10:47:28.851156\n",
      "EPOCH 18\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1438\n",
      "fn:  328\n",
      "tn:  1981\n",
      "fp:  231\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3419\n",
      "tp:  1476\n",
      "fn:  274\n",
      "tn:  1919\n",
      "fp:  315\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3395\n",
      "    TRAIN | Label 2 loss: 434.5678 ; P: 0.8616 ; R: 0.8143 ; F1: 0.8373 ; Acc: 0.8595\n",
      "    TEST | Label 2 loss: 440.0427 ; P: 0.8241 ; R: 0.8434 ; F1: 0.8337 ; Acc: 0.8522\n",
      "2023-01-28 10:50:33.406026\n",
      "counter:  0\n",
      "2023-01-28 10:50:35.382391\n",
      "EPOCH 19\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1458\n",
      "fn:  308\n",
      "tn:  2000\n",
      "fp:  212\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3458\n",
      "tp:  1517\n",
      "fn:  233\n",
      "tn:  1903\n",
      "fp:  331\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3420\n",
      "    TRAIN | Label 2 loss: 419.1029 ; P: 0.8731 ; R: 0.8256 ; F1: 0.8487 ; Acc: 0.8693\n",
      "    TEST | Label 2 loss: 431.6859 ; P: 0.8209 ; R: 0.8669 ; F1: 0.8432 ; Acc: 0.8584\n",
      "2023-01-28 10:53:40.445623\n",
      "counter:  0\n",
      "2023-01-28 10:53:42.346950\n",
      "EPOCH 20\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1488\n",
      "fn:  278\n",
      "tn:  1984\n",
      "fp:  228\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3472\n",
      "tp:  1516\n",
      "fn:  234\n",
      "tn:  1958\n",
      "fp:  276\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3474\n",
      "    TRAIN | Label 2 loss: 413.7544 ; P: 0.8671 ; R: 0.8426 ; F1: 0.8547 ; Acc: 0.8728\n",
      "    TEST | Label 2 loss: 420.2399 ; P: 0.846 ; R: 0.8663 ; F1: 0.856 ; Acc: 0.872\n",
      "2023-01-28 10:56:46.819293\n",
      "counter:  0\n",
      "2023-01-28 10:56:48.741522\n",
      "EPOCH 21\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1518\n",
      "fn:  248\n",
      "tn:  2007\n",
      "fp:  205\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3525\n",
      "tp:  1495\n",
      "fn:  255\n",
      "tn:  1998\n",
      "fp:  236\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3493\n",
      "    TRAIN | Label 2 loss: 394.0855 ; P: 0.881 ; R: 0.8596 ; F1: 0.8702 ; Acc: 0.8861\n",
      "    TEST | Label 2 loss: 410.6422 ; P: 0.8637 ; R: 0.8543 ; F1: 0.8589 ; Acc: 0.8768\n",
      "2023-01-28 10:59:53.198302\n",
      "counter:  0\n",
      "2023-01-28 10:59:55.047998\n",
      "EPOCH 22\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1541\n",
      "fn:  225\n",
      "tn:  2032\n",
      "fp:  180\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3573\n",
      "tp:  1550\n",
      "fn:  200\n",
      "tn:  1958\n",
      "fp:  276\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3508\n",
      "    TRAIN | Label 2 loss: 384.5524 ; P: 0.8954 ; R: 0.8726 ; F1: 0.8839 ; Acc: 0.8982\n",
      "    TEST | Label 2 loss: 406.4491 ; P: 0.8488 ; R: 0.8857 ; F1: 0.8669 ; Acc: 0.8805\n",
      "2023-01-28 11:02:59.247807\n",
      "counter:  0\n",
      "2023-01-28 11:03:01.273507\n",
      "EPOCH 23\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1574\n",
      "fn:  192\n",
      "tn:  2037\n",
      "fp:  175\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3611\n",
      "tp:  1544\n",
      "fn:  206\n",
      "tn:  1994\n",
      "fp:  240\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3538\n",
      "    TRAIN | Label 2 loss: 370.5013 ; P: 0.8999 ; R: 0.8913 ; F1: 0.8956 ; Acc: 0.9077\n",
      "    TEST | Label 2 loss: 399.4479 ; P: 0.8655 ; R: 0.8823 ; F1: 0.8738 ; Acc: 0.8881\n",
      "2023-01-28 11:06:04.860769\n",
      "counter:  0\n",
      "2023-01-28 11:06:06.838498\n",
      "EPOCH 24\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1584\n",
      "fn:  182\n",
      "tn:  2034\n",
      "fp:  178\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3618\n",
      "tp:  1544\n",
      "fn:  206\n",
      "tn:  1988\n",
      "fp:  246\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3532\n",
      "    TRAIN | Label 2 loss: 370.051 ; P: 0.899 ; R: 0.8969 ; F1: 0.898 ; Acc: 0.9095\n",
      "    TEST | Label 2 loss: 397.0838 ; P: 0.8626 ; R: 0.8823 ; F1: 0.8723 ; Acc: 0.8865\n",
      "2023-01-28 11:09:10.932428\n",
      "counter:  1\n",
      "2023-01-28 11:09:10.932428\n",
      "EPOCH 25\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1585\n",
      "fn:  181\n",
      "tn:  2059\n",
      "fp:  153\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3644\n",
      "tp:  1566\n",
      "fn:  184\n",
      "tn:  1984\n",
      "fp:  250\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3550\n",
      "    TRAIN | Label 2 loss: 354.5878 ; P: 0.912 ; R: 0.8975 ; F1: 0.9047 ; Acc: 0.916\n",
      "    TEST | Label 2 loss: 391.9878 ; P: 0.8623 ; R: 0.8949 ; F1: 0.8783 ; Acc: 0.8911\n",
      "2023-01-28 11:12:15.778427\n",
      "counter:  0\n",
      "2023-01-28 11:12:18.382923\n",
      "EPOCH 26\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1602\n",
      "fn:  164\n",
      "tn:  2053\n",
      "fp:  159\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3655\n",
      "tp:  1590\n",
      "fn:  160\n",
      "tn:  1956\n",
      "fp:  278\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3546\n",
      "    TRAIN | Label 2 loss: 348.9746 ; P: 0.9097 ; R: 0.9071 ; F1: 0.9084 ; Acc: 0.9188\n",
      "    TEST | Label 2 loss: 391.9098 ; P: 0.8512 ; R: 0.9086 ; F1: 0.8789 ; Acc: 0.8901\n",
      "2023-01-28 11:15:22.491643\n",
      "counter:  0\n",
      "2023-01-28 11:15:24.391476\n",
      "EPOCH 27\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1611\n",
      "fn:  155\n",
      "tn:  2042\n",
      "fp:  170\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3653\n",
      "tp:  1553\n",
      "fn:  197\n",
      "tn:  2010\n",
      "fp:  224\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3563\n",
      "    TRAIN | Label 2 loss: 347.1725 ; P: 0.9045 ; R: 0.9122 ; F1: 0.9084 ; Acc: 0.9183\n",
      "    TEST | Label 2 loss: 384.1028 ; P: 0.8739 ; R: 0.8874 ; F1: 0.8806 ; Acc: 0.8943\n",
      "2023-01-28 11:18:27.118937\n",
      "counter:  0\n",
      "2023-01-28 11:18:28.977859\n",
      "EPOCH 28\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1620\n",
      "fn:  146\n",
      "tn:  2080\n",
      "fp:  132\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3700\n",
      "tp:  1574\n",
      "fn:  176\n",
      "tn:  1995\n",
      "fp:  239\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3569\n",
      "    TRAIN | Label 2 loss: 335.0993 ; P: 0.9247 ; R: 0.9173 ; F1: 0.921 ; Acc: 0.9301\n",
      "    TEST | Label 2 loss: 382.2279 ; P: 0.8682 ; R: 0.8994 ; F1: 0.8835 ; Acc: 0.8958\n",
      "2023-01-28 11:21:32.871347\n",
      "counter:  0\n",
      "2023-01-28 11:21:34.740975\n",
      "EPOCH 29\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1644\n",
      "fn:  122\n",
      "tn:  2082\n",
      "fp:  130\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3726\n",
      "tp:  1582\n",
      "fn:  168\n",
      "tn:  2002\n",
      "fp:  232\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3584\n",
      "    TRAIN | Label 2 loss: 327.7608 ; P: 0.9267 ; R: 0.9309 ; F1: 0.9288 ; Acc: 0.9367\n",
      "    TEST | Label 2 loss: 379.6265 ; P: 0.8721 ; R: 0.904 ; F1: 0.8878 ; Acc: 0.8996\n",
      "2023-01-28 11:24:37.915438\n",
      "counter:  0\n",
      "2023-01-28 11:24:39.731811\n",
      "EPOCH 30\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1638\n",
      "fn:  128\n",
      "tn:  2086\n",
      "fp:  126\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3724\n",
      "tp:  1584\n",
      "fn:  166\n",
      "tn:  1997\n",
      "fp:  237\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3581\n",
      "    TRAIN | Label 2 loss: 325.6821 ; P: 0.9286 ; R: 0.9275 ; F1: 0.928 ; Acc: 0.9361\n",
      "    TEST | Label 2 loss: 378.1324 ; P: 0.8699 ; R: 0.9051 ; F1: 0.8871 ; Acc: 0.8988\n",
      "2023-01-28 11:27:43.077629\n",
      "counter:  1\n",
      "2023-01-28 11:27:43.078631\n",
      "EPOCH 31\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1647\n",
      "fn:  119\n",
      "tn:  2105\n",
      "fp:  107\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3752\n",
      "tp:  1605\n",
      "fn:  145\n",
      "tn:  1971\n",
      "fp:  263\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3576\n",
      "    TRAIN | Label 2 loss: 314.5127 ; P: 0.939 ; R: 0.9326 ; F1: 0.9358 ; Acc: 0.9432\n",
      "    TEST | Label 2 loss: 381.3041 ; P: 0.8592 ; R: 0.9171 ; F1: 0.8872 ; Acc: 0.8976\n",
      "2023-01-28 11:30:46.781859\n",
      "counter:  2\n",
      "2023-01-28 11:30:46.782859\n",
      "EPOCH 32\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1655\n",
      "fn:  111\n",
      "tn:  2116\n",
      "fp:  96\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3771\n",
      "tp:  1612\n",
      "fn:  138\n",
      "tn:  1965\n",
      "fp:  269\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3577\n",
      "    TRAIN | Label 2 loss: 304.8464 ; P: 0.9452 ; R: 0.9371 ; F1: 0.9411 ; Acc: 0.948\n",
      "    TEST | Label 2 loss: 383.5142 ; P: 0.857 ; R: 0.9211 ; F1: 0.8879 ; Acc: 0.8978\n",
      "2023-01-28 11:33:50.252790\n",
      "counter:  0\n",
      "2023-01-28 11:33:52.122825\n",
      "EPOCH 33\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1663\n",
      "fn:  103\n",
      "tn:  2104\n",
      "fp:  108\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3767\n",
      "tp:  1607\n",
      "fn:  143\n",
      "tn:  1983\n",
      "fp:  251\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3590\n",
      "    TRAIN | Label 2 loss: 304.9039 ; P: 0.939 ; R: 0.9417 ; F1: 0.9403 ; Acc: 0.947\n",
      "    TEST | Label 2 loss: 374.8302 ; P: 0.8649 ; R: 0.9183 ; F1: 0.8908 ; Acc: 0.9011\n",
      "2023-01-28 11:36:54.722316\n",
      "counter:  0\n",
      "2023-01-28 11:36:56.597608\n",
      "EPOCH 34\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1668\n",
      "fn:  98\n",
      "tn:  2100\n",
      "fp:  112\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3768\n",
      "tp:  1591\n",
      "fn:  159\n",
      "tn:  2022\n",
      "fp:  212\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3613\n",
      "    TRAIN | Label 2 loss: 301.2647 ; P: 0.9371 ; R: 0.9445 ; F1: 0.9408 ; Acc: 0.9472\n",
      "    TEST | Label 2 loss: 367.8668 ; P: 0.8824 ; R: 0.9091 ; F1: 0.8956 ; Acc: 0.9069\n",
      "2023-01-28 11:39:59.921080\n",
      "counter:  0\n",
      "2023-01-28 11:40:02.413973\n",
      "EPOCH 35\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1669\n",
      "fn:  97\n",
      "tn:  2118\n",
      "fp:  94\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3787\n",
      "tp:  1592\n",
      "fn:  158\n",
      "tn:  2026\n",
      "fp:  208\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3618\n",
      "    TRAIN | Label 2 loss: 295.8367 ; P: 0.9467 ; R: 0.9451 ; F1: 0.9459 ; Acc: 0.952\n",
      "    TEST | Label 2 loss: 365.1079 ; P: 0.8844 ; R: 0.9097 ; F1: 0.8969 ; Acc: 0.9081\n",
      "2023-01-28 11:43:05.688581\n",
      "counter:  0\n",
      "2023-01-28 11:43:07.598804\n",
      "EPOCH 36\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1683\n",
      "fn:  83\n",
      "tn:  2130\n",
      "fp:  82\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3813\n",
      "tp:  1603\n",
      "fn:  147\n",
      "tn:  2008\n",
      "fp:  226\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3611\n",
      "    TRAIN | Label 2 loss: 288.0122 ; P: 0.9535 ; R: 0.953 ; F1: 0.9533 ; Acc: 0.9585\n",
      "    TEST | Label 2 loss: 366.723 ; P: 0.8764 ; R: 0.916 ; F1: 0.8958 ; Acc: 0.9064\n",
      "2023-01-28 11:46:10.624320\n",
      "counter:  1\n",
      "2023-01-28 11:46:10.625320\n",
      "EPOCH 37\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1683\n",
      "fn:  83\n",
      "tn:  2119\n",
      "fp:  93\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3802\n",
      "tp:  1600\n",
      "fn:  150\n",
      "tn:  2020\n",
      "fp:  214\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3620\n",
      "    TRAIN | Label 2 loss: 287.4051 ; P: 0.9476 ; R: 0.953 ; F1: 0.9503 ; Acc: 0.9558\n",
      "    TEST | Label 2 loss: 364.8298 ; P: 0.882 ; R: 0.9143 ; F1: 0.8979 ; Acc: 0.9086\n",
      "2023-01-28 11:49:13.974944\n",
      "counter:  0\n",
      "2023-01-28 11:49:15.853081\n",
      "EPOCH 38\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1680\n",
      "fn:  86\n",
      "tn:  2144\n",
      "fp:  68\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3824\n",
      "tp:  1617\n",
      "fn:  133\n",
      "tn:  1994\n",
      "fp:  240\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3611\n",
      "    TRAIN | Label 2 loss: 281.5164 ; P: 0.9611 ; R: 0.9513 ; F1: 0.9562 ; Acc: 0.9613\n",
      "    TEST | Label 2 loss: 370.9823 ; P: 0.8708 ; R: 0.924 ; F1: 0.8966 ; Acc: 0.9064\n",
      "2023-01-28 11:52:19.119213\n",
      "counter:  1\n",
      "2023-01-28 11:52:19.119213\n",
      "EPOCH 39\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1691\n",
      "fn:  75\n",
      "tn:  2133\n",
      "fp:  79\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3824\n",
      "tp:  1606\n",
      "fn:  144\n",
      "tn:  2015\n",
      "fp:  219\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3621\n",
      "    TRAIN | Label 2 loss: 283.196 ; P: 0.9554 ; R: 0.9575 ; F1: 0.9564 ; Acc: 0.9613\n",
      "    TEST | Label 2 loss: 363.1846 ; P: 0.88 ; R: 0.9177 ; F1: 0.8985 ; Acc: 0.9089\n",
      "2023-01-28 11:55:22.111476\n",
      "counter:  0\n",
      "2023-01-28 11:55:23.987548\n",
      "EPOCH 40\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1702\n",
      "fn:  64\n",
      "tn:  2139\n",
      "fp:  73\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3841\n",
      "tp:  1601\n",
      "fn:  149\n",
      "tn:  2033\n",
      "fp:  201\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3634\n",
      "    TRAIN | Label 2 loss: 274.0315 ; P: 0.9589 ; R: 0.9638 ; F1: 0.9613 ; Acc: 0.9656\n",
      "    TEST | Label 2 loss: 363.0005 ; P: 0.8885 ; R: 0.9149 ; F1: 0.9015 ; Acc: 0.9121\n",
      "2023-01-28 11:58:27.069458\n",
      "counter:  0\n",
      "2023-01-28 11:58:28.909361\n",
      "EPOCH 41\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1694\n",
      "fn:  72\n",
      "tn:  2149\n",
      "fp:  63\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3843\n",
      "tp:  1619\n",
      "fn:  131\n",
      "tn:  2011\n",
      "fp:  223\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3630\n",
      "    TRAIN | Label 2 loss: 272.8464 ; P: 0.9641 ; R: 0.9592 ; F1: 0.9617 ; Acc: 0.9661\n",
      "    TEST | Label 2 loss: 363.7292 ; P: 0.8789 ; R: 0.9251 ; F1: 0.9014 ; Acc: 0.9111\n",
      "2023-01-28 12:01:31.818909\n",
      "counter:  1\n",
      "2023-01-28 12:01:31.819911\n",
      "EPOCH 42\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1708\n",
      "fn:  58\n",
      "tn:  2158\n",
      "fp:  54\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3866\n",
      "tp:  1620\n",
      "fn:  130\n",
      "tn:  2011\n",
      "fp:  223\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3631\n",
      "    TRAIN | Label 2 loss: 265.6458 ; P: 0.9694 ; R: 0.9672 ; F1: 0.9683 ; Acc: 0.9718\n",
      "    TEST | Label 2 loss: 365.3353 ; P: 0.879 ; R: 0.9257 ; F1: 0.9018 ; Acc: 0.9114\n",
      "2023-01-28 12:04:35.226451\n",
      "counter:  0\n",
      "2023-01-28 12:04:37.098089\n",
      "EPOCH 43\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1711\n",
      "fn:  55\n",
      "tn:  2155\n",
      "fp:  57\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3866\n",
      "tp:  1616\n",
      "fn:  134\n",
      "tn:  2018\n",
      "fp:  216\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3634\n",
      "    TRAIN | Label 2 loss: 265.0519 ; P: 0.9678 ; R: 0.9689 ; F1: 0.9683 ; Acc: 0.9718\n",
      "    TEST | Label 2 loss: 361.1154 ; P: 0.8821 ; R: 0.9234 ; F1: 0.9023 ; Acc: 0.9121\n",
      "2023-01-28 12:07:40.122577\n",
      "counter:  0\n",
      "2023-01-28 12:07:41.779757\n",
      "EPOCH 44\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1713\n",
      "fn:  53\n",
      "tn:  2148\n",
      "fp:  64\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3861\n",
      "tp:  1616\n",
      "fn:  134\n",
      "tn:  2018\n",
      "fp:  216\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3634\n",
      "    TRAIN | Label 2 loss: 265.4922 ; P: 0.964 ; R: 0.97 ; F1: 0.967 ; Acc: 0.9706\n",
      "    TEST | Label 2 loss: 360.1222 ; P: 0.8821 ; R: 0.9234 ; F1: 0.9023 ; Acc: 0.9121\n",
      "2023-01-28 12:10:44.604504\n",
      "counter:  0\n",
      "2023-01-28 12:10:44.605515\n",
      "EPOCH 45\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1708\n",
      "fn:  58\n",
      "tn:  2152\n",
      "fp:  60\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3860\n",
      "tp:  1616\n",
      "fn:  134\n",
      "tn:  2024\n",
      "fp:  210\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3640\n",
      "    TRAIN | Label 2 loss: 263.7019 ; P: 0.9661 ; R: 0.9672 ; F1: 0.9666 ; Acc: 0.9703\n",
      "    TEST | Label 2 loss: 358.9353 ; P: 0.885 ; R: 0.9234 ; F1: 0.9038 ; Acc: 0.9137\n",
      "2023-01-28 12:13:47.883256\n",
      "counter:  0\n",
      "2023-01-28 12:13:49.850087\n",
      "EPOCH 46\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1719\n",
      "fn:  47\n",
      "tn:  2170\n",
      "fp:  42\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3889\n",
      "tp:  1615\n",
      "fn:  135\n",
      "tn:  2035\n",
      "fp:  199\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3650\n",
      "    TRAIN | Label 2 loss: 255.9674 ; P: 0.9761 ; R: 0.9734 ; F1: 0.9748 ; Acc: 0.9776\n",
      "    TEST | Label 2 loss: 355.8568 ; P: 0.8903 ; R: 0.9229 ; F1: 0.9063 ; Acc: 0.9162\n",
      "2023-01-28 12:16:52.595246\n",
      "counter:  0\n",
      "2023-01-28 12:16:54.436224\n",
      "EPOCH 47\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1717\n",
      "fn:  49\n",
      "tn:  2168\n",
      "fp:  44\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3885\n",
      "tp:  1621\n",
      "fn:  129\n",
      "tn:  2016\n",
      "fp:  218\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3637\n",
      "    TRAIN | Label 2 loss: 256.87 ; P: 0.975 ; R: 0.9723 ; F1: 0.9736 ; Acc: 0.9766\n",
      "    TEST | Label 2 loss: 359.117 ; P: 0.8815 ; R: 0.9263 ; F1: 0.9033 ; Acc: 0.9129\n",
      "2023-01-28 12:19:56.645171\n",
      "counter:  1\n",
      "2023-01-28 12:19:56.645171\n",
      "EPOCH 48\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1719\n",
      "fn:  47\n",
      "tn:  2173\n",
      "fp:  39\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3892\n",
      "tp:  1621\n",
      "fn:  129\n",
      "tn:  2019\n",
      "fp:  215\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3640\n",
      "    TRAIN | Label 2 loss: 253.0076 ; P: 0.9778 ; R: 0.9734 ; F1: 0.9756 ; Acc: 0.9784\n",
      "    TEST | Label 2 loss: 359.5688 ; P: 0.8829 ; R: 0.9263 ; F1: 0.9041 ; Acc: 0.9137\n",
      "2023-01-28 12:22:59.659488\n",
      "counter:  2\n",
      "2023-01-28 12:22:59.660479\n",
      "EPOCH 49\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1722\n",
      "fn:  44\n",
      "tn:  2177\n",
      "fp:  35\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3899\n",
      "tp:  1622\n",
      "fn:  128\n",
      "tn:  2027\n",
      "fp:  207\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3649\n",
      "    TRAIN | Label 2 loss: 248.4149 ; P: 0.9801 ; R: 0.9751 ; F1: 0.9776 ; Acc: 0.9801\n",
      "    TEST | Label 2 loss: 357.7515 ; P: 0.8868 ; R: 0.9269 ; F1: 0.9064 ; Acc: 0.9159\n",
      "2023-01-28 12:26:02.733432\n",
      "counter:  0\n",
      "2023-01-28 12:26:04.598094\n",
      "EPOCH 50\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1731\n",
      "fn:  35\n",
      "tn:  2169\n",
      "fp:  43\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3900\n",
      "tp:  1608\n",
      "fn:  142\n",
      "tn:  2048\n",
      "fp:  186\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3656\n",
      "    TRAIN | Label 2 loss: 247.441 ; P: 0.9758 ; R: 0.9802 ; F1: 0.978 ; Acc: 0.9804\n",
      "    TEST | Label 2 loss: 352.1427 ; P: 0.8963 ; R: 0.9189 ; F1: 0.9074 ; Acc: 0.9177\n",
      "2023-01-28 12:29:08.039755\n",
      "counter:  0\n",
      "2023-01-28 12:29:09.885863\n",
      "EPOCH 51\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1726\n",
      "fn:  40\n",
      "tn:  2174\n",
      "fp:  38\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3900\n",
      "tp:  1620\n",
      "fn:  130\n",
      "tn:  2023\n",
      "fp:  211\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3643\n",
      "    TRAIN | Label 2 loss: 247.7269 ; P: 0.9785 ; R: 0.9773 ; F1: 0.9779 ; Acc: 0.9804\n",
      "    TEST | Label 2 loss: 356.8841 ; P: 0.8848 ; R: 0.9257 ; F1: 0.9048 ; Acc: 0.9144\n",
      "2023-01-28 12:32:12.821309\n",
      "counter:  1\n",
      "2023-01-28 12:32:12.823273\n",
      "EPOCH 52\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1730\n",
      "fn:  36\n",
      "tn:  2181\n",
      "fp:  31\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3911\n",
      "tp:  1617\n",
      "fn:  133\n",
      "tn:  2037\n",
      "fp:  197\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3654\n",
      "    TRAIN | Label 2 loss: 243.3474 ; P: 0.9824 ; R: 0.9796 ; F1: 0.981 ; Acc: 0.9832\n",
      "    TEST | Label 2 loss: 356.5305 ; P: 0.8914 ; R: 0.924 ; F1: 0.9074 ; Acc: 0.9172\n",
      "2023-01-28 12:35:15.732111\n",
      "counter:  0\n",
      "2023-01-28 12:35:15.732111\n",
      "EPOCH 53\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1726\n",
      "fn:  40\n",
      "tn:  2184\n",
      "fp:  28\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3910\n",
      "tp:  1621\n",
      "fn:  129\n",
      "tn:  2024\n",
      "fp:  210\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3645\n",
      "    TRAIN | Label 2 loss: 241.734 ; P: 0.984 ; R: 0.9773 ; F1: 0.9807 ; Acc: 0.9829\n",
      "    TEST | Label 2 loss: 360.3156 ; P: 0.8853 ; R: 0.9263 ; F1: 0.9053 ; Acc: 0.9149\n",
      "2023-01-28 12:38:18.234450\n",
      "counter:  1\n",
      "2023-01-28 12:38:18.234450\n",
      "EPOCH 54\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1736\n",
      "fn:  30\n",
      "tn:  2186\n",
      "fp:  26\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3922\n",
      "tp:  1616\n",
      "fn:  134\n",
      "tn:  2039\n",
      "fp:  195\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3655\n",
      "    TRAIN | Label 2 loss: 240.0997 ; P: 0.9852 ; R: 0.983 ; F1: 0.9841 ; Acc: 0.9859\n",
      "    TEST | Label 2 loss: 355.0175 ; P: 0.8923 ; R: 0.9234 ; F1: 0.9076 ; Acc: 0.9174\n",
      "2023-01-28 12:41:21.778198\n",
      "counter:  0\n",
      "2023-01-28 12:41:23.491808\n",
      "EPOCH 55\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1738\n",
      "fn:  28\n",
      "tn:  2184\n",
      "fp:  28\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3922\n",
      "tp:  1623\n",
      "fn:  127\n",
      "tn:  2032\n",
      "fp:  202\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3655\n",
      "    TRAIN | Label 2 loss: 240.3358 ; P: 0.9841 ; R: 0.9841 ; F1: 0.9841 ; Acc: 0.9859\n",
      "    TEST | Label 2 loss: 356.5446 ; P: 0.8893 ; R: 0.9274 ; F1: 0.908 ; Acc: 0.9174\n",
      "2023-01-28 12:44:27.021492\n",
      "counter:  0\n",
      "2023-01-28 12:44:28.847230\n",
      "EPOCH 56\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1734\n",
      "fn:  32\n",
      "tn:  2176\n",
      "fp:  36\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3910\n",
      "tp:  1616\n",
      "fn:  134\n",
      "tn:  2041\n",
      "fp:  193\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3657\n",
      "    TRAIN | Label 2 loss: 240.4948 ; P: 0.9797 ; R: 0.9819 ; F1: 0.9808 ; Acc: 0.9829\n",
      "    TEST | Label 2 loss: 353.6935 ; P: 0.8933 ; R: 0.9234 ; F1: 0.9081 ; Acc: 0.9179\n",
      "2023-01-28 12:47:31.884587\n",
      "counter:  0\n",
      "2023-01-28 12:47:33.773042\n",
      "EPOCH 57\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1742\n",
      "fn:  24\n",
      "tn:  2178\n",
      "fp:  34\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3920\n",
      "tp:  1618\n",
      "fn:  132\n",
      "tn:  2043\n",
      "fp:  191\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3661\n",
      "    TRAIN | Label 2 loss: 239.1586 ; P: 0.9809 ; R: 0.9864 ; F1: 0.9836 ; Acc: 0.9854\n",
      "    TEST | Label 2 loss: 353.9482 ; P: 0.8944 ; R: 0.9246 ; F1: 0.9092 ; Acc: 0.9189\n",
      "2023-01-28 12:50:36.624585\n",
      "counter:  0\n",
      "2023-01-28 12:50:38.519151\n",
      "EPOCH 58\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1743\n",
      "fn:  23\n",
      "tn:  2194\n",
      "fp:  18\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3937\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2030\n",
      "fp:  204\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3656\n",
      "    TRAIN | Label 2 loss: 232.7453 ; P: 0.9898 ; R: 0.987 ; F1: 0.9884 ; Acc: 0.9897\n",
      "    TEST | Label 2 loss: 357.6314 ; P: 0.8885 ; R: 0.9291 ; F1: 0.9084 ; Acc: 0.9177\n",
      "2023-01-28 12:53:41.155951\n",
      "counter:  1\n",
      "2023-01-28 12:53:41.156949\n",
      "EPOCH 59\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1739\n",
      "fn:  27\n",
      "tn:  2186\n",
      "fp:  26\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3925\n",
      "tp:  1616\n",
      "fn:  134\n",
      "tn:  2045\n",
      "fp:  189\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3661\n",
      "    TRAIN | Label 2 loss: 235.0145 ; P: 0.9853 ; R: 0.9847 ; F1: 0.985 ; Acc: 0.9867\n",
      "    TEST | Label 2 loss: 353.1302 ; P: 0.8953 ; R: 0.9234 ; F1: 0.9091 ; Acc: 0.9189\n",
      "2023-01-28 12:56:43.733410\n",
      "counter:  2\n",
      "2023-01-28 12:56:43.734410\n",
      "EPOCH 60\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1743\n",
      "fn:  23\n",
      "tn:  2188\n",
      "fp:  24\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3931\n",
      "tp:  1631\n",
      "fn:  119\n",
      "tn:  2026\n",
      "fp:  208\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3657\n",
      "    TRAIN | Label 2 loss: 234.1991 ; P: 0.9864 ; R: 0.987 ; F1: 0.9867 ; Acc: 0.9882\n",
      "    TEST | Label 2 loss: 356.8519 ; P: 0.8869 ; R: 0.932 ; F1: 0.9089 ; Acc: 0.9179\n",
      "2023-01-28 12:59:47.630075\n",
      "counter:  3\n",
      "2023-01-28 12:59:47.630075\n",
      "EPOCH 61\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1739\n",
      "fn:  27\n",
      "tn:  2187\n",
      "fp:  25\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3926\n",
      "tp:  1631\n",
      "fn:  119\n",
      "tn:  2029\n",
      "fp:  205\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3660\n",
      "    TRAIN | Label 2 loss: 234.0179 ; P: 0.9858 ; R: 0.9847 ; F1: 0.9853 ; Acc: 0.9869\n",
      "    TEST | Label 2 loss: 354.5357 ; P: 0.8883 ; R: 0.932 ; F1: 0.9096 ; Acc: 0.9187\n",
      "2023-01-28 13:02:51.714636\n",
      "counter:  0\n",
      "2023-01-28 13:02:53.587309\n",
      "EPOCH 62\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1743\n",
      "fn:  23\n",
      "tn:  2191\n",
      "fp:  21\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3934\n",
      "tp:  1633\n",
      "fn:  117\n",
      "tn:  2021\n",
      "fp:  213\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3654\n",
      "    TRAIN | Label 2 loss: 233.1985 ; P: 0.9881 ; R: 0.987 ; F1: 0.9875 ; Acc: 0.9889\n",
      "    TEST | Label 2 loss: 358.2852 ; P: 0.8846 ; R: 0.9331 ; F1: 0.9082 ; Acc: 0.9172\n",
      "2023-01-28 13:05:56.907560\n",
      "counter:  1\n",
      "2023-01-28 13:05:56.908560\n",
      "EPOCH 63\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1747\n",
      "fn:  19\n",
      "tn:  2186\n",
      "fp:  26\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3933\n",
      "tp:  1631\n",
      "fn:  119\n",
      "tn:  2033\n",
      "fp:  201\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3664\n",
      "    TRAIN | Label 2 loss: 232.5964 ; P: 0.9853 ; R: 0.9892 ; F1: 0.9873 ; Acc: 0.9887\n",
      "    TEST | Label 2 loss: 354.5917 ; P: 0.8903 ; R: 0.932 ; F1: 0.9107 ; Acc: 0.9197\n",
      "2023-01-28 13:08:59.183721\n",
      "counter:  0\n",
      "2023-01-28 13:09:01.304543\n",
      "EPOCH 64\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1745\n",
      "fn:  21\n",
      "tn:  2190\n",
      "fp:  22\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3935\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2038\n",
      "fp:  196\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3663\n",
      "    TRAIN | Label 2 loss: 231.5797 ; P: 0.9875 ; R: 0.9881 ; F1: 0.9878 ; Acc: 0.9892\n",
      "    TEST | Label 2 loss: 353.5877 ; P: 0.8924 ; R: 0.9286 ; F1: 0.9101 ; Acc: 0.9194\n",
      "2023-01-28 13:12:04.461266\n",
      "counter:  1\n",
      "2023-01-28 13:12:04.462238\n",
      "EPOCH 65\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1741\n",
      "fn:  25\n",
      "tn:  2189\n",
      "fp:  23\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3930\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2039\n",
      "fp:  195\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3664\n",
      "    TRAIN | Label 2 loss: 231.5584 ; P: 0.987 ; R: 0.9858 ; F1: 0.9864 ; Acc: 0.9879\n",
      "    TEST | Label 2 loss: 352.1331 ; P: 0.8929 ; R: 0.9286 ; F1: 0.9104 ; Acc: 0.9197\n",
      "2023-01-28 13:15:07.678541\n",
      "counter:  2\n",
      "2023-01-28 13:15:07.680586\n",
      "EPOCH 66\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1749\n",
      "fn:  17\n",
      "tn:  2201\n",
      "fp:  11\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3950\n",
      "tp:  1631\n",
      "fn:  119\n",
      "tn:  2027\n",
      "fp:  207\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3658\n",
      "    TRAIN | Label 2 loss: 227.4927 ; P: 0.9937 ; R: 0.9904 ; F1: 0.9921 ; Acc: 0.993\n",
      "    TEST | Label 2 loss: 356.9117 ; P: 0.8874 ; R: 0.932 ; F1: 0.9091 ; Acc: 0.9182\n",
      "2023-01-28 13:18:10.955631\n",
      "counter:  3\n",
      "2023-01-28 13:18:10.956631\n",
      "EPOCH 67\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1747\n",
      "fn:  19\n",
      "tn:  2200\n",
      "fp:  12\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3947\n",
      "tp:  1633\n",
      "fn:  117\n",
      "tn:  2031\n",
      "fp:  203\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3664\n",
      "    TRAIN | Label 2 loss: 227.4492 ; P: 0.9932 ; R: 0.9892 ; F1: 0.9912 ; Acc: 0.9922\n",
      "    TEST | Label 2 loss: 355.6668 ; P: 0.8894 ; R: 0.9331 ; F1: 0.9108 ; Acc: 0.9197\n",
      "2023-01-28 13:21:14.308639\n",
      "counter:  0\n",
      "2023-01-28 13:21:16.186632\n",
      "EPOCH 68\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1744\n",
      "fn:  22\n",
      "tn:  2196\n",
      "fp:  16\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3940\n",
      "tp:  1634\n",
      "fn:  116\n",
      "tn:  2029\n",
      "fp:  205\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3663\n",
      "    TRAIN | Label 2 loss: 229.9235 ; P: 0.9909 ; R: 0.9875 ; F1: 0.9892 ; Acc: 0.9904\n",
      "    TEST | Label 2 loss: 355.8389 ; P: 0.8885 ; R: 0.9337 ; F1: 0.9106 ; Acc: 0.9194\n",
      "2023-01-28 13:24:20.459581\n",
      "counter:  1\n",
      "2023-01-28 13:24:20.460586\n",
      "EPOCH 69\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1749\n",
      "fn:  17\n",
      "tn:  2194\n",
      "fp:  18\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3943\n",
      "tp:  1629\n",
      "fn:  121\n",
      "tn:  2032\n",
      "fp:  202\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3661\n",
      "    TRAIN | Label 2 loss: 228.8534 ; P: 0.9898 ; R: 0.9904 ; F1: 0.9901 ; Acc: 0.9912\n",
      "    TEST | Label 2 loss: 355.4138 ; P: 0.8897 ; R: 0.9309 ; F1: 0.9098 ; Acc: 0.9189\n",
      "2023-01-28 13:27:23.182319\n",
      "counter:  2\n",
      "2023-01-28 13:27:23.183309\n",
      "EPOCH 70\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1745\n",
      "fn:  21\n",
      "tn:  2197\n",
      "fp:  15\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3942\n",
      "tp:  1630\n",
      "fn:  120\n",
      "tn:  2029\n",
      "fp:  205\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3659\n",
      "    TRAIN | Label 2 loss: 228.6227 ; P: 0.9915 ; R: 0.9881 ; F1: 0.9898 ; Acc: 0.991\n",
      "    TEST | Label 2 loss: 356.2316 ; P: 0.8883 ; R: 0.9314 ; F1: 0.9093 ; Acc: 0.9184\n",
      "2023-01-28 13:30:26.761612\n",
      "counter:  3\n",
      "2023-01-28 13:30:26.762618\n",
      "EPOCH 71\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1749\n",
      "fn:  17\n",
      "tn:  2198\n",
      "fp:  14\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3947\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2040\n",
      "fp:  194\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3666\n",
      "    TRAIN | Label 2 loss: 226.2135 ; P: 0.9921 ; R: 0.9904 ; F1: 0.9912 ; Acc: 0.9922\n",
      "    TEST | Label 2 loss: 353.3644 ; P: 0.8934 ; R: 0.9291 ; F1: 0.9109 ; Acc: 0.9202\n",
      "2023-01-28 13:33:30.130247\n",
      "counter:  0\n",
      "2023-01-28 13:33:31.996216\n",
      "EPOCH 72\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1748\n",
      "fn:  18\n",
      "tn:  2203\n",
      "fp:  9\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3951\n",
      "tp:  1629\n",
      "fn:  121\n",
      "tn:  2029\n",
      "fp:  205\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3658\n",
      "    TRAIN | Label 2 loss: 226.5596 ; P: 0.9949 ; R: 0.9898 ; F1: 0.9923 ; Acc: 0.9932\n",
      "    TEST | Label 2 loss: 355.6809 ; P: 0.8882 ; R: 0.9309 ; F1: 0.909 ; Acc: 0.9182\n",
      "2023-01-28 13:36:35.736663\n",
      "counter:  1\n",
      "2023-01-28 13:36:35.736663\n",
      "EPOCH 73\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1745\n",
      "fn:  21\n",
      "tn:  2195\n",
      "fp:  17\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3940\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2042\n",
      "fp:  192\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3668\n",
      "    TRAIN | Label 2 loss: 227.1487 ; P: 0.9904 ; R: 0.9881 ; F1: 0.9892 ; Acc: 0.9904\n",
      "    TEST | Label 2 loss: 352.8996 ; P: 0.8944 ; R: 0.9291 ; F1: 0.9114 ; Acc: 0.9207\n",
      "2023-01-28 13:39:39.487975\n",
      "counter:  0\n",
      "2023-01-28 13:39:41.267811\n",
      "EPOCH 74\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1753\n",
      "fn:  13\n",
      "tn:  2201\n",
      "fp:  11\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3954\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2039\n",
      "fp:  195\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3665\n",
      "    TRAIN | Label 2 loss: 223.6474 ; P: 0.9938 ; R: 0.9926 ; F1: 0.9932 ; Acc: 0.994\n",
      "    TEST | Label 2 loss: 352.4388 ; P: 0.8929 ; R: 0.9291 ; F1: 0.9107 ; Acc: 0.9199\n",
      "2023-01-28 13:42:44.752430\n",
      "counter:  1\n",
      "2023-01-28 13:42:44.753430\n",
      "EPOCH 75\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1750\n",
      "fn:  16\n",
      "tn:  2201\n",
      "fp:  11\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3951\n",
      "tp:  1629\n",
      "fn:  121\n",
      "tn:  2037\n",
      "fp:  197\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3666\n",
      "    TRAIN | Label 2 loss: 223.9694 ; P: 0.9938 ; R: 0.9909 ; F1: 0.9923 ; Acc: 0.9932\n",
      "    TEST | Label 2 loss: 353.4954 ; P: 0.8921 ; R: 0.9309 ; F1: 0.9111 ; Acc: 0.9202\n",
      "2023-01-28 13:45:47.715479\n",
      "counter:  2\n",
      "2023-01-28 13:45:47.715479\n",
      "EPOCH 76\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1753\n",
      "fn:  13\n",
      "tn:  2194\n",
      "fp:  18\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3947\n",
      "tp:  1621\n",
      "fn:  129\n",
      "tn:  2053\n",
      "fp:  181\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3674\n",
      "    TRAIN | Label 2 loss: 224.0889 ; P: 0.9898 ; R: 0.9926 ; F1: 0.9912 ; Acc: 0.9922\n",
      "    TEST | Label 2 loss: 349.6851 ; P: 0.8996 ; R: 0.9263 ; F1: 0.9127 ; Acc: 0.9222\n",
      "2023-01-28 13:48:50.210657\n",
      "counter:  0\n",
      "2023-01-28 13:48:52.072326\n",
      "EPOCH 77\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1745\n",
      "fn:  21\n",
      "tn:  2197\n",
      "fp:  15\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3942\n",
      "tp:  1629\n",
      "fn:  121\n",
      "tn:  2040\n",
      "fp:  194\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3669\n",
      "    TRAIN | Label 2 loss: 225.8446 ; P: 0.9915 ; R: 0.9881 ; F1: 0.9898 ; Acc: 0.991\n",
      "    TEST | Label 2 loss: 352.3662 ; P: 0.8936 ; R: 0.9309 ; F1: 0.9118 ; Acc: 0.9209\n",
      "2023-01-28 13:51:55.160127\n",
      "counter:  1\n",
      "2023-01-28 13:51:55.160127\n",
      "EPOCH 78\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1750\n",
      "fn:  16\n",
      "tn:  2200\n",
      "fp:  12\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3950\n",
      "tp:  1628\n",
      "fn:  122\n",
      "tn:  2039\n",
      "fp:  195\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 226.1685 ; P: 0.9932 ; R: 0.9909 ; F1: 0.9921 ; Acc: 0.993\n",
      "    TEST | Label 2 loss: 352.0787 ; P: 0.893 ; R: 0.9303 ; F1: 0.9113 ; Acc: 0.9204\n",
      "2023-01-28 13:54:59.021679\n",
      "counter:  2\n",
      "2023-01-28 13:54:59.021679\n",
      "EPOCH 79\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1750\n",
      "fn:  16\n",
      "tn:  2203\n",
      "fp:  9\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3953\n",
      "tp:  1624\n",
      "fn:  126\n",
      "tn:  2039\n",
      "fp:  195\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3663\n",
      "    TRAIN | Label 2 loss: 223.4988 ; P: 0.9949 ; R: 0.9909 ; F1: 0.9929 ; Acc: 0.9937\n",
      "    TEST | Label 2 loss: 352.0013 ; P: 0.8928 ; R: 0.928 ; F1: 0.9101 ; Acc: 0.9194\n",
      "2023-01-28 13:58:01.868902\n",
      "counter:  3\n",
      "2023-01-28 13:58:01.869903\n",
      "EPOCH 80\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1752\n",
      "fn:  14\n",
      "tn:  2197\n",
      "fp:  15\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3949\n",
      "tp:  1624\n",
      "fn:  126\n",
      "tn:  2044\n",
      "fp:  190\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3668\n",
      "    TRAIN | Label 2 loss: 223.9233 ; P: 0.9915 ; R: 0.9921 ; F1: 0.9918 ; Acc: 0.9927\n",
      "    TEST | Label 2 loss: 351.2977 ; P: 0.8953 ; R: 0.928 ; F1: 0.9113 ; Acc: 0.9207\n",
      "2023-01-28 14:01:05.590160\n",
      "counter:  4\n",
      "2023-01-28 14:01:05.590160\n",
      "EPOCH 81\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1750\n",
      "fn:  16\n",
      "tn:  2204\n",
      "fp:  8\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3954\n",
      "tp:  1631\n",
      "fn:  119\n",
      "tn:  2039\n",
      "fp:  195\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3670\n",
      "    TRAIN | Label 2 loss: 223.0412 ; P: 0.9954 ; R: 0.9909 ; F1: 0.9932 ; Acc: 0.994\n",
      "    TEST | Label 2 loss: 352.6642 ; P: 0.8932 ; R: 0.932 ; F1: 0.9122 ; Acc: 0.9212\n",
      "2023-01-28 14:04:09.164831\n",
      "counter:  5\n",
      "2023-01-28 14:04:09.165847\n",
      "EPOCH 82\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1756\n",
      "fn:  10\n",
      "tn:  2199\n",
      "fp:  13\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3955\n",
      "tp:  1632\n",
      "fn:  118\n",
      "tn:  2036\n",
      "fp:  198\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3668\n",
      "    TRAIN | Label 2 loss: 222.9122 ; P: 0.9927 ; R: 0.9943 ; F1: 0.9935 ; Acc: 0.9942\n",
      "    TEST | Label 2 loss: 352.557 ; P: 0.8918 ; R: 0.9326 ; F1: 0.9117 ; Acc: 0.9207\n",
      "2023-01-28 14:07:11.868697\n",
      "counter:  6\n",
      "2023-01-28 14:07:11.869690\n",
      "EPOCH 83\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1751\n",
      "fn:  15\n",
      "tn:  2202\n",
      "fp:  10\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3953\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2042\n",
      "fp:  192\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 222.5979 ; P: 0.9943 ; R: 0.9915 ; F1: 0.9929 ; Acc: 0.9937\n",
      "    TEST | Label 2 loss: 350.2735 ; P: 0.8943 ; R: 0.9286 ; F1: 0.9111 ; Acc: 0.9204\n",
      "2023-01-28 14:10:14.719149\n",
      "counter:  7\n",
      "2023-01-28 14:10:14.720152\n",
      "EPOCH 84\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1749\n",
      "fn:  17\n",
      "tn:  2196\n",
      "fp:  16\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3945\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2040\n",
      "fp:  194\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 225.4725 ; P: 0.9909 ; R: 0.9904 ; F1: 0.9907 ; Acc: 0.9917\n",
      "    TEST | Label 2 loss: 351.1474 ; P: 0.8935 ; R: 0.9297 ; F1: 0.9112 ; Acc: 0.9204\n",
      "2023-01-28 14:13:17.962002\n",
      "counter:  8\n",
      "2023-01-28 14:13:17.963002\n",
      "EPOCH 85\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1755\n",
      "fn:  11\n",
      "tn:  2198\n",
      "fp:  14\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3953\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2042\n",
      "fp:  192\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3668\n",
      "    TRAIN | Label 2 loss: 222.6444 ; P: 0.9921 ; R: 0.9938 ; F1: 0.9929 ; Acc: 0.9937\n",
      "    TEST | Label 2 loss: 350.6202 ; P: 0.8944 ; R: 0.9291 ; F1: 0.9114 ; Acc: 0.9207\n",
      "2023-01-28 14:16:21.581418\n",
      "counter:  9\n",
      "2023-01-28 14:16:21.582399\n",
      "EPOCH 86\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1755\n",
      "fn:  11\n",
      "tn:  2199\n",
      "fp:  13\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3954\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2040\n",
      "fp:  194\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3666\n",
      "    TRAIN | Label 2 loss: 223.5317 ; P: 0.9926 ; R: 0.9938 ; F1: 0.9932 ; Acc: 0.994\n",
      "    TEST | Label 2 loss: 350.557 ; P: 0.8934 ; R: 0.9291 ; F1: 0.9109 ; Acc: 0.9202\n",
      "2023-01-28 14:19:25.022696\n",
      "counter:  10\n",
      "2023-01-28 14:19:25.022696\n",
      "EPOCH 87\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1756\n",
      "fn:  10\n",
      "tn:  2204\n",
      "fp:  8\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3960\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2040\n",
      "fp:  194\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 220.8106 ; P: 0.9955 ; R: 0.9943 ; F1: 0.9949 ; Acc: 0.9955\n",
      "    TEST | Label 2 loss: 351.6021 ; P: 0.8935 ; R: 0.9297 ; F1: 0.9112 ; Acc: 0.9204\n",
      "2023-01-28 14:22:28.285870\n",
      "counter:  11\n",
      "2023-01-28 14:22:28.286870\n",
      "EPOCH 88\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1751\n",
      "fn:  15\n",
      "tn:  2204\n",
      "fp:  8\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3955\n",
      "tp:  1628\n",
      "fn:  122\n",
      "tn:  2041\n",
      "fp:  193\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3669\n",
      "    TRAIN | Label 2 loss: 221.9586 ; P: 0.9955 ; R: 0.9915 ; F1: 0.9935 ; Acc: 0.9942\n",
      "    TEST | Label 2 loss: 352.2369 ; P: 0.894 ; R: 0.9303 ; F1: 0.9118 ; Acc: 0.9209\n",
      "2023-01-28 14:25:31.475082\n",
      "counter:  12\n",
      "2023-01-28 14:25:31.477065\n",
      "EPOCH 89\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1754\n",
      "fn:  12\n",
      "tn:  2200\n",
      "fp:  12\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3954\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2041\n",
      "fp:  193\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 220.3646 ; P: 0.9932 ; R: 0.9932 ; F1: 0.9932 ; Acc: 0.994\n",
      "    TEST | Label 2 loss: 351.666 ; P: 0.8939 ; R: 0.9291 ; F1: 0.9112 ; Acc: 0.9204\n",
      "2023-01-28 14:28:34.390225\n",
      "counter:  13\n",
      "2023-01-28 14:28:34.391146\n",
      "EPOCH 90\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1755\n",
      "fn:  11\n",
      "tn:  2199\n",
      "fp:  13\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3954\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2041\n",
      "fp:  193\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 221.4453 ; P: 0.9926 ; R: 0.9938 ; F1: 0.9932 ; Acc: 0.994\n",
      "    TEST | Label 2 loss: 351.7064 ; P: 0.8939 ; R: 0.9291 ; F1: 0.9112 ; Acc: 0.9204\n",
      "2023-01-28 14:31:37.740061\n",
      "counter:  14\n",
      "2023-01-28 14:31:37.741051\n",
      "EPOCH 91\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1751\n",
      "fn:  15\n",
      "tn:  2202\n",
      "fp:  10\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3953\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2041\n",
      "fp:  193\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 222.0054 ; P: 0.9943 ; R: 0.9915 ; F1: 0.9929 ; Acc: 0.9937\n",
      "    TEST | Label 2 loss: 352.109 ; P: 0.8939 ; R: 0.9291 ; F1: 0.9112 ; Acc: 0.9204\n",
      "2023-01-28 14:34:41.511106\n",
      "counter:  15\n",
      "2023-01-28 14:34:41.512210\n",
      "EPOCH 92\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1752\n",
      "fn:  14\n",
      "tn:  2200\n",
      "fp:  12\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3952\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2040\n",
      "fp:  194\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 222.5386 ; P: 0.9932 ; R: 0.9921 ; F1: 0.9926 ; Acc: 0.9935\n",
      "    TEST | Label 2 loss: 351.9751 ; P: 0.8935 ; R: 0.9297 ; F1: 0.9112 ; Acc: 0.9204\n",
      "2023-01-28 14:37:45.971608\n",
      "counter:  16\n",
      "2023-01-28 14:37:45.972598\n",
      "EPOCH 93\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1756\n",
      "fn:  10\n",
      "tn:  2198\n",
      "fp:  14\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3954\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2041\n",
      "fp:  193\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3668\n",
      "    TRAIN | Label 2 loss: 221.9563 ; P: 0.9921 ; R: 0.9943 ; F1: 0.9932 ; Acc: 0.994\n",
      "    TEST | Label 2 loss: 351.8595 ; P: 0.894 ; R: 0.9297 ; F1: 0.9115 ; Acc: 0.9207\n",
      "2023-01-28 14:40:48.437963\n",
      "counter:  17\n",
      "2023-01-28 14:40:48.438956\n",
      "EPOCH 94\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1756\n",
      "fn:  10\n",
      "tn:  2205\n",
      "fp:  7\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3961\n",
      "tp:  1628\n",
      "fn:  122\n",
      "tn:  2040\n",
      "fp:  194\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3668\n",
      "    TRAIN | Label 2 loss: 220.8299 ; P: 0.996 ; R: 0.9943 ; F1: 0.9952 ; Acc: 0.9957\n",
      "    TEST | Label 2 loss: 352.0163 ; P: 0.8935 ; R: 0.9303 ; F1: 0.9115 ; Acc: 0.9207\n",
      "2023-01-28 14:43:50.830245\n",
      "counter:  18\n",
      "2023-01-28 14:43:50.831245\n",
      "EPOCH 95\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1751\n",
      "fn:  15\n",
      "tn:  2202\n",
      "fp:  10\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3953\n",
      "tp:  1628\n",
      "fn:  122\n",
      "tn:  2040\n",
      "fp:  194\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3668\n",
      "    TRAIN | Label 2 loss: 221.1571 ; P: 0.9943 ; R: 0.9915 ; F1: 0.9929 ; Acc: 0.9937\n",
      "    TEST | Label 2 loss: 351.9842 ; P: 0.8935 ; R: 0.9303 ; F1: 0.9115 ; Acc: 0.9207\n",
      "2023-01-28 14:46:53.507874\n",
      "counter:  19\n",
      "2023-01-28 14:46:53.507874\n",
      "EPOCH 96\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1753\n",
      "fn:  13\n",
      "tn:  2203\n",
      "fp:  9\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3956\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2040\n",
      "fp:  194\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 222.2937 ; P: 0.9949 ; R: 0.9926 ; F1: 0.9938 ; Acc: 0.9945\n",
      "    TEST | Label 2 loss: 351.9138 ; P: 0.8935 ; R: 0.9297 ; F1: 0.9112 ; Acc: 0.9204\n",
      "2023-01-28 14:49:56.735411\n",
      "counter:  20\n",
      "2023-01-28 14:49:56.735411\n",
      "EPOCH 97\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1753\n",
      "fn:  13\n",
      "tn:  2198\n",
      "fp:  14\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3951\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2040\n",
      "fp:  194\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 221.2652 ; P: 0.9921 ; R: 0.9926 ; F1: 0.9924 ; Acc: 0.9932\n",
      "    TEST | Label 2 loss: 351.8203 ; P: 0.8935 ; R: 0.9297 ; F1: 0.9112 ; Acc: 0.9204\n",
      "2023-01-28 14:53:00.120177\n",
      "counter:  21\n",
      "2023-01-28 14:53:00.121090\n",
      "EPOCH 98\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1753\n",
      "fn:  13\n",
      "tn:  2198\n",
      "fp:  14\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3951\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2040\n",
      "fp:  194\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 222.2186 ; P: 0.9921 ; R: 0.9926 ; F1: 0.9924 ; Acc: 0.9932\n",
      "    TEST | Label 2 loss: 351.7543 ; P: 0.8935 ; R: 0.9297 ; F1: 0.9112 ; Acc: 0.9204\n",
      "2023-01-28 14:56:03.498288\n",
      "counter:  22\n",
      "2023-01-28 14:56:03.498288\n",
      "EPOCH 99\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1752\n",
      "fn:  14\n",
      "tn:  2203\n",
      "fp:  9\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3955\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2040\n",
      "fp:  194\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 221.0621 ; P: 0.9949 ; R: 0.9921 ; F1: 0.9935 ; Acc: 0.9942\n",
      "    TEST | Label 2 loss: 351.7636 ; P: 0.8935 ; R: 0.9297 ; F1: 0.9112 ; Acc: 0.9204\n",
      "2023-01-28 14:59:06.822674\n",
      "counter:  23\n",
      "2023-01-28 14:59:06.822674\n",
      "EPOCH 100\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1752\n",
      "fn:  14\n",
      "tn:  2199\n",
      "fp:  13\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3951\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2041\n",
      "fp:  193\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3668\n",
      "    TRAIN | Label 2 loss: 222.8601 ; P: 0.9926 ; R: 0.9921 ; F1: 0.9924 ; Acc: 0.9932\n",
      "    TEST | Label 2 loss: 351.7536 ; P: 0.894 ; R: 0.9297 ; F1: 0.9115 ; Acc: 0.9207\n",
      "2023-01-28 15:02:09.571553\n",
      "counter:  24\n",
      "2023-01-28 15:02:09.572559\n",
      "EPOCH 101\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1754\n",
      "fn:  12\n",
      "tn:  2195\n",
      "fp:  17\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3949\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2040\n",
      "fp:  194\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 224.4558 ; P: 0.9904 ; R: 0.9932 ; F1: 0.9918 ; Acc: 0.9927\n",
      "    TEST | Label 2 loss: 351.7607 ; P: 0.8935 ; R: 0.9297 ; F1: 0.9112 ; Acc: 0.9204\n",
      "2023-01-28 15:05:12.500404\n",
      "counter:  25\n",
      "2023-01-28 15:05:12.500404\n",
      "EPOCH 102\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1754\n",
      "fn:  12\n",
      "tn:  2202\n",
      "fp:  10\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3956\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2041\n",
      "fp:  193\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 221.0918 ; P: 0.9943 ; R: 0.9932 ; F1: 0.9938 ; Acc: 0.9945\n",
      "    TEST | Label 2 loss: 351.7652 ; P: 0.8939 ; R: 0.9291 ; F1: 0.9112 ; Acc: 0.9204\n",
      "2023-01-28 15:08:16.504099\n",
      "counter:  26\n",
      "2023-01-28 15:08:16.505093\n",
      "EPOCH 103\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1757\n",
      "fn:  9\n",
      "tn:  2204\n",
      "fp:  8\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3961\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2041\n",
      "fp:  193\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3668\n",
      "    TRAIN | Label 2 loss: 219.5122 ; P: 0.9955 ; R: 0.9949 ; F1: 0.9952 ; Acc: 0.9957\n",
      "    TEST | Label 2 loss: 351.7632 ; P: 0.894 ; R: 0.9297 ; F1: 0.9115 ; Acc: 0.9207\n",
      "2023-01-28 15:11:19.876142\n",
      "counter:  27\n",
      "2023-01-28 15:11:19.877142\n",
      "EPOCH 104\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1750\n",
      "fn:  16\n",
      "tn:  2203\n",
      "fp:  9\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3953\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2040\n",
      "fp:  194\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 221.6772 ; P: 0.9949 ; R: 0.9909 ; F1: 0.9929 ; Acc: 0.9937\n",
      "    TEST | Label 2 loss: 351.7376 ; P: 0.8935 ; R: 0.9297 ; F1: 0.9112 ; Acc: 0.9204\n",
      "2023-01-28 15:14:23.190052\n",
      "counter:  28\n",
      "2023-01-28 15:14:23.190052\n",
      "EPOCH 105\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1749\n",
      "fn:  17\n",
      "tn:  2201\n",
      "fp:  11\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3950\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2041\n",
      "fp:  193\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 222.4214 ; P: 0.9937 ; R: 0.9904 ; F1: 0.9921 ; Acc: 0.993\n",
      "    TEST | Label 2 loss: 351.7229 ; P: 0.8939 ; R: 0.9291 ; F1: 0.9112 ; Acc: 0.9204\n",
      "2023-01-28 15:17:26.508602\n",
      "counter:  29\n",
      "2023-01-28 15:17:26.509596\n",
      "EPOCH 106\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1754\n",
      "fn:  12\n",
      "tn:  2203\n",
      "fp:  9\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3957\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2041\n",
      "fp:  193\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 221.3096 ; P: 0.9949 ; R: 0.9932 ; F1: 0.994 ; Acc: 0.9947\n",
      "    TEST | Label 2 loss: 351.6312 ; P: 0.8939 ; R: 0.9291 ; F1: 0.9112 ; Acc: 0.9204\n",
      "2023-01-28 15:20:29.429036\n",
      "counter:  30\n",
      "2023-01-28 15:20:29.429036\n",
      "EPOCH 107\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1748\n",
      "fn:  18\n",
      "tn:  2200\n",
      "fp:  12\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3948\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2041\n",
      "fp:  193\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 224.0987 ; P: 0.9932 ; R: 0.9898 ; F1: 0.9915 ; Acc: 0.9925\n",
      "    TEST | Label 2 loss: 351.6758 ; P: 0.8939 ; R: 0.9291 ; F1: 0.9112 ; Acc: 0.9204\n",
      "2023-01-28 15:23:31.703607\n",
      "counter:  31\n",
      "2023-01-28 15:23:31.704597\n",
      "EPOCH 108\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1750\n",
      "fn:  16\n",
      "tn:  2201\n",
      "fp:  11\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3951\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2041\n",
      "fp:  193\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3668\n",
      "    TRAIN | Label 2 loss: 224.346 ; P: 0.9938 ; R: 0.9909 ; F1: 0.9923 ; Acc: 0.9932\n",
      "    TEST | Label 2 loss: 351.8673 ; P: 0.894 ; R: 0.9297 ; F1: 0.9115 ; Acc: 0.9207\n",
      "2023-01-28 15:26:35.011381\n",
      "counter:  32\n",
      "2023-01-28 15:26:35.012379\n",
      "EPOCH 109\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1748\n",
      "fn:  18\n",
      "tn:  2201\n",
      "fp:  11\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3949\n",
      "tp:  1628\n",
      "fn:  122\n",
      "tn:  2038\n",
      "fp:  196\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3666\n",
      "    TRAIN | Label 2 loss: 222.6699 ; P: 0.9937 ; R: 0.9898 ; F1: 0.9918 ; Acc: 0.9927\n",
      "    TEST | Label 2 loss: 352.2121 ; P: 0.8925 ; R: 0.9303 ; F1: 0.911 ; Acc: 0.9202\n",
      "2023-01-28 15:29:38.709510\n",
      "counter:  33\n",
      "2023-01-28 15:29:38.709510\n",
      "EPOCH 110\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1755\n",
      "fn:  11\n",
      "tn:  2193\n",
      "fp:  19\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3948\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2041\n",
      "fp:  193\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 223.9647 ; P: 0.9893 ; R: 0.9938 ; F1: 0.9915 ; Acc: 0.9925\n",
      "    TEST | Label 2 loss: 351.3261 ; P: 0.8939 ; R: 0.9291 ; F1: 0.9112 ; Acc: 0.9204\n",
      "2023-01-28 15:32:42.543862\n",
      "counter:  34\n",
      "2023-01-28 15:32:42.543862\n",
      "EPOCH 111\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1755\n",
      "fn:  11\n",
      "tn:  2202\n",
      "fp:  10\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3957\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2041\n",
      "fp:  193\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 221.3615 ; P: 0.9943 ; R: 0.9938 ; F1: 0.9941 ; Acc: 0.9947\n",
      "    TEST | Label 2 loss: 351.4782 ; P: 0.8939 ; R: 0.9291 ; F1: 0.9112 ; Acc: 0.9204\n",
      "2023-01-28 15:35:46.017262\n",
      "counter:  35\n",
      "2023-01-28 15:35:46.019249\n",
      "EPOCH 112\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1755\n",
      "fn:  11\n",
      "tn:  2201\n",
      "fp:  11\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3956\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2041\n",
      "fp:  193\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 221.313 ; P: 0.9938 ; R: 0.9938 ; F1: 0.9938 ; Acc: 0.9945\n",
      "    TEST | Label 2 loss: 351.2118 ; P: 0.8939 ; R: 0.9291 ; F1: 0.9112 ; Acc: 0.9204\n",
      "2023-01-28 15:38:49.235993\n",
      "counter:  36\n",
      "2023-01-28 15:38:49.235993\n",
      "EPOCH 113\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1755\n",
      "fn:  11\n",
      "tn:  2198\n",
      "fp:  14\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3953\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2044\n",
      "fp:  190\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3669\n",
      "    TRAIN | Label 2 loss: 221.0187 ; P: 0.9921 ; R: 0.9938 ; F1: 0.9929 ; Acc: 0.9937\n",
      "    TEST | Label 2 loss: 350.5769 ; P: 0.8953 ; R: 0.9286 ; F1: 0.9116 ; Acc: 0.9209\n",
      "2023-01-28 15:41:51.840448\n",
      "counter:  37\n",
      "2023-01-28 15:41:51.840448\n",
      "EPOCH 114\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1751\n",
      "fn:  15\n",
      "tn:  2201\n",
      "fp:  11\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3952\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2040\n",
      "fp:  194\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 220.5344 ; P: 0.9938 ; R: 0.9915 ; F1: 0.9926 ; Acc: 0.9935\n",
      "    TEST | Label 2 loss: 352.0172 ; P: 0.8935 ; R: 0.9297 ; F1: 0.9112 ; Acc: 0.9204\n",
      "2023-01-28 15:44:54.598318\n",
      "counter:  38\n",
      "2023-01-28 15:44:54.598318\n",
      "EPOCH 115\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1752\n",
      "fn:  14\n",
      "tn:  2200\n",
      "fp:  12\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3952\n",
      "tp:  1630\n",
      "fn:  120\n",
      "tn:  2039\n",
      "fp:  195\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3669\n",
      "    TRAIN | Label 2 loss: 223.2648 ; P: 0.9932 ; R: 0.9921 ; F1: 0.9926 ; Acc: 0.9935\n",
      "    TEST | Label 2 loss: 352.5558 ; P: 0.8932 ; R: 0.9314 ; F1: 0.9119 ; Acc: 0.9209\n",
      "2023-01-28 15:47:57.837008\n",
      "counter:  39\n",
      "2023-01-28 15:47:57.837921\n",
      "EPOCH 116\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1754\n",
      "fn:  12\n",
      "tn:  2201\n",
      "fp:  11\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3955\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2043\n",
      "fp:  191\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3668\n",
      "    TRAIN | Label 2 loss: 221.4416 ; P: 0.9938 ; R: 0.9932 ; F1: 0.9935 ; Acc: 0.9942\n",
      "    TEST | Label 2 loss: 351.0975 ; P: 0.8948 ; R: 0.9286 ; F1: 0.9114 ; Acc: 0.9207\n",
      "2023-01-28 15:51:03.745228\n",
      "counter:  40\n",
      "2023-01-28 15:51:03.746925\n",
      "EPOCH 117\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1757\n",
      "fn:  9\n",
      "tn:  2204\n",
      "fp:  8\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3961\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2043\n",
      "fp:  191\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3668\n",
      "    TRAIN | Label 2 loss: 219.1252 ; P: 0.9955 ; R: 0.9949 ; F1: 0.9952 ; Acc: 0.9957\n",
      "    TEST | Label 2 loss: 350.5821 ; P: 0.8948 ; R: 0.9286 ; F1: 0.9114 ; Acc: 0.9207\n",
      "2023-01-28 15:54:06.792803\n",
      "counter:  41\n",
      "2023-01-28 15:54:06.792803\n",
      "EPOCH 118\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1756\n",
      "fn:  10\n",
      "tn:  2204\n",
      "fp:  8\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3960\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2039\n",
      "fp:  195\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3666\n",
      "    TRAIN | Label 2 loss: 219.946 ; P: 0.9955 ; R: 0.9943 ; F1: 0.9949 ; Acc: 0.9955\n",
      "    TEST | Label 2 loss: 351.8625 ; P: 0.893 ; R: 0.9297 ; F1: 0.911 ; Acc: 0.9202\n",
      "2023-01-28 15:57:09.899740\n",
      "counter:  42\n",
      "2023-01-28 15:57:09.899740\n",
      "EPOCH 119\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1750\n",
      "fn:  16\n",
      "tn:  2200\n",
      "fp:  12\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3950\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2040\n",
      "fp:  194\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3666\n",
      "    TRAIN | Label 2 loss: 222.8546 ; P: 0.9932 ; R: 0.9909 ; F1: 0.9921 ; Acc: 0.993\n",
      "    TEST | Label 2 loss: 350.9348 ; P: 0.8934 ; R: 0.9291 ; F1: 0.9109 ; Acc: 0.9202\n",
      "2023-01-28 16:00:12.872903\n",
      "counter:  43\n",
      "2023-01-28 16:00:12.872903\n",
      "EPOCH 120\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1755\n",
      "fn:  11\n",
      "tn:  2208\n",
      "fp:  4\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3963\n",
      "tp:  1631\n",
      "fn:  119\n",
      "tn:  2037\n",
      "fp:  197\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3668\n",
      "    TRAIN | Label 2 loss: 219.8837 ; P: 0.9977 ; R: 0.9938 ; F1: 0.9957 ; Acc: 0.9962\n",
      "    TEST | Label 2 loss: 353.0276 ; P: 0.8922 ; R: 0.932 ; F1: 0.9117 ; Acc: 0.9207\n",
      "2023-01-28 16:03:15.587323\n",
      "counter:  44\n",
      "2023-01-28 16:03:15.587323\n",
      "EPOCH 121\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1748\n",
      "fn:  18\n",
      "tn:  2202\n",
      "fp:  10\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3950\n",
      "tp:  1634\n",
      "fn:  116\n",
      "tn:  2033\n",
      "fp:  201\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 221.8119 ; P: 0.9943 ; R: 0.9898 ; F1: 0.9921 ; Acc: 0.993\n",
      "    TEST | Label 2 loss: 354.0935 ; P: 0.8905 ; R: 0.9337 ; F1: 0.9116 ; Acc: 0.9204\n",
      "2023-01-28 16:06:19.245307\n",
      "counter:  45\n",
      "2023-01-28 16:06:19.245307\n",
      "EPOCH 122\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1752\n",
      "fn:  14\n",
      "tn:  2206\n",
      "fp:  6\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3958\n",
      "tp:  1630\n",
      "fn:  120\n",
      "tn:  2037\n",
      "fp:  197\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 221.6527 ; P: 0.9966 ; R: 0.9921 ; F1: 0.9943 ; Acc: 0.995\n",
      "    TEST | Label 2 loss: 352.7457 ; P: 0.8922 ; R: 0.9314 ; F1: 0.9114 ; Acc: 0.9204\n",
      "2023-01-28 16:09:22.078158\n",
      "counter:  46\n",
      "2023-01-28 16:09:22.079159\n",
      "EPOCH 123\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1754\n",
      "fn:  12\n",
      "tn:  2199\n",
      "fp:  13\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3953\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2043\n",
      "fp:  191\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3668\n",
      "    TRAIN | Label 2 loss: 221.7568 ; P: 0.9926 ; R: 0.9932 ; F1: 0.9929 ; Acc: 0.9937\n",
      "    TEST | Label 2 loss: 350.7935 ; P: 0.8948 ; R: 0.9286 ; F1: 0.9114 ; Acc: 0.9207\n",
      "2023-01-28 16:12:25.011110\n",
      "counter:  47\n",
      "2023-01-28 16:12:25.011110\n",
      "EPOCH 124\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1759\n",
      "fn:  7\n",
      "tn:  2199\n",
      "fp:  13\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3958\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2046\n",
      "fp:  188\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3671\n",
      "    TRAIN | Label 2 loss: 221.2762 ; P: 0.9927 ; R: 0.996 ; F1: 0.9943 ; Acc: 0.995\n",
      "    TEST | Label 2 loss: 349.9762 ; P: 0.8963 ; R: 0.9286 ; F1: 0.9122 ; Acc: 0.9214\n",
      "2023-01-28 16:15:28.270528\n",
      "counter:  48\n",
      "2023-01-28 16:15:28.271439\n",
      "EPOCH 125\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1753\n",
      "fn:  13\n",
      "tn:  2206\n",
      "fp:  6\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3959\n",
      "tp:  1638\n",
      "fn:  112\n",
      "tn:  2031\n",
      "fp:  203\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3669\n",
      "    TRAIN | Label 2 loss: 220.2672 ; P: 0.9966 ; R: 0.9926 ; F1: 0.9946 ; Acc: 0.9952\n",
      "    TEST | Label 2 loss: 355.2262 ; P: 0.8897 ; R: 0.936 ; F1: 0.9123 ; Acc: 0.9209\n",
      "2023-01-28 16:18:30.935300\n",
      "counter:  49\n",
      "2023-01-28 16:18:30.936309\n",
      "EPOCH 126\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1757\n",
      "fn:  9\n",
      "tn:  2207\n",
      "fp:  5\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3964\n",
      "tp:  1633\n",
      "fn:  117\n",
      "tn:  2033\n",
      "fp:  201\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3666\n",
      "    TRAIN | Label 2 loss: 219.8787 ; P: 0.9972 ; R: 0.9949 ; F1: 0.996 ; Acc: 0.9965\n",
      "    TEST | Label 2 loss: 354.2922 ; P: 0.8904 ; R: 0.9331 ; F1: 0.9113 ; Acc: 0.9202\n",
      "2023-01-28 16:21:34.051779\n",
      "counter:  50\n",
      "2023-01-28 16:21:34.052776\n",
      "EPOCH 127\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1756\n",
      "fn:  10\n",
      "tn:  2205\n",
      "fp:  7\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3961\n",
      "tp:  1630\n",
      "fn:  120\n",
      "tn:  2035\n",
      "fp:  199\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3665\n",
      "    TRAIN | Label 2 loss: 219.3879 ; P: 0.996 ; R: 0.9943 ; F1: 0.9952 ; Acc: 0.9957\n",
      "    TEST | Label 2 loss: 352.5857 ; P: 0.8912 ; R: 0.9314 ; F1: 0.9109 ; Acc: 0.9199\n",
      "2023-01-28 16:24:37.679624\n",
      "counter:  51\n",
      "2023-01-28 16:24:37.680647\n",
      "EPOCH 128\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1755\n",
      "fn:  11\n",
      "tn:  2203\n",
      "fp:  9\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3958\n",
      "tp:  1632\n",
      "fn:  118\n",
      "tn:  2030\n",
      "fp:  204\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3662\n",
      "    TRAIN | Label 2 loss: 219.0004 ; P: 0.9949 ; R: 0.9938 ; F1: 0.9943 ; Acc: 0.995\n",
      "    TEST | Label 2 loss: 354.3033 ; P: 0.8889 ; R: 0.9326 ; F1: 0.9102 ; Acc: 0.9192\n",
      "2023-01-28 16:27:40.967424\n",
      "counter:  52\n",
      "2023-01-28 16:27:40.968422\n",
      "EPOCH 129\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1756\n",
      "fn:  10\n",
      "tn:  2205\n",
      "fp:  7\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3961\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2042\n",
      "fp:  192\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3669\n",
      "    TRAIN | Label 2 loss: 219.7542 ; P: 0.996 ; R: 0.9943 ; F1: 0.9952 ; Acc: 0.9957\n",
      "    TEST | Label 2 loss: 351.8169 ; P: 0.8944 ; R: 0.9297 ; F1: 0.9117 ; Acc: 0.9209\n",
      "2023-01-28 16:30:44.261783\n",
      "counter:  53\n",
      "2023-01-28 16:30:44.261783\n",
      "EPOCH 130\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1756\n",
      "fn:  10\n",
      "tn:  2205\n",
      "fp:  7\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3961\n",
      "tp:  1631\n",
      "fn:  119\n",
      "tn:  2033\n",
      "fp:  201\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3664\n",
      "    TRAIN | Label 2 loss: 219.181 ; P: 0.996 ; R: 0.9943 ; F1: 0.9952 ; Acc: 0.9957\n",
      "    TEST | Label 2 loss: 353.3008 ; P: 0.8903 ; R: 0.932 ; F1: 0.9107 ; Acc: 0.9197\n",
      "2023-01-28 16:33:47.131984\n",
      "counter:  54\n",
      "2023-01-28 16:33:47.131984\n",
      "EPOCH 131\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1758\n",
      "fn:  8\n",
      "tn:  2204\n",
      "fp:  8\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3962\n",
      "tp:  1632\n",
      "fn:  118\n",
      "tn:  2034\n",
      "fp:  200\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3666\n",
      "    TRAIN | Label 2 loss: 218.0163 ; P: 0.9955 ; R: 0.9955 ; F1: 0.9955 ; Acc: 0.996\n",
      "    TEST | Label 2 loss: 353.136 ; P: 0.8908 ; R: 0.9326 ; F1: 0.9112 ; Acc: 0.9202\n",
      "2023-01-28 16:36:49.667326\n",
      "counter:  55\n",
      "2023-01-28 16:36:49.668329\n",
      "EPOCH 132\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1759\n",
      "fn:  7\n",
      "tn:  2203\n",
      "fp:  9\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3962\n",
      "tp:  1628\n",
      "fn:  122\n",
      "tn:  2039\n",
      "fp:  195\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 217.0751 ; P: 0.9949 ; R: 0.996 ; F1: 0.9955 ; Acc: 0.996\n",
      "    TEST | Label 2 loss: 350.3529 ; P: 0.893 ; R: 0.9303 ; F1: 0.9113 ; Acc: 0.9204\n",
      "2023-01-28 16:39:53.153036\n",
      "counter:  56\n",
      "2023-01-28 16:39:53.153036\n",
      "EPOCH 133\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1753\n",
      "fn:  13\n",
      "tn:  2203\n",
      "fp:  9\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3956\n",
      "tp:  1629\n",
      "fn:  121\n",
      "tn:  2038\n",
      "fp:  196\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "    TRAIN | Label 2 loss: 220.4699 ; P: 0.9949 ; R: 0.9926 ; F1: 0.9938 ; Acc: 0.9945\n",
      "    TEST | Label 2 loss: 350.7976 ; P: 0.8926 ; R: 0.9309 ; F1: 0.9113 ; Acc: 0.9204\n",
      "2023-01-28 16:42:56.778582\n",
      "counter:  57\n",
      "2023-01-28 16:42:56.779580\n",
      "EPOCH 134\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1755\n",
      "fn:  11\n",
      "tn:  2202\n",
      "fp:  10\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3957\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2050\n",
      "fp:  184\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3676\n",
      "    TRAIN | Label 2 loss: 218.6499 ; P: 0.9943 ; R: 0.9938 ; F1: 0.9941 ; Acc: 0.9947\n",
      "    TEST | Label 2 loss: 348.5869 ; P: 0.8983 ; R: 0.9291 ; F1: 0.9135 ; Acc: 0.9227\n",
      "2023-01-28 16:46:01.169635\n",
      "counter:  0\n",
      "2023-01-28 16:46:03.094018\n",
      "EPOCH 135\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1756\n",
      "fn:  10\n",
      "tn:  2205\n",
      "fp:  7\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3961\n",
      "tp:  1632\n",
      "fn:  118\n",
      "tn:  2033\n",
      "fp:  201\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3665\n",
      "    TRAIN | Label 2 loss: 216.9361 ; P: 0.996 ; R: 0.9943 ; F1: 0.9952 ; Acc: 0.9957\n",
      "    TEST | Label 2 loss: 351.2053 ; P: 0.8903 ; R: 0.9326 ; F1: 0.911 ; Acc: 0.9199\n",
      "2023-01-28 16:49:06.585448\n",
      "counter:  1\n",
      "2023-01-28 16:49:06.585448\n",
      "EPOCH 136\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1757\n",
      "fn:  9\n",
      "tn:  2205\n",
      "fp:  7\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3962\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2050\n",
      "fp:  184\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3677\n",
      "    TRAIN | Label 2 loss: 217.099 ; P: 0.996 ; R: 0.9949 ; F1: 0.9955 ; Acc: 0.996\n",
      "    TEST | Label 2 loss: 349.5512 ; P: 0.8984 ; R: 0.9297 ; F1: 0.9138 ; Acc: 0.9229\n",
      "2023-01-28 16:52:09.609981\n",
      "counter:  0\n",
      "2023-01-28 16:52:11.479297\n",
      "EPOCH 137\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1760\n",
      "fn:  6\n",
      "tn:  2205\n",
      "fp:  7\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3965\n",
      "tp:  1628\n",
      "fn:  122\n",
      "tn:  2055\n",
      "fp:  179\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3683\n",
      "    TRAIN | Label 2 loss: 215.0513 ; P: 0.996 ; R: 0.9966 ; F1: 0.9963 ; Acc: 0.9967\n",
      "    TEST | Label 2 loss: 347.1203 ; P: 0.9009 ; R: 0.9303 ; F1: 0.9154 ; Acc: 0.9244\n",
      "2023-01-28 16:55:13.849754\n",
      "counter:  0\n",
      "2023-01-28 16:55:15.714915\n",
      "EPOCH 138\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1756\n",
      "fn:  10\n",
      "tn:  2206\n",
      "fp:  6\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3962\n",
      "tp:  1630\n",
      "fn:  120\n",
      "tn:  2041\n",
      "fp:  193\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3671\n",
      "    TRAIN | Label 2 loss: 216.5684 ; P: 0.9966 ; R: 0.9943 ; F1: 0.9955 ; Acc: 0.996\n",
      "    TEST | Label 2 loss: 350.1009 ; P: 0.8941 ; R: 0.9314 ; F1: 0.9124 ; Acc: 0.9214\n",
      "2023-01-28 16:58:18.659654\n",
      "counter:  1\n",
      "2023-01-28 16:58:18.660645\n",
      "EPOCH 139\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1757\n",
      "fn:  9\n",
      "tn:  2205\n",
      "fp:  7\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3962\n",
      "tp:  1631\n",
      "fn:  119\n",
      "tn:  2044\n",
      "fp:  190\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3675\n",
      "    TRAIN | Label 2 loss: 216.7588 ; P: 0.996 ; R: 0.9949 ; F1: 0.9955 ; Acc: 0.996\n",
      "    TEST | Label 2 loss: 348.7359 ; P: 0.8957 ; R: 0.932 ; F1: 0.9135 ; Acc: 0.9224\n",
      "2023-01-28 17:01:22.741566\n",
      "counter:  2\n",
      "2023-01-28 17:01:22.742558\n",
      "EPOCH 140\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1761\n",
      "fn:  5\n",
      "tn:  2203\n",
      "fp:  9\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3964\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2062\n",
      "fp:  172\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3687\n",
      "    TRAIN | Label 2 loss: 215.0263 ; P: 0.9949 ; R: 0.9972 ; F1: 0.996 ; Acc: 0.9965\n",
      "    TEST | Label 2 loss: 344.4308 ; P: 0.9043 ; R: 0.9286 ; F1: 0.9163 ; Acc: 0.9255\n",
      "2023-01-28 17:04:25.725253\n",
      "counter:  0\n",
      "2023-01-28 17:04:27.484217\n",
      "EPOCH 141\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1760\n",
      "fn:  6\n",
      "tn:  2209\n",
      "fp:  3\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3969\n",
      "tp:  1628\n",
      "fn:  122\n",
      "tn:  2051\n",
      "fp:  183\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3679\n",
      "    TRAIN | Label 2 loss: 214.0347 ; P: 0.9983 ; R: 0.9966 ; F1: 0.9974 ; Acc: 0.9977\n",
      "    TEST | Label 2 loss: 347.6606 ; P: 0.899 ; R: 0.9303 ; F1: 0.9143 ; Acc: 0.9234\n",
      "2023-01-28 17:07:30.994942\n",
      "counter:  1\n",
      "2023-01-28 17:07:30.995931\n",
      "EPOCH 142\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1758\n",
      "fn:  8\n",
      "tn:  2208\n",
      "fp:  4\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3966\n",
      "tp:  1632\n",
      "fn:  118\n",
      "tn:  2037\n",
      "fp:  197\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3669\n",
      "    TRAIN | Label 2 loss: 213.9939 ; P: 0.9977 ; R: 0.9955 ; F1: 0.9966 ; Acc: 0.997\n",
      "    TEST | Label 2 loss: 351.482 ; P: 0.8923 ; R: 0.9326 ; F1: 0.912 ; Acc: 0.9209\n",
      "2023-01-28 17:10:34.388327\n",
      "counter:  2\n",
      "2023-01-28 17:10:34.388327\n",
      "EPOCH 143\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1757\n",
      "fn:  9\n",
      "tn:  2208\n",
      "fp:  4\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3965\n",
      "tp:  1632\n",
      "fn:  118\n",
      "tn:  2040\n",
      "fp:  194\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3672\n",
      "    TRAIN | Label 2 loss: 213.7261 ; P: 0.9977 ; R: 0.9949 ; F1: 0.9963 ; Acc: 0.9967\n",
      "    TEST | Label 2 loss: 351.1013 ; P: 0.8938 ; R: 0.9326 ; F1: 0.9128 ; Acc: 0.9217\n",
      "2023-01-28 17:13:37.983633\n",
      "counter:  3\n",
      "2023-01-28 17:13:37.984633\n",
      "EPOCH 144\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1756\n",
      "fn:  10\n",
      "tn:  2204\n",
      "fp:  8\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3960\n",
      "tp:  1630\n",
      "fn:  120\n",
      "tn:  2042\n",
      "fp:  192\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3672\n",
      "    TRAIN | Label 2 loss: 215.9558 ; P: 0.9955 ; R: 0.9943 ; F1: 0.9949 ; Acc: 0.9955\n",
      "    TEST | Label 2 loss: 349.9585 ; P: 0.8946 ; R: 0.9314 ; F1: 0.9127 ; Acc: 0.9217\n",
      "2023-01-28 17:16:41.023926\n",
      "counter:  4\n",
      "2023-01-28 17:16:41.024928\n",
      "EPOCH 145\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1759\n",
      "fn:  7\n",
      "tn:  2202\n",
      "fp:  10\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3961\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2055\n",
      "fp:  179\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3681\n",
      "    TRAIN | Label 2 loss: 214.105 ; P: 0.9943 ; R: 0.996 ; F1: 0.9952 ; Acc: 0.9957\n",
      "    TEST | Label 2 loss: 344.5572 ; P: 0.9008 ; R: 0.9291 ; F1: 0.9148 ; Acc: 0.9239\n",
      "2023-01-28 17:19:45.034797\n",
      "counter:  5\n",
      "2023-01-28 17:19:45.035807\n",
      "EPOCH 146\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1761\n",
      "fn:  5\n",
      "tn:  2208\n",
      "fp:  4\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3969\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2052\n",
      "fp:  182\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3679\n",
      "    TRAIN | Label 2 loss: 211.6653 ; P: 0.9977 ; R: 0.9972 ; F1: 0.9975 ; Acc: 0.9977\n",
      "    TEST | Label 2 loss: 345.6518 ; P: 0.8994 ; R: 0.9297 ; F1: 0.9143 ; Acc: 0.9234\n",
      "2023-01-28 17:22:48.820457\n",
      "counter:  6\n",
      "2023-01-28 17:22:48.821447\n",
      "EPOCH 147\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1759\n",
      "fn:  7\n",
      "tn:  2209\n",
      "fp:  3\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3968\n",
      "tp:  1631\n",
      "fn:  119\n",
      "tn:  2043\n",
      "fp:  191\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3674\n",
      "    TRAIN | Label 2 loss: 211.5055 ; P: 0.9983 ; R: 0.996 ; F1: 0.9972 ; Acc: 0.9975\n",
      "    TEST | Label 2 loss: 348.7118 ; P: 0.8952 ; R: 0.932 ; F1: 0.9132 ; Acc: 0.9222\n",
      "2023-01-28 17:25:51.315452\n",
      "counter:  7\n",
      "2023-01-28 17:25:51.316529\n",
      "EPOCH 148\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1757\n",
      "fn:  9\n",
      "tn:  2204\n",
      "fp:  8\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3961\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2057\n",
      "fp:  177\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3683\n",
      "    TRAIN | Label 2 loss: 213.8384 ; P: 0.9955 ; R: 0.9949 ; F1: 0.9952 ; Acc: 0.9957\n",
      "    TEST | Label 2 loss: 345.1225 ; P: 0.9018 ; R: 0.9291 ; F1: 0.9153 ; Acc: 0.9244\n",
      "2023-01-28 17:28:53.899134\n",
      "counter:  8\n",
      "2023-01-28 17:28:53.900126\n",
      "EPOCH 149\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1760\n",
      "fn:  6\n",
      "tn:  2205\n",
      "fp:  7\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3965\n",
      "tp:  1635\n",
      "fn:  115\n",
      "tn:  2026\n",
      "fp:  208\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3661\n",
      "    TRAIN | Label 2 loss: 212.7816 ; P: 0.996 ; R: 0.9966 ; F1: 0.9963 ; Acc: 0.9967\n",
      "    TEST | Label 2 loss: 354.007 ; P: 0.8871 ; R: 0.9343 ; F1: 0.9101 ; Acc: 0.9189\n",
      "2023-01-28 17:31:56.734269\n",
      "counter:  9\n",
      "2023-01-28 17:31:56.735268\n",
      "EPOCH 150\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1761\n",
      "fn:  5\n",
      "tn:  2205\n",
      "fp:  7\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3966\n",
      "tp:  1629\n",
      "fn:  121\n",
      "tn:  2043\n",
      "fp:  191\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3672\n",
      "    TRAIN | Label 2 loss: 212.6245 ; P: 0.996 ; R: 0.9972 ; F1: 0.9966 ; Acc: 0.997\n",
      "    TEST | Label 2 loss: 346.6382 ; P: 0.8951 ; R: 0.9309 ; F1: 0.9126 ; Acc: 0.9217\n",
      "2023-01-28 17:34:59.767140\n",
      "counter:  10\n",
      "2023-01-28 17:34:59.767140\n",
      "EPOCH 151\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2210\n",
      "fp:  2\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3973\n",
      "tp:  1630\n",
      "fn:  120\n",
      "tn:  2043\n",
      "fp:  191\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3673\n",
      "    TRAIN | Label 2 loss: 209.5013 ; P: 0.9989 ; R: 0.9983 ; F1: 0.9986 ; Acc: 0.9987\n",
      "    TEST | Label 2 loss: 348.0992 ; P: 0.8951 ; R: 0.9314 ; F1: 0.9129 ; Acc: 0.9219\n",
      "2023-01-28 17:38:02.964198\n",
      "counter:  11\n",
      "2023-01-28 17:38:02.965188\n",
      "EPOCH 152\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1762\n",
      "fn:  4\n",
      "tn:  2209\n",
      "fp:  3\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3971\n",
      "tp:  1632\n",
      "fn:  118\n",
      "tn:  2045\n",
      "fp:  189\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3677\n",
      "    TRAIN | Label 2 loss: 209.2942 ; P: 0.9983 ; R: 0.9977 ; F1: 0.998 ; Acc: 0.9982\n",
      "    TEST | Label 2 loss: 347.7436 ; P: 0.8962 ; R: 0.9326 ; F1: 0.914 ; Acc: 0.9229\n",
      "2023-01-28 17:41:06.947094\n",
      "counter:  12\n",
      "2023-01-28 17:41:06.947094\n",
      "EPOCH 153\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1761\n",
      "fn:  5\n",
      "tn:  2208\n",
      "fp:  4\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3969\n",
      "tp:  1624\n",
      "fn:  126\n",
      "tn:  2056\n",
      "fp:  178\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3680\n",
      "    TRAIN | Label 2 loss: 209.5774 ; P: 0.9977 ; R: 0.9972 ; F1: 0.9975 ; Acc: 0.9977\n",
      "    TEST | Label 2 loss: 342.1247 ; P: 0.9012 ; R: 0.928 ; F1: 0.9144 ; Acc: 0.9237\n",
      "2023-01-28 17:44:10.422794\n",
      "counter:  13\n",
      "2023-01-28 17:44:10.423785\n",
      "EPOCH 154\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1761\n",
      "fn:  5\n",
      "tn:  2208\n",
      "fp:  4\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3969\n",
      "tp:  1638\n",
      "fn:  112\n",
      "tn:  2026\n",
      "fp:  208\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3664\n",
      "    TRAIN | Label 2 loss: 209.5862 ; P: 0.9977 ; R: 0.9972 ; F1: 0.9975 ; Acc: 0.9977\n",
      "    TEST | Label 2 loss: 350.0226 ; P: 0.8873 ; R: 0.936 ; F1: 0.911 ; Acc: 0.9197\n",
      "2023-01-28 17:47:12.513908\n",
      "counter:  14\n",
      "2023-01-28 17:47:12.513908\n",
      "EPOCH 155\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2210\n",
      "fp:  2\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1632\n",
      "fn:  118\n",
      "tn:  2049\n",
      "fp:  185\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3681\n",
      "    TRAIN | Label 2 loss: 207.8007 ; P: 0.9989 ; R: 0.9989 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 2 loss: 346.0083 ; P: 0.8982 ; R: 0.9326 ; F1: 0.9151 ; Acc: 0.9239\n",
      "2023-01-28 17:50:15.751032\n",
      "counter:  15\n",
      "2023-01-28 17:50:15.752039\n",
      "EPOCH 156\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2206\n",
      "fp:  6\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3969\n",
      "tp:  1620\n",
      "fn:  130\n",
      "tn:  2077\n",
      "fp:  157\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3697\n",
      "    TRAIN | Label 2 loss: 209.0386 ; P: 0.9966 ; R: 0.9983 ; F1: 0.9975 ; Acc: 0.9977\n",
      "    TEST | Label 2 loss: 339.3738 ; P: 0.9116 ; R: 0.9257 ; F1: 0.9186 ; Acc: 0.928\n",
      "2023-01-28 17:53:18.522552\n",
      "counter:  0\n",
      "2023-01-28 17:53:20.411971\n",
      "EPOCH 157\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1761\n",
      "fn:  5\n",
      "tn:  2210\n",
      "fp:  2\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3971\n",
      "tp:  1631\n",
      "fn:  119\n",
      "tn:  2057\n",
      "fp:  177\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3688\n",
      "    TRAIN | Label 2 loss: 207.4156 ; P: 0.9989 ; R: 0.9972 ; F1: 0.998 ; Acc: 0.9982\n",
      "    TEST | Label 2 loss: 344.5448 ; P: 0.9021 ; R: 0.932 ; F1: 0.9168 ; Acc: 0.9257\n",
      "2023-01-28 17:56:23.766314\n",
      "counter:  1\n",
      "2023-01-28 17:56:23.766314\n",
      "EPOCH 158\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1759\n",
      "fn:  7\n",
      "tn:  2208\n",
      "fp:  4\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3967\n",
      "tp:  1628\n",
      "fn:  122\n",
      "tn:  2064\n",
      "fp:  170\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3692\n",
      "    TRAIN | Label 2 loss: 208.9447 ; P: 0.9977 ; R: 0.996 ; F1: 0.9969 ; Acc: 0.9972\n",
      "    TEST | Label 2 loss: 341.8139 ; P: 0.9055 ; R: 0.9303 ; F1: 0.9177 ; Acc: 0.9267\n",
      "2023-01-28 17:59:27.103674\n",
      "counter:  2\n",
      "2023-01-28 17:59:27.104673\n",
      "EPOCH 159\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1760\n",
      "fn:  6\n",
      "tn:  2209\n",
      "fp:  3\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3969\n",
      "tp:  1624\n",
      "fn:  126\n",
      "tn:  2070\n",
      "fp:  164\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3694\n",
      "    TRAIN | Label 2 loss: 207.7199 ; P: 0.9983 ; R: 0.9966 ; F1: 0.9974 ; Acc: 0.9977\n",
      "    TEST | Label 2 loss: 340.9808 ; P: 0.9083 ; R: 0.928 ; F1: 0.918 ; Acc: 0.9272\n",
      "2023-01-28 18:02:30.056709\n",
      "counter:  3\n",
      "2023-01-28 18:02:30.056709\n",
      "EPOCH 160\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2210\n",
      "fp:  2\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3973\n",
      "tp:  1629\n",
      "fn:  121\n",
      "tn:  2067\n",
      "fp:  167\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3696\n",
      "    TRAIN | Label 2 loss: 206.2299 ; P: 0.9989 ; R: 0.9983 ; F1: 0.9986 ; Acc: 0.9987\n",
      "    TEST | Label 2 loss: 341.8033 ; P: 0.907 ; R: 0.9309 ; F1: 0.9188 ; Acc: 0.9277\n",
      "2023-01-28 18:05:32.839855\n",
      "counter:  0\n",
      "2023-01-28 18:05:34.842993\n",
      "EPOCH 161\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2208\n",
      "fp:  4\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3972\n",
      "tp:  1623\n",
      "fn:  127\n",
      "tn:  2071\n",
      "fp:  163\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3694\n",
      "    TRAIN | Label 2 loss: 206.1744 ; P: 0.9977 ; R: 0.9989 ; F1: 0.9983 ; Acc: 0.9985\n",
      "    TEST | Label 2 loss: 341.8193 ; P: 0.9087 ; R: 0.9274 ; F1: 0.918 ; Acc: 0.9272\n",
      "2023-01-28 18:08:38.235834\n",
      "counter:  1\n",
      "2023-01-28 18:08:38.236843\n",
      "EPOCH 162\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1761\n",
      "fn:  5\n",
      "tn:  2209\n",
      "fp:  3\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3970\n",
      "tp:  1637\n",
      "fn:  113\n",
      "tn:  2032\n",
      "fp:  202\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3669\n",
      "    TRAIN | Label 2 loss: 206.0784 ; P: 0.9983 ; R: 0.9972 ; F1: 0.9977 ; Acc: 0.998\n",
      "    TEST | Label 2 loss: 348.3225 ; P: 0.8902 ; R: 0.9354 ; F1: 0.9122 ; Acc: 0.9209\n",
      "2023-01-28 18:11:40.717613\n",
      "counter:  2\n",
      "2023-01-28 18:11:40.718581\n",
      "EPOCH 163\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1619\n",
      "fn:  131\n",
      "tn:  2076\n",
      "fp:  158\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3695\n",
      "    TRAIN | Label 2 loss: 205.04 ; P: 0.9994 ; R: 0.9983 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 2 loss: 339.8827 ; P: 0.9111 ; R: 0.9251 ; F1: 0.9181 ; Acc: 0.9275\n",
      "2023-01-28 18:14:44.223633\n",
      "counter:  3\n",
      "2023-01-28 18:14:44.224638\n",
      "EPOCH 164\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1628\n",
      "fn:  122\n",
      "tn:  2056\n",
      "fp:  178\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3684\n",
      "    TRAIN | Label 2 loss: 204.3269 ; P: 1.0 ; R: 0.9983 ; F1: 0.9991 ; Acc: 0.9992\n",
      "    TEST | Label 2 loss: 341.9129 ; P: 0.9014 ; R: 0.9303 ; F1: 0.9156 ; Acc: 0.9247\n",
      "2023-01-28 18:17:47.132655\n",
      "counter:  4\n",
      "2023-01-28 18:17:47.132655\n",
      "EPOCH 165\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1762\n",
      "fn:  4\n",
      "tn:  2208\n",
      "fp:  4\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3970\n",
      "tp:  1623\n",
      "fn:  127\n",
      "tn:  2059\n",
      "fp:  175\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3682\n",
      "    TRAIN | Label 2 loss: 205.8797 ; P: 0.9977 ; R: 0.9977 ; F1: 0.9977 ; Acc: 0.998\n",
      "    TEST | Label 2 loss: 343.8392 ; P: 0.9027 ; R: 0.9274 ; F1: 0.9149 ; Acc: 0.9242\n",
      "2023-01-28 18:20:50.920391\n",
      "counter:  5\n",
      "2023-01-28 18:20:50.921398\n",
      "EPOCH 166\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1761\n",
      "fn:  5\n",
      "tn:  2209\n",
      "fp:  3\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3970\n",
      "tp:  1631\n",
      "fn:  119\n",
      "tn:  2052\n",
      "fp:  182\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3683\n",
      "    TRAIN | Label 2 loss: 205.2469 ; P: 0.9983 ; R: 0.9972 ; F1: 0.9977 ; Acc: 0.998\n",
      "    TEST | Label 2 loss: 344.4272 ; P: 0.8996 ; R: 0.932 ; F1: 0.9155 ; Acc: 0.9244\n",
      "2023-01-28 18:23:54.142270\n",
      "counter:  6\n",
      "2023-01-28 18:23:54.143348\n",
      "EPOCH 167\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2210\n",
      "fp:  2\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3973\n",
      "tp:  1624\n",
      "fn:  126\n",
      "tn:  2060\n",
      "fp:  174\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3684\n",
      "    TRAIN | Label 2 loss: 203.7781 ; P: 0.9989 ; R: 0.9983 ; F1: 0.9986 ; Acc: 0.9987\n",
      "    TEST | Label 2 loss: 342.7855 ; P: 0.9032 ; R: 0.928 ; F1: 0.9154 ; Acc: 0.9247\n",
      "2023-01-28 18:26:56.705431\n",
      "counter:  7\n",
      "2023-01-28 18:26:56.705431\n",
      "EPOCH 168\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2209\n",
      "fp:  3\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3973\n",
      "tp:  1614\n",
      "fn:  136\n",
      "tn:  2086\n",
      "fp:  148\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3700\n",
      "    TRAIN | Label 2 loss: 203.6488 ; P: 0.9983 ; R: 0.9989 ; F1: 0.9986 ; Acc: 0.9987\n",
      "    TEST | Label 2 loss: 337.1904 ; P: 0.916 ; R: 0.9223 ; F1: 0.9191 ; Acc: 0.9287\n",
      "2023-01-28 18:30:00.094038\n",
      "counter:  0\n",
      "2023-01-28 18:30:02.014082\n",
      "EPOCH 169\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2210\n",
      "fp:  2\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3973\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2060\n",
      "fp:  174\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3685\n",
      "    TRAIN | Label 2 loss: 203.3746 ; P: 0.9989 ; R: 0.9983 ; F1: 0.9986 ; Acc: 0.9987\n",
      "    TEST | Label 2 loss: 344.0281 ; P: 0.9033 ; R: 0.9286 ; F1: 0.9158 ; Acc: 0.9249\n",
      "2023-01-28 18:33:04.603904\n",
      "counter:  1\n",
      "2023-01-28 18:33:04.604904\n",
      "EPOCH 170\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1762\n",
      "fn:  4\n",
      "tn:  2209\n",
      "fp:  3\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3971\n",
      "tp:  1619\n",
      "fn:  131\n",
      "tn:  2065\n",
      "fp:  169\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3684\n",
      "    TRAIN | Label 2 loss: 204.1341 ; P: 0.9983 ; R: 0.9977 ; F1: 0.998 ; Acc: 0.9982\n",
      "    TEST | Label 2 loss: 341.4929 ; P: 0.9055 ; R: 0.9251 ; F1: 0.9152 ; Acc: 0.9247\n",
      "2023-01-28 18:36:08.411246\n",
      "counter:  2\n",
      "2023-01-28 18:36:08.412246\n",
      "EPOCH 171\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1762\n",
      "fn:  4\n",
      "tn:  2210\n",
      "fp:  2\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3972\n",
      "tp:  1623\n",
      "fn:  127\n",
      "tn:  2062\n",
      "fp:  172\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3685\n",
      "    TRAIN | Label 2 loss: 202.8005 ; P: 0.9989 ; R: 0.9977 ; F1: 0.9983 ; Acc: 0.9985\n",
      "    TEST | Label 2 loss: 341.4549 ; P: 0.9042 ; R: 0.9274 ; F1: 0.9157 ; Acc: 0.9249\n",
      "2023-01-28 18:39:12.279214\n",
      "counter:  3\n",
      "2023-01-28 18:39:12.280323\n",
      "EPOCH 172\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2061\n",
      "fp:  173\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3687\n",
      "    TRAIN | Label 2 loss: 201.3034 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 2 loss: 341.5522 ; P: 0.9038 ; R: 0.9291 ; F1: 0.9163 ; Acc: 0.9255\n",
      "2023-01-28 18:42:15.762147\n",
      "counter:  4\n",
      "2023-01-28 18:42:15.762147\n",
      "EPOCH 173\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1621\n",
      "fn:  129\n",
      "tn:  2074\n",
      "fp:  160\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3695\n",
      "    TRAIN | Label 2 loss: 200.618 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 2 loss: 336.825 ; P: 0.9102 ; R: 0.9263 ; F1: 0.9182 ; Acc: 0.9275\n",
      "2023-01-28 18:45:18.725881\n",
      "counter:  5\n",
      "2023-01-28 18:45:18.725881\n",
      "EPOCH 174\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2074\n",
      "fp:  160\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3701\n",
      "    TRAIN | Label 2 loss: 201.225 ; P: 0.9994 ; R: 0.9983 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 2 loss: 337.1232 ; P: 0.9105 ; R: 0.9297 ; F1: 0.92 ; Acc: 0.929\n",
      "2023-01-28 18:48:21.742241\n",
      "counter:  0\n",
      "2023-01-28 18:48:23.497357\n",
      "EPOCH 175\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1619\n",
      "fn:  131\n",
      "tn:  2076\n",
      "fp:  158\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3695\n",
      "    TRAIN | Label 2 loss: 201.2544 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 2 loss: 336.9048 ; P: 0.9111 ; R: 0.9251 ; F1: 0.9181 ; Acc: 0.9275\n",
      "2023-01-28 18:51:27.040042\n",
      "counter:  1\n",
      "2023-01-28 18:51:27.041041\n",
      "EPOCH 176\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1762\n",
      "fn:  4\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3973\n",
      "tp:  1624\n",
      "fn:  126\n",
      "tn:  2071\n",
      "fp:  163\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3695\n",
      "    TRAIN | Label 2 loss: 201.4182 ; P: 0.9994 ; R: 0.9977 ; F1: 0.9986 ; Acc: 0.9987\n",
      "    TEST | Label 2 loss: 338.6751 ; P: 0.9088 ; R: 0.928 ; F1: 0.9183 ; Acc: 0.9275\n",
      "2023-01-28 18:54:30.722552\n",
      "counter:  2\n",
      "2023-01-28 18:54:30.723554\n",
      "EPOCH 177\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2210\n",
      "fp:  2\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1629\n",
      "fn:  121\n",
      "tn:  2052\n",
      "fp:  182\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3681\n",
      "    TRAIN | Label 2 loss: 200.0851 ; P: 0.9989 ; R: 0.9989 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 2 loss: 342.7775 ; P: 0.8995 ; R: 0.9309 ; F1: 0.9149 ; Acc: 0.9239\n",
      "2023-01-28 18:57:34.157337\n",
      "counter:  3\n",
      "2023-01-28 18:57:34.159337\n",
      "EPOCH 178\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1623\n",
      "fn:  127\n",
      "tn:  2070\n",
      "fp:  164\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3693\n",
      "    TRAIN | Label 2 loss: 199.4175 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 2 loss: 336.2352 ; P: 0.9082 ; R: 0.9274 ; F1: 0.9177 ; Acc: 0.927\n",
      "2023-01-28 19:00:37.352732\n",
      "counter:  4\n",
      "2023-01-28 19:00:37.353722\n",
      "EPOCH 179\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2063\n",
      "fp:  171\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3689\n",
      "    TRAIN | Label 2 loss: 198.4077 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 2 loss: 337.7006 ; P: 0.9048 ; R: 0.9291 ; F1: 0.9168 ; Acc: 0.926\n",
      "2023-01-28 19:03:39.851686\n",
      "counter:  5\n",
      "2023-01-28 19:03:39.852784\n",
      "EPOCH 180\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2210\n",
      "fp:  2\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1621\n",
      "fn:  129\n",
      "tn:  2064\n",
      "fp:  170\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3685\n",
      "    TRAIN | Label 2 loss: 198.802 ; P: 0.9989 ; R: 0.9994 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 2 loss: 338.2829 ; P: 0.9051 ; R: 0.9263 ; F1: 0.9156 ; Acc: 0.9249\n",
      "2023-01-28 19:06:42.996395\n",
      "counter:  6\n",
      "2023-01-28 19:06:42.998395\n",
      "EPOCH 181\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1632\n",
      "fn:  118\n",
      "tn:  2046\n",
      "fp:  188\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3678\n",
      "    TRAIN | Label 2 loss: 198.0818 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 2 loss: 342.2161 ; P: 0.8967 ; R: 0.9326 ; F1: 0.9143 ; Acc: 0.9232\n",
      "2023-01-28 19:09:45.869114\n",
      "counter:  7\n",
      "2023-01-28 19:09:45.870189\n",
      "EPOCH 182\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1616\n",
      "fn:  134\n",
      "tn:  2080\n",
      "fp:  154\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3696\n",
      "    TRAIN | Label 2 loss: 198.3258 ; P: 0.9994 ; R: 0.9983 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 2 loss: 334.5035 ; P: 0.913 ; R: 0.9234 ; F1: 0.9182 ; Acc: 0.9277\n",
      "2023-01-28 19:12:49.296151\n",
      "counter:  8\n",
      "2023-01-28 19:12:49.297146\n",
      "EPOCH 183\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2065\n",
      "fp:  169\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3691\n",
      "    TRAIN | Label 2 loss: 197.3099 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 338.2143 ; P: 0.9058 ; R: 0.9291 ; F1: 0.9173 ; Acc: 0.9265\n",
      "2023-01-28 19:15:52.721256\n",
      "counter:  9\n",
      "2023-01-28 19:15:52.722261\n",
      "EPOCH 184\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2210\n",
      "fp:  2\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1620\n",
      "fn:  130\n",
      "tn:  2071\n",
      "fp:  163\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3691\n",
      "    TRAIN | Label 2 loss: 198.0872 ; P: 0.9989 ; R: 0.9994 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 2 loss: 338.7086 ; P: 0.9086 ; R: 0.9257 ; F1: 0.9171 ; Acc: 0.9265\n",
      "2023-01-28 19:18:56.003670\n",
      "counter:  10\n",
      "2023-01-28 19:18:56.004673\n",
      "EPOCH 185\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2066\n",
      "fp:  168\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3692\n",
      "    TRAIN | Label 2 loss: 196.3174 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 337.7763 ; P: 0.9064 ; R: 0.9291 ; F1: 0.9176 ; Acc: 0.9267\n",
      "2023-01-28 19:21:58.947917\n",
      "counter:  11\n",
      "2023-01-28 19:21:58.948916\n",
      "EPOCH 186\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1630\n",
      "fn:  120\n",
      "tn:  2059\n",
      "fp:  175\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3689\n",
      "    TRAIN | Label 2 loss: 197.3132 ; P: 0.9994 ; R: 0.9983 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 2 loss: 335.9924 ; P: 0.903 ; R: 0.9314 ; F1: 0.917 ; Acc: 0.926\n",
      "2023-01-28 19:25:01.446307\n",
      "counter:  12\n",
      "2023-01-28 19:25:01.447298\n",
      "EPOCH 187\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1634\n",
      "fn:  116\n",
      "tn:  2045\n",
      "fp:  189\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3679\n",
      "    TRAIN | Label 2 loss: 196.9581 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 2 loss: 343.4367 ; P: 0.8963 ; R: 0.9337 ; F1: 0.9146 ; Acc: 0.9234\n",
      "2023-01-28 19:28:03.995947\n",
      "counter:  13\n",
      "2023-01-28 19:28:03.995947\n",
      "EPOCH 188\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2209\n",
      "fp:  3\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3973\n",
      "tp:  1633\n",
      "fn:  117\n",
      "tn:  2055\n",
      "fp:  179\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3688\n",
      "    TRAIN | Label 2 loss: 196.8767 ; P: 0.9983 ; R: 0.9989 ; F1: 0.9986 ; Acc: 0.9987\n",
      "    TEST | Label 2 loss: 337.0065 ; P: 0.9012 ; R: 0.9331 ; F1: 0.9169 ; Acc: 0.9257\n",
      "2023-01-28 19:31:07.388304\n",
      "counter:  14\n",
      "2023-01-28 19:31:07.390309\n",
      "EPOCH 189\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1634\n",
      "fn:  116\n",
      "tn:  2057\n",
      "fp:  177\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3691\n",
      "    TRAIN | Label 2 loss: 195.9124 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 2 loss: 335.3038 ; P: 0.9023 ; R: 0.9337 ; F1: 0.9177 ; Acc: 0.9265\n",
      "2023-01-28 19:34:10.674155\n",
      "counter:  15\n",
      "2023-01-28 19:34:10.675154\n",
      "EPOCH 190\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2210\n",
      "fp:  2\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1630\n",
      "fn:  120\n",
      "tn:  2075\n",
      "fp:  159\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3705\n",
      "    TRAIN | Label 2 loss: 195.4326 ; P: 0.9989 ; R: 0.9994 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 2 loss: 332.5438 ; P: 0.9111 ; R: 0.9314 ; F1: 0.9212 ; Acc: 0.93\n",
      "2023-01-28 19:37:13.806356\n",
      "counter:  0\n",
      "2023-01-28 19:37:15.594778\n",
      "EPOCH 191\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1645\n",
      "fn:  105\n",
      "tn:  2046\n",
      "fp:  188\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3691\n",
      "    TRAIN | Label 2 loss: 195.6566 ; P: 0.9994 ; R: 0.9983 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 2 loss: 337.6764 ; P: 0.8974 ; R: 0.94 ; F1: 0.9182 ; Acc: 0.9265\n",
      "2023-01-28 19:40:19.063885\n",
      "counter:  1\n",
      "2023-01-28 19:40:19.064885\n",
      "EPOCH 192\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1634\n",
      "fn:  116\n",
      "tn:  2055\n",
      "fp:  179\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3689\n",
      "    TRAIN | Label 2 loss: 194.7055 ; P: 1.0 ; R: 0.9989 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 2 loss: 336.6255 ; P: 0.9013 ; R: 0.9337 ; F1: 0.9172 ; Acc: 0.926\n",
      "2023-01-28 19:43:21.525759\n",
      "counter:  2\n",
      "2023-01-28 19:43:21.526750\n",
      "EPOCH 193\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2210\n",
      "fp:  2\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1613\n",
      "fn:  137\n",
      "tn:  2087\n",
      "fp:  147\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3700\n",
      "    TRAIN | Label 2 loss: 195.3978 ; P: 0.9989 ; R: 0.9989 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 2 loss: 330.8402 ; P: 0.9165 ; R: 0.9217 ; F1: 0.9191 ; Acc: 0.9287\n",
      "2023-01-28 19:46:24.334199\n",
      "counter:  3\n",
      "2023-01-28 19:46:24.335190\n",
      "EPOCH 194\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1632\n",
      "fn:  118\n",
      "tn:  2065\n",
      "fp:  169\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3697\n",
      "    TRAIN | Label 2 loss: 193.7304 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 334.3505 ; P: 0.9062 ; R: 0.9326 ; F1: 0.9192 ; Acc: 0.928\n",
      "2023-01-28 19:49:27.403481\n",
      "counter:  4\n",
      "2023-01-28 19:49:27.403481\n",
      "EPOCH 195\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2074\n",
      "fp:  160\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3699\n",
      "    TRAIN | Label 2 loss: 193.6867 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 2 loss: 334.9698 ; P: 0.9104 ; R: 0.9286 ; F1: 0.9194 ; Acc: 0.9285\n",
      "2023-01-28 19:52:31.209660\n",
      "counter:  5\n",
      "2023-01-28 19:52:31.210660\n",
      "EPOCH 196\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1628\n",
      "fn:  122\n",
      "tn:  2060\n",
      "fp:  174\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3688\n",
      "    TRAIN | Label 2 loss: 194.2896 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 2 loss: 336.125 ; P: 0.9034 ; R: 0.9303 ; F1: 0.9167 ; Acc: 0.9257\n",
      "2023-01-28 19:55:33.965874\n",
      "counter:  6\n",
      "2023-01-28 19:55:33.966874\n",
      "EPOCH 197\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1637\n",
      "fn:  113\n",
      "tn:  2047\n",
      "fp:  187\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3684\n",
      "    TRAIN | Label 2 loss: 192.8963 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 338.098 ; P: 0.8975 ; R: 0.9354 ; F1: 0.9161 ; Acc: 0.9247\n",
      "2023-01-28 19:58:36.564585\n",
      "counter:  7\n",
      "2023-01-28 19:58:36.565584\n",
      "EPOCH 198\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1629\n",
      "fn:  121\n",
      "tn:  2068\n",
      "fp:  166\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3697\n",
      "    TRAIN | Label 2 loss: 192.5978 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 334.2301 ; P: 0.9075 ; R: 0.9309 ; F1: 0.919 ; Acc: 0.928\n",
      "2023-01-28 20:01:39.904859\n",
      "counter:  8\n",
      "2023-01-28 20:01:39.905860\n",
      "EPOCH 199\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1617\n",
      "fn:  133\n",
      "tn:  2086\n",
      "fp:  148\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3703\n",
      "    TRAIN | Label 2 loss: 192.1414 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 330.9285 ; P: 0.9161 ; R: 0.924 ; F1: 0.9201 ; Acc: 0.9295\n",
      "2023-01-28 20:04:43.144951\n",
      "counter:  9\n",
      "2023-01-28 20:04:43.145951\n",
      "EPOCH 200\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2064\n",
      "fp:  170\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3691\n",
      "    TRAIN | Label 2 loss: 191.9674 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 333.6823 ; P: 0.9054 ; R: 0.9297 ; F1: 0.9174 ; Acc: 0.9265\n",
      "2023-01-28 20:07:46.106104\n",
      "counter:  10\n",
      "2023-01-28 20:07:46.107059\n",
      "EPOCH 201\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2061\n",
      "fp:  173\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3687\n",
      "    TRAIN | Label 2 loss: 191.5167 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 335.29 ; P: 0.9038 ; R: 0.9291 ; F1: 0.9163 ; Acc: 0.9255\n",
      "2023-01-28 20:10:49.491705\n",
      "counter:  11\n",
      "2023-01-28 20:10:49.491705\n",
      "EPOCH 202\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2055\n",
      "fp:  179\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3682\n",
      "    TRAIN | Label 2 loss: 191.3159 ; P: 1.0 ; R: 0.9989 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 2 loss: 336.3868 ; P: 0.9009 ; R: 0.9297 ; F1: 0.9151 ; Acc: 0.9242\n",
      "2023-01-28 20:13:52.654602\n",
      "counter:  12\n",
      "2023-01-28 20:13:52.655668\n",
      "EPOCH 203\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1622\n",
      "fn:  128\n",
      "tn:  2067\n",
      "fp:  167\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3689\n",
      "    TRAIN | Label 2 loss: 191.0813 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 2 loss: 335.3616 ; P: 0.9067 ; R: 0.9269 ; F1: 0.9166 ; Acc: 0.926\n",
      "2023-01-28 20:16:55.418553\n",
      "counter:  13\n",
      "2023-01-28 20:16:55.419553\n",
      "EPOCH 204\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1639\n",
      "fn:  111\n",
      "tn:  2040\n",
      "fp:  194\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3679\n",
      "    TRAIN | Label 2 loss: 191.1714 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 2 loss: 339.8139 ; P: 0.8942 ; R: 0.9366 ; F1: 0.9149 ; Acc: 0.9234\n",
      "2023-01-28 20:19:58.229524\n",
      "counter:  14\n",
      "2023-01-28 20:19:58.230517\n",
      "EPOCH 205\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2210\n",
      "fp:  2\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1633\n",
      "fn:  117\n",
      "tn:  2071\n",
      "fp:  163\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3704\n",
      "    TRAIN | Label 2 loss: 191.4471 ; P: 0.9989 ; R: 0.9994 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 2 loss: 331.4913 ; P: 0.9092 ; R: 0.9331 ; F1: 0.921 ; Acc: 0.9297\n",
      "2023-01-28 20:23:00.919600\n",
      "counter:  15\n",
      "2023-01-28 20:23:00.919600\n",
      "EPOCH 206\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1651\n",
      "fn:  99\n",
      "tn:  2025\n",
      "fp:  209\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3676\n",
      "    TRAIN | Label 2 loss: 191.1373 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 2 loss: 340.4103 ; P: 0.8876 ; R: 0.9434 ; F1: 0.9147 ; Acc: 0.9227\n",
      "2023-01-28 20:26:04.302041\n",
      "counter:  16\n",
      "2023-01-28 20:26:04.302041\n",
      "EPOCH 207\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1632\n",
      "fn:  118\n",
      "tn:  2080\n",
      "fp:  154\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3712\n",
      "    TRAIN | Label 2 loss: 190.3579 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 2 loss: 327.5577 ; P: 0.9138 ; R: 0.9326 ; F1: 0.9231 ; Acc: 0.9317\n",
      "2023-01-28 20:29:07.954602\n",
      "counter:  0\n",
      "2023-01-28 20:29:09.790498\n",
      "EPOCH 208\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1641\n",
      "fn:  109\n",
      "tn:  2050\n",
      "fp:  184\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3691\n",
      "    TRAIN | Label 2 loss: 189.574 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 334.3474 ; P: 0.8992 ; R: 0.9377 ; F1: 0.918 ; Acc: 0.9265\n",
      "2023-01-28 20:32:13.387105\n",
      "counter:  1\n",
      "2023-01-28 20:32:13.388108\n",
      "EPOCH 209\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1629\n",
      "fn:  121\n",
      "tn:  2074\n",
      "fp:  160\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3703\n",
      "    TRAIN | Label 2 loss: 189.5766 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 2 loss: 330.8131 ; P: 0.9106 ; R: 0.9309 ; F1: 0.9206 ; Acc: 0.9295\n",
      "2023-01-28 20:35:16.392596\n",
      "counter:  2\n",
      "2023-01-28 20:35:16.392596\n",
      "EPOCH 210\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1638\n",
      "fn:  112\n",
      "tn:  2044\n",
      "fp:  190\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3682\n",
      "    TRAIN | Label 2 loss: 190.0145 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 2 loss: 338.9681 ; P: 0.8961 ; R: 0.936 ; F1: 0.9156 ; Acc: 0.9242\n",
      "2023-01-28 20:38:18.903621\n",
      "counter:  3\n",
      "2023-01-28 20:38:18.904612\n",
      "EPOCH 211\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2070\n",
      "fp:  164\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3697\n",
      "    TRAIN | Label 2 loss: 189.4331 ; P: 1.0 ; R: 0.9989 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 2 loss: 332.1249 ; P: 0.9084 ; R: 0.9297 ; F1: 0.9189 ; Acc: 0.928\n",
      "2023-01-28 20:41:21.766769\n",
      "counter:  4\n",
      "2023-01-28 20:41:21.766769\n",
      "EPOCH 212\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1615\n",
      "fn:  135\n",
      "tn:  2095\n",
      "fp:  139\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "    TRAIN | Label 2 loss: 188.5983 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 326.2558 ; P: 0.9208 ; R: 0.9229 ; F1: 0.9218 ; Acc: 0.9312\n",
      "2023-01-28 20:44:24.922622\n",
      "counter:  5\n",
      "2023-01-28 20:44:24.923619\n",
      "EPOCH 213\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1613\n",
      "fn:  137\n",
      "tn:  2093\n",
      "fp:  141\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3706\n",
      "    TRAIN | Label 2 loss: 189.2002 ; P: 0.9994 ; R: 0.9983 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 2 loss: 326.3341 ; P: 0.9196 ; R: 0.9217 ; F1: 0.9207 ; Acc: 0.9302\n",
      "2023-01-28 20:47:27.913952\n",
      "counter:  6\n",
      "2023-01-28 20:47:27.913952\n",
      "EPOCH 214\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1631\n",
      "fn:  119\n",
      "tn:  2057\n",
      "fp:  177\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3688\n",
      "    TRAIN | Label 2 loss: 188.506 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 2 loss: 332.4565 ; P: 0.9021 ; R: 0.932 ; F1: 0.9168 ; Acc: 0.9257\n",
      "2023-01-28 20:50:31.617445\n",
      "counter:  7\n",
      "2023-01-28 20:50:31.617445\n",
      "EPOCH 215\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1624\n",
      "fn:  126\n",
      "tn:  2058\n",
      "fp:  176\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3682\n",
      "    TRAIN | Label 2 loss: 187.5203 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 333.6994 ; P: 0.9022 ; R: 0.928 ; F1: 0.9149 ; Acc: 0.9242\n",
      "2023-01-28 20:53:34.325089\n",
      "counter:  8\n",
      "2023-01-28 20:53:34.326088\n",
      "EPOCH 216\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1609\n",
      "fn:  141\n",
      "tn:  2087\n",
      "fp:  147\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3696\n",
      "    TRAIN | Label 2 loss: 187.8581 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 2 loss: 328.6942 ; P: 0.9163 ; R: 0.9194 ; F1: 0.9179 ; Acc: 0.9277\n",
      "2023-01-28 20:56:37.359744\n",
      "counter:  9\n",
      "2023-01-28 20:56:37.359744\n",
      "EPOCH 217\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1630\n",
      "fn:  120\n",
      "tn:  2062\n",
      "fp:  172\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3692\n",
      "    TRAIN | Label 2 loss: 187.5552 ; P: 1.0 ; R: 0.9983 ; F1: 0.9991 ; Acc: 0.9992\n",
      "    TEST | Label 2 loss: 328.5945 ; P: 0.9046 ; R: 0.9314 ; F1: 0.9178 ; Acc: 0.9267\n",
      "2023-01-28 20:59:40.285778\n",
      "counter:  10\n",
      "2023-01-28 20:59:40.286768\n",
      "EPOCH 218\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2072\n",
      "fp:  162\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3697\n",
      "    TRAIN | Label 2 loss: 186.8437 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 327.7393 ; P: 0.9093 ; R: 0.9286 ; F1: 0.9189 ; Acc: 0.928\n",
      "2023-01-28 21:02:43.327608\n",
      "counter:  11\n",
      "2023-01-28 21:02:43.328598\n",
      "EPOCH 219\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2210\n",
      "fp:  2\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1611\n",
      "fn:  139\n",
      "tn:  2092\n",
      "fp:  142\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3703\n",
      "    TRAIN | Label 2 loss: 187.1018 ; P: 0.9989 ; R: 0.9994 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 2 loss: 323.1741 ; P: 0.919 ; R: 0.9206 ; F1: 0.9198 ; Acc: 0.9295\n",
      "2023-01-28 21:05:46.700668\n",
      "counter:  12\n",
      "2023-01-28 21:05:46.701661\n",
      "EPOCH 220\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1632\n",
      "fn:  118\n",
      "tn:  2074\n",
      "fp:  160\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3706\n",
      "    TRAIN | Label 2 loss: 186.6653 ; P: 1.0 ; R: 0.9989 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 2 loss: 326.272 ; P: 0.9107 ; R: 0.9326 ; F1: 0.9215 ; Acc: 0.9302\n",
      "2023-01-28 21:08:50.321695\n",
      "counter:  13\n",
      "2023-01-28 21:08:50.322695\n",
      "EPOCH 221\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1628\n",
      "fn:  122\n",
      "tn:  2081\n",
      "fp:  153\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3709\n",
      "    TRAIN | Label 2 loss: 186.0935 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 325.9195 ; P: 0.9141 ; R: 0.9303 ; F1: 0.9221 ; Acc: 0.931\n",
      "2023-01-28 21:11:53.096094\n",
      "counter:  14\n",
      "2023-01-28 21:11:53.097093\n",
      "EPOCH 222\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2083\n",
      "fp:  151\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "    TRAIN | Label 2 loss: 185.9205 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 2 loss: 324.443 ; P: 0.9151 ; R: 0.9297 ; F1: 0.9223 ; Acc: 0.9312\n",
      "2023-01-28 21:14:56.183432\n",
      "counter:  15\n",
      "2023-01-28 21:14:56.184435\n",
      "EPOCH 223\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1620\n",
      "fn:  130\n",
      "tn:  2090\n",
      "fp:  144\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "    TRAIN | Label 2 loss: 185.4956 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 323.6985 ; P: 0.9184 ; R: 0.9257 ; F1: 0.922 ; Acc: 0.9312\n",
      "2023-01-28 21:17:58.745984\n",
      "counter:  16\n",
      "2023-01-28 21:17:58.747038\n",
      "EPOCH 224\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1624\n",
      "fn:  126\n",
      "tn:  2080\n",
      "fp:  154\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3704\n",
      "    TRAIN | Label 2 loss: 185.5205 ; P: 1.0 ; R: 0.9989 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 2 loss: 324.6414 ; P: 0.9134 ; R: 0.928 ; F1: 0.9206 ; Acc: 0.9297\n",
      "2023-01-28 21:21:01.902355\n",
      "counter:  17\n",
      "2023-01-28 21:21:01.903355\n",
      "EPOCH 225\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1630\n",
      "fn:  120\n",
      "tn:  2068\n",
      "fp:  166\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3698\n",
      "    TRAIN | Label 2 loss: 185.2635 ; P: 1.0 ; R: 0.9989 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 2 loss: 329.5674 ; P: 0.9076 ; R: 0.9314 ; F1: 0.9193 ; Acc: 0.9282\n",
      "2023-01-28 21:24:05.272392\n",
      "counter:  18\n",
      "2023-01-28 21:24:05.273392\n",
      "EPOCH 226\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1618\n",
      "fn:  132\n",
      "tn:  2093\n",
      "fp:  141\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3711\n",
      "    TRAIN | Label 2 loss: 185.2705 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 2 loss: 323.442 ; P: 0.9198 ; R: 0.9246 ; F1: 0.9222 ; Acc: 0.9315\n",
      "2023-01-28 21:27:08.522941\n",
      "counter:  19\n",
      "2023-01-28 21:27:08.523928\n",
      "EPOCH 227\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1631\n",
      "fn:  119\n",
      "tn:  2063\n",
      "fp:  171\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3694\n",
      "    TRAIN | Label 2 loss: 184.5052 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 328.0695 ; P: 0.9051 ; R: 0.932 ; F1: 0.9184 ; Acc: 0.9272\n",
      "2023-01-28 21:30:11.055603\n",
      "counter:  20\n",
      "2023-01-28 21:30:11.056586\n",
      "EPOCH 228\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2209\n",
      "fp:  3\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3973\n",
      "tp:  1601\n",
      "fn:  149\n",
      "tn:  2104\n",
      "fp:  130\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3705\n",
      "    TRAIN | Label 2 loss: 185.6855 ; P: 0.9983 ; R: 0.9989 ; F1: 0.9986 ; Acc: 0.9987\n",
      "    TEST | Label 2 loss: 325.3361 ; P: 0.9249 ; R: 0.9149 ; F1: 0.9199 ; Acc: 0.93\n",
      "2023-01-28 21:33:13.777614\n",
      "counter:  21\n",
      "2023-01-28 21:33:13.778616\n",
      "EPOCH 229\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1609\n",
      "fn:  141\n",
      "tn:  2094\n",
      "fp:  140\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3703\n",
      "    TRAIN | Label 2 loss: 184.6031 ; P: 1.0 ; R: 0.9989 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 2 loss: 324.9171 ; P: 0.92 ; R: 0.9194 ; F1: 0.9197 ; Acc: 0.9295\n",
      "2023-01-28 21:36:16.548287\n",
      "counter:  22\n",
      "2023-01-28 21:36:16.549282\n",
      "EPOCH 230\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1617\n",
      "fn:  133\n",
      "tn:  2089\n",
      "fp:  145\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3706\n",
      "    TRAIN | Label 2 loss: 183.695 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 326.9255 ; P: 0.9177 ; R: 0.924 ; F1: 0.9208 ; Acc: 0.9302\n",
      "2023-01-28 21:39:19.828656\n",
      "counter:  23\n",
      "2023-01-28 21:39:19.829656\n",
      "EPOCH 231\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1623\n",
      "fn:  127\n",
      "tn:  2074\n",
      "fp:  160\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3697\n",
      "    TRAIN | Label 2 loss: 183.6586 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 328.1901 ; P: 0.9103 ; R: 0.9274 ; F1: 0.9188 ; Acc: 0.928\n",
      "2023-01-28 21:42:24.112751\n",
      "counter:  24\n",
      "2023-01-28 21:42:24.113754\n",
      "EPOCH 232\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1617\n",
      "fn:  133\n",
      "tn:  2086\n",
      "fp:  148\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3703\n",
      "    TRAIN | Label 2 loss: 183.4321 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 325.0738 ; P: 0.9161 ; R: 0.924 ; F1: 0.9201 ; Acc: 0.9295\n",
      "2023-01-28 21:45:27.682834\n",
      "counter:  25\n",
      "2023-01-28 21:45:27.682834\n",
      "EPOCH 233\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1612\n",
      "fn:  138\n",
      "tn:  2095\n",
      "fp:  139\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3707\n",
      "    TRAIN | Label 2 loss: 183.1606 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 323.9634 ; P: 0.9206 ; R: 0.9211 ; F1: 0.9209 ; Acc: 0.9305\n",
      "2023-01-28 21:48:30.838273\n",
      "counter:  26\n",
      "2023-01-28 21:48:30.839265\n",
      "EPOCH 234\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1620\n",
      "fn:  130\n",
      "tn:  2082\n",
      "fp:  152\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3702\n",
      "    TRAIN | Label 2 loss: 182.9686 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 326.4695 ; P: 0.9142 ; R: 0.9257 ; F1: 0.9199 ; Acc: 0.9292\n",
      "2023-01-28 21:51:33.356893\n",
      "counter:  27\n",
      "2023-01-28 21:51:33.357889\n",
      "EPOCH 235\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1614\n",
      "fn:  136\n",
      "tn:  2086\n",
      "fp:  148\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3700\n",
      "    TRAIN | Label 2 loss: 182.5366 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 2 loss: 325.8299 ; P: 0.916 ; R: 0.9223 ; F1: 0.9191 ; Acc: 0.9287\n",
      "2023-01-28 21:54:35.854987\n",
      "counter:  28\n",
      "2023-01-28 21:54:35.854987\n",
      "EPOCH 236\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1611\n",
      "fn:  139\n",
      "tn:  2090\n",
      "fp:  144\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3701\n",
      "    TRAIN | Label 2 loss: 182.4081 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 324.1791 ; P: 0.9179 ; R: 0.9206 ; F1: 0.9193 ; Acc: 0.929\n",
      "2023-01-28 21:57:38.897843\n",
      "counter:  29\n",
      "2023-01-28 21:57:38.899830\n",
      "EPOCH 237\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1610\n",
      "fn:  140\n",
      "tn:  2088\n",
      "fp:  146\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3698\n",
      "    TRAIN | Label 2 loss: 182.1484 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 2 loss: 324.4684 ; P: 0.9169 ; R: 0.92 ; F1: 0.9184 ; Acc: 0.9282\n",
      "2023-01-28 22:00:42.342670\n",
      "counter:  30\n",
      "2023-01-28 22:00:42.343717\n",
      "EPOCH 238\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1622\n",
      "fn:  128\n",
      "tn:  2077\n",
      "fp:  157\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3699\n",
      "    TRAIN | Label 2 loss: 182.2901 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 325.3711 ; P: 0.9117 ; R: 0.9269 ; F1: 0.9192 ; Acc: 0.9285\n",
      "2023-01-28 22:03:45.913819\n",
      "counter:  31\n",
      "2023-01-28 22:03:45.913819\n",
      "EPOCH 239\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1612\n",
      "fn:  138\n",
      "tn:  2098\n",
      "fp:  136\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "    TRAIN | Label 2 loss: 182.266 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 2 loss: 322.2986 ; P: 0.9222 ; R: 0.9211 ; F1: 0.9217 ; Acc: 0.9312\n",
      "2023-01-28 22:06:48.769828\n",
      "counter:  32\n",
      "2023-01-28 22:06:48.770818\n",
      "EPOCH 240\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2071\n",
      "fp:  163\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3697\n",
      "    TRAIN | Label 2 loss: 181.9788 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 326.8899 ; P: 0.9089 ; R: 0.9291 ; F1: 0.9189 ; Acc: 0.928\n",
      "2023-01-28 22:09:51.939329\n",
      "counter:  33\n",
      "2023-01-28 22:09:51.940329\n",
      "EPOCH 241\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1622\n",
      "fn:  128\n",
      "tn:  2076\n",
      "fp:  158\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3698\n",
      "    TRAIN | Label 2 loss: 181.3115 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 2 loss: 326.3894 ; P: 0.9112 ; R: 0.9269 ; F1: 0.919 ; Acc: 0.9282\n",
      "2023-01-28 22:12:54.330571\n",
      "counter:  34\n",
      "2023-01-28 22:12:54.332553\n",
      "EPOCH 242\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1620\n",
      "fn:  130\n",
      "tn:  2076\n",
      "fp:  158\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3696\n",
      "    TRAIN | Label 2 loss: 181.2897 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 2 loss: 326.7511 ; P: 0.9111 ; R: 0.9257 ; F1: 0.9184 ; Acc: 0.9277\n",
      "2023-01-28 22:15:57.843211\n",
      "counter:  35\n",
      "2023-01-28 22:15:57.844202\n",
      "EPOCH 243\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1621\n",
      "fn:  129\n",
      "tn:  2080\n",
      "fp:  154\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3701\n",
      "    TRAIN | Label 2 loss: 180.9615 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 2 loss: 326.8422 ; P: 0.9132 ; R: 0.9263 ; F1: 0.9197 ; Acc: 0.929\n",
      "2023-01-28 22:19:01.043898\n",
      "counter:  36\n",
      "2023-01-28 22:19:01.044853\n",
      "EPOCH 244\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1629\n",
      "fn:  121\n",
      "tn:  2066\n",
      "fp:  168\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3695\n",
      "    TRAIN | Label 2 loss: 180.7066 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 2 loss: 330.4241 ; P: 0.9065 ; R: 0.9309 ; F1: 0.9185 ; Acc: 0.9275\n",
      "2023-01-28 22:22:04.587428\n",
      "counter:  37\n",
      "2023-01-28 22:22:04.588428\n",
      "EPOCH 245\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1623\n",
      "fn:  127\n",
      "tn:  2079\n",
      "fp:  155\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3702\n",
      "    TRAIN | Label 2 loss: 181.1081 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 326.1636 ; P: 0.9128 ; R: 0.9274 ; F1: 0.9201 ; Acc: 0.9292\n",
      "2023-01-28 22:25:07.569654\n",
      "counter:  38\n",
      "2023-01-28 22:25:07.569654\n",
      "EPOCH 246\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1619\n",
      "fn:  131\n",
      "tn:  2077\n",
      "fp:  157\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3696\n",
      "    TRAIN | Label 2 loss: 180.477 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 2 loss: 326.455 ; P: 0.9116 ; R: 0.9251 ; F1: 0.9183 ; Acc: 0.9277\n",
      "2023-01-28 22:28:10.599224\n",
      "counter:  39\n",
      "2023-01-28 22:28:10.600230\n",
      "EPOCH 247\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1621\n",
      "fn:  129\n",
      "tn:  2075\n",
      "fp:  159\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3696\n",
      "    TRAIN | Label 2 loss: 180.2891 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 2 loss: 327.1475 ; P: 0.9107 ; R: 0.9263 ; F1: 0.9184 ; Acc: 0.9277\n",
      "2023-01-28 22:31:13.851952\n",
      "counter:  40\n",
      "2023-01-28 22:31:13.853953\n",
      "EPOCH 248\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1622\n",
      "fn:  128\n",
      "tn:  2070\n",
      "fp:  164\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3692\n",
      "    TRAIN | Label 2 loss: 180.0487 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 2 loss: 329.2455 ; P: 0.9082 ; R: 0.9269 ; F1: 0.9174 ; Acc: 0.9267\n",
      "2023-01-28 22:34:17.563792\n",
      "counter:  41\n",
      "2023-01-28 22:34:17.564791\n",
      "EPOCH 249\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1624\n",
      "fn:  126\n",
      "tn:  2067\n",
      "fp:  167\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3691\n",
      "    TRAIN | Label 2 loss: 179.9361 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 2 loss: 329.7184 ; P: 0.9068 ; R: 0.928 ; F1: 0.9173 ; Acc: 0.9265\n",
      "2023-01-28 22:37:20.740065\n",
      "counter:  42\n",
      "2023-01-28 22:37:20.741063\n",
      "EPOCH 250\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1614\n",
      "fn:  136\n",
      "tn:  2084\n",
      "fp:  150\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3698\n",
      "    TRAIN | Label 2 loss: 180.3463 ; P: 0.9994 ; R: 1.0 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 327.1232 ; P: 0.915 ; R: 0.9223 ; F1: 0.9186 ; Acc: 0.9282\n",
      "2023-01-28 22:40:24.397110\n",
      "counter:  43\n",
      "2023-01-28 22:40:24.398110\n",
      "EPOCH 251\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1615\n",
      "fn:  135\n",
      "tn:  2076\n",
      "fp:  158\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3691\n",
      "    TRAIN | Label 2 loss: 179.8909 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 328.6206 ; P: 0.9109 ; R: 0.9229 ; F1: 0.9168 ; Acc: 0.9265\n",
      "2023-01-28 22:43:27.677966\n",
      "counter:  44\n",
      "2023-01-28 22:43:27.678969\n",
      "EPOCH 252\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1617\n",
      "fn:  133\n",
      "tn:  2070\n",
      "fp:  164\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3687\n",
      "    TRAIN | Label 2 loss: 180.2947 ; P: 0.9994 ; R: 1.0 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 329.506 ; P: 0.9079 ; R: 0.924 ; F1: 0.9159 ; Acc: 0.9255\n",
      "2023-01-28 22:46:31.031569\n",
      "counter:  45\n",
      "2023-01-28 22:46:31.031569\n",
      "EPOCH 253\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1624\n",
      "fn:  126\n",
      "tn:  2062\n",
      "fp:  172\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3686\n",
      "    TRAIN | Label 2 loss: 179.696 ; P: 0.9994 ; R: 1.0 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 330.9639 ; P: 0.9042 ; R: 0.928 ; F1: 0.916 ; Acc: 0.9252\n",
      "2023-01-28 22:49:33.555960\n",
      "counter:  46\n",
      "2023-01-28 22:49:33.555960\n",
      "EPOCH 254\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1611\n",
      "fn:  139\n",
      "tn:  2081\n",
      "fp:  153\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3692\n",
      "    TRAIN | Label 2 loss: 179.3699 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 2 loss: 326.5203 ; P: 0.9133 ; R: 0.9206 ; F1: 0.9169 ; Acc: 0.9267\n",
      "2023-01-28 22:52:36.922939\n",
      "counter:  47\n",
      "2023-01-28 22:52:36.923939\n",
      "EPOCH 255\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1617\n",
      "fn:  133\n",
      "tn:  2073\n",
      "fp:  161\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3690\n",
      "    TRAIN | Label 2 loss: 179.1766 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 2 loss: 327.7455 ; P: 0.9094 ; R: 0.924 ; F1: 0.9167 ; Acc: 0.9262\n",
      "2023-01-28 22:55:39.724528\n",
      "counter:  48\n",
      "2023-01-28 22:55:39.725527\n",
      "EPOCH 256\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1617\n",
      "fn:  133\n",
      "tn:  2074\n",
      "fp:  160\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3691\n",
      "    TRAIN | Label 2 loss: 179.0461 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 2 loss: 327.062 ; P: 0.91 ; R: 0.924 ; F1: 0.9169 ; Acc: 0.9265\n",
      "2023-01-28 22:58:43.387736\n",
      "counter:  49\n",
      "2023-01-28 22:58:43.387736\n",
      "EPOCH 257\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1616\n",
      "fn:  134\n",
      "tn:  2080\n",
      "fp:  154\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3696\n",
      "    TRAIN | Label 2 loss: 179.2575 ; P: 0.9994 ; R: 1.0 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 325.6741 ; P: 0.913 ; R: 0.9234 ; F1: 0.9182 ; Acc: 0.9277\n",
      "2023-01-28 23:01:45.823290\n",
      "counter:  50\n",
      "2023-01-28 23:01:45.824332\n",
      "EPOCH 258\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1614\n",
      "fn:  136\n",
      "tn:  2080\n",
      "fp:  154\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3694\n",
      "    TRAIN | Label 2 loss: 178.8163 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 2 loss: 324.5056 ; P: 0.9129 ; R: 0.9223 ; F1: 0.9176 ; Acc: 0.9272\n",
      "2023-01-28 23:04:48.586804\n",
      "counter:  51\n",
      "2023-01-28 23:04:48.587708\n",
      "EPOCH 259\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1620\n",
      "fn:  130\n",
      "tn:  2073\n",
      "fp:  161\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3693\n",
      "    TRAIN | Label 2 loss: 178.7113 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 2 loss: 326.1833 ; P: 0.9096 ; R: 0.9257 ; F1: 0.9176 ; Acc: 0.927\n",
      "2023-01-28 23:07:51.138219\n",
      "counter:  52\n",
      "2023-01-28 23:07:51.139219\n",
      "EPOCH 260\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1617\n",
      "fn:  133\n",
      "tn:  2077\n",
      "fp:  157\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3694\n",
      "    TRAIN | Label 2 loss: 179.1033 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 324.7312 ; P: 0.9115 ; R: 0.924 ; F1: 0.9177 ; Acc: 0.9272\n",
      "2023-01-28 23:10:54.403588\n",
      "counter:  53\n",
      "2023-01-28 23:10:54.404586\n",
      "EPOCH 261\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1607\n",
      "fn:  143\n",
      "tn:  2093\n",
      "fp:  141\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3700\n",
      "    TRAIN | Label 2 loss: 178.5268 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 2 loss: 322.3073 ; P: 0.9193 ; R: 0.9183 ; F1: 0.9188 ; Acc: 0.9287\n",
      "2023-01-28 23:13:57.427191\n",
      "counter:  54\n",
      "2023-01-28 23:13:57.428189\n",
      "EPOCH 262\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2062\n",
      "fp:  172\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3689\n",
      "    TRAIN | Label 2 loss: 178.4146 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 2 loss: 328.735 ; P: 0.9044 ; R: 0.9297 ; F1: 0.9169 ; Acc: 0.926\n",
      "2023-01-28 23:17:00.967354\n",
      "counter:  55\n",
      "2023-01-28 23:17:00.967354\n",
      "EPOCH 263\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1616\n",
      "fn:  134\n",
      "tn:  2079\n",
      "fp:  155\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3695\n",
      "    TRAIN | Label 2 loss: 178.3852 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 2 loss: 323.0537 ; P: 0.9125 ; R: 0.9234 ; F1: 0.9179 ; Acc: 0.9275\n",
      "2023-01-28 23:20:04.471459\n",
      "counter:  56\n",
      "2023-01-28 23:20:04.472458\n",
      "EPOCH 264\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1624\n",
      "fn:  126\n",
      "tn:  2072\n",
      "fp:  162\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3696\n",
      "    TRAIN | Label 2 loss: 178.2006 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 2 loss: 325.2313 ; P: 0.9093 ; R: 0.928 ; F1: 0.9186 ; Acc: 0.9277\n",
      "2023-01-28 23:23:07.045693\n",
      "counter:  57\n",
      "2023-01-28 23:23:07.046723\n",
      "EPOCH 265\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1638\n",
      "fn:  112\n",
      "tn:  2049\n",
      "fp:  185\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3687\n",
      "    TRAIN | Label 2 loss: 178.2818 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 332.4682 ; P: 0.8985 ; R: 0.936 ; F1: 0.9169 ; Acc: 0.9255\n",
      "2023-01-28 23:26:10.001242\n",
      "counter:  58\n",
      "2023-01-28 23:26:10.002233\n",
      "EPOCH 266\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2067\n",
      "fp:  167\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3693\n",
      "    TRAIN | Label 2 loss: 178.1571 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 2 loss: 326.0062 ; P: 0.9069 ; R: 0.9291 ; F1: 0.9179 ; Acc: 0.927\n",
      "2023-01-28 23:29:13.592532\n",
      "counter:  59\n",
      "2023-01-28 23:29:13.592532\n",
      "EPOCH 267\n",
      "TAG_LOSS_WEIGTH:  0.5\n",
      "CLS_LOSS_WEIGTH:  0.5\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2211\n",
      "fp:  1\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1622\n",
      "fn:  128\n",
      "tn:  2073\n",
      "fp:  161\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3695\n",
      "    TRAIN | Label 2 loss: 178.5095 ; P: 0.9994 ; R: 1.0 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 2 loss: 323.9362 ; P: 0.9097 ; R: 0.9269 ; F1: 0.9182 ; Acc: 0.9275\n",
      "2023-01-28 23:32:17.296386\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os, shutil\n",
    "import datetime\n",
    "\n",
    "OUTPUT_PATH = './checkpoint'\n",
    "OUTPUT_PATH =os.path.join(OUTPUT_PATH, BERT_PATH[2:])\n",
    "\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)\n",
    "\n",
    "\n",
    "label1_loss_train_list=[]\n",
    "# label1_loss_validation_list=[]\n",
    "label1_loss_test_list=[]\n",
    "\n",
    "label2_loss_train_list=[]\n",
    "# label2_loss_validation_list=[]\n",
    "label2_loss_test_list=[]\n",
    "\n",
    "label1_f1_train_list=[]\n",
    "# label1_f1_validation_list=[]\n",
    "label1_f1_test_list=[]\n",
    "\n",
    "label2_f1_train_list=[]\n",
    "# label2_f1_validation_list=[]\n",
    "label2_f1_test_list=[]\n",
    "\n",
    "label1_acc_train_list=[]\n",
    "# label1_acc_validation_list=[]\n",
    "label1_acc_test_list=[]\n",
    "\n",
    "label2_acc_train_list=[]\n",
    "# label2_acc_validation_list=[]\n",
    "label2_acc_test_list=[]\n",
    "\n",
    "best_label2_f1_va=-1\n",
    "best_label2_f1_te=-1\n",
    "\n",
    "epoch_num = 0\n",
    "min_validation_loss = np.inf\n",
    "max_validation_f = 0\n",
    "patience = 60\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(datetime.datetime.now())\n",
    "    print('EPOCH', epoch_num)\n",
    "    print('TAG_LOSS_WEIGTH: ', TAG_LOSS_WEIGTH)\n",
    "    print('CLS_LOSS_WEIGTH: ', CLS_LOSS_WEIGTH)\n",
    "    loss_label2_tr, p_label2_tr, r_label2_tr, f_label2_tr, acc_label2_tr = train(model, train_iterator, optimizer, scheduler, criterion_tag, criterion_cls, TAG_PAD_IDX, TAG_LOSS_WEIGTH, CLS_LOSS_WEIGTH)\n",
    "    # if epoch_num==0:\n",
    "    #     # first_epoch_loss_tag = loss_label1_tr\n",
    "    #     first_epoch_loss_cls = loss_label2_tr\n",
    "    # if epoch_num != 0:\n",
    "    #     # TAG_LOSS_WEIGTH = (loss_label1_tr/first_epoch_loss_tag)**2\n",
    "    #     CLS_LOSS_WEIGTH = (loss_label2_tr/first_epoch_loss_cls)**2\n",
    "    # coef=1/(TAG_LOSS_WEIGTH+CLS_LOSS_WEIGTH)\n",
    "    # TAG_LOSS_WEIGTH = coef*TAG_LOSS_WEIGTH\n",
    "    # CLS_LOSS_WEIGTH = coef*CLS_LOSS_WEIGTH\n",
    "    # loss_label1_va, loss_label2_va, p_label1_va, r_label1_va, f_label1_va, acc_label1_va, p_label2_va, r_label2_va, f_label2_va, acc_label2_va = evaluate(model, valid_iterator, criterion_tag, criterion_cls, TAG_PAD_IDX)\n",
    "    loss_label2_te,  p_label2_te, r_label2_te, f_label2_te, acc_label2_te = evaluate(model, test_iterator, criterion_tag, criterion_cls, TAG_PAD_IDX)\n",
    "    \n",
    "    # print('   TRAIN | Label 1 loss:', loss_label1_tr, '; P:', p_label1_tr, '; R:', r_label1_tr, '; F1:', f_label1_tr, '; Acc:', acc_label1_tr)\n",
    "    print('    TRAIN | Label 2 loss:', loss_label2_tr, '; P:', p_label2_tr, '; R:', r_label2_tr, '; F1:', f_label2_tr, '; Acc:', acc_label2_tr)\n",
    "    # print('   VALID | Label 1 loss:', loss_label1_va, '; P:', p_label1_va, '; R:', r_label1_va, '; F1:', f_label1_va, '; Acc:', acc_label1_va)\n",
    "    # print('           Label 2 loss:', loss_label2_va, '; P:', p_label2_va, '; R:', r_label2_va, '; F1:', f_label2_va, '; Acc:', acc_label2_va)\n",
    "    # print('    TEST | Label 1 loss:', loss_label1_te, '; P:', p_label1_te, '; R:', r_label1_te, '; F1:', f_label1_te, '; Acc:', acc_label1_te)\n",
    "    print('    TEST | Label 2 loss:', loss_label2_te, '; P:', p_label2_te, '; R:', r_label2_te, '; F1:', f_label2_te, '; Acc:', acc_label2_te)\n",
    "    print(datetime.datetime.now())\n",
    "    epoch_num +=1\n",
    "    # if loss_label1_tr < 180:\n",
    "    #     TAG_LOSS_WEIGTH =0.1*TAG_LOSS_WEIGTH\n",
    "    \n",
    "    #print(\"Tag loss weight: \", TAG_LOSS_WEIGTH)\n",
    "    \n",
    "    # label1_loss_train_list.append(loss_label1_tr)\n",
    "    # # label1_loss_validation_list.append(loss_label1_va)\n",
    "    # label1_loss_test_list.append(loss_label1_te)\n",
    "    \n",
    "    label2_loss_train_list.append(loss_label2_tr)\n",
    "    # label2_loss_validation_list.append(loss_label2_va)\n",
    "    label2_loss_test_list.append(loss_label2_te)\n",
    "    \n",
    "    # label1_f1_train_list.append(f_label1_tr)\n",
    "    # # label1_f1_validation_list.append(f_label1_va)\n",
    "    # label1_f1_test_list.append(f_label1_te)\n",
    "    \n",
    "    label2_f1_train_list.append(f_label2_tr)\n",
    "    # label2_f1_validation_list.append(f_label2_va)\n",
    "    label2_f1_test_list.append(f_label2_te)\n",
    "    \n",
    "    # label1_acc_train_list.append(acc_label1_tr)\n",
    "    # # label1_f1_validation_list.append(f_label1_va)\n",
    "    # label1_acc_test_list.append(acc_label1_te)\n",
    "    \n",
    "    label2_acc_train_list.append(acc_label2_tr)\n",
    "    # label2_f1_validation_list.append(f_label2_va)\n",
    "    label2_acc_test_list.append(acc_label2_te)\n",
    "    \n",
    "    \n",
    "    # OUTPUT_PATH_validation =os.path.join(OUTPUT_PATH, 'validation')\n",
    "    # if not os.path.exists(OUTPUT_PATH_validation):\n",
    "    #     os.makedirs(OUTPUT_PATH_validation)\n",
    "    # if f_label2_va>best_label2_f1_va:\n",
    "    #     best_label2_f1_va=f_label2_va\n",
    "    #     output_dir_validation = os.path.join(OUTPUT_PATH_validation, 'checkpoint_epoch{}.pt'.format(epoch))\n",
    "    #     # clear the content of folder\n",
    "    #     for files in os.listdir(OUTPUT_PATH_validation):\n",
    "    #         path = os.path.join(OUTPUT_PATH_validation, files)\n",
    "    #         try:\n",
    "    #             shutil.rmtree(path)\n",
    "    #         except OSError:\n",
    "    #             os.remove(path)\n",
    "    #     # if not os.path.exists(output_dir):\n",
    "    #     #     os.makedirs(output_dir)\n",
    "    #     torch.save(model.state_dict(), output_dir_validation)\n",
    "        \n",
    "    OUTPUT_PATH_test =os.path.join(OUTPUT_PATH, 'test/')\n",
    "    if not os.path.exists(OUTPUT_PATH_test):\n",
    "        os.makedirs(OUTPUT_PATH_test)\n",
    "    if f_label2_te>best_label2_f1_te:\n",
    "        best_label2_f1_te=f_label2_te\n",
    "        output_dir_test = os.path.join(OUTPUT_PATH_test, 'checkpoint_epoch{}.pt'.format(epoch))\n",
    "        # clear the content of folder\n",
    "        for files in os.listdir(OUTPUT_PATH_test):\n",
    "            path = os.path.join(OUTPUT_PATH_test, files)\n",
    "            try:\n",
    "                shutil.rmtree(path)\n",
    "            except OSError:\n",
    "                os.remove(path)\n",
    "        # if not os.path.exists(output_dir):\n",
    "        #     os.makedirs(output_dir)\n",
    "        torch.save(model.state_dict(), output_dir_test)\n",
    "    # early stop\n",
    "    if f_label2_te >= max_validation_f:\n",
    "            max_validation_f = f_label2_te\n",
    "            counter = 0\n",
    "    elif f_label2_te < max_validation_f:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                break\n",
    "    print('counter: ',counter)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea40172a-605f-43ec-824b-936130173e0a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# label1_loss_df = pd.DataFrame(\n",
    "#     {'label1_loss_train': label1_loss_train_list,\n",
    "#      # 'label1_loss_validation': label1_loss_validation_list,\n",
    "#      'label1_loss_test': label1_loss_test_list\n",
    "#     })\n",
    "label2_loss_df = pd.DataFrame(\n",
    "    {'label2_loss_train': label2_loss_train_list,\n",
    "     # 'label2_loss_validation': label2_loss_validation_list,\n",
    "     'label2_loss_test': label2_loss_test_list\n",
    "    })\n",
    "# label1_f1_df = pd.DataFrame(\n",
    "#     {'label1_f1_train': label1_f1_train_list,\n",
    "#      # 'label1_f1_validation': label1_f1_validation_list,\n",
    "#      'label1_f1_test': label1_f1_test_list\n",
    "#     })\n",
    "label2_f1_df = pd.DataFrame(\n",
    "    {'label2_f1_train': label2_f1_train_list,\n",
    "     # 'label2_f1_validation': label2_f1_validation_list,\n",
    "     'label2_f1_test': label2_f1_test_list\n",
    "    })\n",
    "# label1_acc_df = pd.DataFrame(\n",
    "#     {'label1_f1_train': label1_acc_train_list,\n",
    "#      # 'label1_f1_validation': label1_f1_validation_list,\n",
    "#      'label1_f1_test': label1_acc_test_list\n",
    "#     })\n",
    "label2_acc_df = pd.DataFrame(\n",
    "    {'label2_acc_train': label2_acc_train_list,\n",
    "     # 'label2_f1_validation': label2_f1_validation_list,\n",
    "     'label2_acc_test': label2_acc_test_list\n",
    "    })\n",
    "# label1_loss_df.plot()\n",
    "# label2_loss_df.plot()\n",
    "# label1_f1_df.plot()\n",
    "# label2_f1_df.plot()\n",
    "# label1_acc_df.plot()\n",
    "# label2_acc_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "777e5eb2-8d49-46c7-9d9e-7d9ce323fc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./checkpoint\\\\bert-large-uncased\\\\test/checkpoint_epoch207.pt'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5918fbda-c096-42f6-b749-32b7c14a9176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'label2 acc'}, xlabel='epochs', ylabel='acc'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# label1_loss_df.plot(title=\"label1 losses\",xlabel=\"epochs\",ylabel=\"loss\")\n",
    "label2_loss_df.plot(title=\"label2 losses\",xlabel=\"epochs\",ylabel=\"loss\")\n",
    "# label1_f1_df.plot(title=\"label1 f1\",xlabel=\"epochs\",ylabel=\"f1\")\n",
    "label2_f1_df.plot(title=\"label2 f1\",xlabel=\"epochs\",ylabel=\"f1\")\n",
    "# label1_acc_df.plot(title=\"label1 acc\",xlabel=\"epochs\",ylabel=\"acc\")\n",
    "label2_acc_df.plot(title=\"label2 acc\",xlabel=\"epochs\",ylabel=\"acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6591fe4a-1a14-41c6-a43d-563c0b1d6af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9231"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(label2_f1_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2629b306-c507-4e4e-bb1a-b671725d8a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9317"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(label2_acc_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a2b8ddc-2236-4252-b626-e33e9a136bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_female = data.TabularDataset(\n",
    "                                    path = DATA_PATH+'gap_test_female_bert_2mask.csv',\n",
    "                                    format = 'csv',\n",
    "                                    fields = fields,\n",
    "                                    skip_header = True)\n",
    "test_data_male = data.TabularDataset(\n",
    "                                    path = DATA_PATH+'gap_test_male_bert_2mask.csv',\n",
    "                                    format = 'csv',\n",
    "                                    fields = fields,\n",
    "                                    skip_header = True)\n",
    "\n",
    "TOKEN.build_vocab(test_data_female, test_data_male)\n",
    "LABEL1.build_vocab(test_data_female, test_data_male)\n",
    "FT_TAGS.build_vocab(test_data_female, test_data_male)\n",
    "SEQ.build_vocab(test_data_female, test_data_male)\n",
    "LABEL2.build_vocab(test_data_female, test_data_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "085e0238-ff9d-4246-a09b-ad82ea7b64b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.legacy.data.dataset.TabularDataset object at 0x0000019ED5FB3070>\n",
      "<torchtext.legacy.data.dataset.TabularDataset object at 0x0000019ED5FB39D0>\n"
     ]
    }
   ],
   "source": [
    "print(test_data_female)\n",
    "print(test_data_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3e2cd5d-8249-4d15-a23e-adc3dd70d0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_female_iterator = data.BucketIterator(\n",
    "    test_data_female, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    shuffle = True,\n",
    "    sort=False)\n",
    "test_male_iterator = data.BucketIterator(\n",
    "    test_data_male, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    shuffle = True,\n",
    "    sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef1828bb-eebc-4cb9-96fb-5cd6e6a17b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.legacy.data.iterator.BucketIterator'>\n",
      "<class 'torchtext.legacy.data.iterator.BucketIterator'>\n"
     ]
    }
   ],
   "source": [
    "print(type(test_female_iterator))\n",
    "print(type(test_male_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6faa13c9-8697-4d0b-a206-67cbd793d1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(output_dir_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73adc569-a586-4b78-9f1e-81189c911538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoint\\bert-large-uncased\\test/checkpoint_epoch207.pt\n"
     ]
    }
   ],
   "source": [
    "print(output_dir_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6186dc67-83c0-45c0-84e6-a9a15a0f633a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp:  1632\n",
      "fn:  118\n",
      "tn:  2080\n",
      "fp:  154\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match number:  3712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_18388\\2308754701.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "loss_label2_te, p_label2_te, r_label2_te, f_label2_te, acc_label2_te, comparison_df_te = evaluate_output_difference(model, test_iterator, criterion_tag, criterion_cls, TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c234d212-0030-4137-9cf5-102091a1845d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9231"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_label2_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "225b213f-7eca-4114-9072-7e0d776ee4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('E:/Google Drive/Continental/coref-multitask/winogender')\n",
    "os.chdir('./gap')\n",
    "comparison_df_te.to_csv(\"comparison_gap_bert_singletask.csv\", index=False,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bfb5a8fd-6148-4f46-9478-a6b9f9097b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp:  798\n",
      "fn:  72\n",
      "tn:  1042\n",
      "fp:  82\n",
      "pred label2 length:  1994\n",
      "true label2 length:  1994\n",
      "match number:  1840\n"
     ]
    }
   ],
   "source": [
    "loss_label2_te_female, p_label2_te_female,r_label2_te_female, f_label2_te_female, acc_label2_te_female = evaluate(model, test_female_iterator, criterion_tag, criterion_cls, TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0f30f234-6a37-450c-b514-82621b4b3e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_label2_te_female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b4fe4f6-5eeb-4f6d-a2ef-8e50fcc8583f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp:  827\n",
      "fn:  53\n",
      "tn:  1030\n",
      "fp:  80\n",
      "pred label2 length:  1990\n",
      "true label2 length:  1990\n",
      "match number:  1857\n"
     ]
    }
   ],
   "source": [
    "loss_label2_te_male, p_label2_te_male, r_label2_te_male, f_label2_te_male, acc_label2_te_male = evaluate(model, test_male_iterator, criterion_tag, criterion_cls, TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7f9457b3-9a99-44d9-b44e-4e566f215340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9256"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_label2_te_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "652e6a64-be35-4f00-8428-286b53ed653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bias=f_label2_te_female/f_label2_te_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8a37c55-6239-4224-813e-18d15af07b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9853068280034573"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "53560c29-27ac-4364-9fd9-95dd05de2cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('E:/Google Drive/Continental/coref-multitask')\n",
    "# DATA_PATH = './winogender/'\n",
    "# winogender_df = data.TabularDataset(\n",
    "#                                     path = DATA_PATH+'winogender_df_new_spanbert.csv',\n",
    "#                                     format = 'csv',\n",
    "#                                     fields = fields,\n",
    "#                                     skip_header = True)\n",
    "\n",
    "# TOKEN.build_vocab(winogender_df)\n",
    "# LABEL1.build_vocab(winogender_df)\n",
    "# FT_TAGS.build_vocab(winogender_df)\n",
    "# SEQ.build_vocab(winogender_df)\n",
    "# LABEL2.build_vocab(winogender_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2106030-16b4-437b-b1be-1e3ba48ff0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(winogender_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "93cc74f5-808b-468c-b2f6-debac9c7dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# winogender_iterator = data.BucketIterator(\n",
    "#     winogender_df, \n",
    "#     batch_size = BATCH_SIZE,\n",
    "#     device = device,\n",
    "#     shuffle = True,\n",
    "#     sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b7fa9392-49c1-48db-bfda-4e751e79a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_label1_winogender, loss_label2_winogender, p_label1_winogender, r_label1_winogender,f_label1_winogender, acc_label1_winogender, p_label2_winogender,r_label2_winogender, f_label2_winogender, acc_label2_winogender = evaluate(model, winogender_iterator, criterion_tag, criterion_cls, TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ed9234cf-f68d-43a6-965e-9dcd1e721bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_label2_winogender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649a08e4-fef1-4930-923a-5b6ee6f83b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
