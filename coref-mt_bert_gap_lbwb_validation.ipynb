{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5544d3ec-a275-43af-9704-32cfe4747c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da81ce68-01b4-45ee-96f2-5ccd272d97aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a97e1236-837f-461b-8dec-57273845ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99309099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.legacy import data\n",
    "#from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "#from transformers import RobertaTokenizer, RobertaModel\n",
    "#from transformers import BertTokenizer, BertModel\n",
    "#from transformers import LongformerTokenizer, LongformerModel\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import statistics\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random\n",
    "import functools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf54be0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./bert-large-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters & setup\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "DROPOUT = 0.2\n",
    "N_EPOCHS = 610\n",
    "BATCH_SIZE = 4\n",
    "# batch accumulation parameter\n",
    "accum_iter = 4\n",
    "LEARNING_RATE = 2e-6\n",
    "NO_HEAD_TRANS = 16\n",
    "\n",
    "TAG_LOSS_WEIGTH = 0.5\n",
    "CLS_LOSS_WEIGTH = 0.5\n",
    "\n",
    "BERT_PATH = './bert-large-uncased' # the path of your downloaded pre-trained language model\n",
    "DATA_PATH = './gap/'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_PATH)\n",
    "bert = AutoModel.from_pretrained(BERT_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "681d50c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pre-processing\n",
    "\n",
    "def read_token_idx_list_n_cut_to_max_length(tokens, max_input_length):\n",
    "    \n",
    "    tokens =  tokens[:max_input_length-1]\n",
    "    tokens_list = []\n",
    "    for i in tokens:\n",
    "        tokens_list.append(int(i))\n",
    "    return torch.tensor(tokens_list)\n",
    "\n",
    "def cut_to_max_length(tokens, max_input_length):\n",
    "    tokens = tokens[:max_input_length-1]\n",
    "    return tokens\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "pad_token = tokenizer.pad_token\n",
    "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
    "max_input_length = tokenizer.max_model_input_sizes['bert-large-cased']\n",
    "text_id_preprocessor = functools.partial(read_token_idx_list_n_cut_to_max_length,max_input_length = max_input_length)\n",
    "tag_preprocessor = functools.partial(cut_to_max_length, max_input_length = max_input_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e0231b7-347d-401b-80f2-18c1cf067f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert-base-uncased': 512,\n",
       " 'bert-large-uncased': 512,\n",
       " 'bert-base-cased': 512,\n",
       " 'bert-large-cased': 512,\n",
       " 'bert-base-multilingual-uncased': 512,\n",
       " 'bert-base-multilingual-cased': 512,\n",
       " 'bert-base-chinese': 512,\n",
       " 'bert-base-german-cased': 512,\n",
       " 'bert-large-uncased-whole-word-masking': 512,\n",
       " 'bert-large-cased-whole-word-masking': 512,\n",
       " 'bert-large-uncased-whole-word-masking-finetuned-squad': 512,\n",
       " 'bert-large-cased-whole-word-masking-finetuned-squad': 512,\n",
       " 'bert-base-cased-finetuned-mrpc': 512,\n",
       " 'bert-base-german-dbmdz-cased': 512,\n",
       " 'bert-base-german-dbmdz-uncased': 512,\n",
       " 'TurkuNLP/bert-base-finnish-cased-v1': 512,\n",
       " 'TurkuNLP/bert-base-finnish-uncased-v1': 512,\n",
       " 'wietsedv/bert-base-dutch-cased': 512}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.max_model_input_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db3a44be-f250-4727-b2f1-a75d8c7482e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b13fb8a6-446f-4e68-a1d9-7d026df063cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-large-uncased'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT_PATH[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2778ba5-e654-43f2-96b9-d0aa7cf2529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "\n",
    "TOKEN = data.Field(batch_first = True)\n",
    "TOKEN_ID = data.Field(batch_first = True,\n",
    "                     use_vocab = False,\n",
    "                     dtype=torch.int64,\n",
    "                     pad_token = pad_token_idx,\n",
    "                     preprocessing = text_id_preprocessor)\n",
    "LABEL1 = data.Field(batch_first = True,\n",
    "                    unk_token = None,\n",
    "                    preprocessing = tag_preprocessor)\n",
    "MASK_AB = data.Field(batch_first = True,\n",
    "                     use_vocab = False,\n",
    "                     dtype=torch.int64,\n",
    "                     pad_token = pad_token_idx,\n",
    "                     preprocessing = text_id_preprocessor)\n",
    "MASK_P = data.Field(batch_first = True,\n",
    "                     use_vocab = False,\n",
    "                     dtype=torch.int64,\n",
    "                     pad_token = pad_token_idx,\n",
    "                     preprocessing = text_id_preprocessor)\n",
    "FT_TAGS = data.Field(batch_first = True,\n",
    "                     use_vocab = False,\n",
    "                     dtype=torch.int64,\n",
    "                     pad_token = pad_token_idx,\n",
    "                     preprocessing = text_id_preprocessor)\n",
    "SEQ = data.Field(batch_first = True)\n",
    "LABEL2 = data.Field(batch_first = True,\n",
    "                    unk_token = None,\n",
    "                    #pad_token = None,\n",
    "                    preprocessing = tag_preprocessor)\n",
    "\n",
    "fields = ((\"token\", TOKEN),\n",
    "          ('token_id', TOKEN_ID),\n",
    "          ('label1', LABEL1),\n",
    "          ('mask_ab', MASK_AB),\n",
    "          ('mask_p', MASK_P),\n",
    "          ('first_token', FT_TAGS),\n",
    "          ('seq', SEQ),\n",
    "          ('label2', LABEL2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "201d6f0a-9b53-49d1-b8fd-a8f21513de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data.TabularDataset.splits(\n",
    "                                    path = DATA_PATH,\n",
    "                                    train = 'gap_train_bert_2mask.csv',\n",
    "                                    validation = None,\n",
    "                                    test = 'gap_test_bert_2mask.csv',\n",
    "                                    format = 'csv',\n",
    "                                    fields = fields,\n",
    "                                    skip_header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a188fd46-c10e-481b-bba6-29a8fff620ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN.build_vocab(train_data, test_data)\n",
    "LABEL1.build_vocab(train_data, test_data)\n",
    "FT_TAGS.build_vocab(train_data, test_data)\n",
    "SEQ.build_vocab(train_data, test_data)\n",
    "LABEL2.build_vocab(train_data, test_data)\n",
    "\n",
    "# if you want to prepare a big vocabulary that covers words that never appear in your dataset:\n",
    "\n",
    "#word_list = [['<unk>', '<pad>', 'I', 'great', \"it's\", 'like', 'swimming', '.', ',', 'BBBBBBB']]\n",
    "#TOKEN.build_vocab(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4454779e-ee86-4d6e-a264-bcf14b48571f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.legacy.data.dataset.TabularDataset'>\n",
      "<torchtext.legacy.data.dataset.TabularDataset object at 0x0000027A885244C0>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09b8cde6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: {'token': ['[CLS]', 'between', 'the', 'years', '1979', '-', '1981', ',', 'river', 'won', 'four', 'local', 'titles', ',', 'and', 'became', 'one', 'of', 'the', 'most', 'expensive', 'teams', 'in', 'the', 'world', ',', 'with', 'a', 'first', 'team', '(', 'alonso', '-', 'lu', '##que', ')', 'playing', 'in', 'league', 'games', 'and', 'an', 'equally', 'prestigious', 'second', 'team', '(', 'carr', '##asco', '-', 'ram', '*', 'n', 'd', '*', 'az', ')', 'used', 'mostly', 'in', 'copa', 'libertadores', 'matches', '.', 'during', 'the', '1981', '`', '`', 'nacional', \"'\", \"'\", 'tournament', '(', 'which', 'river', 'would', 'eventually', 'win', ')', ',', 'alonso', 'often', 'clashed', 'with', 'then', 'coach', 'alfredo', 'di', 'st', '*', 'fan', '##o', '(', 'who', 'seldom', 'selected', 'him', 'for', 'the', 'first', 'team', 'and', 'instead', 'put', 'younger', 'players', 'such', 'as', 'carlos', 'daniel', 'tap', '##ia', 'and', 'jose', 'maria', 'viet', '##a', 'in', 'his', 'position', ')', '.', '[SEP]'], 'token_id': tensor([  101,  2090,  1996,  2086,  3245,  1011,  3261,  1010,  2314,  2180,\n",
      "         2176,  2334,  4486,  1010,  1998,  2150,  2028,  1997,  1996,  2087,\n",
      "         6450,  2780,  1999,  1996,  2088,  1010,  2007,  1037,  2034,  2136,\n",
      "         1006, 17649,  1011, 11320,  4226,  1007,  2652,  1999,  2223,  2399,\n",
      "         1998,  2019,  8053,  8919,  2117,  2136,  1006, 12385, 28187,  1011,\n",
      "         8223,  1008,  1050,  1040,  1008, 17207,  1007,  2109,  3262,  1999,\n",
      "        10613, 27968,  3503,  1012,  2076,  1996,  3261,  1036,  1036, 10718,\n",
      "         1005,  1005,  2977,  1006,  2029,  2314,  2052,  2776,  2663,  1007,\n",
      "         1010, 17649,  2411, 22600,  2007,  2059,  2873, 19423,  4487,  2358,\n",
      "         1008,  5470,  2080,  1006,  2040, 15839,  3479,  2032,  2005,  1996,\n",
      "         2034,  2136,  1998,  2612,  2404,  3920,  2867,  2107,  2004,  5828,\n",
      "         3817, 11112,  2401,  1998,  4560,  3814, 19710,  2050,  1999,  2010,\n",
      "         2597,  1007,  1012,   102]), 'label1': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'mask_ab': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0]), 'mask_p': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0]), 'first_token': tensor([0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 0, 0, 0]), 'seq': ['Between', 'the', 'years', '1979-1981,', 'River', 'won', 'four', 'local', 'titles,', 'and', 'became', 'one', 'of', 'the', 'most', 'expensive', 'teams', 'in', 'the', 'world,', 'with', 'a', 'first', 'team', '(Alonso-', 'Luque)', 'playing', 'in', 'league', 'games', 'and', 'an', 'equally', 'prestigious', 'second', 'team', '(Carrasco-', 'Ram*n', 'D*az)', 'used', 'mostly', 'in', 'Copa', 'Libertadores', 'matches.', 'During', 'the', '1981', \"``Nacional''\", 'tournament', '(which', 'River', 'would', 'eventually', 'win),', 'Alonso', 'often', 'clashed', 'with', 'then', 'coach', 'Alfredo', 'Di', 'St*fano', '(who', 'seldom', 'selected', 'him', 'for', 'the', 'first', 'team', 'and', 'instead', 'put', 'younger', 'players', 'such', 'as', 'Carlos', 'Daniel', 'Tapia', 'and', 'Jose', 'Maria', 'Vieta', 'in', 'his', 'position).'], 'label2': ['1']}\n",
      "Label1 vocab ['<pad>', '0', '1']\n",
      "Label2 vocab ['<pad>', '0', '1']\n"
     ]
    }
   ],
   "source": [
    "print('Example:', vars(test_data.examples[2]))\n",
    "print('Label1 vocab', LABEL1.vocab.itos)\n",
    "print('Label2 vocab', LABEL2.vocab.itos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9491f7ad-bd7e-42c1-954b-7c08e137de3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: {'token': ['[CLS]', 'between', 'the', 'years', '1979', '-', '1981', ',', 'river', 'won', 'four', 'local', 'titles', ',', 'and', 'became', 'one', 'of', 'the', 'most', 'expensive', 'teams', 'in', 'the', 'world', ',', 'with', 'a', 'first', 'team', '(', 'alonso', '-', 'lu', '##que', ')', 'playing', 'in', 'league', 'games', 'and', 'an', 'equally', 'prestigious', 'second', 'team', '(', 'carr', '##asco', '-', 'ram', '*', 'n', 'd', '*', 'az', ')', 'used', 'mostly', 'in', 'copa', 'libertadores', 'matches', '.', 'during', 'the', '1981', '`', '`', 'nacional', \"'\", \"'\", 'tournament', '(', 'which', 'river', 'would', 'eventually', 'win', ')', ',', 'alonso', 'often', 'clashed', 'with', 'then', 'coach', 'alfredo', 'di', 'st', '*', 'fan', '##o', '(', 'who', 'seldom', 'selected', 'him', 'for', 'the', 'first', 'team', 'and', 'instead', 'put', 'younger', 'players', 'such', 'as', 'carlos', 'daniel', 'tap', '##ia', 'and', 'jose', 'maria', 'viet', '##a', 'in', 'his', 'position', ')', '.', '[SEP]'], 'token_id': tensor([  101,  2090,  1996,  2086,  3245,  1011,  3261,  1010,  2314,  2180,\n",
      "         2176,  2334,  4486,  1010,  1998,  2150,  2028,  1997,  1996,  2087,\n",
      "         6450,  2780,  1999,  1996,  2088,  1010,  2007,  1037,  2034,  2136,\n",
      "         1006, 17649,  1011, 11320,  4226,  1007,  2652,  1999,  2223,  2399,\n",
      "         1998,  2019,  8053,  8919,  2117,  2136,  1006, 12385, 28187,  1011,\n",
      "         8223,  1008,  1050,  1040,  1008, 17207,  1007,  2109,  3262,  1999,\n",
      "        10613, 27968,  3503,  1012,  2076,  1996,  3261,  1036,  1036, 10718,\n",
      "         1005,  1005,  2977,  1006,  2029,  2314,  2052,  2776,  2663,  1007,\n",
      "         1010, 17649,  2411, 22600,  2007,  2059,  2873, 19423,  4487,  2358,\n",
      "         1008,  5470,  2080,  1006,  2040, 15839,  3479,  2032,  2005,  1996,\n",
      "         2034,  2136,  1998,  2612,  2404,  3920,  2867,  2107,  2004,  5828,\n",
      "         3817, 11112,  2401,  1998,  4560,  3814, 19710,  2050,  1999,  2010,\n",
      "         2597,  1007,  1012,   102]), 'label1': ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], 'mask_ab': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0]), 'mask_p': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0]), 'first_token': tensor([0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 0, 0, 0]), 'seq': ['Between', 'the', 'years', '1979-1981,', 'River', 'won', 'four', 'local', 'titles,', 'and', 'became', 'one', 'of', 'the', 'most', 'expensive', 'teams', 'in', 'the', 'world,', 'with', 'a', 'first', 'team', '(Alonso-', 'Luque)', 'playing', 'in', 'league', 'games', 'and', 'an', 'equally', 'prestigious', 'second', 'team', '(Carrasco-', 'Ram*n', 'D*az)', 'used', 'mostly', 'in', 'Copa', 'Libertadores', 'matches.', 'During', 'the', '1981', \"``Nacional''\", 'tournament', '(which', 'River', 'would', 'eventually', 'win),', 'Alonso', 'often', 'clashed', 'with', 'then', 'coach', 'Alfredo', 'Di', 'St*fano', '(who', 'seldom', 'selected', 'him', 'for', 'the', 'first', 'team', 'and', 'instead', 'put', 'younger', 'players', 'such', 'as', 'Carlos', 'Daniel', 'Tapia', 'and', 'Jose', 'Maria', 'Vieta', 'in', 'his', 'position).'], 'label2': ['1']}\n"
     ]
    }
   ],
   "source": [
    "print('Example:', vars(test_data.examples[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "601a08eb-25da-4717-8cca-a36accc7ef88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.legacy.data.dataset.TabularDataset"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "770e518b-8b92-4f39-8703-e8eeb68154ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3978"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5d813a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# train_iterator, test_iterator = data.BucketIterator.splits(\n",
    "#     (train_data, test_data), \n",
    "#     batch_size = BATCH_SIZE,\n",
    "#     device = device,\n",
    "#     shuffle = True,\n",
    "#     sort=False)\n",
    "train_iterator = data.BucketIterator(\n",
    "    train_data, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    shuffle = True,\n",
    "    sort=False)\n",
    "test_iterator = data.BucketIterator(\n",
    "    test_data, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    shuffle = False,\n",
    "    sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebd6678c-1ab6-4ff6-98cc-034f1f400fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.config.to_dict()['hidden_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "868bef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTL(nn.Module):\n",
    "    def __init__(self,bert,label1_output_dim,label2_output_dim,dropout,no_head_trans):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        # embedding_dim = 1024\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.tag_layer1 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        self.cls_layer1 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        self.tag_layer2 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        self.cls_layer2 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        # self.tag_layer3 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        # self.cls_layer3 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        # self.tag_layer4 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        # self.cls_layer4 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        \n",
    "        self.fc_tag = nn.Linear(embedding_dim, label1_output_dim)\n",
    "        self.fc_cls = nn.Linear(embedding_dim, label2_output_dim)\n",
    "        # self.fc_cls = nn.Linear(embedding_dim*2, label2_output_dim)\n",
    "        self.fc_layernorm_cls = nn.LayerNorm(label2_output_dim)\n",
    "        \n",
    "    def forward(self, token_id, mask_ab, mask_p):\n",
    "        \n",
    "        emb_share = self.dropout(self.bert(token_id)[0]) # [batch size, seq len, emb dim]\n",
    "        \n",
    "        tag1 = self.dropout(self.tag_layer1(emb_share))  # [batch size, seq len, emb dim]\n",
    "        cls1 = self.dropout(self.cls_layer1(emb_share))    # [batch size, seq len, emb dim]\n",
    "        tag2 = self.dropout(self.tag_layer2(tag1))  # [batch size, seq len, emb dim]\n",
    "        cls2 = self.dropout(self.cls_layer2(cls1))    # [batch size, seq len, emb dim]\n",
    "        # tag3 = self.dropout(self.tag_layer3(tag2))  # [batch size, seq len, emb dim]\n",
    "        # cls3 = self.dropout(self.cls_layer3(cls2))    # [batch size, seq len, emb dim]\n",
    "        # tag4 = self.dropout(self.tag_layer4(tag2))  # [batch size, seq len, emb dim]\n",
    "        # cls4 = self.dropout(self.cls_layer4(cls3))    # [batch size, seq len, emb dim]\n",
    "        \n",
    "        tag_pred = self.fc_tag(tag2) # [batch size, seq len, output dim 1]\n",
    "        \n",
    "        \n",
    "        # get the average for candidate\n",
    "        cls_mask_ab = torch.sum(cls2*mask_ab.unsqueeze(2),1)/torch.sum(mask_ab.unsqueeze(2),1) # [batch size, emb dim]\n",
    "        # cls_mask_ab = torch.sum(cls4*mask_ab.unsqueeze(2),1) # [batch size, emb dim]\n",
    "        # get the average for pronoun\n",
    "        cls_mask_p = torch.sum(cls2*mask_p.unsqueeze(2),1)/torch.sum(mask_p.unsqueeze(2),1) # [batch size, emb dim]\n",
    "        \n",
    "        # element wise product\n",
    "        cls_fusion= cls_mask_ab * cls_mask_p # [batch size, emb dim]\n",
    "        \n",
    "        # # element-wise addition\n",
    "        # cls_fusion= torch.add(cls_mask_ab, cls_mask_p) # [batch size, emb dim]\n",
    "        \n",
    "        # # element-wise square of difference\n",
    "        # cls_fusion= torch.square(torch.sub(cls_mask_ab, cls_mask_p)) # [batch size, emb dim]\n",
    "        \n",
    "        # # concatenation\n",
    "        # cls_fusion= torch.cat((cls_mask_ab,cls_mask_p),dim=1) # [batch size, emb dim*2]\n",
    "                               \n",
    "        # cls_pred = self.fc_layernorm_cls(self.fc_cls(cls_fusion)) # [batch size, output dim 2]\n",
    "        cls_pred = self.fc_cls(cls_fusion)\n",
    "        \n",
    "        return tag_pred, cls_pred\n",
    "    \n",
    "# ############## for softmax trust level ############\n",
    "#         tag_signal = F.softmax(tag_pred,dim=2)[:,:,2] # [batch size, seq len]\n",
    "#         point_five = torch.full(tag_signal.size(), 0.5).cuda() # [batch size, seq len]\n",
    "#         tag_signal = torch.mean(torch.square(tag_signal-point_five), 1) # [batch size]\n",
    "        \n",
    "#         cls_signal = F.softmax(cls_pred,dim=1)[:,2] # [batch size]\n",
    "#         point_five = torch.full(cls_signal.size(), 0.5).cuda() # [batch size]\n",
    "#         cls_signal = torch.square(cls_signal-point_five) # [batch size]\n",
    "        \n",
    "        \n",
    "#         return tag_pred, cls_pred, tag_signal, cls_signal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2f2566a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 368,747,532 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIM_TAGGING = len(LABEL1.vocab)\n",
    "OUTPUT_DIM_CLASSIFICATION = len(LABEL2.vocab)\n",
    "\n",
    "model = MTL(bert,\n",
    "            OUTPUT_DIM_TAGGING, \n",
    "            OUTPUT_DIM_CLASSIFICATION, \n",
    "            DROPOUT,\n",
    "            NO_HEAD_TRANS)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e89581b7-4e6d-4f2c-8afe-b53543b9f54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(OUTPUT_DIM_TAGGING)\n",
    "print(OUTPUT_DIM_CLASSIFICATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cff96df-2b10-45dd-835d-8ab3cbeb316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_params = []\n",
    "other_params = []\n",
    "for name, param in model.named_parameters():\n",
    "  if name.startswith(\"bert\"):\n",
    "    bert_params.append(param)\n",
    "  else:\n",
    "    other_params.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88a34620-9de1-4681-974a-4466b7bdc3b6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66678321-1cb9-4e0c-bb8e-5ac474707dd4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(other_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8323a48a-8550-457e-9add-670b264ecc59",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight\n",
      "bert.embeddings.position_embeddings.weight\n",
      "bert.embeddings.token_type_embeddings.weight\n",
      "bert.embeddings.LayerNorm.weight\n",
      "bert.embeddings.LayerNorm.bias\n",
      "bert.encoder.layer.0.attention.self.query.weight\n",
      "bert.encoder.layer.0.attention.self.query.bias\n",
      "bert.encoder.layer.0.attention.self.key.weight\n",
      "bert.encoder.layer.0.attention.self.key.bias\n",
      "bert.encoder.layer.0.attention.self.value.weight\n",
      "bert.encoder.layer.0.attention.self.value.bias\n",
      "bert.encoder.layer.0.attention.output.dense.weight\n",
      "bert.encoder.layer.0.attention.output.dense.bias\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.0.intermediate.dense.weight\n",
      "bert.encoder.layer.0.intermediate.dense.bias\n",
      "bert.encoder.layer.0.output.dense.weight\n",
      "bert.encoder.layer.0.output.dense.bias\n",
      "bert.encoder.layer.0.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.attention.self.query.weight\n",
      "bert.encoder.layer.1.attention.self.query.bias\n",
      "bert.encoder.layer.1.attention.self.key.weight\n",
      "bert.encoder.layer.1.attention.self.key.bias\n",
      "bert.encoder.layer.1.attention.self.value.weight\n",
      "bert.encoder.layer.1.attention.self.value.bias\n",
      "bert.encoder.layer.1.attention.output.dense.weight\n",
      "bert.encoder.layer.1.attention.output.dense.bias\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.intermediate.dense.weight\n",
      "bert.encoder.layer.1.intermediate.dense.bias\n",
      "bert.encoder.layer.1.output.dense.weight\n",
      "bert.encoder.layer.1.output.dense.bias\n",
      "bert.encoder.layer.1.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.attention.self.query.weight\n",
      "bert.encoder.layer.2.attention.self.query.bias\n",
      "bert.encoder.layer.2.attention.self.key.weight\n",
      "bert.encoder.layer.2.attention.self.key.bias\n",
      "bert.encoder.layer.2.attention.self.value.weight\n",
      "bert.encoder.layer.2.attention.self.value.bias\n",
      "bert.encoder.layer.2.attention.output.dense.weight\n",
      "bert.encoder.layer.2.attention.output.dense.bias\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.intermediate.dense.weight\n",
      "bert.encoder.layer.2.intermediate.dense.bias\n",
      "bert.encoder.layer.2.output.dense.weight\n",
      "bert.encoder.layer.2.output.dense.bias\n",
      "bert.encoder.layer.2.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.attention.self.query.weight\n",
      "bert.encoder.layer.3.attention.self.query.bias\n",
      "bert.encoder.layer.3.attention.self.key.weight\n",
      "bert.encoder.layer.3.attention.self.key.bias\n",
      "bert.encoder.layer.3.attention.self.value.weight\n",
      "bert.encoder.layer.3.attention.self.value.bias\n",
      "bert.encoder.layer.3.attention.output.dense.weight\n",
      "bert.encoder.layer.3.attention.output.dense.bias\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.intermediate.dense.weight\n",
      "bert.encoder.layer.3.intermediate.dense.bias\n",
      "bert.encoder.layer.3.output.dense.weight\n",
      "bert.encoder.layer.3.output.dense.bias\n",
      "bert.encoder.layer.3.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.attention.self.query.weight\n",
      "bert.encoder.layer.4.attention.self.query.bias\n",
      "bert.encoder.layer.4.attention.self.key.weight\n",
      "bert.encoder.layer.4.attention.self.key.bias\n",
      "bert.encoder.layer.4.attention.self.value.weight\n",
      "bert.encoder.layer.4.attention.self.value.bias\n",
      "bert.encoder.layer.4.attention.output.dense.weight\n",
      "bert.encoder.layer.4.attention.output.dense.bias\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.intermediate.dense.weight\n",
      "bert.encoder.layer.4.intermediate.dense.bias\n",
      "bert.encoder.layer.4.output.dense.weight\n",
      "bert.encoder.layer.4.output.dense.bias\n",
      "bert.encoder.layer.4.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.attention.self.query.weight\n",
      "bert.encoder.layer.5.attention.self.query.bias\n",
      "bert.encoder.layer.5.attention.self.key.weight\n",
      "bert.encoder.layer.5.attention.self.key.bias\n",
      "bert.encoder.layer.5.attention.self.value.weight\n",
      "bert.encoder.layer.5.attention.self.value.bias\n",
      "bert.encoder.layer.5.attention.output.dense.weight\n",
      "bert.encoder.layer.5.attention.output.dense.bias\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.intermediate.dense.weight\n",
      "bert.encoder.layer.5.intermediate.dense.bias\n",
      "bert.encoder.layer.5.output.dense.weight\n",
      "bert.encoder.layer.5.output.dense.bias\n",
      "bert.encoder.layer.5.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.attention.self.query.weight\n",
      "bert.encoder.layer.6.attention.self.query.bias\n",
      "bert.encoder.layer.6.attention.self.key.weight\n",
      "bert.encoder.layer.6.attention.self.key.bias\n",
      "bert.encoder.layer.6.attention.self.value.weight\n",
      "bert.encoder.layer.6.attention.self.value.bias\n",
      "bert.encoder.layer.6.attention.output.dense.weight\n",
      "bert.encoder.layer.6.attention.output.dense.bias\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.intermediate.dense.weight\n",
      "bert.encoder.layer.6.intermediate.dense.bias\n",
      "bert.encoder.layer.6.output.dense.weight\n",
      "bert.encoder.layer.6.output.dense.bias\n",
      "bert.encoder.layer.6.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.attention.self.query.weight\n",
      "bert.encoder.layer.7.attention.self.query.bias\n",
      "bert.encoder.layer.7.attention.self.key.weight\n",
      "bert.encoder.layer.7.attention.self.key.bias\n",
      "bert.encoder.layer.7.attention.self.value.weight\n",
      "bert.encoder.layer.7.attention.self.value.bias\n",
      "bert.encoder.layer.7.attention.output.dense.weight\n",
      "bert.encoder.layer.7.attention.output.dense.bias\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.intermediate.dense.weight\n",
      "bert.encoder.layer.7.intermediate.dense.bias\n",
      "bert.encoder.layer.7.output.dense.weight\n",
      "bert.encoder.layer.7.output.dense.bias\n",
      "bert.encoder.layer.7.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.attention.self.query.weight\n",
      "bert.encoder.layer.8.attention.self.query.bias\n",
      "bert.encoder.layer.8.attention.self.key.weight\n",
      "bert.encoder.layer.8.attention.self.key.bias\n",
      "bert.encoder.layer.8.attention.self.value.weight\n",
      "bert.encoder.layer.8.attention.self.value.bias\n",
      "bert.encoder.layer.8.attention.output.dense.weight\n",
      "bert.encoder.layer.8.attention.output.dense.bias\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.intermediate.dense.weight\n",
      "bert.encoder.layer.8.intermediate.dense.bias\n",
      "bert.encoder.layer.8.output.dense.weight\n",
      "bert.encoder.layer.8.output.dense.bias\n",
      "bert.encoder.layer.8.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.attention.self.query.weight\n",
      "bert.encoder.layer.9.attention.self.query.bias\n",
      "bert.encoder.layer.9.attention.self.key.weight\n",
      "bert.encoder.layer.9.attention.self.key.bias\n",
      "bert.encoder.layer.9.attention.self.value.weight\n",
      "bert.encoder.layer.9.attention.self.value.bias\n",
      "bert.encoder.layer.9.attention.output.dense.weight\n",
      "bert.encoder.layer.9.attention.output.dense.bias\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.intermediate.dense.weight\n",
      "bert.encoder.layer.9.intermediate.dense.bias\n",
      "bert.encoder.layer.9.output.dense.weight\n",
      "bert.encoder.layer.9.output.dense.bias\n",
      "bert.encoder.layer.9.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.attention.self.query.weight\n",
      "bert.encoder.layer.10.attention.self.query.bias\n",
      "bert.encoder.layer.10.attention.self.key.weight\n",
      "bert.encoder.layer.10.attention.self.key.bias\n",
      "bert.encoder.layer.10.attention.self.value.weight\n",
      "bert.encoder.layer.10.attention.self.value.bias\n",
      "bert.encoder.layer.10.attention.output.dense.weight\n",
      "bert.encoder.layer.10.attention.output.dense.bias\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.intermediate.dense.weight\n",
      "bert.encoder.layer.10.intermediate.dense.bias\n",
      "bert.encoder.layer.10.output.dense.weight\n",
      "bert.encoder.layer.10.output.dense.bias\n",
      "bert.encoder.layer.10.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.attention.self.query.weight\n",
      "bert.encoder.layer.11.attention.self.query.bias\n",
      "bert.encoder.layer.11.attention.self.key.weight\n",
      "bert.encoder.layer.11.attention.self.key.bias\n",
      "bert.encoder.layer.11.attention.self.value.weight\n",
      "bert.encoder.layer.11.attention.self.value.bias\n",
      "bert.encoder.layer.11.attention.output.dense.weight\n",
      "bert.encoder.layer.11.attention.output.dense.bias\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.intermediate.dense.weight\n",
      "bert.encoder.layer.11.intermediate.dense.bias\n",
      "bert.encoder.layer.11.output.dense.weight\n",
      "bert.encoder.layer.11.output.dense.bias\n",
      "bert.encoder.layer.11.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.output.LayerNorm.bias\n",
      "bert.encoder.layer.12.attention.self.query.weight\n",
      "bert.encoder.layer.12.attention.self.query.bias\n",
      "bert.encoder.layer.12.attention.self.key.weight\n",
      "bert.encoder.layer.12.attention.self.key.bias\n",
      "bert.encoder.layer.12.attention.self.value.weight\n",
      "bert.encoder.layer.12.attention.self.value.bias\n",
      "bert.encoder.layer.12.attention.output.dense.weight\n",
      "bert.encoder.layer.12.attention.output.dense.bias\n",
      "bert.encoder.layer.12.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.12.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.12.intermediate.dense.weight\n",
      "bert.encoder.layer.12.intermediate.dense.bias\n",
      "bert.encoder.layer.12.output.dense.weight\n",
      "bert.encoder.layer.12.output.dense.bias\n",
      "bert.encoder.layer.12.output.LayerNorm.weight\n",
      "bert.encoder.layer.12.output.LayerNorm.bias\n",
      "bert.encoder.layer.13.attention.self.query.weight\n",
      "bert.encoder.layer.13.attention.self.query.bias\n",
      "bert.encoder.layer.13.attention.self.key.weight\n",
      "bert.encoder.layer.13.attention.self.key.bias\n",
      "bert.encoder.layer.13.attention.self.value.weight\n",
      "bert.encoder.layer.13.attention.self.value.bias\n",
      "bert.encoder.layer.13.attention.output.dense.weight\n",
      "bert.encoder.layer.13.attention.output.dense.bias\n",
      "bert.encoder.layer.13.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.13.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.13.intermediate.dense.weight\n",
      "bert.encoder.layer.13.intermediate.dense.bias\n",
      "bert.encoder.layer.13.output.dense.weight\n",
      "bert.encoder.layer.13.output.dense.bias\n",
      "bert.encoder.layer.13.output.LayerNorm.weight\n",
      "bert.encoder.layer.13.output.LayerNorm.bias\n",
      "bert.encoder.layer.14.attention.self.query.weight\n",
      "bert.encoder.layer.14.attention.self.query.bias\n",
      "bert.encoder.layer.14.attention.self.key.weight\n",
      "bert.encoder.layer.14.attention.self.key.bias\n",
      "bert.encoder.layer.14.attention.self.value.weight\n",
      "bert.encoder.layer.14.attention.self.value.bias\n",
      "bert.encoder.layer.14.attention.output.dense.weight\n",
      "bert.encoder.layer.14.attention.output.dense.bias\n",
      "bert.encoder.layer.14.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.14.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.14.intermediate.dense.weight\n",
      "bert.encoder.layer.14.intermediate.dense.bias\n",
      "bert.encoder.layer.14.output.dense.weight\n",
      "bert.encoder.layer.14.output.dense.bias\n",
      "bert.encoder.layer.14.output.LayerNorm.weight\n",
      "bert.encoder.layer.14.output.LayerNorm.bias\n",
      "bert.encoder.layer.15.attention.self.query.weight\n",
      "bert.encoder.layer.15.attention.self.query.bias\n",
      "bert.encoder.layer.15.attention.self.key.weight\n",
      "bert.encoder.layer.15.attention.self.key.bias\n",
      "bert.encoder.layer.15.attention.self.value.weight\n",
      "bert.encoder.layer.15.attention.self.value.bias\n",
      "bert.encoder.layer.15.attention.output.dense.weight\n",
      "bert.encoder.layer.15.attention.output.dense.bias\n",
      "bert.encoder.layer.15.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.15.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.15.intermediate.dense.weight\n",
      "bert.encoder.layer.15.intermediate.dense.bias\n",
      "bert.encoder.layer.15.output.dense.weight\n",
      "bert.encoder.layer.15.output.dense.bias\n",
      "bert.encoder.layer.15.output.LayerNorm.weight\n",
      "bert.encoder.layer.15.output.LayerNorm.bias\n",
      "bert.encoder.layer.16.attention.self.query.weight\n",
      "bert.encoder.layer.16.attention.self.query.bias\n",
      "bert.encoder.layer.16.attention.self.key.weight\n",
      "bert.encoder.layer.16.attention.self.key.bias\n",
      "bert.encoder.layer.16.attention.self.value.weight\n",
      "bert.encoder.layer.16.attention.self.value.bias\n",
      "bert.encoder.layer.16.attention.output.dense.weight\n",
      "bert.encoder.layer.16.attention.output.dense.bias\n",
      "bert.encoder.layer.16.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.16.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.16.intermediate.dense.weight\n",
      "bert.encoder.layer.16.intermediate.dense.bias\n",
      "bert.encoder.layer.16.output.dense.weight\n",
      "bert.encoder.layer.16.output.dense.bias\n",
      "bert.encoder.layer.16.output.LayerNorm.weight\n",
      "bert.encoder.layer.16.output.LayerNorm.bias\n",
      "bert.encoder.layer.17.attention.self.query.weight\n",
      "bert.encoder.layer.17.attention.self.query.bias\n",
      "bert.encoder.layer.17.attention.self.key.weight\n",
      "bert.encoder.layer.17.attention.self.key.bias\n",
      "bert.encoder.layer.17.attention.self.value.weight\n",
      "bert.encoder.layer.17.attention.self.value.bias\n",
      "bert.encoder.layer.17.attention.output.dense.weight\n",
      "bert.encoder.layer.17.attention.output.dense.bias\n",
      "bert.encoder.layer.17.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.17.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.17.intermediate.dense.weight\n",
      "bert.encoder.layer.17.intermediate.dense.bias\n",
      "bert.encoder.layer.17.output.dense.weight\n",
      "bert.encoder.layer.17.output.dense.bias\n",
      "bert.encoder.layer.17.output.LayerNorm.weight\n",
      "bert.encoder.layer.17.output.LayerNorm.bias\n",
      "bert.encoder.layer.18.attention.self.query.weight\n",
      "bert.encoder.layer.18.attention.self.query.bias\n",
      "bert.encoder.layer.18.attention.self.key.weight\n",
      "bert.encoder.layer.18.attention.self.key.bias\n",
      "bert.encoder.layer.18.attention.self.value.weight\n",
      "bert.encoder.layer.18.attention.self.value.bias\n",
      "bert.encoder.layer.18.attention.output.dense.weight\n",
      "bert.encoder.layer.18.attention.output.dense.bias\n",
      "bert.encoder.layer.18.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.18.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.18.intermediate.dense.weight\n",
      "bert.encoder.layer.18.intermediate.dense.bias\n",
      "bert.encoder.layer.18.output.dense.weight\n",
      "bert.encoder.layer.18.output.dense.bias\n",
      "bert.encoder.layer.18.output.LayerNorm.weight\n",
      "bert.encoder.layer.18.output.LayerNorm.bias\n",
      "bert.encoder.layer.19.attention.self.query.weight\n",
      "bert.encoder.layer.19.attention.self.query.bias\n",
      "bert.encoder.layer.19.attention.self.key.weight\n",
      "bert.encoder.layer.19.attention.self.key.bias\n",
      "bert.encoder.layer.19.attention.self.value.weight\n",
      "bert.encoder.layer.19.attention.self.value.bias\n",
      "bert.encoder.layer.19.attention.output.dense.weight\n",
      "bert.encoder.layer.19.attention.output.dense.bias\n",
      "bert.encoder.layer.19.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.19.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.19.intermediate.dense.weight\n",
      "bert.encoder.layer.19.intermediate.dense.bias\n",
      "bert.encoder.layer.19.output.dense.weight\n",
      "bert.encoder.layer.19.output.dense.bias\n",
      "bert.encoder.layer.19.output.LayerNorm.weight\n",
      "bert.encoder.layer.19.output.LayerNorm.bias\n",
      "bert.encoder.layer.20.attention.self.query.weight\n",
      "bert.encoder.layer.20.attention.self.query.bias\n",
      "bert.encoder.layer.20.attention.self.key.weight\n",
      "bert.encoder.layer.20.attention.self.key.bias\n",
      "bert.encoder.layer.20.attention.self.value.weight\n",
      "bert.encoder.layer.20.attention.self.value.bias\n",
      "bert.encoder.layer.20.attention.output.dense.weight\n",
      "bert.encoder.layer.20.attention.output.dense.bias\n",
      "bert.encoder.layer.20.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.20.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.20.intermediate.dense.weight\n",
      "bert.encoder.layer.20.intermediate.dense.bias\n",
      "bert.encoder.layer.20.output.dense.weight\n",
      "bert.encoder.layer.20.output.dense.bias\n",
      "bert.encoder.layer.20.output.LayerNorm.weight\n",
      "bert.encoder.layer.20.output.LayerNorm.bias\n",
      "bert.encoder.layer.21.attention.self.query.weight\n",
      "bert.encoder.layer.21.attention.self.query.bias\n",
      "bert.encoder.layer.21.attention.self.key.weight\n",
      "bert.encoder.layer.21.attention.self.key.bias\n",
      "bert.encoder.layer.21.attention.self.value.weight\n",
      "bert.encoder.layer.21.attention.self.value.bias\n",
      "bert.encoder.layer.21.attention.output.dense.weight\n",
      "bert.encoder.layer.21.attention.output.dense.bias\n",
      "bert.encoder.layer.21.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.21.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.21.intermediate.dense.weight\n",
      "bert.encoder.layer.21.intermediate.dense.bias\n",
      "bert.encoder.layer.21.output.dense.weight\n",
      "bert.encoder.layer.21.output.dense.bias\n",
      "bert.encoder.layer.21.output.LayerNorm.weight\n",
      "bert.encoder.layer.21.output.LayerNorm.bias\n",
      "bert.encoder.layer.22.attention.self.query.weight\n",
      "bert.encoder.layer.22.attention.self.query.bias\n",
      "bert.encoder.layer.22.attention.self.key.weight\n",
      "bert.encoder.layer.22.attention.self.key.bias\n",
      "bert.encoder.layer.22.attention.self.value.weight\n",
      "bert.encoder.layer.22.attention.self.value.bias\n",
      "bert.encoder.layer.22.attention.output.dense.weight\n",
      "bert.encoder.layer.22.attention.output.dense.bias\n",
      "bert.encoder.layer.22.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.22.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.22.intermediate.dense.weight\n",
      "bert.encoder.layer.22.intermediate.dense.bias\n",
      "bert.encoder.layer.22.output.dense.weight\n",
      "bert.encoder.layer.22.output.dense.bias\n",
      "bert.encoder.layer.22.output.LayerNorm.weight\n",
      "bert.encoder.layer.22.output.LayerNorm.bias\n",
      "bert.encoder.layer.23.attention.self.query.weight\n",
      "bert.encoder.layer.23.attention.self.query.bias\n",
      "bert.encoder.layer.23.attention.self.key.weight\n",
      "bert.encoder.layer.23.attention.self.key.bias\n",
      "bert.encoder.layer.23.attention.self.value.weight\n",
      "bert.encoder.layer.23.attention.self.value.bias\n",
      "bert.encoder.layer.23.attention.output.dense.weight\n",
      "bert.encoder.layer.23.attention.output.dense.bias\n",
      "bert.encoder.layer.23.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.23.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.23.intermediate.dense.weight\n",
      "bert.encoder.layer.23.intermediate.dense.bias\n",
      "bert.encoder.layer.23.output.dense.weight\n",
      "bert.encoder.layer.23.output.dense.bias\n",
      "bert.encoder.layer.23.output.LayerNorm.weight\n",
      "bert.encoder.layer.23.output.LayerNorm.bias\n",
      "bert.pooler.dense.weight\n",
      "bert.pooler.dense.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if param.requires_grad:\n",
    "        if name.startswith(\"bert\"):\n",
    "            print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa8face5-f407-4596-bba9-13b73adec0ec",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag_layer1.self_attn.in_proj_weight\n",
      "tag_layer1.self_attn.in_proj_bias\n",
      "tag_layer1.self_attn.out_proj.weight\n",
      "tag_layer1.self_attn.out_proj.bias\n",
      "tag_layer1.linear1.weight\n",
      "tag_layer1.linear1.bias\n",
      "tag_layer1.linear2.weight\n",
      "tag_layer1.linear2.bias\n",
      "tag_layer1.norm1.weight\n",
      "tag_layer1.norm1.bias\n",
      "tag_layer1.norm2.weight\n",
      "tag_layer1.norm2.bias\n",
      "cls_layer1.self_attn.in_proj_weight\n",
      "cls_layer1.self_attn.in_proj_bias\n",
      "cls_layer1.self_attn.out_proj.weight\n",
      "cls_layer1.self_attn.out_proj.bias\n",
      "cls_layer1.linear1.weight\n",
      "cls_layer1.linear1.bias\n",
      "cls_layer1.linear2.weight\n",
      "cls_layer1.linear2.bias\n",
      "cls_layer1.norm1.weight\n",
      "cls_layer1.norm1.bias\n",
      "cls_layer1.norm2.weight\n",
      "cls_layer1.norm2.bias\n",
      "tag_layer2.self_attn.in_proj_weight\n",
      "tag_layer2.self_attn.in_proj_bias\n",
      "tag_layer2.self_attn.out_proj.weight\n",
      "tag_layer2.self_attn.out_proj.bias\n",
      "tag_layer2.linear1.weight\n",
      "tag_layer2.linear1.bias\n",
      "tag_layer2.linear2.weight\n",
      "tag_layer2.linear2.bias\n",
      "tag_layer2.norm1.weight\n",
      "tag_layer2.norm1.bias\n",
      "tag_layer2.norm2.weight\n",
      "tag_layer2.norm2.bias\n",
      "cls_layer2.self_attn.in_proj_weight\n",
      "cls_layer2.self_attn.in_proj_bias\n",
      "cls_layer2.self_attn.out_proj.weight\n",
      "cls_layer2.self_attn.out_proj.bias\n",
      "cls_layer2.linear1.weight\n",
      "cls_layer2.linear1.bias\n",
      "cls_layer2.linear2.weight\n",
      "cls_layer2.linear2.bias\n",
      "cls_layer2.norm1.weight\n",
      "cls_layer2.norm1.bias\n",
      "cls_layer2.norm2.weight\n",
      "cls_layer2.norm2.bias\n",
      "fc_tag.weight\n",
      "fc_tag.bias\n",
      "fc_cls.weight\n",
      "fc_cls.bias\n",
      "fc_layernorm_cls.weight\n",
      "fc_layernorm_cls.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if param.requires_grad:\n",
    "        if not name.startswith(\"bert\"):\n",
    "            print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a75a5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606645\n",
      "12.0\n"
     ]
    }
   ],
   "source": [
    "from transformers.optimization import (\n",
    "    get_linear_schedule_with_warmup, get_constant_schedule, get_constant_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup,\n",
    "get_cosine_schedule_with_warmup)\n",
    "\n",
    "TAG_PAD_IDX = LABEL1.vocab.stoi[LABEL1.pad_token]\n",
    "\n",
    "criterion_tag = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
    "criterion_cls = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
    "\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "criterion_tag = criterion_tag.to(device)\n",
    "criterion_cls = criterion_cls.to(device)\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    [\n",
    "        {\"params\": bert_params, \"lr\": 0.5*LEARNING_RATE},\n",
    "        {\"params\": other_params}\n",
    "    ],\n",
    "    lr=LEARNING_RATE,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "num_train_steps = int(\n",
    "            len(train_data) / BATCH_SIZE  * N_EPOCHS)\n",
    "\n",
    "print(num_train_steps)\n",
    "num_cycles=(N_EPOCHS-10)/50\n",
    "print(num_cycles)\n",
    "\n",
    "# scheduler = get_constant_schedule_with_warmup(\n",
    "#                 optimizer,\n",
    "#                 num_warmup_steps = 15)\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "#                 optimizer,\n",
    "#                 num_warmup_steps = 15,\n",
    "#                 num_training_steps = num_train_steps*2)\n",
    "\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "#                 optimizer,\n",
    "#                 num_warmup_steps = num_train_steps*0.1,\n",
    "#                 num_training_steps = num_train_steps*2)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer,\n",
    "                num_warmup_steps = 10,\n",
    "                num_training_steps = num_train_steps,\n",
    "                num_cycles = num_cycles)\n",
    "\n",
    "# scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(\n",
    "#                 optimizer,\n",
    "#                 num_warmup_steps = num_train_steps*0.2,\n",
    "#                 num_training_steps = num_train_steps,\n",
    "#                 num_cycles = 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f916de3-69e4-499f-af5d-32cb19956d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.bert.named_parameters():                \n",
    "#     if name.startswith('embeddings'):\n",
    "#         param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdfb3735-b997-4630-a493-8880fa71ea15",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight\n",
      "bert.embeddings.position_embeddings.weight\n",
      "bert.embeddings.token_type_embeddings.weight\n",
      "bert.embeddings.LayerNorm.weight\n",
      "bert.embeddings.LayerNorm.bias\n",
      "bert.encoder.layer.0.attention.self.query.weight\n",
      "bert.encoder.layer.0.attention.self.query.bias\n",
      "bert.encoder.layer.0.attention.self.key.weight\n",
      "bert.encoder.layer.0.attention.self.key.bias\n",
      "bert.encoder.layer.0.attention.self.value.weight\n",
      "bert.encoder.layer.0.attention.self.value.bias\n",
      "bert.encoder.layer.0.attention.output.dense.weight\n",
      "bert.encoder.layer.0.attention.output.dense.bias\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.0.intermediate.dense.weight\n",
      "bert.encoder.layer.0.intermediate.dense.bias\n",
      "bert.encoder.layer.0.output.dense.weight\n",
      "bert.encoder.layer.0.output.dense.bias\n",
      "bert.encoder.layer.0.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.attention.self.query.weight\n",
      "bert.encoder.layer.1.attention.self.query.bias\n",
      "bert.encoder.layer.1.attention.self.key.weight\n",
      "bert.encoder.layer.1.attention.self.key.bias\n",
      "bert.encoder.layer.1.attention.self.value.weight\n",
      "bert.encoder.layer.1.attention.self.value.bias\n",
      "bert.encoder.layer.1.attention.output.dense.weight\n",
      "bert.encoder.layer.1.attention.output.dense.bias\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.intermediate.dense.weight\n",
      "bert.encoder.layer.1.intermediate.dense.bias\n",
      "bert.encoder.layer.1.output.dense.weight\n",
      "bert.encoder.layer.1.output.dense.bias\n",
      "bert.encoder.layer.1.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.attention.self.query.weight\n",
      "bert.encoder.layer.2.attention.self.query.bias\n",
      "bert.encoder.layer.2.attention.self.key.weight\n",
      "bert.encoder.layer.2.attention.self.key.bias\n",
      "bert.encoder.layer.2.attention.self.value.weight\n",
      "bert.encoder.layer.2.attention.self.value.bias\n",
      "bert.encoder.layer.2.attention.output.dense.weight\n",
      "bert.encoder.layer.2.attention.output.dense.bias\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.intermediate.dense.weight\n",
      "bert.encoder.layer.2.intermediate.dense.bias\n",
      "bert.encoder.layer.2.output.dense.weight\n",
      "bert.encoder.layer.2.output.dense.bias\n",
      "bert.encoder.layer.2.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.attention.self.query.weight\n",
      "bert.encoder.layer.3.attention.self.query.bias\n",
      "bert.encoder.layer.3.attention.self.key.weight\n",
      "bert.encoder.layer.3.attention.self.key.bias\n",
      "bert.encoder.layer.3.attention.self.value.weight\n",
      "bert.encoder.layer.3.attention.self.value.bias\n",
      "bert.encoder.layer.3.attention.output.dense.weight\n",
      "bert.encoder.layer.3.attention.output.dense.bias\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.intermediate.dense.weight\n",
      "bert.encoder.layer.3.intermediate.dense.bias\n",
      "bert.encoder.layer.3.output.dense.weight\n",
      "bert.encoder.layer.3.output.dense.bias\n",
      "bert.encoder.layer.3.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.attention.self.query.weight\n",
      "bert.encoder.layer.4.attention.self.query.bias\n",
      "bert.encoder.layer.4.attention.self.key.weight\n",
      "bert.encoder.layer.4.attention.self.key.bias\n",
      "bert.encoder.layer.4.attention.self.value.weight\n",
      "bert.encoder.layer.4.attention.self.value.bias\n",
      "bert.encoder.layer.4.attention.output.dense.weight\n",
      "bert.encoder.layer.4.attention.output.dense.bias\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.intermediate.dense.weight\n",
      "bert.encoder.layer.4.intermediate.dense.bias\n",
      "bert.encoder.layer.4.output.dense.weight\n",
      "bert.encoder.layer.4.output.dense.bias\n",
      "bert.encoder.layer.4.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.attention.self.query.weight\n",
      "bert.encoder.layer.5.attention.self.query.bias\n",
      "bert.encoder.layer.5.attention.self.key.weight\n",
      "bert.encoder.layer.5.attention.self.key.bias\n",
      "bert.encoder.layer.5.attention.self.value.weight\n",
      "bert.encoder.layer.5.attention.self.value.bias\n",
      "bert.encoder.layer.5.attention.output.dense.weight\n",
      "bert.encoder.layer.5.attention.output.dense.bias\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.intermediate.dense.weight\n",
      "bert.encoder.layer.5.intermediate.dense.bias\n",
      "bert.encoder.layer.5.output.dense.weight\n",
      "bert.encoder.layer.5.output.dense.bias\n",
      "bert.encoder.layer.5.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.attention.self.query.weight\n",
      "bert.encoder.layer.6.attention.self.query.bias\n",
      "bert.encoder.layer.6.attention.self.key.weight\n",
      "bert.encoder.layer.6.attention.self.key.bias\n",
      "bert.encoder.layer.6.attention.self.value.weight\n",
      "bert.encoder.layer.6.attention.self.value.bias\n",
      "bert.encoder.layer.6.attention.output.dense.weight\n",
      "bert.encoder.layer.6.attention.output.dense.bias\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.intermediate.dense.weight\n",
      "bert.encoder.layer.6.intermediate.dense.bias\n",
      "bert.encoder.layer.6.output.dense.weight\n",
      "bert.encoder.layer.6.output.dense.bias\n",
      "bert.encoder.layer.6.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.attention.self.query.weight\n",
      "bert.encoder.layer.7.attention.self.query.bias\n",
      "bert.encoder.layer.7.attention.self.key.weight\n",
      "bert.encoder.layer.7.attention.self.key.bias\n",
      "bert.encoder.layer.7.attention.self.value.weight\n",
      "bert.encoder.layer.7.attention.self.value.bias\n",
      "bert.encoder.layer.7.attention.output.dense.weight\n",
      "bert.encoder.layer.7.attention.output.dense.bias\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.intermediate.dense.weight\n",
      "bert.encoder.layer.7.intermediate.dense.bias\n",
      "bert.encoder.layer.7.output.dense.weight\n",
      "bert.encoder.layer.7.output.dense.bias\n",
      "bert.encoder.layer.7.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.attention.self.query.weight\n",
      "bert.encoder.layer.8.attention.self.query.bias\n",
      "bert.encoder.layer.8.attention.self.key.weight\n",
      "bert.encoder.layer.8.attention.self.key.bias\n",
      "bert.encoder.layer.8.attention.self.value.weight\n",
      "bert.encoder.layer.8.attention.self.value.bias\n",
      "bert.encoder.layer.8.attention.output.dense.weight\n",
      "bert.encoder.layer.8.attention.output.dense.bias\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.intermediate.dense.weight\n",
      "bert.encoder.layer.8.intermediate.dense.bias\n",
      "bert.encoder.layer.8.output.dense.weight\n",
      "bert.encoder.layer.8.output.dense.bias\n",
      "bert.encoder.layer.8.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.attention.self.query.weight\n",
      "bert.encoder.layer.9.attention.self.query.bias\n",
      "bert.encoder.layer.9.attention.self.key.weight\n",
      "bert.encoder.layer.9.attention.self.key.bias\n",
      "bert.encoder.layer.9.attention.self.value.weight\n",
      "bert.encoder.layer.9.attention.self.value.bias\n",
      "bert.encoder.layer.9.attention.output.dense.weight\n",
      "bert.encoder.layer.9.attention.output.dense.bias\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.intermediate.dense.weight\n",
      "bert.encoder.layer.9.intermediate.dense.bias\n",
      "bert.encoder.layer.9.output.dense.weight\n",
      "bert.encoder.layer.9.output.dense.bias\n",
      "bert.encoder.layer.9.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.attention.self.query.weight\n",
      "bert.encoder.layer.10.attention.self.query.bias\n",
      "bert.encoder.layer.10.attention.self.key.weight\n",
      "bert.encoder.layer.10.attention.self.key.bias\n",
      "bert.encoder.layer.10.attention.self.value.weight\n",
      "bert.encoder.layer.10.attention.self.value.bias\n",
      "bert.encoder.layer.10.attention.output.dense.weight\n",
      "bert.encoder.layer.10.attention.output.dense.bias\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.intermediate.dense.weight\n",
      "bert.encoder.layer.10.intermediate.dense.bias\n",
      "bert.encoder.layer.10.output.dense.weight\n",
      "bert.encoder.layer.10.output.dense.bias\n",
      "bert.encoder.layer.10.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.attention.self.query.weight\n",
      "bert.encoder.layer.11.attention.self.query.bias\n",
      "bert.encoder.layer.11.attention.self.key.weight\n",
      "bert.encoder.layer.11.attention.self.key.bias\n",
      "bert.encoder.layer.11.attention.self.value.weight\n",
      "bert.encoder.layer.11.attention.self.value.bias\n",
      "bert.encoder.layer.11.attention.output.dense.weight\n",
      "bert.encoder.layer.11.attention.output.dense.bias\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.intermediate.dense.weight\n",
      "bert.encoder.layer.11.intermediate.dense.bias\n",
      "bert.encoder.layer.11.output.dense.weight\n",
      "bert.encoder.layer.11.output.dense.bias\n",
      "bert.encoder.layer.11.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.output.LayerNorm.bias\n",
      "bert.encoder.layer.12.attention.self.query.weight\n",
      "bert.encoder.layer.12.attention.self.query.bias\n",
      "bert.encoder.layer.12.attention.self.key.weight\n",
      "bert.encoder.layer.12.attention.self.key.bias\n",
      "bert.encoder.layer.12.attention.self.value.weight\n",
      "bert.encoder.layer.12.attention.self.value.bias\n",
      "bert.encoder.layer.12.attention.output.dense.weight\n",
      "bert.encoder.layer.12.attention.output.dense.bias\n",
      "bert.encoder.layer.12.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.12.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.12.intermediate.dense.weight\n",
      "bert.encoder.layer.12.intermediate.dense.bias\n",
      "bert.encoder.layer.12.output.dense.weight\n",
      "bert.encoder.layer.12.output.dense.bias\n",
      "bert.encoder.layer.12.output.LayerNorm.weight\n",
      "bert.encoder.layer.12.output.LayerNorm.bias\n",
      "bert.encoder.layer.13.attention.self.query.weight\n",
      "bert.encoder.layer.13.attention.self.query.bias\n",
      "bert.encoder.layer.13.attention.self.key.weight\n",
      "bert.encoder.layer.13.attention.self.key.bias\n",
      "bert.encoder.layer.13.attention.self.value.weight\n",
      "bert.encoder.layer.13.attention.self.value.bias\n",
      "bert.encoder.layer.13.attention.output.dense.weight\n",
      "bert.encoder.layer.13.attention.output.dense.bias\n",
      "bert.encoder.layer.13.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.13.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.13.intermediate.dense.weight\n",
      "bert.encoder.layer.13.intermediate.dense.bias\n",
      "bert.encoder.layer.13.output.dense.weight\n",
      "bert.encoder.layer.13.output.dense.bias\n",
      "bert.encoder.layer.13.output.LayerNorm.weight\n",
      "bert.encoder.layer.13.output.LayerNorm.bias\n",
      "bert.encoder.layer.14.attention.self.query.weight\n",
      "bert.encoder.layer.14.attention.self.query.bias\n",
      "bert.encoder.layer.14.attention.self.key.weight\n",
      "bert.encoder.layer.14.attention.self.key.bias\n",
      "bert.encoder.layer.14.attention.self.value.weight\n",
      "bert.encoder.layer.14.attention.self.value.bias\n",
      "bert.encoder.layer.14.attention.output.dense.weight\n",
      "bert.encoder.layer.14.attention.output.dense.bias\n",
      "bert.encoder.layer.14.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.14.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.14.intermediate.dense.weight\n",
      "bert.encoder.layer.14.intermediate.dense.bias\n",
      "bert.encoder.layer.14.output.dense.weight\n",
      "bert.encoder.layer.14.output.dense.bias\n",
      "bert.encoder.layer.14.output.LayerNorm.weight\n",
      "bert.encoder.layer.14.output.LayerNorm.bias\n",
      "bert.encoder.layer.15.attention.self.query.weight\n",
      "bert.encoder.layer.15.attention.self.query.bias\n",
      "bert.encoder.layer.15.attention.self.key.weight\n",
      "bert.encoder.layer.15.attention.self.key.bias\n",
      "bert.encoder.layer.15.attention.self.value.weight\n",
      "bert.encoder.layer.15.attention.self.value.bias\n",
      "bert.encoder.layer.15.attention.output.dense.weight\n",
      "bert.encoder.layer.15.attention.output.dense.bias\n",
      "bert.encoder.layer.15.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.15.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.15.intermediate.dense.weight\n",
      "bert.encoder.layer.15.intermediate.dense.bias\n",
      "bert.encoder.layer.15.output.dense.weight\n",
      "bert.encoder.layer.15.output.dense.bias\n",
      "bert.encoder.layer.15.output.LayerNorm.weight\n",
      "bert.encoder.layer.15.output.LayerNorm.bias\n",
      "bert.encoder.layer.16.attention.self.query.weight\n",
      "bert.encoder.layer.16.attention.self.query.bias\n",
      "bert.encoder.layer.16.attention.self.key.weight\n",
      "bert.encoder.layer.16.attention.self.key.bias\n",
      "bert.encoder.layer.16.attention.self.value.weight\n",
      "bert.encoder.layer.16.attention.self.value.bias\n",
      "bert.encoder.layer.16.attention.output.dense.weight\n",
      "bert.encoder.layer.16.attention.output.dense.bias\n",
      "bert.encoder.layer.16.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.16.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.16.intermediate.dense.weight\n",
      "bert.encoder.layer.16.intermediate.dense.bias\n",
      "bert.encoder.layer.16.output.dense.weight\n",
      "bert.encoder.layer.16.output.dense.bias\n",
      "bert.encoder.layer.16.output.LayerNorm.weight\n",
      "bert.encoder.layer.16.output.LayerNorm.bias\n",
      "bert.encoder.layer.17.attention.self.query.weight\n",
      "bert.encoder.layer.17.attention.self.query.bias\n",
      "bert.encoder.layer.17.attention.self.key.weight\n",
      "bert.encoder.layer.17.attention.self.key.bias\n",
      "bert.encoder.layer.17.attention.self.value.weight\n",
      "bert.encoder.layer.17.attention.self.value.bias\n",
      "bert.encoder.layer.17.attention.output.dense.weight\n",
      "bert.encoder.layer.17.attention.output.dense.bias\n",
      "bert.encoder.layer.17.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.17.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.17.intermediate.dense.weight\n",
      "bert.encoder.layer.17.intermediate.dense.bias\n",
      "bert.encoder.layer.17.output.dense.weight\n",
      "bert.encoder.layer.17.output.dense.bias\n",
      "bert.encoder.layer.17.output.LayerNorm.weight\n",
      "bert.encoder.layer.17.output.LayerNorm.bias\n",
      "bert.encoder.layer.18.attention.self.query.weight\n",
      "bert.encoder.layer.18.attention.self.query.bias\n",
      "bert.encoder.layer.18.attention.self.key.weight\n",
      "bert.encoder.layer.18.attention.self.key.bias\n",
      "bert.encoder.layer.18.attention.self.value.weight\n",
      "bert.encoder.layer.18.attention.self.value.bias\n",
      "bert.encoder.layer.18.attention.output.dense.weight\n",
      "bert.encoder.layer.18.attention.output.dense.bias\n",
      "bert.encoder.layer.18.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.18.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.18.intermediate.dense.weight\n",
      "bert.encoder.layer.18.intermediate.dense.bias\n",
      "bert.encoder.layer.18.output.dense.weight\n",
      "bert.encoder.layer.18.output.dense.bias\n",
      "bert.encoder.layer.18.output.LayerNorm.weight\n",
      "bert.encoder.layer.18.output.LayerNorm.bias\n",
      "bert.encoder.layer.19.attention.self.query.weight\n",
      "bert.encoder.layer.19.attention.self.query.bias\n",
      "bert.encoder.layer.19.attention.self.key.weight\n",
      "bert.encoder.layer.19.attention.self.key.bias\n",
      "bert.encoder.layer.19.attention.self.value.weight\n",
      "bert.encoder.layer.19.attention.self.value.bias\n",
      "bert.encoder.layer.19.attention.output.dense.weight\n",
      "bert.encoder.layer.19.attention.output.dense.bias\n",
      "bert.encoder.layer.19.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.19.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.19.intermediate.dense.weight\n",
      "bert.encoder.layer.19.intermediate.dense.bias\n",
      "bert.encoder.layer.19.output.dense.weight\n",
      "bert.encoder.layer.19.output.dense.bias\n",
      "bert.encoder.layer.19.output.LayerNorm.weight\n",
      "bert.encoder.layer.19.output.LayerNorm.bias\n",
      "bert.encoder.layer.20.attention.self.query.weight\n",
      "bert.encoder.layer.20.attention.self.query.bias\n",
      "bert.encoder.layer.20.attention.self.key.weight\n",
      "bert.encoder.layer.20.attention.self.key.bias\n",
      "bert.encoder.layer.20.attention.self.value.weight\n",
      "bert.encoder.layer.20.attention.self.value.bias\n",
      "bert.encoder.layer.20.attention.output.dense.weight\n",
      "bert.encoder.layer.20.attention.output.dense.bias\n",
      "bert.encoder.layer.20.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.20.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.20.intermediate.dense.weight\n",
      "bert.encoder.layer.20.intermediate.dense.bias\n",
      "bert.encoder.layer.20.output.dense.weight\n",
      "bert.encoder.layer.20.output.dense.bias\n",
      "bert.encoder.layer.20.output.LayerNorm.weight\n",
      "bert.encoder.layer.20.output.LayerNorm.bias\n",
      "bert.encoder.layer.21.attention.self.query.weight\n",
      "bert.encoder.layer.21.attention.self.query.bias\n",
      "bert.encoder.layer.21.attention.self.key.weight\n",
      "bert.encoder.layer.21.attention.self.key.bias\n",
      "bert.encoder.layer.21.attention.self.value.weight\n",
      "bert.encoder.layer.21.attention.self.value.bias\n",
      "bert.encoder.layer.21.attention.output.dense.weight\n",
      "bert.encoder.layer.21.attention.output.dense.bias\n",
      "bert.encoder.layer.21.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.21.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.21.intermediate.dense.weight\n",
      "bert.encoder.layer.21.intermediate.dense.bias\n",
      "bert.encoder.layer.21.output.dense.weight\n",
      "bert.encoder.layer.21.output.dense.bias\n",
      "bert.encoder.layer.21.output.LayerNorm.weight\n",
      "bert.encoder.layer.21.output.LayerNorm.bias\n",
      "bert.encoder.layer.22.attention.self.query.weight\n",
      "bert.encoder.layer.22.attention.self.query.bias\n",
      "bert.encoder.layer.22.attention.self.key.weight\n",
      "bert.encoder.layer.22.attention.self.key.bias\n",
      "bert.encoder.layer.22.attention.self.value.weight\n",
      "bert.encoder.layer.22.attention.self.value.bias\n",
      "bert.encoder.layer.22.attention.output.dense.weight\n",
      "bert.encoder.layer.22.attention.output.dense.bias\n",
      "bert.encoder.layer.22.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.22.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.22.intermediate.dense.weight\n",
      "bert.encoder.layer.22.intermediate.dense.bias\n",
      "bert.encoder.layer.22.output.dense.weight\n",
      "bert.encoder.layer.22.output.dense.bias\n",
      "bert.encoder.layer.22.output.LayerNorm.weight\n",
      "bert.encoder.layer.22.output.LayerNorm.bias\n",
      "bert.encoder.layer.23.attention.self.query.weight\n",
      "bert.encoder.layer.23.attention.self.query.bias\n",
      "bert.encoder.layer.23.attention.self.key.weight\n",
      "bert.encoder.layer.23.attention.self.key.bias\n",
      "bert.encoder.layer.23.attention.self.value.weight\n",
      "bert.encoder.layer.23.attention.self.value.bias\n",
      "bert.encoder.layer.23.attention.output.dense.weight\n",
      "bert.encoder.layer.23.attention.output.dense.bias\n",
      "bert.encoder.layer.23.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.23.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.23.intermediate.dense.weight\n",
      "bert.encoder.layer.23.intermediate.dense.bias\n",
      "bert.encoder.layer.23.output.dense.weight\n",
      "bert.encoder.layer.23.output.dense.bias\n",
      "bert.encoder.layer.23.output.LayerNorm.weight\n",
      "bert.encoder.layer.23.output.LayerNorm.bias\n",
      "bert.pooler.dense.weight\n",
      "bert.pooler.dense.bias\n",
      "tag_layer1.self_attn.in_proj_weight\n",
      "tag_layer1.self_attn.in_proj_bias\n",
      "tag_layer1.self_attn.out_proj.weight\n",
      "tag_layer1.self_attn.out_proj.bias\n",
      "tag_layer1.linear1.weight\n",
      "tag_layer1.linear1.bias\n",
      "tag_layer1.linear2.weight\n",
      "tag_layer1.linear2.bias\n",
      "tag_layer1.norm1.weight\n",
      "tag_layer1.norm1.bias\n",
      "tag_layer1.norm2.weight\n",
      "tag_layer1.norm2.bias\n",
      "cls_layer1.self_attn.in_proj_weight\n",
      "cls_layer1.self_attn.in_proj_bias\n",
      "cls_layer1.self_attn.out_proj.weight\n",
      "cls_layer1.self_attn.out_proj.bias\n",
      "cls_layer1.linear1.weight\n",
      "cls_layer1.linear1.bias\n",
      "cls_layer1.linear2.weight\n",
      "cls_layer1.linear2.bias\n",
      "cls_layer1.norm1.weight\n",
      "cls_layer1.norm1.bias\n",
      "cls_layer1.norm2.weight\n",
      "cls_layer1.norm2.bias\n",
      "tag_layer2.self_attn.in_proj_weight\n",
      "tag_layer2.self_attn.in_proj_bias\n",
      "tag_layer2.self_attn.out_proj.weight\n",
      "tag_layer2.self_attn.out_proj.bias\n",
      "tag_layer2.linear1.weight\n",
      "tag_layer2.linear1.bias\n",
      "tag_layer2.linear2.weight\n",
      "tag_layer2.linear2.bias\n",
      "tag_layer2.norm1.weight\n",
      "tag_layer2.norm1.bias\n",
      "tag_layer2.norm2.weight\n",
      "tag_layer2.norm2.bias\n",
      "cls_layer2.self_attn.in_proj_weight\n",
      "cls_layer2.self_attn.in_proj_bias\n",
      "cls_layer2.self_attn.out_proj.weight\n",
      "cls_layer2.self_attn.out_proj.bias\n",
      "cls_layer2.linear1.weight\n",
      "cls_layer2.linear1.bias\n",
      "cls_layer2.linear2.weight\n",
      "cls_layer2.linear2.bias\n",
      "cls_layer2.norm1.weight\n",
      "cls_layer2.norm1.bias\n",
      "cls_layer2.norm2.weight\n",
      "cls_layer2.norm2.bias\n",
      "fc_tag.weight\n",
      "fc_tag.bias\n",
      "fc_cls.weight\n",
      "fc_cls.bias\n",
      "fc_layernorm_cls.weight\n",
      "fc_layernorm_cls.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a491051-4c10-4b28-8878-e78baa48e52f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight\n",
      "embeddings.position_embeddings.weight\n",
      "embeddings.token_type_embeddings.weight\n",
      "embeddings.LayerNorm.weight\n",
      "embeddings.LayerNorm.bias\n",
      "encoder.layer.0.attention.self.query.weight\n",
      "encoder.layer.0.attention.self.query.bias\n",
      "encoder.layer.0.attention.self.key.weight\n",
      "encoder.layer.0.attention.self.key.bias\n",
      "encoder.layer.0.attention.self.value.weight\n",
      "encoder.layer.0.attention.self.value.bias\n",
      "encoder.layer.0.attention.output.dense.weight\n",
      "encoder.layer.0.attention.output.dense.bias\n",
      "encoder.layer.0.attention.output.LayerNorm.weight\n",
      "encoder.layer.0.attention.output.LayerNorm.bias\n",
      "encoder.layer.0.intermediate.dense.weight\n",
      "encoder.layer.0.intermediate.dense.bias\n",
      "encoder.layer.0.output.dense.weight\n",
      "encoder.layer.0.output.dense.bias\n",
      "encoder.layer.0.output.LayerNorm.weight\n",
      "encoder.layer.0.output.LayerNorm.bias\n",
      "encoder.layer.1.attention.self.query.weight\n",
      "encoder.layer.1.attention.self.query.bias\n",
      "encoder.layer.1.attention.self.key.weight\n",
      "encoder.layer.1.attention.self.key.bias\n",
      "encoder.layer.1.attention.self.value.weight\n",
      "encoder.layer.1.attention.self.value.bias\n",
      "encoder.layer.1.attention.output.dense.weight\n",
      "encoder.layer.1.attention.output.dense.bias\n",
      "encoder.layer.1.attention.output.LayerNorm.weight\n",
      "encoder.layer.1.attention.output.LayerNorm.bias\n",
      "encoder.layer.1.intermediate.dense.weight\n",
      "encoder.layer.1.intermediate.dense.bias\n",
      "encoder.layer.1.output.dense.weight\n",
      "encoder.layer.1.output.dense.bias\n",
      "encoder.layer.1.output.LayerNorm.weight\n",
      "encoder.layer.1.output.LayerNorm.bias\n",
      "encoder.layer.2.attention.self.query.weight\n",
      "encoder.layer.2.attention.self.query.bias\n",
      "encoder.layer.2.attention.self.key.weight\n",
      "encoder.layer.2.attention.self.key.bias\n",
      "encoder.layer.2.attention.self.value.weight\n",
      "encoder.layer.2.attention.self.value.bias\n",
      "encoder.layer.2.attention.output.dense.weight\n",
      "encoder.layer.2.attention.output.dense.bias\n",
      "encoder.layer.2.attention.output.LayerNorm.weight\n",
      "encoder.layer.2.attention.output.LayerNorm.bias\n",
      "encoder.layer.2.intermediate.dense.weight\n",
      "encoder.layer.2.intermediate.dense.bias\n",
      "encoder.layer.2.output.dense.weight\n",
      "encoder.layer.2.output.dense.bias\n",
      "encoder.layer.2.output.LayerNorm.weight\n",
      "encoder.layer.2.output.LayerNorm.bias\n",
      "encoder.layer.3.attention.self.query.weight\n",
      "encoder.layer.3.attention.self.query.bias\n",
      "encoder.layer.3.attention.self.key.weight\n",
      "encoder.layer.3.attention.self.key.bias\n",
      "encoder.layer.3.attention.self.value.weight\n",
      "encoder.layer.3.attention.self.value.bias\n",
      "encoder.layer.3.attention.output.dense.weight\n",
      "encoder.layer.3.attention.output.dense.bias\n",
      "encoder.layer.3.attention.output.LayerNorm.weight\n",
      "encoder.layer.3.attention.output.LayerNorm.bias\n",
      "encoder.layer.3.intermediate.dense.weight\n",
      "encoder.layer.3.intermediate.dense.bias\n",
      "encoder.layer.3.output.dense.weight\n",
      "encoder.layer.3.output.dense.bias\n",
      "encoder.layer.3.output.LayerNorm.weight\n",
      "encoder.layer.3.output.LayerNorm.bias\n",
      "encoder.layer.4.attention.self.query.weight\n",
      "encoder.layer.4.attention.self.query.bias\n",
      "encoder.layer.4.attention.self.key.weight\n",
      "encoder.layer.4.attention.self.key.bias\n",
      "encoder.layer.4.attention.self.value.weight\n",
      "encoder.layer.4.attention.self.value.bias\n",
      "encoder.layer.4.attention.output.dense.weight\n",
      "encoder.layer.4.attention.output.dense.bias\n",
      "encoder.layer.4.attention.output.LayerNorm.weight\n",
      "encoder.layer.4.attention.output.LayerNorm.bias\n",
      "encoder.layer.4.intermediate.dense.weight\n",
      "encoder.layer.4.intermediate.dense.bias\n",
      "encoder.layer.4.output.dense.weight\n",
      "encoder.layer.4.output.dense.bias\n",
      "encoder.layer.4.output.LayerNorm.weight\n",
      "encoder.layer.4.output.LayerNorm.bias\n",
      "encoder.layer.5.attention.self.query.weight\n",
      "encoder.layer.5.attention.self.query.bias\n",
      "encoder.layer.5.attention.self.key.weight\n",
      "encoder.layer.5.attention.self.key.bias\n",
      "encoder.layer.5.attention.self.value.weight\n",
      "encoder.layer.5.attention.self.value.bias\n",
      "encoder.layer.5.attention.output.dense.weight\n",
      "encoder.layer.5.attention.output.dense.bias\n",
      "encoder.layer.5.attention.output.LayerNorm.weight\n",
      "encoder.layer.5.attention.output.LayerNorm.bias\n",
      "encoder.layer.5.intermediate.dense.weight\n",
      "encoder.layer.5.intermediate.dense.bias\n",
      "encoder.layer.5.output.dense.weight\n",
      "encoder.layer.5.output.dense.bias\n",
      "encoder.layer.5.output.LayerNorm.weight\n",
      "encoder.layer.5.output.LayerNorm.bias\n",
      "encoder.layer.6.attention.self.query.weight\n",
      "encoder.layer.6.attention.self.query.bias\n",
      "encoder.layer.6.attention.self.key.weight\n",
      "encoder.layer.6.attention.self.key.bias\n",
      "encoder.layer.6.attention.self.value.weight\n",
      "encoder.layer.6.attention.self.value.bias\n",
      "encoder.layer.6.attention.output.dense.weight\n",
      "encoder.layer.6.attention.output.dense.bias\n",
      "encoder.layer.6.attention.output.LayerNorm.weight\n",
      "encoder.layer.6.attention.output.LayerNorm.bias\n",
      "encoder.layer.6.intermediate.dense.weight\n",
      "encoder.layer.6.intermediate.dense.bias\n",
      "encoder.layer.6.output.dense.weight\n",
      "encoder.layer.6.output.dense.bias\n",
      "encoder.layer.6.output.LayerNorm.weight\n",
      "encoder.layer.6.output.LayerNorm.bias\n",
      "encoder.layer.7.attention.self.query.weight\n",
      "encoder.layer.7.attention.self.query.bias\n",
      "encoder.layer.7.attention.self.key.weight\n",
      "encoder.layer.7.attention.self.key.bias\n",
      "encoder.layer.7.attention.self.value.weight\n",
      "encoder.layer.7.attention.self.value.bias\n",
      "encoder.layer.7.attention.output.dense.weight\n",
      "encoder.layer.7.attention.output.dense.bias\n",
      "encoder.layer.7.attention.output.LayerNorm.weight\n",
      "encoder.layer.7.attention.output.LayerNorm.bias\n",
      "encoder.layer.7.intermediate.dense.weight\n",
      "encoder.layer.7.intermediate.dense.bias\n",
      "encoder.layer.7.output.dense.weight\n",
      "encoder.layer.7.output.dense.bias\n",
      "encoder.layer.7.output.LayerNorm.weight\n",
      "encoder.layer.7.output.LayerNorm.bias\n",
      "encoder.layer.8.attention.self.query.weight\n",
      "encoder.layer.8.attention.self.query.bias\n",
      "encoder.layer.8.attention.self.key.weight\n",
      "encoder.layer.8.attention.self.key.bias\n",
      "encoder.layer.8.attention.self.value.weight\n",
      "encoder.layer.8.attention.self.value.bias\n",
      "encoder.layer.8.attention.output.dense.weight\n",
      "encoder.layer.8.attention.output.dense.bias\n",
      "encoder.layer.8.attention.output.LayerNorm.weight\n",
      "encoder.layer.8.attention.output.LayerNorm.bias\n",
      "encoder.layer.8.intermediate.dense.weight\n",
      "encoder.layer.8.intermediate.dense.bias\n",
      "encoder.layer.8.output.dense.weight\n",
      "encoder.layer.8.output.dense.bias\n",
      "encoder.layer.8.output.LayerNorm.weight\n",
      "encoder.layer.8.output.LayerNorm.bias\n",
      "encoder.layer.9.attention.self.query.weight\n",
      "encoder.layer.9.attention.self.query.bias\n",
      "encoder.layer.9.attention.self.key.weight\n",
      "encoder.layer.9.attention.self.key.bias\n",
      "encoder.layer.9.attention.self.value.weight\n",
      "encoder.layer.9.attention.self.value.bias\n",
      "encoder.layer.9.attention.output.dense.weight\n",
      "encoder.layer.9.attention.output.dense.bias\n",
      "encoder.layer.9.attention.output.LayerNorm.weight\n",
      "encoder.layer.9.attention.output.LayerNorm.bias\n",
      "encoder.layer.9.intermediate.dense.weight\n",
      "encoder.layer.9.intermediate.dense.bias\n",
      "encoder.layer.9.output.dense.weight\n",
      "encoder.layer.9.output.dense.bias\n",
      "encoder.layer.9.output.LayerNorm.weight\n",
      "encoder.layer.9.output.LayerNorm.bias\n",
      "encoder.layer.10.attention.self.query.weight\n",
      "encoder.layer.10.attention.self.query.bias\n",
      "encoder.layer.10.attention.self.key.weight\n",
      "encoder.layer.10.attention.self.key.bias\n",
      "encoder.layer.10.attention.self.value.weight\n",
      "encoder.layer.10.attention.self.value.bias\n",
      "encoder.layer.10.attention.output.dense.weight\n",
      "encoder.layer.10.attention.output.dense.bias\n",
      "encoder.layer.10.attention.output.LayerNorm.weight\n",
      "encoder.layer.10.attention.output.LayerNorm.bias\n",
      "encoder.layer.10.intermediate.dense.weight\n",
      "encoder.layer.10.intermediate.dense.bias\n",
      "encoder.layer.10.output.dense.weight\n",
      "encoder.layer.10.output.dense.bias\n",
      "encoder.layer.10.output.LayerNorm.weight\n",
      "encoder.layer.10.output.LayerNorm.bias\n",
      "encoder.layer.11.attention.self.query.weight\n",
      "encoder.layer.11.attention.self.query.bias\n",
      "encoder.layer.11.attention.self.key.weight\n",
      "encoder.layer.11.attention.self.key.bias\n",
      "encoder.layer.11.attention.self.value.weight\n",
      "encoder.layer.11.attention.self.value.bias\n",
      "encoder.layer.11.attention.output.dense.weight\n",
      "encoder.layer.11.attention.output.dense.bias\n",
      "encoder.layer.11.attention.output.LayerNorm.weight\n",
      "encoder.layer.11.attention.output.LayerNorm.bias\n",
      "encoder.layer.11.intermediate.dense.weight\n",
      "encoder.layer.11.intermediate.dense.bias\n",
      "encoder.layer.11.output.dense.weight\n",
      "encoder.layer.11.output.dense.bias\n",
      "encoder.layer.11.output.LayerNorm.weight\n",
      "encoder.layer.11.output.LayerNorm.bias\n",
      "encoder.layer.12.attention.self.query.weight\n",
      "encoder.layer.12.attention.self.query.bias\n",
      "encoder.layer.12.attention.self.key.weight\n",
      "encoder.layer.12.attention.self.key.bias\n",
      "encoder.layer.12.attention.self.value.weight\n",
      "encoder.layer.12.attention.self.value.bias\n",
      "encoder.layer.12.attention.output.dense.weight\n",
      "encoder.layer.12.attention.output.dense.bias\n",
      "encoder.layer.12.attention.output.LayerNorm.weight\n",
      "encoder.layer.12.attention.output.LayerNorm.bias\n",
      "encoder.layer.12.intermediate.dense.weight\n",
      "encoder.layer.12.intermediate.dense.bias\n",
      "encoder.layer.12.output.dense.weight\n",
      "encoder.layer.12.output.dense.bias\n",
      "encoder.layer.12.output.LayerNorm.weight\n",
      "encoder.layer.12.output.LayerNorm.bias\n",
      "encoder.layer.13.attention.self.query.weight\n",
      "encoder.layer.13.attention.self.query.bias\n",
      "encoder.layer.13.attention.self.key.weight\n",
      "encoder.layer.13.attention.self.key.bias\n",
      "encoder.layer.13.attention.self.value.weight\n",
      "encoder.layer.13.attention.self.value.bias\n",
      "encoder.layer.13.attention.output.dense.weight\n",
      "encoder.layer.13.attention.output.dense.bias\n",
      "encoder.layer.13.attention.output.LayerNorm.weight\n",
      "encoder.layer.13.attention.output.LayerNorm.bias\n",
      "encoder.layer.13.intermediate.dense.weight\n",
      "encoder.layer.13.intermediate.dense.bias\n",
      "encoder.layer.13.output.dense.weight\n",
      "encoder.layer.13.output.dense.bias\n",
      "encoder.layer.13.output.LayerNorm.weight\n",
      "encoder.layer.13.output.LayerNorm.bias\n",
      "encoder.layer.14.attention.self.query.weight\n",
      "encoder.layer.14.attention.self.query.bias\n",
      "encoder.layer.14.attention.self.key.weight\n",
      "encoder.layer.14.attention.self.key.bias\n",
      "encoder.layer.14.attention.self.value.weight\n",
      "encoder.layer.14.attention.self.value.bias\n",
      "encoder.layer.14.attention.output.dense.weight\n",
      "encoder.layer.14.attention.output.dense.bias\n",
      "encoder.layer.14.attention.output.LayerNorm.weight\n",
      "encoder.layer.14.attention.output.LayerNorm.bias\n",
      "encoder.layer.14.intermediate.dense.weight\n",
      "encoder.layer.14.intermediate.dense.bias\n",
      "encoder.layer.14.output.dense.weight\n",
      "encoder.layer.14.output.dense.bias\n",
      "encoder.layer.14.output.LayerNorm.weight\n",
      "encoder.layer.14.output.LayerNorm.bias\n",
      "encoder.layer.15.attention.self.query.weight\n",
      "encoder.layer.15.attention.self.query.bias\n",
      "encoder.layer.15.attention.self.key.weight\n",
      "encoder.layer.15.attention.self.key.bias\n",
      "encoder.layer.15.attention.self.value.weight\n",
      "encoder.layer.15.attention.self.value.bias\n",
      "encoder.layer.15.attention.output.dense.weight\n",
      "encoder.layer.15.attention.output.dense.bias\n",
      "encoder.layer.15.attention.output.LayerNorm.weight\n",
      "encoder.layer.15.attention.output.LayerNorm.bias\n",
      "encoder.layer.15.intermediate.dense.weight\n",
      "encoder.layer.15.intermediate.dense.bias\n",
      "encoder.layer.15.output.dense.weight\n",
      "encoder.layer.15.output.dense.bias\n",
      "encoder.layer.15.output.LayerNorm.weight\n",
      "encoder.layer.15.output.LayerNorm.bias\n",
      "encoder.layer.16.attention.self.query.weight\n",
      "encoder.layer.16.attention.self.query.bias\n",
      "encoder.layer.16.attention.self.key.weight\n",
      "encoder.layer.16.attention.self.key.bias\n",
      "encoder.layer.16.attention.self.value.weight\n",
      "encoder.layer.16.attention.self.value.bias\n",
      "encoder.layer.16.attention.output.dense.weight\n",
      "encoder.layer.16.attention.output.dense.bias\n",
      "encoder.layer.16.attention.output.LayerNorm.weight\n",
      "encoder.layer.16.attention.output.LayerNorm.bias\n",
      "encoder.layer.16.intermediate.dense.weight\n",
      "encoder.layer.16.intermediate.dense.bias\n",
      "encoder.layer.16.output.dense.weight\n",
      "encoder.layer.16.output.dense.bias\n",
      "encoder.layer.16.output.LayerNorm.weight\n",
      "encoder.layer.16.output.LayerNorm.bias\n",
      "encoder.layer.17.attention.self.query.weight\n",
      "encoder.layer.17.attention.self.query.bias\n",
      "encoder.layer.17.attention.self.key.weight\n",
      "encoder.layer.17.attention.self.key.bias\n",
      "encoder.layer.17.attention.self.value.weight\n",
      "encoder.layer.17.attention.self.value.bias\n",
      "encoder.layer.17.attention.output.dense.weight\n",
      "encoder.layer.17.attention.output.dense.bias\n",
      "encoder.layer.17.attention.output.LayerNorm.weight\n",
      "encoder.layer.17.attention.output.LayerNorm.bias\n",
      "encoder.layer.17.intermediate.dense.weight\n",
      "encoder.layer.17.intermediate.dense.bias\n",
      "encoder.layer.17.output.dense.weight\n",
      "encoder.layer.17.output.dense.bias\n",
      "encoder.layer.17.output.LayerNorm.weight\n",
      "encoder.layer.17.output.LayerNorm.bias\n",
      "encoder.layer.18.attention.self.query.weight\n",
      "encoder.layer.18.attention.self.query.bias\n",
      "encoder.layer.18.attention.self.key.weight\n",
      "encoder.layer.18.attention.self.key.bias\n",
      "encoder.layer.18.attention.self.value.weight\n",
      "encoder.layer.18.attention.self.value.bias\n",
      "encoder.layer.18.attention.output.dense.weight\n",
      "encoder.layer.18.attention.output.dense.bias\n",
      "encoder.layer.18.attention.output.LayerNorm.weight\n",
      "encoder.layer.18.attention.output.LayerNorm.bias\n",
      "encoder.layer.18.intermediate.dense.weight\n",
      "encoder.layer.18.intermediate.dense.bias\n",
      "encoder.layer.18.output.dense.weight\n",
      "encoder.layer.18.output.dense.bias\n",
      "encoder.layer.18.output.LayerNorm.weight\n",
      "encoder.layer.18.output.LayerNorm.bias\n",
      "encoder.layer.19.attention.self.query.weight\n",
      "encoder.layer.19.attention.self.query.bias\n",
      "encoder.layer.19.attention.self.key.weight\n",
      "encoder.layer.19.attention.self.key.bias\n",
      "encoder.layer.19.attention.self.value.weight\n",
      "encoder.layer.19.attention.self.value.bias\n",
      "encoder.layer.19.attention.output.dense.weight\n",
      "encoder.layer.19.attention.output.dense.bias\n",
      "encoder.layer.19.attention.output.LayerNorm.weight\n",
      "encoder.layer.19.attention.output.LayerNorm.bias\n",
      "encoder.layer.19.intermediate.dense.weight\n",
      "encoder.layer.19.intermediate.dense.bias\n",
      "encoder.layer.19.output.dense.weight\n",
      "encoder.layer.19.output.dense.bias\n",
      "encoder.layer.19.output.LayerNorm.weight\n",
      "encoder.layer.19.output.LayerNorm.bias\n",
      "encoder.layer.20.attention.self.query.weight\n",
      "encoder.layer.20.attention.self.query.bias\n",
      "encoder.layer.20.attention.self.key.weight\n",
      "encoder.layer.20.attention.self.key.bias\n",
      "encoder.layer.20.attention.self.value.weight\n",
      "encoder.layer.20.attention.self.value.bias\n",
      "encoder.layer.20.attention.output.dense.weight\n",
      "encoder.layer.20.attention.output.dense.bias\n",
      "encoder.layer.20.attention.output.LayerNorm.weight\n",
      "encoder.layer.20.attention.output.LayerNorm.bias\n",
      "encoder.layer.20.intermediate.dense.weight\n",
      "encoder.layer.20.intermediate.dense.bias\n",
      "encoder.layer.20.output.dense.weight\n",
      "encoder.layer.20.output.dense.bias\n",
      "encoder.layer.20.output.LayerNorm.weight\n",
      "encoder.layer.20.output.LayerNorm.bias\n",
      "encoder.layer.21.attention.self.query.weight\n",
      "encoder.layer.21.attention.self.query.bias\n",
      "encoder.layer.21.attention.self.key.weight\n",
      "encoder.layer.21.attention.self.key.bias\n",
      "encoder.layer.21.attention.self.value.weight\n",
      "encoder.layer.21.attention.self.value.bias\n",
      "encoder.layer.21.attention.output.dense.weight\n",
      "encoder.layer.21.attention.output.dense.bias\n",
      "encoder.layer.21.attention.output.LayerNorm.weight\n",
      "encoder.layer.21.attention.output.LayerNorm.bias\n",
      "encoder.layer.21.intermediate.dense.weight\n",
      "encoder.layer.21.intermediate.dense.bias\n",
      "encoder.layer.21.output.dense.weight\n",
      "encoder.layer.21.output.dense.bias\n",
      "encoder.layer.21.output.LayerNorm.weight\n",
      "encoder.layer.21.output.LayerNorm.bias\n",
      "encoder.layer.22.attention.self.query.weight\n",
      "encoder.layer.22.attention.self.query.bias\n",
      "encoder.layer.22.attention.self.key.weight\n",
      "encoder.layer.22.attention.self.key.bias\n",
      "encoder.layer.22.attention.self.value.weight\n",
      "encoder.layer.22.attention.self.value.bias\n",
      "encoder.layer.22.attention.output.dense.weight\n",
      "encoder.layer.22.attention.output.dense.bias\n",
      "encoder.layer.22.attention.output.LayerNorm.weight\n",
      "encoder.layer.22.attention.output.LayerNorm.bias\n",
      "encoder.layer.22.intermediate.dense.weight\n",
      "encoder.layer.22.intermediate.dense.bias\n",
      "encoder.layer.22.output.dense.weight\n",
      "encoder.layer.22.output.dense.bias\n",
      "encoder.layer.22.output.LayerNorm.weight\n",
      "encoder.layer.22.output.LayerNorm.bias\n",
      "encoder.layer.23.attention.self.query.weight\n",
      "encoder.layer.23.attention.self.query.bias\n",
      "encoder.layer.23.attention.self.key.weight\n",
      "encoder.layer.23.attention.self.key.bias\n",
      "encoder.layer.23.attention.self.value.weight\n",
      "encoder.layer.23.attention.self.value.bias\n",
      "encoder.layer.23.attention.output.dense.weight\n",
      "encoder.layer.23.attention.output.dense.bias\n",
      "encoder.layer.23.attention.output.LayerNorm.weight\n",
      "encoder.layer.23.attention.output.LayerNorm.bias\n",
      "encoder.layer.23.intermediate.dense.weight\n",
      "encoder.layer.23.intermediate.dense.bias\n",
      "encoder.layer.23.output.dense.weight\n",
      "encoder.layer.23.output.dense.bias\n",
      "encoder.layer.23.output.LayerNorm.weight\n",
      "encoder.layer.23.output.LayerNorm.bias\n",
      "pooler.dense.weight\n",
      "pooler.dense.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.bert.named_parameters():                \n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bee1c39a-b0a7-4985-ba18-3ceff209ea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_tagging_pred_n_true(preds, y, tag_pad_idx, org_shap, fist_tokens, FT_TAGS):\n",
    "\n",
    "    max_preds_p = preds.argmax(dim = 1, keepdim = True).view(org_shap)\n",
    "    y_p = y.view(org_shap)\n",
    "    fist_tokens_p = fist_tokens.view(org_shap)\n",
    "   \n",
    "    preds_list = []\n",
    "    true_list = []\n",
    "    for i in range(len(y_p)):\n",
    "        seq_pred = []\n",
    "        seq_true = []\n",
    "        for j in range(len(y_p[i])):\n",
    "\n",
    "            if y_p[i][j].item() != tag_pad_idx and fist_tokens_p[i][j] == 1:\n",
    "                seq_pred.append(max_preds_p[i][j].item()-1)\n",
    "                seq_true.append(y_p[i][j].item()-1)\n",
    "\n",
    "        preds_list.append(seq_pred)\n",
    "        true_list.append(seq_true)\n",
    "\n",
    "    return preds_list, true_list\n",
    "\n",
    "def obtain_classification_pred_n_true(preds, y):\n",
    "\n",
    "    max_preds = preds.argmax(dim = 1)\n",
    "   \n",
    "    preds_list = []\n",
    "    true_list = []\n",
    "    for i in range(len(y)):\n",
    "        preds_list.append(max_preds[i].item()-1)\n",
    "        true_list.append(y[i].item()-1)\n",
    "\n",
    "    return preds_list, true_list\n",
    "\n",
    "def f1_score_tag(preds_list, true_list):\n",
    "    tp,tn,fp,fn = 0,0,0,0\n",
    "    for i in range(len(true_list)):\n",
    "        for j in range(len(true_list[i])):\n",
    "            if true_list[i][j] == 1:\n",
    "                if preds_list[i][j] == 1:\n",
    "                    tp+=1\n",
    "                elif preds_list[i][j] == 0:\n",
    "                    fn += 1\n",
    "            elif true_list[i][j] == 0:\n",
    "                if preds_list[i][j] == 0:\n",
    "                    tn += 1\n",
    "                elif preds_list[i][j] == 1:\n",
    "                    fp += 1\n",
    "               \n",
    "    recall = tp/(tp+fn+1e-9)\n",
    "    precision = tp/(tp+fp+1e-9)\n",
    "    f1 = 2*recall*precision/(recall+precision+1e-9)\n",
    "    acc = (tp+tn)/(tp+tn+fp+fn+1e-9)\n",
    "    return round(precision,4), round(recall,4), round(f1,4), round(acc,4)\n",
    "\n",
    "def f1_score_cls(preds_list, true_list):\n",
    "    tp,tn,fp,fn = 0,0,0,0\n",
    "    for i in range(len(true_list)):\n",
    "        if true_list[i] == 1:\n",
    "            if preds_list[i] == true_list[i]:\n",
    "                tp+=1\n",
    "            elif preds_list[i] != true_list[i]:\n",
    "                fn += 1\n",
    "        elif true_list[i] == 0:\n",
    "            if preds_list[i] == true_list[i]:\n",
    "                tn += 1\n",
    "            elif preds_list[i] != true_list[i]:\n",
    "                fp += 1\n",
    "               \n",
    "    print(\"tp: \",tp)\n",
    "    print(\"fn: \",fn)\n",
    "    print(\"tn: \",tn)\n",
    "    print(\"fp: \",fp)\n",
    "    \n",
    "    recall = tp/(tp+fn+1e-9)\n",
    "    precision = tp/(tp+fp+1e-9)\n",
    "    f1 = 2*recall*precision/(recall+precision+1e-9)\n",
    "    acc = (tp+tn)/(tp+tn+fp+fn+1e-9)\n",
    "    return round(precision,4), round(recall,4), round(f1,4), round(acc,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c08d620b-e74d-4bce-b381-d92438628619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, scheduler, criterion_label, criterion_pos, tag_pad_idx, ori_tag_loss_weight, ori_cls_loss_weight):\n",
    "    \n",
    "    loss_label1 = 0\n",
    "    loss_label2 = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    pred_label1_list=[]\n",
    "    true_label1_list=[]\n",
    "    pred_label2_list=[]\n",
    "    true_label2_list=[]\n",
    "    \n",
    "    tag_signal_list=[]\n",
    "    cls_signal_list=[]\n",
    "    \n",
    "    for batch_idx, batch in enumerate(iterator):\n",
    "        \n",
    "        org_label1_shap = batch.label1.size() # [batch size, seq len]\n",
    "        org_label2_shap = batch.label2.size() # [batch size, 1]\n",
    "        \n",
    "        token_idx_ = batch.token_id # [batch size, seq len]\n",
    "        mask_ab = batch.mask_ab # [batch size, seq len]\n",
    "        mask_p = batch.mask_p # [batch size, seq len]\n",
    "        ft_tags = batch.first_token.view(-1) # [batch size * seq len]\n",
    "        tag_true = batch.label1.view(-1) # [batch size * seq len]\n",
    "        cls_true = batch.label2.view(-1) # [batch size]\n",
    "        \n",
    "        \n",
    "        \n",
    "        # tag_pred:[batch size, seq len, label1 dim]\n",
    "        # cls_pred:[batch size, label2 dim]\n",
    "        \n",
    "        tag_pred, cls_pred = model(token_idx_,mask_ab, mask_p)\n",
    "        # ######## for softmax trust level ###########\n",
    "        # tag_pred, cls_pred, tag_signal, cls_signal = model(token_idx_,mask_ab, mask_p)\n",
    "\n",
    "        tag_pred = tag_pred.view(-1, tag_pred.shape[-1]) # [batch size * seq len, label1 dim]\n",
    "\n",
    "        loss_tag = criterion_tag(tag_pred, tag_true)\n",
    "        loss_cls = criterion_cls(cls_pred, cls_true)\n",
    "        \n",
    "        loss_label1 += loss_tag.item()\n",
    "        loss_label2 += loss_cls.item()\n",
    "        \n",
    "        \n",
    "        \n",
    "#         ######## for softmax trust level ###########\n",
    "#         # Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy().\n",
    "#         tag_signal = np.average(tag_signal.cpu().detach().numpy())\n",
    "#         cls_signal = np.average(cls_signal.cpu().detach().numpy())\n",
    "        \n",
    "#         tag_signal_list.append(tag_signal)\n",
    "#         cls_signal_list.append(cls_signal)\n",
    "        \n",
    "        # loss_tag is larger than loss_cls, so the overall loss is weighted summed up.\n",
    "        # if loss_cls > loss_tag*10:\n",
    "        #     cls_loss_weight=0.1\n",
    "        # elif loss_cls > loss_tag*5:\n",
    "        #     cls_loss_weight=0.2\n",
    "        # elif loss_cls > loss_tag*2:\n",
    "        #     cls_loss_weight=0.5\n",
    "        # elif loss_cls < loss_tag*0.5:\n",
    "        #     cls_loss_weight=2\n",
    "        \n",
    "        # tag_loss_weight=1\n",
    "        # cls_loss_weight=tag_loss_weight*loss_tag/loss_cls\n",
    "        \n",
    "        \n",
    "        # if loss_label2 < 500 and loss_label2 > 100 and loss_label2 > loss_label1*2:\n",
    "        #     tag_loss_weight=0\n",
    "        \n",
    "        # weight = F.softmax(torch.randn(2), dim=-1)\n",
    "        \n",
    "        # loss = tag_loss_weight*loss_tag + cls_loss_weight*loss_cls\n",
    "        #loss = weight[0]*loss_tag + weight[1]*loss_cls\n",
    "        loss = ori_tag_loss_weight*loss_tag + ori_cls_loss_weight*loss_cls\n",
    "        \n",
    "        # normalize loss to account for batch accumulation\n",
    "        loss = loss / accum_iter\n",
    "        \n",
    "        # backward pass, The gradients are computed when we call loss.backward() and are stored by PyTorch until we call optimizer.zero_grad().\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        # weights update. It is important to also update weights on the last batch when batch_idx + 1 == len(data_loader) - \n",
    "        # this makes sure that data from the last batches are not discarded and used for optimizing the network.\n",
    "        if ((batch_idx + 1) % accum_iter == 0) or (batch_idx + 1 == len(iterator)):\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        pred_label1, true_label1 = obtain_tagging_pred_n_true(tag_pred, tag_true, tag_pad_idx, org_label1_shap, ft_tags, FT_TAGS)\n",
    "        pred_label2, true_label2 = obtain_classification_pred_n_true(cls_pred, cls_true)\n",
    "        \n",
    "        \n",
    "        pred_label1_list.extend(pred_label1)\n",
    "        true_label1_list.extend(true_label1)\n",
    "        pred_label2_list.extend(pred_label2)\n",
    "        true_label2_list.extend(true_label2)\n",
    "            \n",
    "            \n",
    "    p_label1, r_label1, f_label1, acc_label1 = f1_score_tag(pred_label1_list, true_label1_list)\n",
    "    p_label2, r_label2, f_label2, acc_label2 = f1_score_cls(pred_label2_list, true_label2_list)\n",
    "    \n",
    "    print(\"length of iterator: \",len(iterator))\n",
    "    print(\"train set pred label2 length: \",len(pred_label2_list))\n",
    "    print(\"train set true label2 length: \",len(true_label2_list))\n",
    "    match_number=0\n",
    "    for i in range(len(pred_label2_list)):\n",
    "        if pred_label2_list[i] == true_label2_list[i]:\n",
    "            match_number+=1\n",
    "    print(\"match number: \",match_number)   \n",
    "    \n",
    "    \n",
    "#     ######## for softmax trust level ###########\n",
    "#     avg_tag_signal=statistics.mean(tag_signal_list)\n",
    "#     avg_cls_signal=statistics.mean(cls_signal_list)\n",
    "    \n",
    "#     avg_tag_signal=math.sqrt(avg_tag_signal)\n",
    "#     avg_cls_signal=math.sqrt(avg_cls_signal)\n",
    "    \n",
    "#     print(\"tag signal: \",avg_tag_signal)\n",
    "#     print(\"cls signal: \",avg_cls_signal)\n",
    "        \n",
    "    return round(loss_label1,4), round(loss_label2,4), p_label1, r_label1, f_label1, \\\n",
    "acc_label1, p_label2, r_label2, f_label2, acc_label2\n",
    "\n",
    "#     ######## for softmax trust level ###########\n",
    "#     return round(loss_label1,4), round(loss_label2,4), p_label1, r_label1, f_label1, \\\n",
    "# acc_label1, p_label2, r_label2, f_label2, acc_label2, avg_tag_signal, avg_cls_signal\n",
    "\n",
    "def evaluate(model, iterator, criterion_label, criterion_pos, tag_pad_idx):\n",
    "    \n",
    "    loss_label1 = 0\n",
    "    loss_label2 = 0\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        pred_label1_list=[]\n",
    "        true_label1_list=[]\n",
    "        pred_label2_list=[]\n",
    "        true_label2_list=[]\n",
    "        \n",
    "        for batch in iterator:\n",
    "\n",
    "            org_label1_shap = batch.label1.size() # [batch size, seq len]\n",
    "            org_label2_shap = batch.label2.size() # [batch size, 1]\n",
    "\n",
    "            token_idx_ = batch.token_id # [batch size, seq len]\n",
    "            mask_ab = batch.mask_ab # [batch size, seq len]\n",
    "            mask_p = batch.mask_p # [batch size, seq len]\n",
    "            ft_tags = batch.first_token.view(-1) # [batch size * seq len]\n",
    "            tag_true = batch.label1.view(-1) # [batch size * seq len]\n",
    "            cls_true = batch.label2.view(-1) # [batch size]\n",
    "\n",
    "            # tag_pred:[batch size, seq len, label1 dim]\n",
    "            # cls_pred:[batch size, label2 dim]\n",
    "            \n",
    "            tag_pred, cls_pred = model(token_idx_,mask_ab,mask_p)\n",
    "            # ######## for softmax trust level ###########\n",
    "            # tag_pred, cls_pred, _, _ = model(token_idx_,mask_ab,mask_p)\n",
    "\n",
    "            tag_pred = tag_pred.view(-1, tag_pred.shape[-1]) # [batch size * seq len, label1 dim]\n",
    "\n",
    "            loss_tag = criterion_tag(tag_pred, tag_true)\n",
    "            loss_cls = criterion_cls(cls_pred, cls_true)\n",
    "\n",
    "            loss_label1 += loss_tag.item()\n",
    "            loss_label2 += loss_cls.item()\n",
    "\n",
    "            pred_label1, true_label1 = obtain_tagging_pred_n_true(tag_pred, tag_true, tag_pad_idx, org_label1_shap, ft_tags, FT_TAGS)\n",
    "            pred_label2, true_label2 = obtain_classification_pred_n_true(cls_pred, cls_true)\n",
    "            \n",
    "            pred_label1_list.extend(pred_label1)\n",
    "            true_label1_list.extend(true_label1)\n",
    "            pred_label2_list.extend(pred_label2)\n",
    "            true_label2_list.extend(true_label2)\n",
    "            \n",
    "            \n",
    "        p_label1, r_label1, f_label1, acc_label1 = f1_score_tag(pred_label1_list, true_label1_list)\n",
    "        p_label2, r_label2, f_label2, acc_label2 = f1_score_cls(pred_label2_list, true_label2_list)\n",
    "        \n",
    "        print(\"pred label2 length: \",len(pred_label2_list))\n",
    "        print(\"true label2 length: \",len(true_label2_list))\n",
    "        match_number=0\n",
    "        for i in range(len(pred_label2_list)):\n",
    "            if pred_label2_list[i] == true_label2_list[i]:\n",
    "                match_number+=1\n",
    "        print(\"match number: \",match_number)   \n",
    "        \n",
    "    return round(loss_label1,4), round(loss_label2,4), p_label1, r_label1, f_label1, acc_label1, \\\n",
    "p_label2, r_label2, f_label2, acc_label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31736127-1666-4727-9871-4f4d0be936e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = F.softmax(torch.randn(2), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9dfb11e-fb5f-4e21-b989-d19832f3a2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0678)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13f38094-0574-46d3-a726-3c69537015bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_output_difference(model, iterator, criterion_label, criterion_pos, tag_pad_idx):\n",
    "    \n",
    "    loss_label1 = 0\n",
    "    loss_label2 = 0\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        pred_label1_list=[]\n",
    "        true_label1_list=[]\n",
    "        pred_label2_list=[]\n",
    "        true_label2_list=[]\n",
    "        token_idx_list=[]\n",
    "        \n",
    "        for batch in iterator:\n",
    "\n",
    "            org_label1_shap = batch.label1.size() # [batch size, seq len]\n",
    "            org_label2_shap = batch.label2.size() # [batch size, 1]\n",
    "\n",
    "            token_idx_ = batch.token_id # [batch size, seq len]\n",
    "            mask_ab = batch.mask_ab # [batch size, seq len]\n",
    "            mask_p = batch.mask_p # [batch size, seq len]\n",
    "            ft_tags = batch.first_token.view(-1) # [batch size * seq len]\n",
    "            tag_true = batch.label1.view(-1) # [batch size * seq len]\n",
    "            cls_true = batch.label2.view(-1) # [batch size]\n",
    "            #seq = batch.seq.view(-1) # [batch size]\n",
    "\n",
    "            # tag_pred:[batch size, seq len, label1 dim]\n",
    "            # cls_pred:[batch size, label2 dim]\n",
    "            \n",
    "            tag_pred, cls_pred = model(token_idx_,mask_ab,mask_p)\n",
    "            # ######## for softmax trust level ###########\n",
    "            # tag_pred, cls_pred, _, _ = model(token_idx_,mask_ab,mask_p)\n",
    "\n",
    "            tag_pred = tag_pred.view(-1, tag_pred.shape[-1]) # [batch size * seq len, label1 dim]\n",
    "\n",
    "            loss_tag = criterion_tag(tag_pred, tag_true)\n",
    "            loss_cls = criterion_cls(cls_pred, cls_true)\n",
    "\n",
    "            loss_label1 += loss_tag.item()\n",
    "            loss_label2 += loss_cls.item()\n",
    "\n",
    "            pred_label1, true_label1 = obtain_tagging_pred_n_true(tag_pred, tag_true, tag_pad_idx, org_label1_shap, ft_tags, FT_TAGS)\n",
    "            pred_label2, true_label2 = obtain_classification_pred_n_true(cls_pred, cls_true)\n",
    "            \n",
    "            pred_label1_list.extend(pred_label1)\n",
    "            true_label1_list.extend(true_label1)\n",
    "            pred_label2_list.extend(pred_label2)\n",
    "            true_label2_list.extend(true_label2)\n",
    "            \n",
    "            for i in range(len(batch.token_id.tolist())):\n",
    "                token_idx_list.append(batch.token_id.tolist()[i])\n",
    "            \n",
    "            \n",
    "        p_label1, r_label1, f_label1, acc_label1 = f1_score_tag(pred_label1_list, true_label1_list)\n",
    "        p_label2, r_label2, f_label2, acc_label2 = f1_score_cls(pred_label2_list, true_label2_list)\n",
    "        \n",
    "        print(\"pred label2 length: \",len(pred_label2_list))\n",
    "        print(\"true label2 length: \",len(true_label2_list))\n",
    "        print(\"token_idx_list length: \",len(true_label2_list))\n",
    "        match_number=0\n",
    "        comparison_df = pd.DataFrame(columns=['index', 'token_idx','pred_label2', 'true_label2'])\n",
    "        for i in range(len(pred_label2_list)):\n",
    "            if pred_label2_list[i] == true_label2_list[i]:\n",
    "                match_number+=1\n",
    "            elif pred_label2_list[i] != true_label2_list[i]:\n",
    "                df2={'index': i, 'token_idx':' '.join(str(e) for e in token_idx_list[i]), 'pred_label2': pred_label2_list[i], 'true_label2': true_label2_list[i]}\n",
    "                comparison_df = comparison_df.append(df2, ignore_index = True)\n",
    "        print(\"match number: \",match_number)   \n",
    "        \n",
    "    return round(loss_label1,4), round(loss_label2,4), p_label1, r_label1, f_label1, acc_label1, p_label2, r_label2, f_label2, acc_label2, comparison_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5d0749a-ae40-45c1-a76b-f2736d2322f1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for batch in test_iterator:\n",
    "#     print(batch.token_id.tolist()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91b20b0b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-24 21:34:28.500603\n",
      "EPOCH 0\n",
      "TAG_LOSS_WEIGHT:  0.5\n",
      "CLS_LOSS_WEIGHT:  0.5\n",
      "tp:  741\n",
      "fn:  1025\n",
      "tn:  1350\n",
      "fp:  862\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  2091\n",
      "tp:  219\n",
      "fn:  1531\n",
      "tn:  2119\n",
      "fp:  115\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  2338\n",
      "EPOCH 0\n",
      "   TRAIN | Label 1 loss: 221.8159 ; P: 0.0279 ; R: 0.0133 ; F1: 0.018 ; Acc: 0.9576\n",
      "           Label 2 loss: 890.1276 ; P: 0.4623 ; R: 0.4196 ; F1: 0.4399 ; Acc: 0.5256\n",
      "    TEST | Label 1 loss: 150.9037 ; P: 0.0 ; R: 0.0 ; F1: 0.0 ; Acc: 0.9709\n",
      "           Label 2 loss: 692.9372 ; P: 0.6557 ; R: 0.1251 ; F1: 0.2102 ; Acc: 0.5868\n",
      "2023-01-24 21:38:48.894793\n",
      "counter:  0\n",
      "2023-01-24 21:38:51.181262\n",
      "EPOCH 1\n",
      "TAG_LOSS_WEIGHT:  0.5\n",
      "CLS_LOSS_WEIGHT:  0.5\n",
      "tp:  776\n",
      "fn:  990\n",
      "tn:  1500\n",
      "fp:  712\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  2276\n",
      "tp:  691\n",
      "fn:  1059\n",
      "tn:  1980\n",
      "fp:  254\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  2671\n",
      "EPOCH 1\n",
      "   TRAIN | Label 1 loss: 142.6986 ; P: 0.0 ; R: 0.0 ; F1: 0.0 ; Acc: 0.9707\n",
      "           Label 2 loss: 701.7012 ; P: 0.5215 ; R: 0.4394 ; F1: 0.477 ; Acc: 0.5721\n",
      "    TEST | Label 1 loss: 137.8798 ; P: 0.0 ; R: 0.0 ; F1: 0.0 ; Acc: 0.9709\n",
      "           Label 2 loss: 626.8672 ; P: 0.7312 ; R: 0.3949 ; F1: 0.5128 ; Acc: 0.6704\n",
      "2023-01-24 21:43:27.205510\n",
      "counter:  0\n",
      "2023-01-24 21:43:29.711576\n",
      "EPOCH 2\n",
      "TAG_LOSS_WEIGHT:  0.45414587310920396\n",
      "CLS_LOSS_WEIGHT:  0.545854126890796\n",
      "tp:  837\n",
      "fn:  929\n",
      "tn:  1585\n",
      "fp:  627\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  2422\n",
      "tp:  1048\n",
      "fn:  702\n",
      "tn:  1760\n",
      "fp:  474\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  2808\n",
      "EPOCH 2\n",
      "   TRAIN | Label 1 loss: 133.8527 ; P: 0.0 ; R: 0.0 ; F1: 0.0 ; Acc: 0.9707\n",
      "           Label 2 loss: 670.8998 ; P: 0.5717 ; R: 0.474 ; F1: 0.5183 ; Acc: 0.6088\n",
      "    TEST | Label 1 loss: 126.4851 ; P: 0.0 ; R: 0.0 ; F1: 0.0 ; Acc: 0.9709\n",
      "           Label 2 loss: 599.5323 ; P: 0.6886 ; R: 0.5989 ; F1: 0.6406 ; Acc: 0.7048\n",
      "2023-01-24 21:48:00.238427\n",
      "counter:  0\n",
      "2023-01-24 21:48:02.314901\n",
      "EPOCH 3\n",
      "TAG_LOSS_WEIGHT:  0.4537362770904205\n",
      "CLS_LOSS_WEIGHT:  0.5462637229095796\n",
      "tp:  938\n",
      "fn:  828\n",
      "tn:  1675\n",
      "fp:  537\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  2613\n",
      "tp:  944\n",
      "fn:  806\n",
      "tn:  1958\n",
      "fp:  276\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  2902\n",
      "EPOCH 3\n",
      "   TRAIN | Label 1 loss: 123.4464 ; P: 0.4468 ; R: 0.0025 ; F1: 0.005 ; Acc: 0.9707\n",
      "           Label 2 loss: 634.9937 ; P: 0.6359 ; R: 0.5311 ; F1: 0.5788 ; Acc: 0.6569\n",
      "    TEST | Label 1 loss: 112.7897 ; P: 0.4333 ; R: 0.0031 ; F1: 0.0062 ; Acc: 0.9709\n",
      "           Label 2 loss: 570.0296 ; P: 0.7738 ; R: 0.5394 ; F1: 0.6357 ; Acc: 0.7284\n",
      "2023-01-24 21:52:38.568073\n",
      "counter:  1\n",
      "2023-01-24 21:52:40.814681\n",
      "EPOCH 4\n",
      "TAG_LOSS_WEIGHT:  0.45329818964230373\n",
      "CLS_LOSS_WEIGHT:  0.5467018103576963\n",
      "tp:  980\n",
      "fn:  786\n",
      "tn:  1719\n",
      "fp:  493\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  2699\n",
      "tp:  1028\n",
      "fn:  722\n",
      "tn:  1951\n",
      "fp:  283\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  2979\n",
      "EPOCH 4\n",
      "   TRAIN | Label 1 loss: 112.9757 ; P: 0.4713 ; R: 0.0178 ; F1: 0.0344 ; Acc: 0.9707\n",
      "           Label 2 loss: 608.3252 ; P: 0.6653 ; R: 0.5549 ; F1: 0.6051 ; Acc: 0.6785\n",
      "    TEST | Label 1 loss: 100.6967 ; P: 0.4704 ; R: 0.0786 ; F1: 0.1347 ; Acc: 0.9706\n",
      "           Label 2 loss: 537.5043 ; P: 0.7841 ; R: 0.5874 ; F1: 0.6717 ; Acc: 0.7477\n",
      "2023-01-24 21:57:12.241904\n",
      "counter:  0\n",
      "2023-01-24 21:57:14.051646\n",
      "EPOCH 5\n",
      "TAG_LOSS_WEIGHT:  0.44979891878039713\n",
      "CLS_LOSS_WEIGHT:  0.550201081219603\n",
      "tp:  1045\n",
      "fn:  721\n",
      "tn:  1745\n",
      "fp:  467\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  2790\n",
      "tp:  1078\n",
      "fn:  672\n",
      "tn:  1945\n",
      "fp:  289\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3023\n",
      "EPOCH 5\n",
      "   TRAIN | Label 1 loss: 103.0087 ; P: 0.4914 ; R: 0.0788 ; F1: 0.1358 ; Acc: 0.9706\n",
      "           Label 2 loss: 574.5528 ; P: 0.6911 ; R: 0.5917 ; F1: 0.6376 ; Acc: 0.7014\n",
      "    TEST | Label 1 loss: 95.9639 ; P: 0.4623 ; R: 0.2186 ; F1: 0.2968 ; Acc: 0.9699\n",
      "           Label 2 loss: 515.9896 ; P: 0.7886 ; R: 0.616 ; F1: 0.6917 ; Acc: 0.7588\n",
      "2023-01-24 22:01:32.144177\n",
      "counter:  0\n",
      "2023-01-24 22:01:34.147262\n",
      "EPOCH 6\n",
      "TAG_LOSS_WEIGHT:  0.4496416459512813\n",
      "CLS_LOSS_WEIGHT:  0.5503583540487187\n",
      "tp:  1111\n",
      "fn:  655\n",
      "tn:  1767\n",
      "fp:  445\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  2878\n",
      "tp:  1129\n",
      "fn:  621\n",
      "tn:  1944\n",
      "fp:  290\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3073\n",
      "EPOCH 6\n",
      "   TRAIN | Label 1 loss: 96.2116 ; P: 0.4765 ; R: 0.1514 ; F1: 0.2297 ; Acc: 0.9703\n",
      "           Label 2 loss: 550.3938 ; P: 0.714 ; R: 0.6291 ; F1: 0.6689 ; Acc: 0.7235\n",
      "    TEST | Label 1 loss: 92.5547 ; P: 0.4621 ; R: 0.3169 ; F1: 0.376 ; Acc: 0.9694\n",
      "           Label 2 loss: 492.4257 ; P: 0.7956 ; R: 0.6451 ; F1: 0.7125 ; Acc: 0.7713\n",
      "2023-01-24 22:05:48.394270\n",
      "counter:  0\n",
      "2023-01-24 22:05:50.492870\n",
      "EPOCH 7\n",
      "TAG_LOSS_WEIGHT:  0.45002809401619004\n",
      "CLS_LOSS_WEIGHT:  0.54997190598381\n",
      "tp:  1180\n",
      "fn:  586\n",
      "tn:  1841\n",
      "fp:  371\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3021\n",
      "tp:  1409\n",
      "fn:  341\n",
      "tn:  1619\n",
      "fp:  615\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3028\n",
      "EPOCH 7\n",
      "   TRAIN | Label 1 loss: 90.8868 ; P: 0.4975 ; R: 0.2134 ; F1: 0.2987 ; Acc: 0.9707\n",
      "           Label 2 loss: 503.3549 ; P: 0.7608 ; R: 0.6682 ; F1: 0.7115 ; Acc: 0.7594\n",
      "    TEST | Label 1 loss: 88.3693 ; P: 0.4653 ; R: 0.4644 ; F1: 0.4649 ; Acc: 0.9689\n",
      "           Label 2 loss: 501.5653 ; P: 0.6961 ; R: 0.8051 ; F1: 0.7467 ; Acc: 0.76\n",
      "2023-01-24 22:10:05.105320\n",
      "counter:  0\n",
      "2023-01-24 22:10:05.106315\n",
      "EPOCH 8\n",
      "TAG_LOSS_WEIGHT:  0.4593497314456773\n",
      "CLS_LOSS_WEIGHT:  0.5406502685543226\n",
      "tp:  1229\n",
      "fn:  537\n",
      "tn:  1846\n",
      "fp:  366\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3075\n",
      "tp:  1273\n",
      "fn:  477\n",
      "tn:  1912\n",
      "fp:  322\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3185\n",
      "EPOCH 8\n",
      "   TRAIN | Label 1 loss: 86.5871 ; P: 0.5372 ; R: 0.2539 ; F1: 0.3448 ; Acc: 0.9718\n",
      "           Label 2 loss: 477.3049 ; P: 0.7705 ; R: 0.6959 ; F1: 0.7313 ; Acc: 0.773\n",
      "    TEST | Label 1 loss: 87.0831 ; P: 0.4664 ; R: 0.5541 ; F1: 0.5065 ; Acc: 0.9686\n",
      "           Label 2 loss: 437.1819 ; P: 0.7981 ; R: 0.7274 ; F1: 0.7611 ; Acc: 0.7994\n",
      "2023-01-24 22:14:13.418461\n",
      "counter:  0\n",
      "2023-01-24 22:14:15.385437\n",
      "EPOCH 9\n",
      "TAG_LOSS_WEIGHT:  0.46287577206681285\n",
      "CLS_LOSS_WEIGHT:  0.5371242279331873\n",
      "tp:  1289\n",
      "fn:  477\n",
      "tn:  1878\n",
      "fp:  334\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3167\n",
      "tp:  1354\n",
      "fn:  396\n",
      "tn:  1865\n",
      "fp:  369\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3219\n",
      "EPOCH 9\n",
      "   TRAIN | Label 1 loss: 83.2807 ; P: 0.5351 ; R: 0.2927 ; F1: 0.3784 ; Acc: 0.9718\n",
      "           Label 2 loss: 435.6506 ; P: 0.7942 ; R: 0.7299 ; F1: 0.7607 ; Acc: 0.7961\n",
      "    TEST | Label 1 loss: 83.4227 ; P: 0.4856 ; R: 0.5895 ; F1: 0.5325 ; Acc: 0.9699\n",
      "           Label 2 loss: 411.5037 ; P: 0.7858 ; R: 0.7737 ; F1: 0.7797 ; Acc: 0.808\n",
      "2023-01-24 22:18:36.152988\n",
      "counter:  0\n",
      "2023-01-24 22:18:38.230752\n",
      "EPOCH 10\n",
      "TAG_LOSS_WEIGHT:  0.47194362727548833\n",
      "CLS_LOSS_WEIGHT:  0.5280563727245117\n",
      "tp:  1353\n",
      "fn:  413\n",
      "tn:  1897\n",
      "fp:  315\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3250\n",
      "tp:  1397\n",
      "fn:  353\n",
      "tn:  1899\n",
      "fp:  335\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3296\n",
      "EPOCH 10\n",
      "   TRAIN | Label 1 loss: 79.6026 ; P: 0.5672 ; R: 0.3404 ; F1: 0.4255 ; Acc: 0.9731\n",
      "           Label 2 loss: 403.0839 ; P: 0.8112 ; R: 0.7661 ; F1: 0.788 ; Acc: 0.817\n",
      "    TEST | Label 1 loss: 81.5616 ; P: 0.4943 ; R: 0.6206 ; F1: 0.5503 ; Acc: 0.9705\n",
      "           Label 2 loss: 381.5085 ; P: 0.8066 ; R: 0.7983 ; F1: 0.8024 ; Acc: 0.8273\n",
      "2023-01-24 22:22:48.381164\n",
      "counter:  0\n",
      "2023-01-24 22:22:50.279465\n",
      "EPOCH 11\n",
      "TAG_LOSS_WEIGHT:  0.4775780959043538\n",
      "CLS_LOSS_WEIGHT:  0.5224219040956463\n",
      "tp:  1381\n",
      "fn:  385\n",
      "tn:  1922\n",
      "fp:  290\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3303\n",
      "tp:  1443\n",
      "fn:  307\n",
      "tn:  1915\n",
      "fp:  319\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3358\n",
      "EPOCH 11\n",
      "   TRAIN | Label 1 loss: 77.5083 ; P: 0.5729 ; R: 0.3598 ; F1: 0.442 ; Acc: 0.9734\n",
      "           Label 2 loss: 368.7382 ; P: 0.8265 ; R: 0.782 ; F1: 0.8036 ; Acc: 0.8303\n",
      "    TEST | Label 1 loss: 77.4455 ; P: 0.5226 ; R: 0.577 ; F1: 0.5485 ; Acc: 0.9724\n",
      "           Label 2 loss: 348.798 ; P: 0.819 ; R: 0.8246 ; F1: 0.8218 ; Acc: 0.8429\n",
      "2023-01-24 22:27:03.237653\n",
      "counter:  0\n",
      "2023-01-24 22:27:05.187348\n",
      "EPOCH 12\n",
      "TAG_LOSS_WEIGHT:  0.48498704618926497\n",
      "CLS_LOSS_WEIGHT:  0.515012953810735\n",
      "tp:  1426\n",
      "fn:  340\n",
      "tn:  1941\n",
      "fp:  271\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3367\n",
      "tp:  1533\n",
      "fn:  217\n",
      "tn:  1879\n",
      "fp:  355\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3412\n",
      "EPOCH 12\n",
      "   TRAIN | Label 1 loss: 74.6125 ; P: 0.5826 ; R: 0.3914 ; F1: 0.4682 ; Acc: 0.974\n",
      "           Label 2 loss: 330.5681 ; P: 0.8403 ; R: 0.8075 ; F1: 0.8236 ; Acc: 0.8464\n",
      "    TEST | Label 1 loss: 75.2783 ; P: 0.5297 ; R: 0.6112 ; F1: 0.5675 ; Acc: 0.9729\n",
      "           Label 2 loss: 335.4748 ; P: 0.812 ; R: 0.876 ; F1: 0.8428 ; Acc: 0.8564\n",
      "2023-01-24 22:31:17.698739\n",
      "counter:  0\n",
      "2023-01-24 22:31:19.610608\n",
      "EPOCH 13\n",
      "TAG_LOSS_WEIGHT:  0.4921936824181007\n",
      "CLS_LOSS_WEIGHT:  0.5078063175818994\n",
      "tp:  1491\n",
      "fn:  275\n",
      "tn:  1988\n",
      "fp:  224\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3479\n",
      "tp:  1516\n",
      "fn:  234\n",
      "tn:  1957\n",
      "fp:  277\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3473\n",
      "EPOCH 13\n",
      "   TRAIN | Label 1 loss: 72.1422 ; P: 0.5866 ; R: 0.4095 ; F1: 0.4823 ; Acc: 0.9743\n",
      "           Label 2 loss: 291.1391 ; P: 0.8694 ; R: 0.8443 ; F1: 0.8567 ; Acc: 0.8746\n",
      "    TEST | Label 1 loss: 75.8036 ; P: 0.5179 ; R: 0.6816 ; F1: 0.5886 ; Acc: 0.9723\n",
      "           Label 2 loss: 311.9889 ; P: 0.8455 ; R: 0.8663 ; F1: 0.8558 ; Acc: 0.8717\n",
      "2023-01-24 22:35:31.108721\n",
      "counter:  0\n",
      "2023-01-24 22:35:33.049580\n",
      "EPOCH 14\n",
      "TAG_LOSS_WEIGHT:  0.4996057022512197\n",
      "CLS_LOSS_WEIGHT:  0.5003942977487804\n",
      "tp:  1519\n",
      "fn:  247\n",
      "tn:  2004\n",
      "fp:  208\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3523\n",
      "tp:  1528\n",
      "fn:  222\n",
      "tn:  1990\n",
      "fp:  244\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3518\n",
      "EPOCH 14\n",
      "   TRAIN | Label 1 loss: 70.7394 ; P: 0.597 ; R: 0.4252 ; F1: 0.4966 ; Acc: 0.9748\n",
      "           Label 2 loss: 263.0449 ; P: 0.8796 ; R: 0.8601 ; F1: 0.8697 ; Acc: 0.8856\n",
      "    TEST | Label 1 loss: 71.8999 ; P: 0.5634 ; R: 0.6028 ; F1: 0.5824 ; Acc: 0.9748\n",
      "           Label 2 loss: 304.8352 ; P: 0.8623 ; R: 0.8731 ; F1: 0.8677 ; Acc: 0.883\n",
      "2023-01-24 22:39:43.894717\n",
      "counter:  0\n",
      "2023-01-24 22:39:45.925705\n",
      "EPOCH 15\n",
      "TAG_LOSS_WEIGHT:  0.5048625635654205\n",
      "CLS_LOSS_WEIGHT:  0.4951374364345795\n",
      "tp:  1547\n",
      "fn:  219\n",
      "tn:  2038\n",
      "fp:  174\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3585\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  1863\n",
      "fp:  371\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3488\n",
      "EPOCH 15\n",
      "   TRAIN | Label 1 loss: 68.6339 ; P: 0.6093 ; R: 0.4447 ; F1: 0.5141 ; Acc: 0.9754\n",
      "           Label 2 loss: 239.1282 ; P: 0.8989 ; R: 0.876 ; F1: 0.8873 ; Acc: 0.9012\n",
      "    TEST | Label 1 loss: 71.4175 ; P: 0.5523 ; R: 0.6696 ; F1: 0.6053 ; Acc: 0.9746\n",
      "           Label 2 loss: 327.0785 ; P: 0.8141 ; R: 0.9286 ; F1: 0.8676 ; Acc: 0.8755\n",
      "2023-01-24 22:43:56.522641\n",
      "counter:  1\n",
      "2023-01-24 22:43:56.522641\n",
      "EPOCH 16\n",
      "TAG_LOSS_WEIGHT:  0.5082177354540137\n",
      "CLS_LOSS_WEIGHT:  0.49178226454598634\n",
      "tp:  1588\n",
      "fn:  178\n",
      "tn:  2054\n",
      "fp:  158\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3642\n",
      "tp:  1590\n",
      "fn:  160\n",
      "tn:  1978\n",
      "fp:  256\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3568\n",
      "EPOCH 16\n",
      "   TRAIN | Label 1 loss: 67.2989 ; P: 0.6244 ; R: 0.4771 ; F1: 0.5409 ; Acc: 0.9763\n",
      "           Label 2 loss: 221.0864 ; P: 0.9095 ; R: 0.8992 ; F1: 0.9043 ; Acc: 0.9155\n",
      "    TEST | Label 1 loss: 72.4082 ; P: 0.5364 ; R: 0.7281 ; F1: 0.6177 ; Acc: 0.9738\n",
      "           Label 2 loss: 303.2426 ; P: 0.8613 ; R: 0.9086 ; F1: 0.8843 ; Acc: 0.8956\n",
      "2023-01-24 22:48:03.774337\n",
      "counter:  0\n",
      "2023-01-24 22:48:05.710117\n",
      "EPOCH 17\n",
      "TAG_LOSS_WEIGHT:  0.5108317678536333\n",
      "CLS_LOSS_WEIGHT:  0.48916823214636673\n",
      "tp:  1595\n",
      "fn:  171\n",
      "tn:  2060\n",
      "fp:  152\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3655\n",
      "tp:  1618\n",
      "fn:  132\n",
      "tn:  1953\n",
      "fp:  281\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3571\n",
      "EPOCH 17\n",
      "   TRAIN | Label 1 loss: 66.0141 ; P: 0.6249 ; R: 0.4724 ; F1: 0.5381 ; Acc: 0.9763\n",
      "           Label 2 loss: 201.5474 ; P: 0.913 ; R: 0.9032 ; F1: 0.9081 ; Acc: 0.9188\n",
      "    TEST | Label 1 loss: 70.8512 ; P: 0.5535 ; R: 0.7264 ; F1: 0.6283 ; Acc: 0.975\n",
      "           Label 2 loss: 296.27 ; P: 0.852 ; R: 0.9246 ; F1: 0.8868 ; Acc: 0.8963\n",
      "2023-01-24 22:52:15.937013\n",
      "counter:  0\n",
      "2023-01-24 22:52:17.867420\n",
      "EPOCH 18\n",
      "TAG_LOSS_WEIGHT:  0.5136497465253872\n",
      "CLS_LOSS_WEIGHT:  0.48635025347461286\n",
      "tp:  1611\n",
      "fn:  155\n",
      "tn:  2068\n",
      "fp:  144\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3679\n",
      "tp:  1614\n",
      "fn:  136\n",
      "tn:  1993\n",
      "fp:  241\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3607\n",
      "EPOCH 18\n",
      "   TRAIN | Label 1 loss: 64.7582 ; P: 0.636 ; R: 0.4947 ; F1: 0.5565 ; Acc: 0.9769\n",
      "           Label 2 loss: 190.9404 ; P: 0.9179 ; R: 0.9122 ; F1: 0.9151 ; Acc: 0.9248\n",
      "    TEST | Label 1 loss: 68.3605 ; P: 0.571 ; R: 0.7214 ; F1: 0.6374 ; Acc: 0.9761\n",
      "           Label 2 loss: 291.5306 ; P: 0.8701 ; R: 0.9223 ; F1: 0.8954 ; Acc: 0.9054\n",
      "2023-01-24 22:56:26.777203\n",
      "counter:  0\n",
      "2023-01-24 22:56:28.712510\n",
      "EPOCH 19\n",
      "TAG_LOSS_WEIGHT:  0.5145943529620084\n",
      "CLS_LOSS_WEIGHT:  0.48540564703799155\n",
      "tp:  1624\n",
      "fn:  142\n",
      "tn:  2080\n",
      "fp:  132\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3704\n",
      "tp:  1615\n",
      "fn:  135\n",
      "tn:  1991\n",
      "fp:  243\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3606\n",
      "EPOCH 19\n",
      "   TRAIN | Label 1 loss: 62.3625 ; P: 0.6442 ; R: 0.511 ; F1: 0.5699 ; Acc: 0.9774\n",
      "           Label 2 loss: 172.2767 ; P: 0.9248 ; R: 0.9196 ; F1: 0.9222 ; Acc: 0.9311\n",
      "    TEST | Label 1 loss: 72.155 ; P: 0.5389 ; R: 0.792 ; F1: 0.6414 ; Acc: 0.9742\n",
      "           Label 2 loss: 302.2752 ; P: 0.8692 ; R: 0.9229 ; F1: 0.8952 ; Acc: 0.9051\n",
      "2023-01-24 23:00:39.098958\n",
      "counter:  1\n",
      "2023-01-24 23:00:39.098958\n",
      "EPOCH 20\n",
      "TAG_LOSS_WEIGHT:  0.5159762146504696\n",
      "CLS_LOSS_WEIGHT:  0.48402378534953044\n",
      "tp:  1644\n",
      "fn:  122\n",
      "tn:  2106\n",
      "fp:  106\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3750\n",
      "tp:  1606\n",
      "fn:  144\n",
      "tn:  2040\n",
      "fp:  194\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3646\n",
      "EPOCH 20\n",
      "   TRAIN | Label 1 loss: 62.2266 ; P: 0.6496 ; R: 0.5217 ; F1: 0.5787 ; Acc: 0.9778\n",
      "           Label 2 loss: 160.5999 ; P: 0.9394 ; R: 0.9309 ; F1: 0.9352 ; Acc: 0.9427\n",
      "    TEST | Label 1 loss: 67.5997 ; P: 0.5784 ; R: 0.7426 ; F1: 0.6503 ; Acc: 0.9768\n",
      "           Label 2 loss: 294.2575 ; P: 0.8922 ; R: 0.9177 ; F1: 0.9048 ; Acc: 0.9152\n",
      "2023-01-24 23:04:45.378732\n",
      "counter:  0\n",
      "2023-01-24 23:04:47.340517\n",
      "EPOCH 21\n",
      "TAG_LOSS_WEIGHT:  0.5179792114338491\n",
      "CLS_LOSS_WEIGHT:  0.4820207885661509\n",
      "tp:  1655\n",
      "fn:  111\n",
      "tn:  2111\n",
      "fp:  101\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3766\n",
      "tp:  1609\n",
      "fn:  141\n",
      "tn:  2033\n",
      "fp:  201\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3642\n",
      "EPOCH 21\n",
      "   TRAIN | Label 1 loss: 60.5153 ; P: 0.6562 ; R: 0.5317 ; F1: 0.5874 ; Acc: 0.9781\n",
      "           Label 2 loss: 135.6943 ; P: 0.9425 ; R: 0.9371 ; F1: 0.9398 ; Acc: 0.9467\n",
      "    TEST | Label 1 loss: 68.667 ; P: 0.5637 ; R: 0.7792 ; F1: 0.6542 ; Acc: 0.976\n",
      "           Label 2 loss: 308.8097 ; P: 0.889 ; R: 0.9194 ; F1: 0.9039 ; Acc: 0.9142\n",
      "2023-01-24 23:08:56.907293\n",
      "counter:  1\n",
      "2023-01-24 23:08:56.907293\n",
      "EPOCH 22\n",
      "TAG_LOSS_WEIGHT:  0.520732568891217\n",
      "CLS_LOSS_WEIGHT:  0.47926743110878306\n",
      "tp:  1662\n",
      "fn:  104\n",
      "tn:  2126\n",
      "fp:  86\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3788\n",
      "tp:  1629\n",
      "fn:  121\n",
      "tn:  1996\n",
      "fp:  238\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3625\n",
      "EPOCH 22\n",
      "   TRAIN | Label 1 loss: 59.6541 ; P: 0.661 ; R: 0.5516 ; F1: 0.6014 ; Acc: 0.9786\n",
      "           Label 2 loss: 128.5136 ; P: 0.9508 ; R: 0.9411 ; F1: 0.9459 ; Acc: 0.9522\n",
      "    TEST | Label 1 loss: 65.6133 ; P: 0.5904 ; R: 0.7517 ; F1: 0.6614 ; Acc: 0.9776\n",
      "           Label 2 loss: 321.7865 ; P: 0.8725 ; R: 0.9309 ; F1: 0.9007 ; Acc: 0.9099\n",
      "2023-01-24 23:13:05.589875\n",
      "counter:  2\n",
      "2023-01-24 23:13:05.590877\n",
      "EPOCH 23\n",
      "TAG_LOSS_WEIGHT:  0.5211394727805316\n",
      "CLS_LOSS_WEIGHT:  0.4788605272194683\n",
      "tp:  1683\n",
      "fn:  83\n",
      "tn:  2137\n",
      "fp:  75\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3820\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2015\n",
      "fp:  219\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3641\n",
      "EPOCH 23\n",
      "   TRAIN | Label 1 loss: 58.1397 ; P: 0.6613 ; R: 0.5542 ; F1: 0.603 ; Acc: 0.9786\n",
      "           Label 2 loss: 111.9903 ; P: 0.9573 ; R: 0.953 ; F1: 0.9552 ; Acc: 0.9603\n",
      "    TEST | Label 1 loss: 66.8354 ; P: 0.5712 ; R: 0.7908 ; F1: 0.6633 ; Acc: 0.9766\n",
      "           Label 2 loss: 327.2232 ; P: 0.8813 ; R: 0.9291 ; F1: 0.9046 ; Acc: 0.9139\n",
      "2023-01-24 23:17:13.837600\n",
      "counter:  3\n",
      "2023-01-24 23:17:13.837600\n",
      "EPOCH 24\n",
      "TAG_LOSS_WEIGHT:  0.5223759364609192\n",
      "CLS_LOSS_WEIGHT:  0.4776240635390808\n",
      "tp:  1684\n",
      "fn:  82\n",
      "tn:  2125\n",
      "fp:  87\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3809\n",
      "tp:  1613\n",
      "fn:  137\n",
      "tn:  2057\n",
      "fp:  177\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3670\n",
      "EPOCH 24\n",
      "   TRAIN | Label 1 loss: 57.3768 ; P: 0.6708 ; R: 0.5759 ; F1: 0.6198 ; Acc: 0.9793\n",
      "           Label 2 loss: 110.9069 ; P: 0.9509 ; R: 0.9536 ; F1: 0.9522 ; Acc: 0.9575\n",
      "    TEST | Label 1 loss: 63.7566 ; P: 0.5994 ; R: 0.7636 ; F1: 0.6716 ; Acc: 0.9783\n",
      "           Label 2 loss: 313.4919 ; P: 0.9011 ; R: 0.9217 ; F1: 0.9113 ; Acc: 0.9212\n",
      "2023-01-24 23:21:23.063743\n",
      "counter:  0\n",
      "2023-01-24 23:21:24.939668\n",
      "EPOCH 25\n",
      "TAG_LOSS_WEIGHT:  0.5218802747869544\n",
      "CLS_LOSS_WEIGHT:  0.4781197252130456\n",
      "tp:  1701\n",
      "fn:  65\n",
      "tn:  2153\n",
      "fp:  59\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3854\n",
      "tp:  1620\n",
      "fn:  130\n",
      "tn:  2036\n",
      "fp:  198\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3656\n",
      "EPOCH 25\n",
      "   TRAIN | Label 1 loss: 56.687 ; P: 0.67 ; R: 0.5732 ; F1: 0.6178 ; Acc: 0.9792\n",
      "           Label 2 loss: 90.0357 ; P: 0.9665 ; R: 0.9632 ; F1: 0.9648 ; Acc: 0.9688\n",
      "    TEST | Label 1 loss: 63.318 ; P: 0.6026 ; R: 0.765 ; F1: 0.6742 ; Acc: 0.9785\n",
      "           Label 2 loss: 337.3225 ; P: 0.8911 ; R: 0.9257 ; F1: 0.9081 ; Acc: 0.9177\n",
      "2023-01-24 23:25:34.875187\n",
      "counter:  1\n",
      "2023-01-24 23:25:34.876122\n",
      "EPOCH 26\n",
      "TAG_LOSS_WEIGHT:  0.5242366695449406\n",
      "CLS_LOSS_WEIGHT:  0.47576333045505936\n",
      "tp:  1701\n",
      "fn:  65\n",
      "tn:  2155\n",
      "fp:  57\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3856\n",
      "tp:  1619\n",
      "fn:  131\n",
      "tn:  2044\n",
      "fp:  190\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3663\n",
      "EPOCH 26\n",
      "   TRAIN | Label 1 loss: 55.1689 ; P: 0.6739 ; R: 0.5895 ; F1: 0.6289 ; Acc: 0.9796\n",
      "           Label 2 loss: 88.6665 ; P: 0.9676 ; R: 0.9632 ; F1: 0.9654 ; Acc: 0.9693\n",
      "    TEST | Label 1 loss: 63.9943 ; P: 0.5907 ; R: 0.798 ; F1: 0.6789 ; Acc: 0.978\n",
      "           Label 2 loss: 354.2254 ; P: 0.895 ; R: 0.9251 ; F1: 0.9098 ; Acc: 0.9194\n",
      "2023-01-24 23:29:42.060173\n",
      "counter:  2\n",
      "2023-01-24 23:29:42.060173\n",
      "EPOCH 27\n",
      "TAG_LOSS_WEIGHT:  0.523133200669342\n",
      "CLS_LOSS_WEIGHT:  0.47686679933065795\n",
      "tp:  1705\n",
      "fn:  61\n",
      "tn:  2159\n",
      "fp:  53\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3864\n",
      "tp:  1624\n",
      "fn:  126\n",
      "tn:  2032\n",
      "fp:  202\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3656\n",
      "EPOCH 27\n",
      "   TRAIN | Label 1 loss: 54.5289 ; P: 0.6748 ; R: 0.6057 ; F1: 0.6384 ; Acc: 0.9799\n",
      "           Label 2 loss: 80.5584 ; P: 0.9699 ; R: 0.9655 ; F1: 0.9677 ; Acc: 0.9713\n",
      "    TEST | Label 1 loss: 63.0962 ; P: 0.5983 ; R: 0.7939 ; F1: 0.6823 ; Acc: 0.9785\n",
      "           Label 2 loss: 367.7065 ; P: 0.8894 ; R: 0.928 ; F1: 0.9083 ; Acc: 0.9177\n",
      "2023-01-24 23:33:49.508240\n",
      "counter:  3\n",
      "2023-01-24 23:33:49.508240\n",
      "EPOCH 28\n",
      "TAG_LOSS_WEIGHT:  0.5236470911663813\n",
      "CLS_LOSS_WEIGHT:  0.47635290883361864\n",
      "tp:  1715\n",
      "fn:  51\n",
      "tn:  2165\n",
      "fp:  47\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3880\n",
      "tp:  1623\n",
      "fn:  127\n",
      "tn:  2037\n",
      "fp:  197\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3660\n",
      "EPOCH 28\n",
      "   TRAIN | Label 1 loss: 53.7895 ; P: 0.6784 ; R: 0.6081 ; F1: 0.6413 ; Acc: 0.9801\n",
      "           Label 2 loss: 71.9448 ; P: 0.9733 ; R: 0.9711 ; F1: 0.9722 ; Acc: 0.9754\n",
      "    TEST | Label 1 loss: 64.7952 ; P: 0.5855 ; R: 0.8156 ; F1: 0.6816 ; Acc: 0.9778\n",
      "           Label 2 loss: 352.0591 ; P: 0.8918 ; R: 0.9274 ; F1: 0.9092 ; Acc: 0.9187\n",
      "2023-01-24 23:37:57.474066\n",
      "counter:  4\n",
      "2023-01-24 23:37:57.475018\n",
      "EPOCH 29\n",
      "TAG_LOSS_WEIGHT:  0.524090358529945\n",
      "CLS_LOSS_WEIGHT:  0.47590964147005504\n",
      "tp:  1724\n",
      "fn:  42\n",
      "tn:  2180\n",
      "fp:  32\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3904\n",
      "tp:  1621\n",
      "fn:  129\n",
      "tn:  2046\n",
      "fp:  188\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "EPOCH 29\n",
      "   TRAIN | Label 1 loss: 52.967 ; P: 0.6849 ; R: 0.6238 ; F1: 0.6529 ; Acc: 0.9806\n",
      "           Label 2 loss: 60.1128 ; P: 0.9818 ; R: 0.9762 ; F1: 0.979 ; Acc: 0.9814\n",
      "    TEST | Label 1 loss: 63.2096 ; P: 0.6019 ; R: 0.8002 ; F1: 0.687 ; Acc: 0.9788\n",
      "           Label 2 loss: 370.1949 ; P: 0.8961 ; R: 0.9263 ; F1: 0.9109 ; Acc: 0.9204\n",
      "2023-01-24 23:42:06.112543\n",
      "counter:  5\n",
      "2023-01-24 23:42:06.112543\n",
      "EPOCH 30\n",
      "TAG_LOSS_WEIGHT:  0.5247637933306045\n",
      "CLS_LOSS_WEIGHT:  0.4752362066693956\n",
      "tp:  1722\n",
      "fn:  44\n",
      "tn:  2171\n",
      "fp:  41\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3893\n",
      "tp:  1630\n",
      "fn:  120\n",
      "tn:  2030\n",
      "fp:  204\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3660\n",
      "EPOCH 30\n",
      "   TRAIN | Label 1 loss: 52.3232 ; P: 0.6881 ; R: 0.6258 ; F1: 0.6555 ; Acc: 0.9807\n",
      "           Label 2 loss: 59.85 ; P: 0.9767 ; R: 0.9751 ; F1: 0.9759 ; Acc: 0.9786\n",
      "    TEST | Label 1 loss: 63.7058 ; P: 0.5948 ; R: 0.8094 ; F1: 0.6857 ; Acc: 0.9784\n",
      "           Label 2 loss: 386.6229 ; P: 0.8888 ; R: 0.9314 ; F1: 0.9096 ; Acc: 0.9187\n",
      "2023-01-24 23:46:13.179554\n",
      "counter:  6\n",
      "2023-01-24 23:46:13.179554\n",
      "EPOCH 31\n",
      "TAG_LOSS_WEIGHT:  0.5242634999593132\n",
      "CLS_LOSS_WEIGHT:  0.47573650004068674\n",
      "tp:  1734\n",
      "fn:  32\n",
      "tn:  2180\n",
      "fp:  32\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3914\n",
      "tp:  1636\n",
      "fn:  114\n",
      "tn:  2011\n",
      "fp:  223\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3647\n",
      "EPOCH 31\n",
      "   TRAIN | Label 1 loss: 51.258 ; P: 0.695 ; R: 0.64 ; F1: 0.6664 ; Acc: 0.9812\n",
      "           Label 2 loss: 50.3441 ; P: 0.9819 ; R: 0.9819 ; F1: 0.9819 ; Acc: 0.9839\n",
      "    TEST | Label 1 loss: 63.8844 ; P: 0.5894 ; R: 0.8221 ; F1: 0.6866 ; Acc: 0.9782\n",
      "           Label 2 loss: 410.3258 ; P: 0.88 ; R: 0.9349 ; F1: 0.9066 ; Acc: 0.9154\n",
      "2023-01-24 23:50:20.764707\n",
      "counter:  7\n",
      "2023-01-24 23:50:20.764707\n",
      "EPOCH 32\n",
      "TAG_LOSS_WEIGHT:  0.524389083142667\n",
      "CLS_LOSS_WEIGHT:  0.47561091685733303\n",
      "tp:  1743\n",
      "fn:  23\n",
      "tn:  2191\n",
      "fp:  21\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3934\n",
      "tp:  1636\n",
      "fn:  114\n",
      "tn:  2031\n",
      "fp:  203\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3667\n",
      "EPOCH 32\n",
      "   TRAIN | Label 1 loss: 50.1962 ; P: 0.6955 ; R: 0.6491 ; F1: 0.6715 ; Acc: 0.9814\n",
      "           Label 2 loss: 38.3843 ; P: 0.9881 ; R: 0.987 ; F1: 0.9875 ; Acc: 0.9889\n",
      "    TEST | Label 1 loss: 61.7397 ; P: 0.6125 ; R: 0.7956 ; F1: 0.6922 ; Acc: 0.9794\n",
      "           Label 2 loss: 417.4634 ; P: 0.8896 ; R: 0.9349 ; F1: 0.9117 ; Acc: 0.9204\n",
      "2023-01-24 23:54:29.023876\n",
      "counter:  0\n",
      "2023-01-24 23:54:29.023876\n",
      "EPOCH 33\n",
      "TAG_LOSS_WEIGHT:  0.5246540097456693\n",
      "CLS_LOSS_WEIGHT:  0.47534599025433066\n",
      "tp:  1744\n",
      "fn:  22\n",
      "tn:  2189\n",
      "fp:  23\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3933\n",
      "tp:  1631\n",
      "fn:  119\n",
      "tn:  2040\n",
      "fp:  194\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3671\n",
      "EPOCH 33\n",
      "   TRAIN | Label 1 loss: 49.7633 ; P: 0.6981 ; R: 0.6602 ; F1: 0.6786 ; Acc: 0.9817\n",
      "           Label 2 loss: 41.1679 ; P: 0.987 ; R: 0.9875 ; F1: 0.9873 ; Acc: 0.9887\n",
      "    TEST | Label 1 loss: 60.6467 ; P: 0.6304 ; R: 0.7768 ; F1: 0.696 ; Acc: 0.9802\n",
      "           Label 2 loss: 424.9603 ; P: 0.8937 ; R: 0.932 ; F1: 0.9124 ; Acc: 0.9214\n",
      "2023-01-24 23:58:38.022083\n",
      "counter:  0\n",
      "2023-01-24 23:58:39.937613\n",
      "EPOCH 34\n",
      "TAG_LOSS_WEIGHT:  0.5240601409979321\n",
      "CLS_LOSS_WEIGHT:  0.475939859002068\n",
      "tp:  1746\n",
      "fn:  20\n",
      "tn:  2195\n",
      "fp:  17\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3941\n",
      "tp:  1631\n",
      "fn:  119\n",
      "tn:  2045\n",
      "fp:  189\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3676\n",
      "EPOCH 34\n",
      "   TRAIN | Label 1 loss: 49.0365 ; P: 0.6951 ; R: 0.6521 ; F1: 0.6729 ; Acc: 0.9814\n",
      "           Label 2 loss: 36.1542 ; P: 0.9904 ; R: 0.9887 ; F1: 0.9895 ; Acc: 0.9907\n",
      "    TEST | Label 1 loss: 61.6609 ; P: 0.6149 ; R: 0.7978 ; F1: 0.6945 ; Acc: 0.9796\n",
      "           Label 2 loss: 425.7189 ; P: 0.8962 ; R: 0.932 ; F1: 0.9137 ; Acc: 0.9227\n",
      "2023-01-25 00:02:50.167116\n",
      "counter:  0\n",
      "2023-01-25 00:02:52.032124\n",
      "EPOCH 35\n",
      "TAG_LOSS_WEIGHT:  0.5239207287131994\n",
      "CLS_LOSS_WEIGHT:  0.4760792712868007\n",
      "tp:  1751\n",
      "fn:  15\n",
      "tn:  2194\n",
      "fp:  18\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3945\n",
      "tp:  1630\n",
      "fn:  120\n",
      "tn:  2040\n",
      "fp:  194\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3670\n",
      "EPOCH 35\n",
      "   TRAIN | Label 1 loss: 48.4724 ; P: 0.7055 ; R: 0.675 ; F1: 0.6899 ; Acc: 0.9822\n",
      "           Label 2 loss: 31.1495 ; P: 0.9898 ; R: 0.9915 ; F1: 0.9907 ; Acc: 0.9917\n",
      "    TEST | Label 1 loss: 62.5868 ; P: 0.6027 ; R: 0.8294 ; F1: 0.6981 ; Acc: 0.9791\n",
      "           Label 2 loss: 446.1429 ; P: 0.8936 ; R: 0.9314 ; F1: 0.9121 ; Acc: 0.9212\n",
      "2023-01-25 00:07:03.366010\n",
      "counter:  1\n",
      "2023-01-25 00:07:03.366010\n",
      "EPOCH 36\n",
      "TAG_LOSS_WEIGHT:  0.523883573295909\n",
      "CLS_LOSS_WEIGHT:  0.47611642670409093\n",
      "tp:  1749\n",
      "fn:  17\n",
      "tn:  2194\n",
      "fp:  18\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3943\n",
      "tp:  1636\n",
      "fn:  114\n",
      "tn:  2041\n",
      "fp:  193\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3677\n",
      "EPOCH 36\n",
      "   TRAIN | Label 1 loss: 47.6716 ; P: 0.7112 ; R: 0.6756 ; F1: 0.6929 ; Acc: 0.9825\n",
      "           Label 2 loss: 31.1222 ; P: 0.9898 ; R: 0.9904 ; F1: 0.9901 ; Acc: 0.9912\n",
      "    TEST | Label 1 loss: 62.2616 ; P: 0.5973 ; R: 0.8409 ; F1: 0.6985 ; Acc: 0.9789\n",
      "           Label 2 loss: 446.7868 ; P: 0.8945 ; R: 0.9349 ; F1: 0.9142 ; Acc: 0.9229\n",
      "2023-01-25 00:11:12.108984\n",
      "counter:  0\n",
      "2023-01-25 00:11:13.941629\n",
      "EPOCH 37\n",
      "TAG_LOSS_WEIGHT:  0.5232568726317309\n",
      "CLS_LOSS_WEIGHT:  0.476743127368269\n",
      "tp:  1748\n",
      "fn:  18\n",
      "tn:  2194\n",
      "fp:  18\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3942\n",
      "tp:  1642\n",
      "fn:  108\n",
      "tn:  2023\n",
      "fp:  211\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3665\n",
      "EPOCH 37\n",
      "   TRAIN | Label 1 loss: 47.3232 ; P: 0.7088 ; R: 0.6782 ; F1: 0.6932 ; Acc: 0.9824\n",
      "           Label 2 loss: 29.3779 ; P: 0.9898 ; R: 0.9898 ; F1: 0.9898 ; Acc: 0.991\n",
      "    TEST | Label 1 loss: 61.0527 ; P: 0.6077 ; R: 0.8296 ; F1: 0.7015 ; Acc: 0.9795\n",
      "           Label 2 loss: 479.25 ; P: 0.8861 ; R: 0.9383 ; F1: 0.9115 ; Acc: 0.9199\n",
      "2023-01-25 00:15:25.399170\n",
      "counter:  1\n",
      "2023-01-25 00:15:25.401172\n",
      "EPOCH 38\n",
      "TAG_LOSS_WEIGHT:  0.523120075337511\n",
      "CLS_LOSS_WEIGHT:  0.4768799246624888\n",
      "tp:  1749\n",
      "fn:  17\n",
      "tn:  2193\n",
      "fp:  19\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3942\n",
      "tp:  1624\n",
      "fn:  126\n",
      "tn:  2054\n",
      "fp:  180\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3678\n",
      "EPOCH 38\n",
      "   TRAIN | Label 1 loss: 46.484 ; P: 0.7113 ; R: 0.6921 ; F1: 0.7016 ; Acc: 0.9828\n",
      "           Label 2 loss: 28.6951 ; P: 0.9893 ; R: 0.9904 ; F1: 0.9898 ; Acc: 0.991\n",
      "    TEST | Label 1 loss: 61.3366 ; P: 0.6138 ; R: 0.8257 ; F1: 0.7041 ; Acc: 0.9798\n",
      "           Label 2 loss: 458.8715 ; P: 0.9002 ; R: 0.928 ; F1: 0.9139 ; Acc: 0.9232\n",
      "2023-01-25 00:19:34.191016\n",
      "counter:  2\n",
      "2023-01-25 00:19:35.897264\n",
      "EPOCH 39\n",
      "TAG_LOSS_WEIGHT:  0.5225208867066199\n",
      "CLS_LOSS_WEIGHT:  0.47747911329338005\n",
      "tp:  1754\n",
      "fn:  12\n",
      "tn:  2199\n",
      "fp:  13\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3953\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2061\n",
      "fp:  173\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3686\n",
      "EPOCH 39\n",
      "   TRAIN | Label 1 loss: 46.1336 ; P: 0.7129 ; R: 0.689 ; F1: 0.7007 ; Acc: 0.9828\n",
      "           Label 2 loss: 19.7191 ; P: 0.9926 ; R: 0.9932 ; F1: 0.9929 ; Acc: 0.9937\n",
      "    TEST | Label 1 loss: 60.2195 ; P: 0.6267 ; R: 0.8171 ; F1: 0.7094 ; Acc: 0.9805\n",
      "           Label 2 loss: 469.4448 ; P: 0.9038 ; R: 0.9286 ; F1: 0.916 ; Acc: 0.9252\n",
      "2023-01-25 00:23:47.062010\n",
      "counter:  0\n",
      "2023-01-25 00:23:48.977597\n",
      "EPOCH 40\n",
      "TAG_LOSS_WEIGHT:  0.5228721951774509\n",
      "CLS_LOSS_WEIGHT:  0.47712780482254913\n",
      "tp:  1756\n",
      "fn:  10\n",
      "tn:  2196\n",
      "fp:  16\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3952\n",
      "tp:  1620\n",
      "fn:  130\n",
      "tn:  2071\n",
      "fp:  163\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3691\n",
      "EPOCH 40\n",
      "   TRAIN | Label 1 loss: 45.7643 ; P: 0.7176 ; R: 0.6937 ; F1: 0.7054 ; Acc: 0.983\n",
      "           Label 2 loss: 21.9219 ; P: 0.991 ; R: 0.9943 ; F1: 0.9927 ; Acc: 0.9935\n",
      "    TEST | Label 1 loss: 60.949 ; P: 0.6203 ; R: 0.8267 ; F1: 0.7088 ; Acc: 0.9802\n",
      "           Label 2 loss: 469.6559 ; P: 0.9086 ; R: 0.9257 ; F1: 0.9171 ; Acc: 0.9265\n",
      "2023-01-25 00:27:59.204163\n",
      "counter:  0\n",
      "2023-01-25 00:28:00.962564\n",
      "EPOCH 41\n",
      "TAG_LOSS_WEIGHT:  0.5224469995990259\n",
      "CLS_LOSS_WEIGHT:  0.4775530004009741\n",
      "tp:  1755\n",
      "fn:  11\n",
      "tn:  2203\n",
      "fp:  9\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3958\n",
      "tp:  1622\n",
      "fn:  128\n",
      "tn:  2071\n",
      "fp:  163\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3693\n",
      "EPOCH 41\n",
      "   TRAIN | Label 1 loss: 44.6667 ; P: 0.7166 ; R: 0.7016 ; F1: 0.709 ; Acc: 0.9831\n",
      "           Label 2 loss: 21.6294 ; P: 0.9949 ; R: 0.9938 ; F1: 0.9943 ; Acc: 0.995\n",
      "    TEST | Label 1 loss: 60.6902 ; P: 0.6213 ; R: 0.8301 ; F1: 0.7107 ; Acc: 0.9803\n",
      "           Label 2 loss: 471.8351 ; P: 0.9087 ; R: 0.9269 ; F1: 0.9177 ; Acc: 0.927\n",
      "2023-01-25 00:32:11.735047\n",
      "counter:  0\n",
      "2023-01-25 00:32:13.599925\n",
      "EPOCH 42\n",
      "TAG_LOSS_WEIGHT:  0.5216300886599275\n",
      "CLS_LOSS_WEIGHT:  0.4783699113400725\n",
      "tp:  1760\n",
      "fn:  6\n",
      "tn:  2203\n",
      "fp:  9\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3963\n",
      "tp:  1628\n",
      "fn:  122\n",
      "tn:  2064\n",
      "fp:  170\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3692\n",
      "EPOCH 42\n",
      "   TRAIN | Label 1 loss: 44.7877 ; P: 0.7201 ; R: 0.7068 ; F1: 0.7134 ; Acc: 0.9834\n",
      "           Label 2 loss: 17.0211 ; P: 0.9949 ; R: 0.9966 ; F1: 0.9958 ; Acc: 0.9962\n",
      "    TEST | Label 1 loss: 61.2385 ; P: 0.6136 ; R: 0.8373 ; F1: 0.7082 ; Acc: 0.9799\n",
      "           Label 2 loss: 488.2489 ; P: 0.9055 ; R: 0.9303 ; F1: 0.9177 ; Acc: 0.9267\n",
      "2023-01-25 00:36:22.733374\n",
      "counter:  1\n",
      "2023-01-25 00:36:22.734370\n",
      "EPOCH 43\n",
      "TAG_LOSS_WEIGHT:  0.5220071160580942\n",
      "CLS_LOSS_WEIGHT:  0.4779928839419058\n",
      "tp:  1760\n",
      "fn:  6\n",
      "tn:  2204\n",
      "fp:  8\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3964\n",
      "tp:  1623\n",
      "fn:  127\n",
      "tn:  2066\n",
      "fp:  168\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3689\n",
      "EPOCH 43\n",
      "   TRAIN | Label 1 loss: 44.18 ; P: 0.7228 ; R: 0.7161 ; F1: 0.7194 ; Acc: 0.9836\n",
      "           Label 2 loss: 15.5666 ; P: 0.9955 ; R: 0.9966 ; F1: 0.996 ; Acc: 0.9965\n",
      "    TEST | Label 1 loss: 60.1875 ; P: 0.6318 ; R: 0.8209 ; F1: 0.714 ; Acc: 0.9809\n",
      "           Label 2 loss: 494.8375 ; P: 0.9062 ; R: 0.9274 ; F1: 0.9167 ; Acc: 0.926\n",
      "2023-01-25 00:40:29.051917\n",
      "counter:  2\n",
      "2023-01-25 00:40:29.051917\n",
      "EPOCH 44\n",
      "TAG_LOSS_WEIGHT:  0.5216306536177168\n",
      "CLS_LOSS_WEIGHT:  0.47836934638228334\n",
      "tp:  1757\n",
      "fn:  9\n",
      "tn:  2206\n",
      "fp:  6\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3963\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2069\n",
      "fp:  165\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3695\n",
      "EPOCH 44\n",
      "   TRAIN | Label 1 loss: 44.0312 ; P: 0.7261 ; R: 0.7204 ; F1: 0.7232 ; Acc: 0.9839\n",
      "           Label 2 loss: 17.7291 ; P: 0.9966 ; R: 0.9949 ; F1: 0.9957 ; Acc: 0.9962\n",
      "    TEST | Label 1 loss: 59.3881 ; P: 0.6364 ; R: 0.8151 ; F1: 0.7148 ; Acc: 0.9811\n",
      "           Label 2 loss: 498.0846 ; P: 0.9079 ; R: 0.9291 ; F1: 0.9184 ; Acc: 0.9275\n",
      "2023-01-25 00:44:36.355648\n",
      "counter:  0\n",
      "2023-01-25 00:44:38.249803\n",
      "EPOCH 45\n",
      "TAG_LOSS_WEIGHT:  0.5213943484396864\n",
      "CLS_LOSS_WEIGHT:  0.47860565156031365\n",
      "tp:  1756\n",
      "fn:  10\n",
      "tn:  2205\n",
      "fp:  7\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3961\n",
      "tp:  1623\n",
      "fn:  127\n",
      "tn:  2070\n",
      "fp:  164\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3693\n",
      "EPOCH 45\n",
      "   TRAIN | Label 1 loss: 43.6886 ; P: 0.7283 ; R: 0.7191 ; F1: 0.7237 ; Acc: 0.9839\n",
      "           Label 2 loss: 15.3507 ; P: 0.996 ; R: 0.9943 ; F1: 0.9952 ; Acc: 0.9957\n",
      "    TEST | Label 1 loss: 60.7509 ; P: 0.621 ; R: 0.8383 ; F1: 0.7134 ; Acc: 0.9804\n",
      "           Label 2 loss: 506.2554 ; P: 0.9082 ; R: 0.9274 ; F1: 0.9177 ; Acc: 0.927\n",
      "2023-01-25 00:48:48.058704\n",
      "counter:  1\n",
      "2023-01-25 00:48:48.059709\n",
      "EPOCH 46\n",
      "TAG_LOSS_WEIGHT:  0.5212735736944375\n",
      "CLS_LOSS_WEIGHT:  0.47872642630556256\n",
      "tp:  1762\n",
      "fn:  4\n",
      "tn:  2202\n",
      "fp:  10\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3964\n",
      "tp:  1616\n",
      "fn:  134\n",
      "tn:  2096\n",
      "fp:  138\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3712\n",
      "EPOCH 46\n",
      "   TRAIN | Label 1 loss: 43.3514 ; P: 0.7239 ; R: 0.7226 ; F1: 0.7232 ; Acc: 0.9838\n",
      "           Label 2 loss: 13.0255 ; P: 0.9944 ; R: 0.9977 ; F1: 0.996 ; Acc: 0.9965\n",
      "    TEST | Label 1 loss: 61.1246 ; P: 0.6229 ; R: 0.8376 ; F1: 0.7144 ; Acc: 0.9805\n",
      "           Label 2 loss: 501.4989 ; P: 0.9213 ; R: 0.9234 ; F1: 0.9224 ; Acc: 0.9317\n",
      "2023-01-25 00:52:56.188592\n",
      "counter:  0\n",
      "2023-01-25 00:52:58.128720\n",
      "EPOCH 47\n",
      "TAG_LOSS_WEIGHT:  0.521144936711508\n",
      "CLS_LOSS_WEIGHT:  0.47885506328849187\n",
      "tp:  1759\n",
      "fn:  7\n",
      "tn:  2207\n",
      "fp:  5\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3966\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2059\n",
      "fp:  175\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3686\n",
      "EPOCH 47\n",
      "   TRAIN | Label 1 loss: 42.9038 ; P: 0.7314 ; R: 0.7321 ; F1: 0.7318 ; Acc: 0.9843\n",
      "           Label 2 loss: 14.6387 ; P: 0.9972 ; R: 0.996 ; F1: 0.9966 ; Acc: 0.997\n",
      "    TEST | Label 1 loss: 62.1247 ; P: 0.6113 ; R: 0.8486 ; F1: 0.7107 ; Acc: 0.9799\n",
      "           Label 2 loss: 511.6965 ; P: 0.9029 ; R: 0.9297 ; F1: 0.9161 ; Acc: 0.9252\n",
      "2023-01-25 00:57:08.075060\n",
      "counter:  1\n",
      "2023-01-25 00:57:08.076072\n",
      "EPOCH 48\n",
      "TAG_LOSS_WEIGHT:  0.5207272983209627\n",
      "CLS_LOSS_WEIGHT:  0.4792727016790374\n",
      "tp:  1760\n",
      "fn:  6\n",
      "tn:  2204\n",
      "fp:  8\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3964\n",
      "tp:  1620\n",
      "fn:  130\n",
      "tn:  2069\n",
      "fp:  165\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3689\n",
      "EPOCH 48\n",
      "   TRAIN | Label 1 loss: 42.6352 ; P: 0.731 ; R: 0.7322 ; F1: 0.7316 ; Acc: 0.9843\n",
      "           Label 2 loss: 15.5549 ; P: 0.9955 ; R: 0.9966 ; F1: 0.996 ; Acc: 0.9965\n",
      "    TEST | Label 1 loss: 60.5532 ; P: 0.6276 ; R: 0.8376 ; F1: 0.7175 ; Acc: 0.9808\n",
      "           Label 2 loss: 512.5435 ; P: 0.9076 ; R: 0.9257 ; F1: 0.9165 ; Acc: 0.926\n",
      "2023-01-25 01:01:15.169223\n",
      "counter:  2\n",
      "2023-01-25 01:01:15.169223\n",
      "EPOCH 49\n",
      "TAG_LOSS_WEIGHT:  0.5204780614263614\n",
      "CLS_LOSS_WEIGHT:  0.4795219385736385\n",
      "tp:  1760\n",
      "fn:  6\n",
      "tn:  2206\n",
      "fp:  6\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3966\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2063\n",
      "fp:  171\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3688\n",
      "EPOCH 49\n",
      "   TRAIN | Label 1 loss: 42.5121 ; P: 0.728 ; R: 0.7329 ; F1: 0.7305 ; Acc: 0.9842\n",
      "           Label 2 loss: 11.31 ; P: 0.9966 ; R: 0.9966 ; F1: 0.9966 ; Acc: 0.997\n",
      "    TEST | Label 1 loss: 60.4044 ; P: 0.6287 ; R: 0.8366 ; F1: 0.7179 ; Acc: 0.9809\n",
      "           Label 2 loss: 524.8195 ; P: 0.9048 ; R: 0.9286 ; F1: 0.9165 ; Acc: 0.9257\n",
      "2023-01-25 01:05:23.374269\n",
      "counter:  3\n",
      "2023-01-25 01:05:23.374269\n",
      "EPOCH 50\n",
      "TAG_LOSS_WEIGHT:  0.5206061251044188\n",
      "CLS_LOSS_WEIGHT:  0.4793938748955811\n",
      "tp:  1760\n",
      "fn:  6\n",
      "tn:  2208\n",
      "fp:  4\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3968\n",
      "tp:  1621\n",
      "fn:  129\n",
      "tn:  2075\n",
      "fp:  159\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3696\n",
      "EPOCH 50\n",
      "   TRAIN | Label 1 loss: 42.246 ; P: 0.7351 ; R: 0.7338 ; F1: 0.7345 ; Acc: 0.9845\n",
      "           Label 2 loss: 12.8877 ; P: 0.9977 ; R: 0.9966 ; F1: 0.9972 ; Acc: 0.9975\n",
      "    TEST | Label 1 loss: 60.0054 ; P: 0.632 ; R: 0.8327 ; F1: 0.7186 ; Acc: 0.981\n",
      "           Label 2 loss: 521.4617 ; P: 0.9107 ; R: 0.9263 ; F1: 0.9184 ; Acc: 0.9277\n",
      "2023-01-25 01:09:31.372401\n",
      "counter:  4\n",
      "2023-01-25 01:09:31.373404\n",
      "EPOCH 51\n",
      "TAG_LOSS_WEIGHT:  0.5203324718086524\n",
      "CLS_LOSS_WEIGHT:  0.47966752819134767\n",
      "tp:  1759\n",
      "fn:  7\n",
      "tn:  2206\n",
      "fp:  6\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3965\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2065\n",
      "fp:  169\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3690\n",
      "EPOCH 51\n",
      "   TRAIN | Label 1 loss: 41.9265 ; P: 0.7379 ; R: 0.744 ; F1: 0.741 ; Acc: 0.9848\n",
      "           Label 2 loss: 13.52 ; P: 0.9966 ; R: 0.996 ; F1: 0.9963 ; Acc: 0.9967\n",
      "    TEST | Label 1 loss: 60.5912 ; P: 0.6279 ; R: 0.8402 ; F1: 0.7187 ; Acc: 0.9809\n",
      "           Label 2 loss: 524.804 ; P: 0.9058 ; R: 0.9286 ; F1: 0.917 ; Acc: 0.9262\n",
      "2023-01-25 01:13:38.471373\n",
      "counter:  5\n",
      "2023-01-25 01:13:38.473373\n",
      "EPOCH 52\n",
      "TAG_LOSS_WEIGHT:  0.5200651872090798\n",
      "CLS_LOSS_WEIGHT:  0.4799348127909203\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2209\n",
      "fp:  3\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3972\n",
      "tp:  1624\n",
      "fn:  126\n",
      "tn:  2062\n",
      "fp:  172\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3686\n",
      "EPOCH 52\n",
      "   TRAIN | Label 1 loss: 42.2208 ; P: 0.7318 ; R: 0.7376 ; F1: 0.7347 ; Acc: 0.9844\n",
      "           Label 2 loss: 9.1211 ; P: 0.9983 ; R: 0.9983 ; F1: 0.9983 ; Acc: 0.9985\n",
      "    TEST | Label 1 loss: 60.4581 ; P: 0.6288 ; R: 0.8426 ; F1: 0.7202 ; Acc: 0.9809\n",
      "           Label 2 loss: 536.8318 ; P: 0.9042 ; R: 0.928 ; F1: 0.916 ; Acc: 0.9252\n",
      "2023-01-25 01:17:45.375397\n",
      "counter:  6\n",
      "2023-01-25 01:17:45.376400\n",
      "EPOCH 53\n",
      "TAG_LOSS_WEIGHT:  0.5204898383070705\n",
      "CLS_LOSS_WEIGHT:  0.4795101616929294\n",
      "tp:  1762\n",
      "fn:  4\n",
      "tn:  2208\n",
      "fp:  4\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3970\n",
      "tp:  1621\n",
      "fn:  129\n",
      "tn:  2072\n",
      "fp:  162\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3693\n",
      "EPOCH 53\n",
      "   TRAIN | Label 1 loss: 41.3628 ; P: 0.7357 ; R: 0.7452 ; F1: 0.7404 ; Acc: 0.9847\n",
      "           Label 2 loss: 12.4738 ; P: 0.9977 ; R: 0.9977 ; F1: 0.9977 ; Acc: 0.998\n",
      "    TEST | Label 1 loss: 59.4432 ; P: 0.6419 ; R: 0.8269 ; F1: 0.7228 ; Acc: 0.9815\n",
      "           Label 2 loss: 535.0101 ; P: 0.9091 ; R: 0.9263 ; F1: 0.9176 ; Acc: 0.927\n",
      "2023-01-25 01:21:54.376612\n",
      "counter:  7\n",
      "2023-01-25 01:21:54.378612\n",
      "EPOCH 54\n",
      "TAG_LOSS_WEIGHT:  0.5197060878590651\n",
      "CLS_LOSS_WEIGHT:  0.4802939121409348\n",
      "tp:  1761\n",
      "fn:  5\n",
      "tn:  2209\n",
      "fp:  3\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3970\n",
      "tp:  1621\n",
      "fn:  129\n",
      "tn:  2076\n",
      "fp:  158\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3697\n",
      "EPOCH 54\n",
      "   TRAIN | Label 1 loss: 41.2307 ; P: 0.7389 ; R: 0.7495 ; F1: 0.7442 ; Acc: 0.9849\n",
      "           Label 2 loss: 9.8231 ; P: 0.9983 ; R: 0.9972 ; F1: 0.9977 ; Acc: 0.998\n",
      "    TEST | Label 1 loss: 61.0842 ; P: 0.6276 ; R: 0.8443 ; F1: 0.72 ; Acc: 0.9809\n",
      "           Label 2 loss: 532.3454 ; P: 0.9112 ; R: 0.9263 ; F1: 0.9187 ; Acc: 0.928\n",
      "2023-01-25 01:26:02.311462\n",
      "counter:  8\n",
      "2023-01-25 01:26:02.312461\n",
      "EPOCH 55\n",
      "TAG_LOSS_WEIGHT:  0.5197345825980246\n",
      "CLS_LOSS_WEIGHT:  0.4802654174019753\n",
      "tp:  1760\n",
      "fn:  6\n",
      "tn:  2209\n",
      "fp:  3\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3969\n",
      "tp:  1621\n",
      "fn:  129\n",
      "tn:  2086\n",
      "fp:  148\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3707\n",
      "EPOCH 55\n",
      "   TRAIN | Label 1 loss: 41.0162 ; P: 0.7413 ; R: 0.7505 ; F1: 0.7459 ; Acc: 0.985\n",
      "           Label 2 loss: 8.7577 ; P: 0.9983 ; R: 0.9966 ; F1: 0.9974 ; Acc: 0.9977\n",
      "    TEST | Label 1 loss: 61.2093 ; P: 0.6244 ; R: 0.8457 ; F1: 0.7184 ; Acc: 0.9807\n",
      "           Label 2 loss: 537.5691 ; P: 0.9163 ; R: 0.9263 ; F1: 0.9213 ; Acc: 0.9305\n",
      "2023-01-25 01:30:09.166370\n",
      "counter:  9\n",
      "2023-01-25 01:30:09.168370\n",
      "EPOCH 56\n",
      "TAG_LOSS_WEIGHT:  0.5196244617449193\n",
      "CLS_LOSS_WEIGHT:  0.48037553825508067\n",
      "tp:  1760\n",
      "fn:  6\n",
      "tn:  2207\n",
      "fp:  5\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3967\n",
      "tp:  1621\n",
      "fn:  129\n",
      "tn:  2069\n",
      "fp:  165\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3690\n",
      "EPOCH 56\n",
      "   TRAIN | Label 1 loss: 40.9974 ; P: 0.7392 ; R: 0.7493 ; F1: 0.7442 ; Acc: 0.9849\n",
      "           Label 2 loss: 11.6918 ; P: 0.9972 ; R: 0.9966 ; F1: 0.9969 ; Acc: 0.9972\n",
      "    TEST | Label 1 loss: 60.8605 ; P: 0.6271 ; R: 0.8455 ; F1: 0.7201 ; Acc: 0.9809\n",
      "           Label 2 loss: 546.6746 ; P: 0.9076 ; R: 0.9263 ; F1: 0.9169 ; Acc: 0.9262\n",
      "2023-01-25 01:34:15.340649\n",
      "counter:  10\n",
      "2023-01-25 01:34:15.342645\n",
      "EPOCH 57\n",
      "TAG_LOSS_WEIGHT:  0.5194786523779498\n",
      "CLS_LOSS_WEIGHT:  0.4805213476220501\n",
      "tp:  1760\n",
      "fn:  6\n",
      "tn:  2207\n",
      "fp:  5\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3967\n",
      "tp:  1616\n",
      "fn:  134\n",
      "tn:  2090\n",
      "fp:  144\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3706\n",
      "EPOCH 57\n",
      "   TRAIN | Label 1 loss: 40.5978 ; P: 0.7444 ; R: 0.7516 ; F1: 0.748 ; Acc: 0.9852\n",
      "           Label 2 loss: 15.1571 ; P: 0.9972 ; R: 0.9966 ; F1: 0.9969 ; Acc: 0.9972\n",
      "    TEST | Label 1 loss: 61.075 ; P: 0.6278 ; R: 0.8457 ; F1: 0.7207 ; Acc: 0.9809\n",
      "           Label 2 loss: 534.136 ; P: 0.9182 ; R: 0.9234 ; F1: 0.9208 ; Acc: 0.9302\n",
      "2023-01-25 01:38:21.193535\n",
      "counter:  11\n",
      "2023-01-25 01:38:21.193535\n",
      "EPOCH 58\n",
      "TAG_LOSS_WEIGHT:  0.5190104635861887\n",
      "CLS_LOSS_WEIGHT:  0.4809895364138113\n",
      "tp:  1761\n",
      "fn:  5\n",
      "tn:  2207\n",
      "fp:  5\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3968\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2072\n",
      "fp:  162\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3697\n",
      "EPOCH 58\n",
      "   TRAIN | Label 1 loss: 40.1189 ; P: 0.7453 ; R: 0.7567 ; F1: 0.7509 ; Acc: 0.9853\n",
      "           Label 2 loss: 7.3224 ; P: 0.9972 ; R: 0.9972 ; F1: 0.9972 ; Acc: 0.9975\n",
      "    TEST | Label 1 loss: 60.224 ; P: 0.6354 ; R: 0.84 ; F1: 0.7235 ; Acc: 0.9813\n",
      "           Label 2 loss: 549.7809 ; P: 0.9093 ; R: 0.9286 ; F1: 0.9189 ; Acc: 0.928\n",
      "2023-01-25 01:42:28.802466\n",
      "counter:  12\n",
      "2023-01-25 01:42:28.803452\n",
      "EPOCH 59\n",
      "TAG_LOSS_WEIGHT:  0.5190340595603801\n",
      "CLS_LOSS_WEIGHT:  0.48096594043961993\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2207\n",
      "fp:  5\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3970\n",
      "tp:  1618\n",
      "fn:  132\n",
      "tn:  2091\n",
      "fp:  143\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3709\n",
      "EPOCH 59\n",
      "   TRAIN | Label 1 loss: 40.439 ; P: 0.7434 ; R: 0.755 ; F1: 0.7492 ; Acc: 0.9852\n",
      "           Label 2 loss: 9.2033 ; P: 0.9972 ; R: 0.9983 ; F1: 0.9977 ; Acc: 0.998\n",
      "    TEST | Label 1 loss: 60.799 ; P: 0.6328 ; R: 0.8424 ; F1: 0.7227 ; Acc: 0.9812\n",
      "           Label 2 loss: 545.3908 ; P: 0.9188 ; R: 0.9246 ; F1: 0.9217 ; Acc: 0.931\n",
      "2023-01-25 01:46:35.552995\n",
      "counter:  13\n",
      "2023-01-25 01:46:35.553986\n",
      "EPOCH 60\n",
      "TAG_LOSS_WEIGHT:  0.519188133870919\n",
      "CLS_LOSS_WEIGHT:  0.48081186612908094\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2207\n",
      "fp:  5\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3970\n",
      "tp:  1622\n",
      "fn:  128\n",
      "tn:  2076\n",
      "fp:  158\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3698\n",
      "EPOCH 60\n",
      "   TRAIN | Label 1 loss: 40.3271 ; P: 0.7455 ; R: 0.762 ; F1: 0.7536 ; Acc: 0.9854\n",
      "           Label 2 loss: 8.2334 ; P: 0.9972 ; R: 0.9983 ; F1: 0.9977 ; Acc: 0.998\n",
      "    TEST | Label 1 loss: 60.0284 ; P: 0.6362 ; R: 0.8414 ; F1: 0.7246 ; Acc: 0.9814\n",
      "           Label 2 loss: 555.6337 ; P: 0.9112 ; R: 0.9269 ; F1: 0.919 ; Acc: 0.9282\n",
      "2023-01-25 01:50:42.727429\n",
      "counter:  14\n",
      "2023-01-25 01:50:42.727429\n",
      "EPOCH 61\n",
      "TAG_LOSS_WEIGHT:  0.5191479082656474\n",
      "CLS_LOSS_WEIGHT:  0.48085209173435245\n",
      "tp:  1762\n",
      "fn:  4\n",
      "tn:  2209\n",
      "fp:  3\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3971\n",
      "tp:  1622\n",
      "fn:  128\n",
      "tn:  2077\n",
      "fp:  157\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3699\n",
      "EPOCH 61\n",
      "   TRAIN | Label 1 loss: 39.4848 ; P: 0.746 ; R: 0.7651 ; F1: 0.7554 ; Acc: 0.9855\n",
      "           Label 2 loss: 8.4079 ; P: 0.9983 ; R: 0.9977 ; F1: 0.998 ; Acc: 0.9982\n",
      "    TEST | Label 1 loss: 59.759 ; P: 0.6394 ; R: 0.8402 ; F1: 0.7262 ; Acc: 0.9816\n",
      "           Label 2 loss: 554.2147 ; P: 0.9117 ; R: 0.9269 ; F1: 0.9192 ; Acc: 0.9285\n",
      "2023-01-25 01:54:49.964921\n",
      "counter:  15\n",
      "2023-01-25 01:54:49.965996\n",
      "EPOCH 62\n",
      "TAG_LOSS_WEIGHT:  0.5185376839797313\n",
      "CLS_LOSS_WEIGHT:  0.48146231602026873\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2209\n",
      "fp:  3\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3972\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2066\n",
      "fp:  168\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3691\n",
      "EPOCH 62\n",
      "   TRAIN | Label 1 loss: 39.3006 ; P: 0.7457 ; R: 0.7613 ; F1: 0.7534 ; Acc: 0.9854\n",
      "           Label 2 loss: 6.7554 ; P: 0.9983 ; R: 0.9983 ; F1: 0.9983 ; Acc: 0.9985\n",
      "    TEST | Label 1 loss: 60.1698 ; P: 0.6353 ; R: 0.8457 ; F1: 0.7256 ; Acc: 0.9814\n",
      "           Label 2 loss: 564.2046 ; P: 0.9063 ; R: 0.9286 ; F1: 0.9173 ; Acc: 0.9265\n",
      "2023-01-25 01:58:57.037549\n",
      "counter:  16\n",
      "2023-01-25 01:58:57.038539\n",
      "EPOCH 63\n",
      "TAG_LOSS_WEIGHT:  0.5184707623777124\n",
      "CLS_LOSS_WEIGHT:  0.48152923762228766\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1623\n",
      "fn:  127\n",
      "tn:  2086\n",
      "fp:  148\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3709\n",
      "EPOCH 63\n",
      "   TRAIN | Label 1 loss: 39.4206 ; P: 0.7447 ; R: 0.7679 ; F1: 0.7561 ; Acc: 0.9855\n",
      "           Label 2 loss: 6.4658 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 1 loss: 60.4302 ; P: 0.6351 ; R: 0.8462 ; F1: 0.7256 ; Acc: 0.9814\n",
      "           Label 2 loss: 560.6185 ; P: 0.9164 ; R: 0.9274 ; F1: 0.9219 ; Acc: 0.931\n",
      "2023-01-25 02:03:04.538045\n",
      "counter:  17\n",
      "2023-01-25 02:03:04.538045\n",
      "EPOCH 64\n",
      "TAG_LOSS_WEIGHT:  0.5185666029231691\n",
      "CLS_LOSS_WEIGHT:  0.481433397076831\n",
      "tp:  1761\n",
      "fn:  5\n",
      "tn:  2206\n",
      "fp:  6\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3967\n",
      "tp:  1624\n",
      "fn:  126\n",
      "tn:  2080\n",
      "fp:  154\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3704\n",
      "EPOCH 64\n",
      "   TRAIN | Label 1 loss: 39.4918 ; P: 0.7467 ; R: 0.7657 ; F1: 0.7561 ; Acc: 0.9855\n",
      "           Label 2 loss: 8.5513 ; P: 0.9966 ; R: 0.9972 ; F1: 0.9969 ; Acc: 0.9972\n",
      "    TEST | Label 1 loss: 59.6076 ; P: 0.6406 ; R: 0.8433 ; F1: 0.7281 ; Acc: 0.9817\n",
      "           Label 2 loss: 568.6737 ; P: 0.9134 ; R: 0.928 ; F1: 0.9206 ; Acc: 0.9297\n",
      "2023-01-25 02:07:13.527013\n",
      "counter:  18\n",
      "2023-01-25 02:07:13.528005\n",
      "EPOCH 65\n",
      "TAG_LOSS_WEIGHT:  0.5185367819502197\n",
      "CLS_LOSS_WEIGHT:  0.4814632180497802\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2209\n",
      "fp:  3\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1619\n",
      "fn:  131\n",
      "tn:  2095\n",
      "fp:  139\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3714\n",
      "EPOCH 65\n",
      "   TRAIN | Label 1 loss: 39.0245 ; P: 0.7513 ; R: 0.766 ; F1: 0.7586 ; Acc: 0.9857\n",
      "           Label 2 loss: 5.7674 ; P: 0.9983 ; R: 0.9994 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 1 loss: 59.6409 ; P: 0.645 ; R: 0.8356 ; F1: 0.7281 ; Acc: 0.9818\n",
      "           Label 2 loss: 560.3218 ; P: 0.9209 ; R: 0.9251 ; F1: 0.923 ; Acc: 0.9322\n",
      "2023-01-25 02:11:22.773605\n",
      "counter:  0\n",
      "2023-01-25 02:11:24.685584\n",
      "EPOCH 66\n",
      "TAG_LOSS_WEIGHT:  0.5183097511286097\n",
      "CLS_LOSS_WEIGHT:  0.48169024887139034\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2207\n",
      "fp:  5\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3971\n",
      "tp:  1616\n",
      "fn:  134\n",
      "tn:  2102\n",
      "fp:  132\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3718\n",
      "EPOCH 66\n",
      "   TRAIN | Label 1 loss: 39.0132 ; P: 0.7563 ; R: 0.7721 ; F1: 0.7641 ; Acc: 0.986\n",
      "           Label 2 loss: 7.2026 ; P: 0.9972 ; R: 0.9989 ; F1: 0.998 ; Acc: 0.9982\n",
      "    TEST | Label 1 loss: 60.3338 ; P: 0.638 ; R: 0.8445 ; F1: 0.7269 ; Acc: 0.9815\n",
      "           Label 2 loss: 559.7741 ; P: 0.9245 ; R: 0.9234 ; F1: 0.924 ; Acc: 0.9332\n",
      "2023-01-25 02:15:35.489606\n",
      "counter:  0\n",
      "2023-01-25 02:15:37.405947\n",
      "EPOCH 67\n",
      "TAG_LOSS_WEIGHT:  0.5182502364751588\n",
      "CLS_LOSS_WEIGHT:  0.48174976352484133\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2209\n",
      "fp:  3\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3972\n",
      "tp:  1621\n",
      "fn:  129\n",
      "tn:  2090\n",
      "fp:  144\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3711\n",
      "EPOCH 67\n",
      "   TRAIN | Label 1 loss: 38.7102 ; P: 0.7486 ; R: 0.765 ; F1: 0.7567 ; Acc: 0.9856\n",
      "           Label 2 loss: 6.2706 ; P: 0.9983 ; R: 0.9983 ; F1: 0.9983 ; Acc: 0.9985\n",
      "    TEST | Label 1 loss: 60.0376 ; P: 0.6393 ; R: 0.8433 ; F1: 0.7273 ; Acc: 0.9816\n",
      "           Label 2 loss: 566.7493 ; P: 0.9184 ; R: 0.9263 ; F1: 0.9223 ; Acc: 0.9315\n",
      "2023-01-25 02:19:48.434882\n",
      "counter:  1\n",
      "2023-01-25 02:19:48.434882\n",
      "EPOCH 68\n",
      "TAG_LOSS_WEIGHT:  0.5180702149639962\n",
      "CLS_LOSS_WEIGHT:  0.481929785036004\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2208\n",
      "fp:  4\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3972\n",
      "tp:  1622\n",
      "fn:  128\n",
      "tn:  2087\n",
      "fp:  147\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3709\n",
      "EPOCH 68\n",
      "   TRAIN | Label 1 loss: 38.2268 ; P: 0.7539 ; R: 0.778 ; F1: 0.7657 ; Acc: 0.9861\n",
      "           Label 2 loss: 7.9601 ; P: 0.9977 ; R: 0.9989 ; F1: 0.9983 ; Acc: 0.9985\n",
      "    TEST | Label 1 loss: 60.1819 ; P: 0.6391 ; R: 0.8445 ; F1: 0.7276 ; Acc: 0.9816\n",
      "           Label 2 loss: 567.9663 ; P: 0.9169 ; R: 0.9269 ; F1: 0.9219 ; Acc: 0.931\n",
      "2023-01-25 02:23:56.706531\n",
      "counter:  2\n",
      "2023-01-25 02:23:56.708444\n",
      "EPOCH 69\n",
      "TAG_LOSS_WEIGHT:  0.5176668009492227\n",
      "CLS_LOSS_WEIGHT:  0.4823331990507772\n",
      "tp:  1761\n",
      "fn:  5\n",
      "tn:  2209\n",
      "fp:  3\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3970\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2079\n",
      "fp:  155\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3705\n",
      "EPOCH 69\n",
      "   TRAIN | Label 1 loss: 38.3258 ; P: 0.7584 ; R: 0.7731 ; F1: 0.7657 ; Acc: 0.9861\n",
      "           Label 2 loss: 7.0935 ; P: 0.9983 ; R: 0.9972 ; F1: 0.9977 ; Acc: 0.998\n",
      "    TEST | Label 1 loss: 60.0173 ; P: 0.6411 ; R: 0.8429 ; F1: 0.7282 ; Acc: 0.9817\n",
      "           Label 2 loss: 578.104 ; P: 0.913 ; R: 0.9291 ; F1: 0.921 ; Acc: 0.93\n",
      "2023-01-25 02:28:04.146261\n",
      "counter:  3\n",
      "2023-01-25 02:28:04.148258\n",
      "EPOCH 70\n",
      "TAG_LOSS_WEIGHT:  0.5177697640389709\n",
      "CLS_LOSS_WEIGHT:  0.48223023596102893\n",
      "tp:  1762\n",
      "fn:  4\n",
      "tn:  2207\n",
      "fp:  5\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3969\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2083\n",
      "fp:  151\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3708\n",
      "EPOCH 70\n",
      "   TRAIN | Label 1 loss: 38.103 ; P: 0.755 ; R: 0.7765 ; F1: 0.7656 ; Acc: 0.9861\n",
      "           Label 2 loss: 7.9501 ; P: 0.9972 ; R: 0.9977 ; F1: 0.9975 ; Acc: 0.9977\n",
      "    TEST | Label 1 loss: 60.4787 ; P: 0.6366 ; R: 0.8501 ; F1: 0.728 ; Acc: 0.9815\n",
      "           Label 2 loss: 576.3412 ; P: 0.915 ; R: 0.9286 ; F1: 0.9217 ; Acc: 0.9307\n",
      "2023-01-25 02:32:10.733114\n",
      "counter:  4\n",
      "2023-01-25 02:32:10.733114\n",
      "EPOCH 71\n",
      "TAG_LOSS_WEIGHT:  0.5175804915495948\n",
      "CLS_LOSS_WEIGHT:  0.4824195084504051\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2207\n",
      "fp:  5\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3970\n",
      "tp:  1621\n",
      "fn:  129\n",
      "tn:  2091\n",
      "fp:  143\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3712\n",
      "EPOCH 71\n",
      "   TRAIN | Label 1 loss: 37.7168 ; P: 0.7573 ; R: 0.778 ; F1: 0.7675 ; Acc: 0.9862\n",
      "           Label 2 loss: 6.8353 ; P: 0.9972 ; R: 0.9983 ; F1: 0.9977 ; Acc: 0.998\n",
      "    TEST | Label 1 loss: 60.2018 ; P: 0.6422 ; R: 0.8457 ; F1: 0.7301 ; Acc: 0.9818\n",
      "           Label 2 loss: 571.793 ; P: 0.9189 ; R: 0.9263 ; F1: 0.9226 ; Acc: 0.9317\n",
      "2023-01-25 02:36:20.176510\n",
      "counter:  5\n",
      "2023-01-25 02:36:20.177513\n",
      "EPOCH 72\n",
      "TAG_LOSS_WEIGHT:  0.5173536422509573\n",
      "CLS_LOSS_WEIGHT:  0.4826463577490427\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2208\n",
      "fp:  4\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3972\n",
      "tp:  1622\n",
      "fn:  128\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3707\n",
      "EPOCH 72\n",
      "   TRAIN | Label 1 loss: 38.1344 ; P: 0.7528 ; R: 0.7714 ; F1: 0.762 ; Acc: 0.9859\n",
      "           Label 2 loss: 5.5077 ; P: 0.9977 ; R: 0.9989 ; F1: 0.9983 ; Acc: 0.9985\n",
      "    TEST | Label 1 loss: 60.3545 ; P: 0.6392 ; R: 0.8491 ; F1: 0.7293 ; Acc: 0.9817\n",
      "           Label 2 loss: 573.5923 ; P: 0.9159 ; R: 0.9269 ; F1: 0.9213 ; Acc: 0.9305\n",
      "2023-01-25 02:40:28.510173\n",
      "counter:  6\n",
      "2023-01-25 02:40:28.510173\n",
      "EPOCH 73\n",
      "TAG_LOSS_WEIGHT:  0.517691698105796\n",
      "CLS_LOSS_WEIGHT:  0.4823083018942042\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2209\n",
      "fp:  3\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3973\n",
      "tp:  1620\n",
      "fn:  130\n",
      "tn:  2101\n",
      "fp:  133\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3721\n",
      "EPOCH 73\n",
      "   TRAIN | Label 1 loss: 37.6701 ; P: 0.7564 ; R: 0.7774 ; F1: 0.7668 ; Acc: 0.9862\n",
      "           Label 2 loss: 4.7339 ; P: 0.9983 ; R: 0.9989 ; F1: 0.9986 ; Acc: 0.9987\n",
      "    TEST | Label 1 loss: 60.8866 ; P: 0.6355 ; R: 0.8515 ; F1: 0.7279 ; Acc: 0.9815\n",
      "           Label 2 loss: 575.1018 ; P: 0.9241 ; R: 0.9257 ; F1: 0.9249 ; Acc: 0.934\n",
      "2023-01-25 02:44:34.998992\n",
      "counter:  0\n",
      "2023-01-25 02:44:36.743871\n",
      "EPOCH 74\n",
      "TAG_LOSS_WEIGHT:  0.5173923183308351\n",
      "CLS_LOSS_WEIGHT:  0.4826076816691649\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3973\n",
      "tp:  1620\n",
      "fn:  130\n",
      "tn:  2092\n",
      "fp:  142\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3712\n",
      "EPOCH 74\n",
      "   TRAIN | Label 1 loss: 37.4025 ; P: 0.7583 ; R: 0.7786 ; F1: 0.7683 ; Acc: 0.9863\n",
      "           Label 2 loss: 4.4718 ; P: 0.9989 ; R: 0.9983 ; F1: 0.9986 ; Acc: 0.9987\n",
      "    TEST | Label 1 loss: 60.6914 ; P: 0.6385 ; R: 0.8494 ; F1: 0.729 ; Acc: 0.9816\n",
      "           Label 2 loss: 582.3295 ; P: 0.9194 ; R: 0.9257 ; F1: 0.9226 ; Acc: 0.9317\n",
      "2023-01-25 02:48:46.479708\n",
      "counter:  1\n",
      "2023-01-25 02:48:46.480708\n",
      "EPOCH 75\n",
      "TAG_LOSS_WEIGHT:  0.51721436845949\n",
      "CLS_LOSS_WEIGHT:  0.4827856315405099\n",
      "tp:  1762\n",
      "fn:  4\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3972\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2083\n",
      "fp:  151\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3709\n",
      "EPOCH 75\n",
      "   TRAIN | Label 1 loss: 37.2727 ; P: 0.7581 ; R: 0.7863 ; F1: 0.772 ; Acc: 0.9864\n",
      "           Label 2 loss: 5.2773 ; P: 0.9989 ; R: 0.9977 ; F1: 0.9983 ; Acc: 0.9985\n",
      "    TEST | Label 1 loss: 60.6235 ; P: 0.6376 ; R: 0.8503 ; F1: 0.7288 ; Acc: 0.9816\n",
      "           Label 2 loss: 591.7569 ; P: 0.915 ; R: 0.9291 ; F1: 0.922 ; Acc: 0.931\n",
      "2023-01-25 02:52:54.424450\n",
      "counter:  2\n",
      "2023-01-25 02:52:54.425441\n",
      "EPOCH 76\n",
      "TAG_LOSS_WEIGHT:  0.5170993683340784\n",
      "CLS_LOSS_WEIGHT:  0.4829006316659214\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1622\n",
      "fn:  128\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3707\n",
      "EPOCH 76\n",
      "   TRAIN | Label 1 loss: 37.0645 ; P: 0.7629 ; R: 0.785 ; F1: 0.7738 ; Acc: 0.9866\n",
      "           Label 2 loss: 2.9373 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 60.3832 ; P: 0.6432 ; R: 0.847 ; F1: 0.7312 ; Acc: 0.9819\n",
      "           Label 2 loss: 592.0217 ; P: 0.9159 ; R: 0.9269 ; F1: 0.9213 ; Acc: 0.9305\n",
      "2023-01-25 02:57:00.636991\n",
      "counter:  3\n",
      "2023-01-25 02:57:00.636991\n",
      "EPOCH 77\n",
      "TAG_LOSS_WEIGHT:  0.5170221108775019\n",
      "CLS_LOSS_WEIGHT:  0.48297788912249806\n",
      "tp:  1762\n",
      "fn:  4\n",
      "tn:  2209\n",
      "fp:  3\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3971\n",
      "tp:  1622\n",
      "fn:  128\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3707\n",
      "EPOCH 77\n",
      "   TRAIN | Label 1 loss: 37.3808 ; P: 0.7601 ; R: 0.7816 ; F1: 0.7707 ; Acc: 0.9864\n",
      "           Label 2 loss: 5.7422 ; P: 0.9983 ; R: 0.9977 ; F1: 0.998 ; Acc: 0.9982\n",
      "    TEST | Label 1 loss: 60.6712 ; P: 0.6396 ; R: 0.8491 ; F1: 0.7296 ; Acc: 0.9817\n",
      "           Label 2 loss: 594.6619 ; P: 0.9159 ; R: 0.9269 ; F1: 0.9213 ; Acc: 0.9305\n",
      "2023-01-25 03:01:08.219614\n",
      "counter:  4\n",
      "2023-01-25 03:01:08.219614\n",
      "EPOCH 78\n",
      "TAG_LOSS_WEIGHT:  0.5171588587956447\n",
      "CLS_LOSS_WEIGHT:  0.48284114120435523\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1621\n",
      "fn:  129\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3706\n",
      "EPOCH 78\n",
      "   TRAIN | Label 1 loss: 37.3183 ; P: 0.7613 ; R: 0.7836 ; F1: 0.7723 ; Acc: 0.9865\n",
      "           Label 2 loss: 3.9669 ; P: 0.9994 ; R: 1.0 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 61.0303 ; P: 0.6352 ; R: 0.8523 ; F1: 0.7279 ; Acc: 0.9815\n",
      "           Label 2 loss: 595.313 ; P: 0.9158 ; R: 0.9263 ; F1: 0.921 ; Acc: 0.9302\n",
      "2023-01-25 03:05:16.855740\n",
      "counter:  5\n",
      "2023-01-25 03:05:16.856740\n",
      "EPOCH 79\n",
      "TAG_LOSS_WEIGHT:  0.5171706429482962\n",
      "CLS_LOSS_WEIGHT:  0.48282935705170377\n",
      "tp:  1762\n",
      "fn:  4\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3973\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2081\n",
      "fp:  153\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3708\n",
      "EPOCH 79\n",
      "   TRAIN | Label 1 loss: 37.5489 ; P: 0.7619 ; R: 0.7852 ; F1: 0.7734 ; Acc: 0.9865\n",
      "           Label 2 loss: 5.0595 ; P: 0.9994 ; R: 0.9977 ; F1: 0.9986 ; Acc: 0.9987\n",
      "    TEST | Label 1 loss: 60.6349 ; P: 0.6369 ; R: 0.8515 ; F1: 0.7288 ; Acc: 0.9816\n",
      "           Label 2 loss: 595.1224 ; P: 0.914 ; R: 0.9297 ; F1: 0.9218 ; Acc: 0.9307\n",
      "2023-01-25 03:09:25.010318\n",
      "counter:  6\n",
      "2023-01-25 03:09:25.010318\n",
      "EPOCH 80\n",
      "TAG_LOSS_WEIGHT:  0.5172978875591199\n",
      "CLS_LOSS_WEIGHT:  0.48270211244088024\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1624\n",
      "fn:  126\n",
      "tn:  2084\n",
      "fp:  150\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3708\n",
      "EPOCH 80\n",
      "   TRAIN | Label 1 loss: 36.7578 ; P: 0.7654 ; R: 0.7836 ; F1: 0.7744 ; Acc: 0.9866\n",
      "           Label 2 loss: 3.5349 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 1 loss: 60.9396 ; P: 0.6359 ; R: 0.853 ; F1: 0.7286 ; Acc: 0.9815\n",
      "           Label 2 loss: 594.4692 ; P: 0.9154 ; R: 0.928 ; F1: 0.9217 ; Acc: 0.9307\n",
      "2023-01-25 03:13:33.042750\n",
      "counter:  7\n",
      "2023-01-25 03:13:33.042750\n",
      "EPOCH 81\n",
      "TAG_LOSS_WEIGHT:  0.5167956836830523\n",
      "CLS_LOSS_WEIGHT:  0.48320431631694766\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1621\n",
      "fn:  129\n",
      "tn:  2087\n",
      "fp:  147\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3708\n",
      "EPOCH 81\n",
      "   TRAIN | Label 1 loss: 36.2572 ; P: 0.7647 ; R: 0.7908 ; F1: 0.7775 ; Acc: 0.9868\n",
      "           Label 2 loss: 2.8393 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 60.5393 ; P: 0.6423 ; R: 0.8482 ; F1: 0.731 ; Acc: 0.9818\n",
      "           Label 2 loss: 594.6543 ; P: 0.9169 ; R: 0.9263 ; F1: 0.9215 ; Acc: 0.9307\n",
      "2023-01-25 03:17:41.686017\n",
      "counter:  8\n",
      "2023-01-25 03:17:41.686017\n",
      "EPOCH 82\n",
      "TAG_LOSS_WEIGHT:  0.5164702315803325\n",
      "CLS_LOSS_WEIGHT:  0.48352976841966755\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2208\n",
      "fp:  4\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1620\n",
      "fn:  130\n",
      "tn:  2100\n",
      "fp:  134\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3720\n",
      "EPOCH 82\n",
      "   TRAIN | Label 1 loss: 36.6842 ; P: 0.763 ; R: 0.7849 ; F1: 0.7738 ; Acc: 0.9866\n",
      "           Label 2 loss: 4.7445 ; P: 0.9977 ; R: 1.0 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 1 loss: 61.0202 ; P: 0.6391 ; R: 0.8515 ; F1: 0.7302 ; Acc: 0.9817\n",
      "           Label 2 loss: 587.8764 ; P: 0.9236 ; R: 0.9257 ; F1: 0.9247 ; Acc: 0.9337\n",
      "2023-01-25 03:21:50.799496\n",
      "counter:  9\n",
      "2023-01-25 03:21:50.799496\n",
      "EPOCH 83\n",
      "TAG_LOSS_WEIGHT:  0.5167104321587204\n",
      "CLS_LOSS_WEIGHT:  0.48328956784127963\n",
      "tp:  1760\n",
      "fn:  6\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3971\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2087\n",
      "fp:  147\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3712\n",
      "EPOCH 83\n",
      "   TRAIN | Label 1 loss: 36.934 ; P: 0.7592 ; R: 0.7848 ; F1: 0.7718 ; Acc: 0.9864\n",
      "           Label 2 loss: 6.2447 ; P: 0.9994 ; R: 0.9966 ; F1: 0.998 ; Acc: 0.9982\n",
      "    TEST | Label 1 loss: 61.0888 ; P: 0.6347 ; R: 0.8556 ; F1: 0.7288 ; Acc: 0.9815\n",
      "           Label 2 loss: 590.9124 ; P: 0.917 ; R: 0.9286 ; F1: 0.9228 ; Acc: 0.9317\n",
      "2023-01-25 03:25:59.328934\n",
      "counter:  10\n",
      "2023-01-25 03:25:59.328934\n",
      "EPOCH 84\n",
      "TAG_LOSS_WEIGHT:  0.5168327104340796\n",
      "CLS_LOSS_WEIGHT:  0.4831672895659203\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2208\n",
      "fp:  4\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3971\n",
      "tp:  1623\n",
      "fn:  127\n",
      "tn:  2089\n",
      "fp:  145\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3712\n",
      "EPOCH 84\n",
      "   TRAIN | Label 1 loss: 36.4537 ; P: 0.7647 ; R: 0.789 ; F1: 0.7767 ; Acc: 0.9867\n",
      "           Label 2 loss: 5.6546 ; P: 0.9977 ; R: 0.9983 ; F1: 0.998 ; Acc: 0.9982\n",
      "    TEST | Label 1 loss: 60.3032 ; P: 0.6437 ; R: 0.8472 ; F1: 0.7315 ; Acc: 0.9819\n",
      "           Label 2 loss: 590.9267 ; P: 0.918 ; R: 0.9274 ; F1: 0.9227 ; Acc: 0.9317\n",
      "2023-01-25 03:30:06.125420\n",
      "counter:  11\n",
      "2023-01-25 03:30:06.126431\n",
      "EPOCH 85\n",
      "TAG_LOSS_WEIGHT:  0.5165231219033586\n",
      "CLS_LOSS_WEIGHT:  0.4834768780966413\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1624\n",
      "fn:  126\n",
      "tn:  2090\n",
      "fp:  144\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3714\n",
      "EPOCH 85\n",
      "   TRAIN | Label 1 loss: 36.3026 ; P: 0.7662 ; R: 0.7843 ; F1: 0.7751 ; Acc: 0.9867\n",
      "           Label 2 loss: 3.8939 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 1 loss: 60.8032 ; P: 0.6386 ; R: 0.8508 ; F1: 0.7296 ; Acc: 0.9816\n",
      "           Label 2 loss: 591.2501 ; P: 0.9186 ; R: 0.928 ; F1: 0.9233 ; Acc: 0.9322\n",
      "2023-01-25 03:34:13.018022\n",
      "counter:  12\n",
      "2023-01-25 03:34:13.019012\n",
      "EPOCH 86\n",
      "TAG_LOSS_WEIGHT:  0.5164739727444252\n",
      "CLS_LOSS_WEIGHT:  0.4835260272555747\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1624\n",
      "fn:  126\n",
      "tn:  2087\n",
      "fp:  147\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3711\n",
      "EPOCH 86\n",
      "   TRAIN | Label 1 loss: 37.0189 ; P: 0.7592 ; R: 0.7897 ; F1: 0.7742 ; Acc: 0.9865\n",
      "           Label 2 loss: 2.7655 ; P: 1.0 ; R: 0.9989 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 60.8195 ; P: 0.6375 ; R: 0.8515 ; F1: 0.7291 ; Acc: 0.9816\n",
      "           Label 2 loss: 593.3545 ; P: 0.917 ; R: 0.928 ; F1: 0.9225 ; Acc: 0.9315\n",
      "2023-01-25 03:38:20.044296\n",
      "counter:  13\n",
      "2023-01-25 03:38:20.044296\n",
      "EPOCH 87\n",
      "TAG_LOSS_WEIGHT:  0.5169947358160143\n",
      "CLS_LOSS_WEIGHT:  0.4830052641839856\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2084\n",
      "fp:  150\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "EPOCH 87\n",
      "   TRAIN | Label 1 loss: 36.6145 ; P: 0.7608 ; R: 0.7842 ; F1: 0.7723 ; Acc: 0.9865\n",
      "           Label 2 loss: 4.3269 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 1 loss: 60.6454 ; P: 0.6389 ; R: 0.8508 ; F1: 0.7298 ; Acc: 0.9817\n",
      "           Label 2 loss: 594.5299 ; P: 0.9155 ; R: 0.9291 ; F1: 0.9223 ; Acc: 0.9312\n",
      "2023-01-25 03:42:28.561178\n",
      "counter:  14\n",
      "2023-01-25 03:42:28.561178\n",
      "EPOCH 88\n",
      "TAG_LOSS_WEIGHT:  0.5166751318908047\n",
      "CLS_LOSS_WEIGHT:  0.4833248681091954\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2083\n",
      "fp:  151\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "EPOCH 88\n",
      "   TRAIN | Label 1 loss: 36.3672 ; P: 0.7567 ; R: 0.7907 ; F1: 0.7733 ; Acc: 0.9864\n",
      "           Label 2 loss: 4.0186 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 1 loss: 60.3581 ; P: 0.6422 ; R: 0.8474 ; F1: 0.7307 ; Acc: 0.9818\n",
      "           Label 2 loss: 597.2708 ; P: 0.9151 ; R: 0.9297 ; F1: 0.9223 ; Acc: 0.9312\n",
      "2023-01-25 03:46:34.915361\n",
      "counter:  15\n",
      "2023-01-25 03:46:34.916312\n",
      "EPOCH 89\n",
      "TAG_LOSS_WEIGHT:  0.5165146276000099\n",
      "CLS_LOSS_WEIGHT:  0.48348537239999023\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2080\n",
      "fp:  154\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3707\n",
      "EPOCH 89\n",
      "   TRAIN | Label 1 loss: 36.6446 ; P: 0.7634 ; R: 0.7938 ; F1: 0.7783 ; Acc: 0.9868\n",
      "           Label 2 loss: 4.5622 ; P: 0.9989 ; R: 0.9989 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 1 loss: 60.1317 ; P: 0.6449 ; R: 0.8453 ; F1: 0.7316 ; Acc: 0.982\n",
      "           Label 2 loss: 597.6649 ; P: 0.9135 ; R: 0.9297 ; F1: 0.9216 ; Acc: 0.9305\n",
      "2023-01-25 03:50:41.806995\n",
      "counter:  16\n",
      "2023-01-25 03:50:41.806995\n",
      "EPOCH 90\n",
      "TAG_LOSS_WEIGHT:  0.5166887909497875\n",
      "CLS_LOSS_WEIGHT:  0.4833112090502127\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2084\n",
      "fp:  150\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3709\n",
      "EPOCH 90\n",
      "   TRAIN | Label 1 loss: 36.2687 ; P: 0.7642 ; R: 0.7826 ; F1: 0.7733 ; Acc: 0.9866\n",
      "           Label 2 loss: 2.7749 ; P: 0.9994 ; R: 1.0 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 60.4166 ; P: 0.6423 ; R: 0.8477 ; F1: 0.7308 ; Acc: 0.9818\n",
      "           Label 2 loss: 596.6158 ; P: 0.9155 ; R: 0.9286 ; F1: 0.922 ; Acc: 0.931\n",
      "2023-01-25 03:54:48.987873\n",
      "counter:  17\n",
      "2023-01-25 03:54:48.987873\n",
      "EPOCH 91\n",
      "TAG_LOSS_WEIGHT:  0.5164796058607841\n",
      "CLS_LOSS_WEIGHT:  0.48352039413921577\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2083\n",
      "fp:  151\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3709\n",
      "EPOCH 91\n",
      "   TRAIN | Label 1 loss: 36.2635 ; P: 0.7655 ; R: 0.7903 ; F1: 0.7777 ; Acc: 0.9868\n",
      "           Label 2 loss: 3.0566 ; P: 1.0 ; R: 0.9983 ; F1: 0.9991 ; Acc: 0.9992\n",
      "    TEST | Label 1 loss: 60.5534 ; P: 0.6403 ; R: 0.8496 ; F1: 0.7303 ; Acc: 0.9817\n",
      "           Label 2 loss: 596.7059 ; P: 0.915 ; R: 0.9291 ; F1: 0.922 ; Acc: 0.931\n",
      "2023-01-25 03:58:58.846665\n",
      "counter:  18\n",
      "2023-01-25 03:58:58.847656\n",
      "EPOCH 92\n",
      "TAG_LOSS_WEIGHT:  0.5164692708416975\n",
      "CLS_LOSS_WEIGHT:  0.48353072915830253\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "EPOCH 92\n",
      "   TRAIN | Label 1 loss: 36.5114 ; P: 0.7644 ; R: 0.7846 ; F1: 0.7744 ; Acc: 0.9866\n",
      "           Label 2 loss: 4.7218 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 60.5757 ; P: 0.6409 ; R: 0.8491 ; F1: 0.7305 ; Acc: 0.9818\n",
      "           Label 2 loss: 596.3837 ; P: 0.916 ; R: 0.9286 ; F1: 0.9222 ; Acc: 0.9312\n",
      "2023-01-25 04:03:08.237819\n",
      "counter:  19\n",
      "2023-01-25 04:03:08.238829\n",
      "EPOCH 93\n",
      "TAG_LOSS_WEIGHT:  0.5165925978780808\n",
      "CLS_LOSS_WEIGHT:  0.4834074021219192\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "EPOCH 93\n",
      "   TRAIN | Label 1 loss: 36.2022 ; P: 0.7683 ; R: 0.7979 ; F1: 0.7828 ; Acc: 0.987\n",
      "           Label 2 loss: 3.6419 ; P: 0.9989 ; R: 0.9994 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 1 loss: 60.5001 ; P: 0.6423 ; R: 0.8477 ; F1: 0.7308 ; Acc: 0.9818\n",
      "           Label 2 loss: 596.6893 ; P: 0.916 ; R: 0.9286 ; F1: 0.9222 ; Acc: 0.9312\n",
      "2023-01-25 04:07:16.961234\n",
      "counter:  20\n",
      "2023-01-25 04:07:16.962313\n",
      "EPOCH 94\n",
      "TAG_LOSS_WEIGHT:  0.5164123273923238\n",
      "CLS_LOSS_WEIGHT:  0.4835876726076762\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "EPOCH 94\n",
      "   TRAIN | Label 1 loss: 36.5564 ; P: 0.7595 ; R: 0.7927 ; F1: 0.7758 ; Acc: 0.9866\n",
      "           Label 2 loss: 3.5171 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 1 loss: 60.4842 ; P: 0.6423 ; R: 0.8477 ; F1: 0.7308 ; Acc: 0.9818\n",
      "           Label 2 loss: 596.9596 ; P: 0.916 ; R: 0.9286 ; F1: 0.9222 ; Acc: 0.9312\n",
      "2023-01-25 04:11:26.002831\n",
      "counter:  21\n",
      "2023-01-25 04:11:26.002831\n",
      "EPOCH 95\n",
      "TAG_LOSS_WEIGHT:  0.5166578958328426\n",
      "CLS_LOSS_WEIGHT:  0.4833421041671574\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "EPOCH 95\n",
      "   TRAIN | Label 1 loss: 35.8097 ; P: 0.766 ; R: 0.7881 ; F1: 0.7769 ; Acc: 0.9867\n",
      "           Label 2 loss: 4.0854 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 60.5089 ; P: 0.6417 ; R: 0.8479 ; F1: 0.7306 ; Acc: 0.9818\n",
      "           Label 2 loss: 597.3046 ; P: 0.916 ; R: 0.9286 ; F1: 0.9222 ; Acc: 0.9312\n",
      "2023-01-25 04:15:33.724231\n",
      "counter:  22\n",
      "2023-01-25 04:15:33.724231\n",
      "EPOCH 96\n",
      "TAG_LOSS_WEIGHT:  0.5161329728388345\n",
      "CLS_LOSS_WEIGHT:  0.48386702716116553\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "EPOCH 96\n",
      "   TRAIN | Label 1 loss: 36.5583 ; P: 0.7632 ; R: 0.7874 ; F1: 0.7751 ; Acc: 0.9866\n",
      "           Label 2 loss: 3.5738 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 60.5046 ; P: 0.6418 ; R: 0.8482 ; F1: 0.7307 ; Acc: 0.9818\n",
      "           Label 2 loss: 597.2241 ; P: 0.916 ; R: 0.9286 ; F1: 0.9222 ; Acc: 0.9312\n",
      "2023-01-25 04:19:42.730796\n",
      "counter:  23\n",
      "2023-01-25 04:19:42.730796\n",
      "EPOCH 97\n",
      "TAG_LOSS_WEIGHT:  0.5166576925300421\n",
      "CLS_LOSS_WEIGHT:  0.483342307469958\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "EPOCH 97\n",
      "   TRAIN | Label 1 loss: 36.3904 ; P: 0.7643 ; R: 0.7832 ; F1: 0.7736 ; Acc: 0.9866\n",
      "           Label 2 loss: 3.1711 ; P: 0.9994 ; R: 1.0 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 60.5378 ; P: 0.6415 ; R: 0.8484 ; F1: 0.7306 ; Acc: 0.9818\n",
      "           Label 2 loss: 597.0816 ; P: 0.916 ; R: 0.9286 ; F1: 0.9222 ; Acc: 0.9312\n",
      "2023-01-25 04:23:50.738624\n",
      "counter:  24\n",
      "2023-01-25 04:23:50.738624\n",
      "EPOCH 98\n",
      "TAG_LOSS_WEIGHT:  0.5165531459843137\n",
      "CLS_LOSS_WEIGHT:  0.48344685401568643\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "EPOCH 98\n",
      "   TRAIN | Label 1 loss: 36.532 ; P: 0.7699 ; R: 0.7867 ; F1: 0.7782 ; Acc: 0.9869\n",
      "           Label 2 loss: 2.9654 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 60.5598 ; P: 0.6412 ; R: 0.8486 ; F1: 0.7305 ; Acc: 0.9818\n",
      "           Label 2 loss: 597.2223 ; P: 0.916 ; R: 0.9286 ; F1: 0.9222 ; Acc: 0.9312\n",
      "2023-01-25 04:27:58.641842\n",
      "counter:  25\n",
      "2023-01-25 04:27:58.641842\n",
      "EPOCH 99\n",
      "TAG_LOSS_WEIGHT:  0.5166551766042353\n",
      "CLS_LOSS_WEIGHT:  0.48334482339576473\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "EPOCH 99\n",
      "   TRAIN | Label 1 loss: 36.2133 ; P: 0.7617 ; R: 0.7819 ; F1: 0.7716 ; Acc: 0.9865\n",
      "           Label 2 loss: 2.156 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 60.5744 ; P: 0.6412 ; R: 0.8489 ; F1: 0.7306 ; Acc: 0.9818\n",
      "           Label 2 loss: 597.1922 ; P: 0.916 ; R: 0.9286 ; F1: 0.9222 ; Acc: 0.9312\n",
      "2023-01-25 04:32:06.652833\n",
      "counter:  26\n",
      "2023-01-25 04:32:06.652833\n",
      "EPOCH 100\n",
      "TAG_LOSS_WEIGHT:  0.5164554876295088\n",
      "CLS_LOSS_WEIGHT:  0.4835445123704914\n",
      "tp:  1762\n",
      "fn:  4\n",
      "tn:  2209\n",
      "fp:  3\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3971\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "EPOCH 100\n",
      "   TRAIN | Label 1 loss: 36.4132 ; P: 0.7662 ; R: 0.7898 ; F1: 0.7778 ; Acc: 0.9868\n",
      "           Label 2 loss: 7.0165 ; P: 0.9983 ; R: 0.9977 ; F1: 0.998 ; Acc: 0.9982\n",
      "    TEST | Label 1 loss: 60.5742 ; P: 0.6412 ; R: 0.8489 ; F1: 0.7306 ; Acc: 0.9818\n",
      "           Label 2 loss: 597.1494 ; P: 0.916 ; R: 0.9286 ; F1: 0.9222 ; Acc: 0.9312\n",
      "2023-01-25 04:36:13.685197\n",
      "counter:  27\n",
      "2023-01-25 04:36:13.685197\n",
      "EPOCH 101\n",
      "TAG_LOSS_WEIGHT:  0.5164470740018047\n",
      "CLS_LOSS_WEIGHT:  0.4835529259981954\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2209\n",
      "fp:  3\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3972\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "EPOCH 101\n",
      "   TRAIN | Label 1 loss: 36.3084 ; P: 0.7633 ; R: 0.7844 ; F1: 0.7737 ; Acc: 0.9866\n",
      "           Label 2 loss: 4.2082 ; P: 0.9983 ; R: 0.9983 ; F1: 0.9983 ; Acc: 0.9985\n",
      "    TEST | Label 1 loss: 60.5743 ; P: 0.6412 ; R: 0.8491 ; F1: 0.7307 ; Acc: 0.9818\n",
      "           Label 2 loss: 597.1776 ; P: 0.916 ; R: 0.9286 ; F1: 0.9222 ; Acc: 0.9312\n",
      "2023-01-25 04:40:20.569356\n",
      "counter:  28\n",
      "2023-01-25 04:40:20.570373\n",
      "EPOCH 102\n",
      "TAG_LOSS_WEIGHT:  0.5164690129756003\n",
      "CLS_LOSS_WEIGHT:  0.48353098702439956\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "EPOCH 102\n",
      "   TRAIN | Label 1 loss: 36.1571 ; P: 0.7622 ; R: 0.7916 ; F1: 0.7766 ; Acc: 0.9867\n",
      "           Label 2 loss: 4.193 ; P: 0.9994 ; R: 0.9983 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 1 loss: 60.5742 ; P: 0.6414 ; R: 0.8491 ; F1: 0.7308 ; Acc: 0.9818\n",
      "           Label 2 loss: 597.2004 ; P: 0.916 ; R: 0.9286 ; F1: 0.9222 ; Acc: 0.9312\n",
      "2023-01-25 04:44:27.867148\n",
      "counter:  29\n",
      "2023-01-25 04:44:27.868148\n",
      "EPOCH 103\n",
      "TAG_LOSS_WEIGHT:  0.5163661849937932\n",
      "CLS_LOSS_WEIGHT:  0.48363381500620684\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "EPOCH 103\n",
      "   TRAIN | Label 1 loss: 36.2627 ; P: 0.766 ; R: 0.7904 ; F1: 0.778 ; Acc: 0.9868\n",
      "           Label 2 loss: 3.2777 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 60.579 ; P: 0.6413 ; R: 0.8489 ; F1: 0.7306 ; Acc: 0.9818\n",
      "           Label 2 loss: 597.2062 ; P: 0.916 ; R: 0.9286 ; F1: 0.9222 ; Acc: 0.9312\n",
      "2023-01-25 04:48:34.936576\n",
      "counter:  30\n",
      "2023-01-25 04:48:34.936576\n",
      "EPOCH 104\n",
      "TAG_LOSS_WEIGHT:  0.5164631747218199\n",
      "CLS_LOSS_WEIGHT:  0.48353682527818015\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "EPOCH 104\n",
      "   TRAIN | Label 1 loss: 36.0177 ; P: 0.7716 ; R: 0.7969 ; F1: 0.7841 ; Acc: 0.9872\n",
      "           Label 2 loss: 2.8519 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 60.5768 ; P: 0.6411 ; R: 0.8489 ; F1: 0.7305 ; Acc: 0.9818\n",
      "           Label 2 loss: 597.252 ; P: 0.916 ; R: 0.9286 ; F1: 0.9222 ; Acc: 0.9312\n",
      "2023-01-25 04:52:41.243978\n",
      "counter:  31\n",
      "2023-01-25 04:52:41.243978\n",
      "EPOCH 105\n",
      "TAG_LOSS_WEIGHT:  0.5163066794003464\n",
      "CLS_LOSS_WEIGHT:  0.48369332059965364\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "EPOCH 105\n",
      "   TRAIN | Label 1 loss: 36.2404 ; P: 0.7615 ; R: 0.7939 ; F1: 0.7774 ; Acc: 0.9867\n",
      "           Label 2 loss: 4.4821 ; P: 0.9994 ; R: 0.9983 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 1 loss: 60.5412 ; P: 0.6416 ; R: 0.8486 ; F1: 0.7307 ; Acc: 0.9818\n",
      "           Label 2 loss: 597.2827 ; P: 0.916 ; R: 0.9286 ; F1: 0.9222 ; Acc: 0.9312\n",
      "2023-01-25 04:56:47.806114\n",
      "counter:  32\n",
      "2023-01-25 04:56:47.807110\n",
      "EPOCH 106\n",
      "TAG_LOSS_WEIGHT:  0.5164145210989571\n",
      "CLS_LOSS_WEIGHT:  0.483585478901043\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "EPOCH 106\n",
      "   TRAIN | Label 1 loss: 36.1148 ; P: 0.7676 ; R: 0.7937 ; F1: 0.7804 ; Acc: 0.9869\n",
      "           Label 2 loss: 2.9866 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 60.522 ; P: 0.6416 ; R: 0.8484 ; F1: 0.7307 ; Acc: 0.9818\n",
      "           Label 2 loss: 597.1764 ; P: 0.916 ; R: 0.9286 ; F1: 0.9222 ; Acc: 0.9312\n",
      "2023-01-25 05:00:55.796167\n",
      "counter:  33\n",
      "2023-01-25 05:00:55.797080\n",
      "EPOCH 107\n",
      "TAG_LOSS_WEIGHT:  0.5163695554518315\n",
      "CLS_LOSS_WEIGHT:  0.4836304445481684\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "EPOCH 107\n",
      "   TRAIN | Label 1 loss: 36.2713 ; P: 0.7651 ; R: 0.7877 ; F1: 0.7762 ; Acc: 0.9867\n",
      "           Label 2 loss: 4.7309 ; P: 0.9994 ; R: 0.9983 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 1 loss: 60.6173 ; P: 0.6411 ; R: 0.8503 ; F1: 0.731 ; Acc: 0.9818\n",
      "           Label 2 loss: 597.4739 ; P: 0.916 ; R: 0.9286 ; F1: 0.9222 ; Acc: 0.9312\n",
      "2023-01-25 05:05:01.760714\n",
      "counter:  34\n",
      "2023-01-25 05:05:01.760714\n",
      "EPOCH 108\n",
      "TAG_LOSS_WEIGHT:  0.5164280861767515\n",
      "CLS_LOSS_WEIGHT:  0.4835719138232485\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2209\n",
      "fp:  3\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3973\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "EPOCH 108\n",
      "   TRAIN | Label 1 loss: 36.2739 ; P: 0.7645 ; R: 0.7846 ; F1: 0.7744 ; Acc: 0.9866\n",
      "           Label 2 loss: 6.5655 ; P: 0.9983 ; R: 0.9989 ; F1: 0.9986 ; Acc: 0.9987\n",
      "    TEST | Label 1 loss: 60.6142 ; P: 0.6412 ; R: 0.8501 ; F1: 0.731 ; Acc: 0.9818\n",
      "           Label 2 loss: 597.4493 ; P: 0.916 ; R: 0.9286 ; F1: 0.9222 ; Acc: 0.9312\n",
      "2023-01-25 05:09:10.463938\n",
      "counter:  35\n",
      "2023-01-25 05:09:10.463938\n",
      "EPOCH 109\n",
      "TAG_LOSS_WEIGHT:  0.5163684287105368\n",
      "CLS_LOSS_WEIGHT:  0.48363157128946316\n",
      "tp:  1760\n",
      "fn:  6\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3970\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "EPOCH 109\n",
      "   TRAIN | Label 1 loss: 36.0892 ; P: 0.765 ; R: 0.7918 ; F1: 0.7782 ; Acc: 0.9868\n",
      "           Label 2 loss: 5.2513 ; P: 0.9989 ; R: 0.9966 ; F1: 0.9977 ; Acc: 0.998\n",
      "    TEST | Label 1 loss: 60.5611 ; P: 0.6419 ; R: 0.8498 ; F1: 0.7314 ; Acc: 0.9818\n",
      "           Label 2 loss: 597.8433 ; P: 0.916 ; R: 0.9286 ; F1: 0.9222 ; Acc: 0.9312\n",
      "2023-01-25 05:13:17.469658\n",
      "counter:  36\n",
      "2023-01-25 05:13:17.469658\n",
      "EPOCH 110\n",
      "TAG_LOSS_WEIGHT:  0.5162874884728699\n",
      "CLS_LOSS_WEIGHT:  0.48371251152713024\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2087\n",
      "fp:  147\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3712\n",
      "EPOCH 110\n",
      "   TRAIN | Label 1 loss: 36.1342 ; P: 0.7669 ; R: 0.792 ; F1: 0.7792 ; Acc: 0.9869\n",
      "           Label 2 loss: 4.318 ; P: 0.9989 ; R: 1.0 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 60.4668 ; P: 0.6439 ; R: 0.8479 ; F1: 0.7319 ; Acc: 0.9819\n",
      "           Label 2 loss: 596.1469 ; P: 0.917 ; R: 0.9286 ; F1: 0.9228 ; Acc: 0.9317\n",
      "2023-01-25 05:17:24.100315\n",
      "counter:  37\n",
      "2023-01-25 05:17:24.100315\n",
      "EPOCH 111\n",
      "TAG_LOSS_WEIGHT:  0.5163469364159837\n",
      "CLS_LOSS_WEIGHT:  0.4836530635840162\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1624\n",
      "fn:  126\n",
      "tn:  2088\n",
      "fp:  146\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3712\n",
      "EPOCH 111\n",
      "   TRAIN | Label 1 loss: 36.5436 ; P: 0.7673 ; R: 0.7849 ; F1: 0.776 ; Acc: 0.9867\n",
      "           Label 2 loss: 3.2085 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 60.5138 ; P: 0.6433 ; R: 0.8482 ; F1: 0.7317 ; Acc: 0.9819\n",
      "           Label 2 loss: 597.1152 ; P: 0.9175 ; R: 0.928 ; F1: 0.9227 ; Acc: 0.9317\n",
      "2023-01-25 05:21:32.516792\n",
      "counter:  38\n",
      "2023-01-25 05:21:32.517739\n",
      "EPOCH 112\n",
      "TAG_LOSS_WEIGHT:  0.5166571029064545\n",
      "CLS_LOSS_WEIGHT:  0.48334289709354544\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1620\n",
      "fn:  130\n",
      "tn:  2090\n",
      "fp:  144\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "EPOCH 112\n",
      "   TRAIN | Label 1 loss: 35.9199 ; P: 0.7668 ; R: 0.7884 ; F1: 0.7774 ; Acc: 0.9868\n",
      "           Label 2 loss: 7.4287 ; P: 0.9989 ; R: 1.0 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 60.7861 ; P: 0.6411 ; R: 0.8498 ; F1: 0.7309 ; Acc: 0.9818\n",
      "           Label 2 loss: 595.3409 ; P: 0.9184 ; R: 0.9257 ; F1: 0.922 ; Acc: 0.9312\n",
      "2023-01-25 05:25:40.631919\n",
      "counter:  39\n",
      "2023-01-25 05:25:40.632916\n",
      "EPOCH 113\n",
      "TAG_LOSS_WEIGHT:  0.5160950563605669\n",
      "CLS_LOSS_WEIGHT:  0.48390494363943315\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3973\n",
      "tp:  1621\n",
      "fn:  129\n",
      "tn:  2088\n",
      "fp:  146\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3709\n",
      "EPOCH 113\n",
      "   TRAIN | Label 1 loss: 35.9293 ; P: 0.7636 ; R: 0.7886 ; F1: 0.7759 ; Acc: 0.9867\n",
      "           Label 2 loss: 5.3129 ; P: 0.9989 ; R: 0.9983 ; F1: 0.9986 ; Acc: 0.9987\n",
      "    TEST | Label 1 loss: 60.7887 ; P: 0.6407 ; R: 0.8498 ; F1: 0.7306 ; Acc: 0.9818\n",
      "           Label 2 loss: 596.6959 ; P: 0.9174 ; R: 0.9263 ; F1: 0.9218 ; Acc: 0.931\n",
      "2023-01-25 05:29:47.750749\n",
      "counter:  40\n",
      "2023-01-25 05:29:47.750749\n",
      "EPOCH 114\n",
      "TAG_LOSS_WEIGHT:  0.5161766887614219\n",
      "CLS_LOSS_WEIGHT:  0.4838233112385783\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1624\n",
      "fn:  126\n",
      "tn:  2088\n",
      "fp:  146\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3712\n",
      "EPOCH 114\n",
      "   TRAIN | Label 1 loss: 36.1355 ; P: 0.7655 ; R: 0.7914 ; F1: 0.7782 ; Acc: 0.9868\n",
      "           Label 2 loss: 4.3019 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 1 loss: 60.99 ; P: 0.6371 ; R: 0.853 ; F1: 0.7294 ; Acc: 0.9816\n",
      "           Label 2 loss: 596.172 ; P: 0.9175 ; R: 0.928 ; F1: 0.9227 ; Acc: 0.9317\n",
      "2023-01-25 05:33:54.727261\n",
      "counter:  41\n",
      "2023-01-25 05:33:54.728199\n",
      "EPOCH 115\n",
      "TAG_LOSS_WEIGHT:  0.5163482939849575\n",
      "CLS_LOSS_WEIGHT:  0.4836517060150425\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1623\n",
      "fn:  127\n",
      "tn:  2084\n",
      "fp:  150\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3707\n",
      "EPOCH 115\n",
      "   TRAIN | Label 1 loss: 35.8677 ; P: 0.7632 ; R: 0.7951 ; F1: 0.7788 ; Acc: 0.9868\n",
      "           Label 2 loss: 4.2096 ; P: 0.9989 ; R: 0.9989 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 1 loss: 60.9222 ; P: 0.6387 ; R: 0.8518 ; F1: 0.73 ; Acc: 0.9817\n",
      "           Label 2 loss: 599.5879 ; P: 0.9154 ; R: 0.9274 ; F1: 0.9214 ; Acc: 0.9305\n",
      "2023-01-25 05:38:02.692718\n",
      "counter:  42\n",
      "2023-01-25 05:38:02.692718\n",
      "EPOCH 116\n",
      "TAG_LOSS_WEIGHT:  0.5161687774580966\n",
      "CLS_LOSS_WEIGHT:  0.4838312225419034\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1623\n",
      "fn:  127\n",
      "tn:  2084\n",
      "fp:  150\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3707\n",
      "EPOCH 116\n",
      "   TRAIN | Label 1 loss: 35.7377 ; P: 0.7616 ; R: 0.7904 ; F1: 0.7758 ; Acc: 0.9866\n",
      "           Label 2 loss: 3.5714 ; P: 0.9989 ; R: 0.9994 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 1 loss: 60.8876 ; P: 0.6394 ; R: 0.8513 ; F1: 0.7303 ; Acc: 0.9817\n",
      "           Label 2 loss: 601.1422 ; P: 0.9154 ; R: 0.9274 ; F1: 0.9214 ; Acc: 0.9305\n",
      "2023-01-25 05:42:10.347007\n",
      "counter:  43\n",
      "2023-01-25 05:42:10.347007\n",
      "EPOCH 117\n",
      "TAG_LOSS_WEIGHT:  0.516098324522341\n",
      "CLS_LOSS_WEIGHT:  0.4839016754776591\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1622\n",
      "fn:  128\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3707\n",
      "EPOCH 117\n",
      "   TRAIN | Label 1 loss: 36.0509 ; P: 0.7618 ; R: 0.7896 ; F1: 0.7754 ; Acc: 0.9866\n",
      "           Label 2 loss: 2.6344 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 60.6824 ; P: 0.6423 ; R: 0.8489 ; F1: 0.7313 ; Acc: 0.9818\n",
      "           Label 2 loss: 601.3403 ; P: 0.9159 ; R: 0.9269 ; F1: 0.9213 ; Acc: 0.9305\n",
      "2023-01-25 05:46:17.979129\n",
      "counter:  44\n",
      "2023-01-25 05:46:17.980128\n",
      "EPOCH 118\n",
      "TAG_LOSS_WEIGHT:  0.5163343586389672\n",
      "CLS_LOSS_WEIGHT:  0.4836656413610329\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1622\n",
      "fn:  128\n",
      "tn:  2086\n",
      "fp:  148\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3708\n",
      "EPOCH 118\n",
      "   TRAIN | Label 1 loss: 36.1507 ; P: 0.7632 ; R: 0.7944 ; F1: 0.7785 ; Acc: 0.9868\n",
      "           Label 2 loss: 2.8697 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 60.8247 ; P: 0.6411 ; R: 0.8508 ; F1: 0.7312 ; Acc: 0.9818\n",
      "           Label 2 loss: 602.4259 ; P: 0.9164 ; R: 0.9269 ; F1: 0.9216 ; Acc: 0.9307\n",
      "2023-01-25 05:50:24.685331\n",
      "counter:  45\n",
      "2023-01-25 05:50:24.686325\n",
      "EPOCH 119\n",
      "TAG_LOSS_WEIGHT:  0.51639684626988\n",
      "CLS_LOSS_WEIGHT:  0.4836031537301201\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3973\n",
      "tp:  1622\n",
      "fn:  128\n",
      "tn:  2089\n",
      "fp:  145\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3711\n",
      "EPOCH 119\n",
      "   TRAIN | Label 1 loss: 35.7566 ; P: 0.7698 ; R: 0.8036 ; F1: 0.7863 ; Acc: 0.9872\n",
      "           Label 2 loss: 4.3306 ; P: 0.9989 ; R: 0.9983 ; F1: 0.9986 ; Acc: 0.9987\n",
      "    TEST | Label 1 loss: 60.7991 ; P: 0.6414 ; R: 0.8496 ; F1: 0.7309 ; Acc: 0.9818\n",
      "           Label 2 loss: 605.0066 ; P: 0.9179 ; R: 0.9269 ; F1: 0.9224 ; Acc: 0.9315\n",
      "2023-01-25 05:54:31.817087\n",
      "counter:  46\n",
      "2023-01-25 05:54:31.818119\n",
      "EPOCH 120\n",
      "TAG_LOSS_WEIGHT:  0.5160898595262642\n",
      "CLS_LOSS_WEIGHT:  0.4839101404737358\n",
      "tp:  1762\n",
      "fn:  4\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3973\n",
      "tp:  1625\n",
      "fn:  125\n",
      "tn:  2079\n",
      "fp:  155\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3704\n",
      "EPOCH 120\n",
      "   TRAIN | Label 1 loss: 36.0628 ; P: 0.7686 ; R: 0.7963 ; F1: 0.7822 ; Acc: 0.987\n",
      "           Label 2 loss: 3.7735 ; P: 0.9994 ; R: 0.9977 ; F1: 0.9986 ; Acc: 0.9987\n",
      "    TEST | Label 1 loss: 60.8701 ; P: 0.6382 ; R: 0.853 ; F1: 0.7301 ; Acc: 0.9817\n",
      "           Label 2 loss: 609.1871 ; P: 0.9129 ; R: 0.9286 ; F1: 0.9207 ; Acc: 0.9297\n",
      "2023-01-25 05:58:37.675016\n",
      "counter:  47\n",
      "2023-01-25 05:58:37.675016\n",
      "EPOCH 121\n",
      "TAG_LOSS_WEIGHT:  0.5163137388843211\n",
      "CLS_LOSS_WEIGHT:  0.48368626111567903\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1624\n",
      "fn:  126\n",
      "tn:  2083\n",
      "fp:  151\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3707\n",
      "EPOCH 121\n",
      "   TRAIN | Label 1 loss: 36.2365 ; P: 0.7636 ; R: 0.7938 ; F1: 0.7784 ; Acc: 0.9868\n",
      "           Label 2 loss: 2.7645 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 60.8683 ; P: 0.6387 ; R: 0.8525 ; F1: 0.7303 ; Acc: 0.9817\n",
      "           Label 2 loss: 607.875 ; P: 0.9149 ; R: 0.928 ; F1: 0.9214 ; Acc: 0.9305\n",
      "2023-01-25 06:02:45.002806\n",
      "counter:  48\n",
      "2023-01-25 06:02:45.002806\n",
      "EPOCH 122\n",
      "TAG_LOSS_WEIGHT:  0.5164578665239462\n",
      "CLS_LOSS_WEIGHT:  0.4835421334760537\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3973\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2082\n",
      "fp:  152\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3708\n",
      "EPOCH 122\n",
      "   TRAIN | Label 1 loss: 35.9699 ; P: 0.7641 ; R: 0.795 ; F1: 0.7792 ; Acc: 0.9868\n",
      "           Label 2 loss: 5.4019 ; P: 0.9989 ; R: 0.9983 ; F1: 0.9986 ; Acc: 0.9987\n",
      "    TEST | Label 1 loss: 60.5611 ; P: 0.6406 ; R: 0.8501 ; F1: 0.7306 ; Acc: 0.9818\n",
      "           Label 2 loss: 614.1923 ; P: 0.9145 ; R: 0.9291 ; F1: 0.9218 ; Acc: 0.9307\n",
      "2023-01-25 06:06:51.759276\n",
      "counter:  49\n",
      "2023-01-25 06:06:51.759276\n",
      "EPOCH 123\n",
      "TAG_LOSS_WEIGHT:  0.5162013862014172\n",
      "CLS_LOSS_WEIGHT:  0.4837986137985827\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1622\n",
      "fn:  128\n",
      "tn:  2091\n",
      "fp:  143\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3713\n",
      "EPOCH 123\n",
      "   TRAIN | Label 1 loss: 35.8495 ; P: 0.7633 ; R: 0.7936 ; F1: 0.7781 ; Acc: 0.9868\n",
      "           Label 2 loss: 2.6244 ; P: 0.9989 ; R: 0.9994 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 1 loss: 60.228 ; P: 0.6451 ; R: 0.8472 ; F1: 0.7324 ; Acc: 0.982\n",
      "           Label 2 loss: 606.3349 ; P: 0.919 ; R: 0.9269 ; F1: 0.9229 ; Acc: 0.932\n",
      "2023-01-25 06:11:00.937117\n",
      "counter:  50\n",
      "2023-01-25 06:11:00.937117\n",
      "EPOCH 124\n",
      "TAG_LOSS_WEIGHT:  0.5161976593370207\n",
      "CLS_LOSS_WEIGHT:  0.48380234066297934\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1622\n",
      "fn:  128\n",
      "tn:  2097\n",
      "fp:  137\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3719\n",
      "EPOCH 124\n",
      "   TRAIN | Label 1 loss: 35.8415 ; P: 0.7683 ; R: 0.7903 ; F1: 0.7791 ; Acc: 0.9869\n",
      "           Label 2 loss: 3.1454 ; P: 0.9994 ; R: 1.0 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 60.8277 ; P: 0.6405 ; R: 0.852 ; F1: 0.7313 ; Acc: 0.9818\n",
      "           Label 2 loss: 603.5815 ; P: 0.9221 ; R: 0.9269 ; F1: 0.9245 ; Acc: 0.9335\n",
      "2023-01-25 06:15:08.197456\n",
      "counter:  51\n",
      "2023-01-25 06:15:08.198452\n",
      "EPOCH 125\n",
      "TAG_LOSS_WEIGHT:  0.5161797499379566\n",
      "CLS_LOSS_WEIGHT:  0.48382025006204343\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1628\n",
      "fn:  122\n",
      "tn:  2087\n",
      "fp:  147\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3715\n",
      "EPOCH 125\n",
      "   TRAIN | Label 1 loss: 35.6577 ; P: 0.7644 ; R: 0.7928 ; F1: 0.7783 ; Acc: 0.9868\n",
      "           Label 2 loss: 4.656 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 1 loss: 60.1872 ; P: 0.6461 ; R: 0.8491 ; F1: 0.7338 ; Acc: 0.9821\n",
      "           Label 2 loss: 611.9879 ; P: 0.9172 ; R: 0.9303 ; F1: 0.9237 ; Acc: 0.9325\n",
      "2023-01-25 06:19:16.290271\n",
      "counter:  52\n",
      "2023-01-25 06:19:16.291233\n",
      "EPOCH 126\n",
      "TAG_LOSS_WEIGHT:  0.5160131158022361\n",
      "CLS_LOSS_WEIGHT:  0.4839868841977638\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1630\n",
      "fn:  120\n",
      "tn:  2074\n",
      "fp:  160\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3704\n",
      "EPOCH 126\n",
      "   TRAIN | Label 1 loss: 35.5561 ; P: 0.7679 ; R: 0.7931 ; F1: 0.7803 ; Acc: 0.9869\n",
      "           Label 2 loss: 4.1665 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 1 loss: 60.0047 ; P: 0.6472 ; R: 0.8474 ; F1: 0.7339 ; Acc: 0.9821\n",
      "           Label 2 loss: 632.7264 ; P: 0.9106 ; R: 0.9314 ; F1: 0.9209 ; Acc: 0.9297\n",
      "2023-01-25 06:23:24.334031\n",
      "counter:  53\n",
      "2023-01-25 06:23:24.334031\n",
      "EPOCH 127\n",
      "TAG_LOSS_WEIGHT:  0.51595886861332\n",
      "CLS_LOSS_WEIGHT:  0.48404113138668003\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2209\n",
      "fp:  3\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3972\n",
      "tp:  1628\n",
      "fn:  122\n",
      "tn:  2079\n",
      "fp:  155\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3707\n",
      "EPOCH 127\n",
      "   TRAIN | Label 1 loss: 35.3782 ; P: 0.767 ; R: 0.7955 ; F1: 0.781 ; Acc: 0.9869\n",
      "           Label 2 loss: 3.9503 ; P: 0.9983 ; R: 0.9983 ; F1: 0.9983 ; Acc: 0.9985\n",
      "    TEST | Label 1 loss: 60.7644 ; P: 0.6406 ; R: 0.8537 ; F1: 0.732 ; Acc: 0.9818\n",
      "           Label 2 loss: 625.9896 ; P: 0.9131 ; R: 0.9303 ; F1: 0.9216 ; Acc: 0.9305\n",
      "2023-01-25 06:27:31.450356\n",
      "counter:  54\n",
      "2023-01-25 06:27:31.451463\n",
      "EPOCH 128\n",
      "TAG_LOSS_WEIGHT:  0.5158448712288107\n",
      "CLS_LOSS_WEIGHT:  0.48415512877118944\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1627\n",
      "fn:  123\n",
      "tn:  2085\n",
      "fp:  149\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3712\n",
      "EPOCH 128\n",
      "   TRAIN | Label 1 loss: 35.4637 ; P: 0.7718 ; R: 0.8013 ; F1: 0.7863 ; Acc: 0.9872\n",
      "           Label 2 loss: 3.0125 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 60.5912 ; P: 0.6434 ; R: 0.8523 ; F1: 0.7332 ; Acc: 0.982\n",
      "           Label 2 loss: 620.4642 ; P: 0.9161 ; R: 0.9297 ; F1: 0.9229 ; Acc: 0.9317\n",
      "2023-01-25 06:31:39.313168\n",
      "counter:  55\n",
      "2023-01-25 06:31:39.313168\n",
      "EPOCH 129\n",
      "TAG_LOSS_WEIGHT:  0.5159272388955899\n",
      "CLS_LOSS_WEIGHT:  0.48407276110441\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2209\n",
      "fp:  3\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1619\n",
      "fn:  131\n",
      "tn:  2097\n",
      "fp:  137\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3716\n",
      "EPOCH 129\n",
      "   TRAIN | Label 1 loss: 35.4467 ; P: 0.7659 ; R: 0.7981 ; F1: 0.7817 ; Acc: 0.9869\n",
      "           Label 2 loss: 3.424 ; P: 0.9983 ; R: 1.0 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 1 loss: 61.2018 ; P: 0.6419 ; R: 0.8547 ; F1: 0.7332 ; Acc: 0.9819\n",
      "           Label 2 loss: 616.0541 ; P: 0.922 ; R: 0.9251 ; F1: 0.9236 ; Acc: 0.9327\n",
      "2023-01-25 06:35:46.649053\n",
      "counter:  56\n",
      "2023-01-25 06:35:46.650080\n",
      "EPOCH 130\n",
      "TAG_LOSS_WEIGHT:  0.515905348625637\n",
      "CLS_LOSS_WEIGHT:  0.48409465137436297\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1616\n",
      "fn:  134\n",
      "tn:  2100\n",
      "fp:  134\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3716\n",
      "EPOCH 130\n",
      "   TRAIN | Label 1 loss: 34.9709 ; P: 0.772 ; R: 0.8033 ; F1: 0.7873 ; Acc: 0.9873\n",
      "           Label 2 loss: 4.5032 ; P: 0.9989 ; R: 1.0 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 60.492 ; P: 0.6506 ; R: 0.847 ; F1: 0.7359 ; Acc: 0.9823\n",
      "           Label 2 loss: 612.5773 ; P: 0.9234 ; R: 0.9234 ; F1: 0.9234 ; Acc: 0.9327\n",
      "2023-01-25 06:39:54.184505\n",
      "counter:  57\n",
      "2023-01-25 06:39:54.185516\n",
      "EPOCH 131\n",
      "TAG_LOSS_WEIGHT:  0.5155549074255754\n",
      "CLS_LOSS_WEIGHT:  0.48444509257442464\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1620\n",
      "fn:  130\n",
      "tn:  2093\n",
      "fp:  141\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3713\n",
      "EPOCH 131\n",
      "   TRAIN | Label 1 loss: 35.0506 ; P: 0.7718 ; R: 0.7968 ; F1: 0.7841 ; Acc: 0.9872\n",
      "           Label 2 loss: 2.2487 ; P: 0.9994 ; R: 1.0 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 61.3739 ; P: 0.6395 ; R: 0.858 ; F1: 0.7328 ; Acc: 0.9818\n",
      "           Label 2 loss: 620.7846 ; P: 0.9199 ; R: 0.9257 ; F1: 0.9228 ; Acc: 0.932\n",
      "2023-01-25 06:44:02.503395\n",
      "counter:  58\n",
      "2023-01-25 06:44:02.503395\n",
      "EPOCH 132\n",
      "TAG_LOSS_WEIGHT:  0.5156665439554585\n",
      "CLS_LOSS_WEIGHT:  0.48433345604454137\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1623\n",
      "fn:  127\n",
      "tn:  2089\n",
      "fp:  145\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3712\n",
      "EPOCH 132\n",
      "   TRAIN | Label 1 loss: 34.8868 ; P: 0.7707 ; R: 0.8004 ; F1: 0.7853 ; Acc: 0.9872\n",
      "           Label 2 loss: 2.4784 ; P: 1.0 ; R: 0.9989 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 60.5453 ; P: 0.6505 ; R: 0.8508 ; F1: 0.7373 ; Acc: 0.9824\n",
      "           Label 2 loss: 623.6171 ; P: 0.918 ; R: 0.9274 ; F1: 0.9227 ; Acc: 0.9317\n",
      "2023-01-25 06:48:09.562493\n",
      "counter:  59\n",
      "2023-01-25 06:48:09.562493\n",
      "EPOCH 133\n",
      "TAG_LOSS_WEIGHT:  0.5155517198131127\n",
      "CLS_LOSS_WEIGHT:  0.4844482801868873\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3973\n",
      "tp:  1620\n",
      "fn:  130\n",
      "tn:  2106\n",
      "fp:  128\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3726\n",
      "EPOCH 133\n",
      "   TRAIN | Label 1 loss: 34.3559 ; P: 0.7764 ; R: 0.8085 ; F1: 0.7921 ; Acc: 0.9876\n",
      "           Label 2 loss: 4.5209 ; P: 0.9989 ; R: 0.9983 ; F1: 0.9986 ; Acc: 0.9987\n",
      "    TEST | Label 1 loss: 60.3423 ; P: 0.6524 ; R: 0.8477 ; F1: 0.7373 ; Acc: 0.9824\n",
      "           Label 2 loss: 607.5862 ; P: 0.9268 ; R: 0.9257 ; F1: 0.9262 ; Acc: 0.9352\n",
      "2023-01-25 06:52:17.643209\n",
      "counter:  0\n",
      "2023-01-25 06:52:19.414483\n",
      "EPOCH 134\n",
      "TAG_LOSS_WEIGHT:  0.5151437552011405\n",
      "CLS_LOSS_WEIGHT:  0.4848562447988594\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1620\n",
      "fn:  130\n",
      "tn:  2098\n",
      "fp:  136\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3718\n",
      "EPOCH 134\n",
      "   TRAIN | Label 1 loss: 33.9975 ; P: 0.7761 ; R: 0.8094 ; F1: 0.7924 ; Acc: 0.9876\n",
      "           Label 2 loss: 3.0785 ; P: 0.9989 ; R: 0.9989 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 1 loss: 60.5073 ; P: 0.6532 ; R: 0.8474 ; F1: 0.7377 ; Acc: 0.9825\n",
      "           Label 2 loss: 617.5178 ; P: 0.9226 ; R: 0.9257 ; F1: 0.9241 ; Acc: 0.9332\n",
      "2023-01-25 06:56:29.074007\n",
      "counter:  1\n",
      "2023-01-25 06:56:29.074007\n",
      "EPOCH 135\n",
      "TAG_LOSS_WEIGHT:  0.5149457422326652\n",
      "CLS_LOSS_WEIGHT:  0.48505425776733496\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2082\n",
      "fp:  152\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3708\n",
      "EPOCH 135\n",
      "   TRAIN | Label 1 loss: 34.0878 ; P: 0.7768 ; R: 0.8078 ; F1: 0.792 ; Acc: 0.9876\n",
      "           Label 2 loss: 4.192 ; P: 0.9989 ; R: 0.9989 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 1 loss: 61.2933 ; P: 0.6406 ; R: 0.858 ; F1: 0.7336 ; Acc: 0.9819\n",
      "           Label 2 loss: 625.4425 ; P: 0.9145 ; R: 0.9291 ; F1: 0.9218 ; Acc: 0.9307\n",
      "2023-01-25 07:00:36.625854\n",
      "counter:  2\n",
      "2023-01-25 07:00:36.625854\n",
      "EPOCH 136\n",
      "TAG_LOSS_WEIGHT:  0.5149755719816165\n",
      "CLS_LOSS_WEIGHT:  0.4850244280183835\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1617\n",
      "fn:  133\n",
      "tn:  2098\n",
      "fp:  136\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3715\n",
      "EPOCH 136\n",
      "   TRAIN | Label 1 loss: 33.8396 ; P: 0.7815 ; R: 0.8148 ; F1: 0.7978 ; Acc: 0.9879\n",
      "           Label 2 loss: 3.6112 ; P: 0.9989 ; R: 0.9994 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 1 loss: 60.9603 ; P: 0.6508 ; R: 0.8496 ; F1: 0.7371 ; Acc: 0.9824\n",
      "           Label 2 loss: 622.3029 ; P: 0.9224 ; R: 0.924 ; F1: 0.9232 ; Acc: 0.9325\n",
      "2023-01-25 07:04:43.456455\n",
      "counter:  3\n",
      "2023-01-25 07:04:43.457463\n",
      "EPOCH 137\n",
      "TAG_LOSS_WEIGHT:  0.5148277074316536\n",
      "CLS_LOSS_WEIGHT:  0.48517229256834654\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1622\n",
      "fn:  128\n",
      "tn:  2093\n",
      "fp:  141\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3715\n",
      "EPOCH 137\n",
      "   TRAIN | Label 1 loss: 33.4078 ; P: 0.778 ; R: 0.8106 ; F1: 0.794 ; Acc: 0.9877\n",
      "           Label 2 loss: 2.6303 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 59.8097 ; P: 0.6629 ; R: 0.8404 ; F1: 0.7412 ; Acc: 0.9829\n",
      "           Label 2 loss: 627.2999 ; P: 0.92 ; R: 0.9269 ; F1: 0.9234 ; Acc: 0.9325\n",
      "2023-01-25 07:08:51.777727\n",
      "counter:  4\n",
      "2023-01-25 07:08:51.778730\n",
      "EPOCH 138\n",
      "TAG_LOSS_WEIGHT:  0.5145681601598734\n",
      "CLS_LOSS_WEIGHT:  0.4854318398401265\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1623\n",
      "fn:  127\n",
      "tn:  2083\n",
      "fp:  151\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3706\n",
      "EPOCH 138\n",
      "   TRAIN | Label 1 loss: 33.7075 ; P: 0.7825 ; R: 0.818 ; F1: 0.7999 ; Acc: 0.988\n",
      "           Label 2 loss: 3.8817 ; P: 1.0 ; R: 0.9989 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 60.6065 ; P: 0.6551 ; R: 0.8472 ; F1: 0.7388 ; Acc: 0.9826\n",
      "           Label 2 loss: 639.4951 ; P: 0.9149 ; R: 0.9274 ; F1: 0.9211 ; Acc: 0.9302\n",
      "2023-01-25 07:12:58.786728\n",
      "counter:  5\n",
      "2023-01-25 07:12:58.787725\n",
      "EPOCH 139\n",
      "TAG_LOSS_WEIGHT:  0.5147332541121815\n",
      "CLS_LOSS_WEIGHT:  0.4852667458878183\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1618\n",
      "fn:  132\n",
      "tn:  2102\n",
      "fp:  132\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3720\n",
      "EPOCH 139\n",
      "   TRAIN | Label 1 loss: 33.3301 ; P: 0.782 ; R: 0.8169 ; F1: 0.7991 ; Acc: 0.988\n",
      "           Label 2 loss: 3.038 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 61.7545 ; P: 0.6502 ; R: 0.8515 ; F1: 0.7373 ; Acc: 0.9823\n",
      "           Label 2 loss: 631.6163 ; P: 0.9246 ; R: 0.9246 ; F1: 0.9246 ; Acc: 0.9337\n",
      "2023-01-25 07:17:06.797816\n",
      "counter:  6\n",
      "2023-01-25 07:17:06.797816\n",
      "EPOCH 140\n",
      "TAG_LOSS_WEIGHT:  0.5145075728365844\n",
      "CLS_LOSS_WEIGHT:  0.4854924271634155\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1616\n",
      "fn:  134\n",
      "tn:  2101\n",
      "fp:  133\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3717\n",
      "EPOCH 140\n",
      "   TRAIN | Label 1 loss: 32.9776 ; P: 0.7778 ; R: 0.8139 ; F1: 0.7955 ; Acc: 0.9877\n",
      "           Label 2 loss: 2.5387 ; P: 0.9989 ; R: 0.9994 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 1 loss: 61.0559 ; P: 0.6585 ; R: 0.8455 ; F1: 0.7404 ; Acc: 0.9827\n",
      "           Label 2 loss: 632.1302 ; P: 0.924 ; R: 0.9234 ; F1: 0.9237 ; Acc: 0.933\n",
      "2023-01-25 07:21:16.201231\n",
      "counter:  7\n",
      "2023-01-25 07:21:16.202222\n",
      "EPOCH 141\n",
      "TAG_LOSS_WEIGHT:  0.514289130978225\n",
      "CLS_LOSS_WEIGHT:  0.485710869021775\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1620\n",
      "fn:  130\n",
      "tn:  2105\n",
      "fp:  129\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3725\n",
      "EPOCH 141\n",
      "   TRAIN | Label 1 loss: 32.7773 ; P: 0.7848 ; R: 0.8225 ; F1: 0.8032 ; Acc: 0.9882\n",
      "           Label 2 loss: 2.3649 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 60.9647 ; P: 0.66 ; R: 0.8457 ; F1: 0.7414 ; Acc: 0.9828\n",
      "           Label 2 loss: 629.1352 ; P: 0.9262 ; R: 0.9257 ; F1: 0.926 ; Acc: 0.935\n",
      "2023-01-25 07:25:23.518141\n",
      "counter:  8\n",
      "2023-01-25 07:25:23.519177\n",
      "EPOCH 142\n",
      "TAG_LOSS_WEIGHT:  0.5141627076481976\n",
      "CLS_LOSS_WEIGHT:  0.48583729235180245\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1623\n",
      "fn:  127\n",
      "tn:  2082\n",
      "fp:  152\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3705\n",
      "EPOCH 142\n",
      "   TRAIN | Label 1 loss: 32.5413 ; P: 0.7832 ; R: 0.8209 ; F1: 0.8016 ; Acc: 0.9881\n",
      "           Label 2 loss: 2.4321 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 60.9839 ; P: 0.6538 ; R: 0.8506 ; F1: 0.7393 ; Acc: 0.9825\n",
      "           Label 2 loss: 648.1461 ; P: 0.9144 ; R: 0.9274 ; F1: 0.9209 ; Acc: 0.93\n",
      "2023-01-25 07:29:31.624114\n",
      "counter:  9\n",
      "2023-01-25 07:29:31.624114\n",
      "EPOCH 143\n",
      "TAG_LOSS_WEIGHT:  0.5140082669980193\n",
      "CLS_LOSS_WEIGHT:  0.48599173300198073\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1621\n",
      "fn:  129\n",
      "tn:  2086\n",
      "fp:  148\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3707\n",
      "EPOCH 143\n",
      "   TRAIN | Label 1 loss: 32.3795 ; P: 0.7865 ; R: 0.8156 ; F1: 0.8008 ; Acc: 0.9881\n",
      "           Label 2 loss: 1.4387 ; P: 0.9994 ; R: 1.0 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 61.2758 ; P: 0.6555 ; R: 0.852 ; F1: 0.7409 ; Acc: 0.9827\n",
      "           Label 2 loss: 661.0216 ; P: 0.9163 ; R: 0.9263 ; F1: 0.9213 ; Acc: 0.9305\n",
      "2023-01-25 07:33:41.010616\n",
      "counter:  10\n",
      "2023-01-25 07:33:41.011617\n",
      "EPOCH 144\n",
      "TAG_LOSS_WEIGHT:  0.5139231539747583\n",
      "CLS_LOSS_WEIGHT:  0.48607684602524187\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1614\n",
      "fn:  136\n",
      "tn:  2102\n",
      "fp:  132\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3716\n",
      "EPOCH 144\n",
      "   TRAIN | Label 1 loss: 31.9019 ; P: 0.7854 ; R: 0.8206 ; F1: 0.8026 ; Acc: 0.9882\n",
      "           Label 2 loss: 1.8476 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 62.5617 ; P: 0.6469 ; R: 0.8556 ; F1: 0.7367 ; Acc: 0.9822\n",
      "           Label 2 loss: 652.9186 ; P: 0.9244 ; R: 0.9223 ; F1: 0.9233 ; Acc: 0.9327\n",
      "2023-01-25 07:37:46.966488\n",
      "counter:  11\n",
      "2023-01-25 07:37:46.966488\n",
      "EPOCH 145\n",
      "TAG_LOSS_WEIGHT:  0.5136086460241654\n",
      "CLS_LOSS_WEIGHT:  0.48639135397583444\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1622\n",
      "fn:  128\n",
      "tn:  2095\n",
      "fp:  139\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3717\n",
      "EPOCH 145\n",
      "   TRAIN | Label 1 loss: 31.4561 ; P: 0.7893 ; R: 0.8225 ; F1: 0.8055 ; Acc: 0.9884\n",
      "           Label 2 loss: 1.5819 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 59.6194 ; P: 0.6765 ; R: 0.8322 ; F1: 0.7464 ; Acc: 0.9835\n",
      "           Label 2 loss: 660.01 ; P: 0.9211 ; R: 0.9269 ; F1: 0.924 ; Acc: 0.933\n",
      "2023-01-25 07:41:54.269856\n",
      "counter:  12\n",
      "2023-01-25 07:41:54.270856\n",
      "EPOCH 146\n",
      "TAG_LOSS_WEIGHT:  0.5133289430690744\n",
      "CLS_LOSS_WEIGHT:  0.4866710569309256\n",
      "tp:  1763\n",
      "fn:  3\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3973\n",
      "tp:  1626\n",
      "fn:  124\n",
      "tn:  2065\n",
      "fp:  169\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3691\n",
      "EPOCH 146\n",
      "   TRAIN | Label 1 loss: 31.2636 ; P: 0.7896 ; R: 0.8178 ; F1: 0.8035 ; Acc: 0.9883\n",
      "           Label 2 loss: 3.1652 ; P: 0.9989 ; R: 0.9983 ; F1: 0.9986 ; Acc: 0.9987\n",
      "    TEST | Label 1 loss: 61.9141 ; P: 0.6477 ; R: 0.8573 ; F1: 0.7379 ; Acc: 0.9823\n",
      "           Label 2 loss: 687.2428 ; P: 0.9058 ; R: 0.9291 ; F1: 0.9173 ; Acc: 0.9265\n",
      "2023-01-25 07:46:02.238322\n",
      "counter:  13\n",
      "2023-01-25 07:46:02.238322\n",
      "EPOCH 147\n",
      "TAG_LOSS_WEIGHT:  0.5131724063505291\n",
      "CLS_LOSS_WEIGHT:  0.4868275936494709\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1619\n",
      "fn:  131\n",
      "tn:  2099\n",
      "fp:  135\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3718\n",
      "EPOCH 147\n",
      "   TRAIN | Label 1 loss: 30.8976 ; P: 0.7943 ; R: 0.8289 ; F1: 0.8112 ; Acc: 0.9887\n",
      "           Label 2 loss: 1.4267 ; P: 0.9994 ; R: 1.0 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 63.8246 ; P: 0.6376 ; R: 0.8682 ; F1: 0.7353 ; Acc: 0.9818\n",
      "           Label 2 loss: 663.1249 ; P: 0.923 ; R: 0.9251 ; F1: 0.9241 ; Acc: 0.9332\n",
      "2023-01-25 07:50:08.618356\n",
      "counter:  14\n",
      "2023-01-25 07:50:08.618356\n",
      "EPOCH 148\n",
      "TAG_LOSS_WEIGHT:  0.5129778926693542\n",
      "CLS_LOSS_WEIGHT:  0.48702210733064577\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1618\n",
      "fn:  132\n",
      "tn:  2101\n",
      "fp:  133\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3719\n",
      "EPOCH 148\n",
      "   TRAIN | Label 1 loss: 31.0669 ; P: 0.7919 ; R: 0.8312 ; F1: 0.8111 ; Acc: 0.9887\n",
      "           Label 2 loss: 3.6572 ; P: 0.9989 ; R: 0.9989 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 1 loss: 61.5 ; P: 0.666 ; R: 0.8448 ; F1: 0.7448 ; Acc: 0.9832\n",
      "           Label 2 loss: 657.1337 ; P: 0.924 ; R: 0.9246 ; F1: 0.9243 ; Acc: 0.9335\n",
      "2023-01-25 07:54:15.207986\n",
      "counter:  15\n",
      "2023-01-25 07:54:15.207986\n",
      "EPOCH 149\n",
      "TAG_LOSS_WEIGHT:  0.5130350252547989\n",
      "CLS_LOSS_WEIGHT:  0.4869649747452011\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1619\n",
      "fn:  131\n",
      "tn:  2097\n",
      "fp:  137\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3716\n",
      "EPOCH 149\n",
      "   TRAIN | Label 1 loss: 30.3223 ; P: 0.7968 ; R: 0.8376 ; F1: 0.8167 ; Acc: 0.989\n",
      "           Label 2 loss: 4.1128 ; P: 0.9989 ; R: 0.9989 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 1 loss: 61.7162 ; P: 0.6608 ; R: 0.8472 ; F1: 0.7425 ; Acc: 0.9829\n",
      "           Label 2 loss: 653.9183 ; P: 0.922 ; R: 0.9251 ; F1: 0.9236 ; Acc: 0.9327\n",
      "2023-01-25 07:58:22.043744\n",
      "counter:  16\n",
      "2023-01-25 07:58:22.043744\n",
      "EPOCH 150\n",
      "TAG_LOSS_WEIGHT:  0.5125543945988297\n",
      "CLS_LOSS_WEIGHT:  0.48744560540117016\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1618\n",
      "fn:  132\n",
      "tn:  2097\n",
      "fp:  137\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3715\n",
      "EPOCH 150\n",
      "   TRAIN | Label 1 loss: 30.2861 ; P: 0.7968 ; R: 0.835 ; F1: 0.8155 ; Acc: 0.9889\n",
      "           Label 2 loss: 2.2962 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 61.4133 ; P: 0.6713 ; R: 0.8416 ; F1: 0.7469 ; Acc: 0.9834\n",
      "           Label 2 loss: 664.5359 ; P: 0.9219 ; R: 0.9246 ; F1: 0.9233 ; Acc: 0.9325\n",
      "2023-01-25 08:02:29.403063\n",
      "counter:  17\n",
      "2023-01-25 08:02:29.405070\n",
      "EPOCH 151\n",
      "TAG_LOSS_WEIGHT:  0.5125775223644709\n",
      "CLS_LOSS_WEIGHT:  0.4874224776355292\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1620\n",
      "fn:  130\n",
      "tn:  2099\n",
      "fp:  135\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3719\n",
      "EPOCH 151\n",
      "   TRAIN | Label 1 loss: 29.7824 ; P: 0.7984 ; R: 0.8354 ; F1: 0.8165 ; Acc: 0.989\n",
      "           Label 2 loss: 1.1639 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 61.9674 ; P: 0.6669 ; R: 0.8472 ; F1: 0.7463 ; Acc: 0.9832\n",
      "           Label 2 loss: 669.7516 ; P: 0.9231 ; R: 0.9257 ; F1: 0.9244 ; Acc: 0.9335\n",
      "2023-01-25 08:06:36.424317\n",
      "counter:  18\n",
      "2023-01-25 08:06:36.425375\n",
      "EPOCH 152\n",
      "TAG_LOSS_WEIGHT:  0.5122852935782974\n",
      "CLS_LOSS_WEIGHT:  0.48771470642170256\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1621\n",
      "fn:  129\n",
      "tn:  2089\n",
      "fp:  145\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3710\n",
      "EPOCH 152\n",
      "   TRAIN | Label 1 loss: 29.6069 ; P: 0.8025 ; R: 0.8423 ; F1: 0.8219 ; Acc: 0.9893\n",
      "           Label 2 loss: 1.0667 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 62.5794 ; P: 0.6576 ; R: 0.8564 ; F1: 0.7439 ; Acc: 0.9828\n",
      "           Label 2 loss: 687.8739 ; P: 0.9179 ; R: 0.9263 ; F1: 0.9221 ; Acc: 0.9312\n",
      "2023-01-25 08:10:43.765819\n",
      "counter:  19\n",
      "2023-01-25 08:10:43.766818\n",
      "EPOCH 153\n",
      "TAG_LOSS_WEIGHT:  0.5121782499303137\n",
      "CLS_LOSS_WEIGHT:  0.48782175006968626\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1616\n",
      "fn:  134\n",
      "tn:  2098\n",
      "fp:  136\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3714\n",
      "EPOCH 153\n",
      "   TRAIN | Label 1 loss: 29.3727 ; P: 0.8057 ; R: 0.8415 ; F1: 0.8232 ; Acc: 0.9894\n",
      "           Label 2 loss: 0.8289 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 62.4813 ; P: 0.6674 ; R: 0.8491 ; F1: 0.7473 ; Acc: 0.9833\n",
      "           Label 2 loss: 683.908 ; P: 0.9224 ; R: 0.9234 ; F1: 0.9229 ; Acc: 0.9322\n",
      "2023-01-25 08:14:51.179350\n",
      "counter:  20\n",
      "2023-01-25 08:14:51.180346\n",
      "EPOCH 154\n",
      "TAG_LOSS_WEIGHT:  0.5120372336305788\n",
      "CLS_LOSS_WEIGHT:  0.48796276636942104\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1618\n",
      "fn:  132\n",
      "tn:  2104\n",
      "fp:  130\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3722\n",
      "EPOCH 154\n",
      "   TRAIN | Label 1 loss: 28.6574 ; P: 0.8002 ; R: 0.84 ; F1: 0.8196 ; Acc: 0.9892\n",
      "           Label 2 loss: 0.7265 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 62.445 ; P: 0.6654 ; R: 0.8559 ; F1: 0.7487 ; Acc: 0.9833\n",
      "           Label 2 loss: 678.8967 ; P: 0.9256 ; R: 0.9246 ; F1: 0.9251 ; Acc: 0.9342\n",
      "2023-01-25 08:18:58.016461\n",
      "counter:  21\n",
      "2023-01-25 08:18:58.018462\n",
      "EPOCH 155\n",
      "TAG_LOSS_WEIGHT:  0.5116013919126118\n",
      "CLS_LOSS_WEIGHT:  0.48839860808738816\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1614\n",
      "fn:  136\n",
      "tn:  2108\n",
      "fp:  126\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3722\n",
      "EPOCH 155\n",
      "   TRAIN | Label 1 loss: 28.4676 ; P: 0.8071 ; R: 0.8479 ; F1: 0.827 ; Acc: 0.9896\n",
      "           Label 2 loss: 1.2991 ; P: 0.9989 ; R: 1.0 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 62.8457 ; P: 0.668 ; R: 0.8542 ; F1: 0.7497 ; Acc: 0.9834\n",
      "           Label 2 loss: 685.6587 ; P: 0.9276 ; R: 0.9223 ; F1: 0.9249 ; Acc: 0.9342\n",
      "2023-01-25 08:23:05.686685\n",
      "counter:  22\n",
      "2023-01-25 08:23:05.687698\n",
      "EPOCH 156\n",
      "TAG_LOSS_WEIGHT:  0.5114782053534808\n",
      "CLS_LOSS_WEIGHT:  0.48852179464651935\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1610\n",
      "fn:  140\n",
      "tn:  2112\n",
      "fp:  122\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3722\n",
      "EPOCH 156\n",
      "   TRAIN | Label 1 loss: 27.8983 ; P: 0.8081 ; R: 0.8489 ; F1: 0.828 ; Acc: 0.9897\n",
      "           Label 2 loss: 2.5698 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 63.1555 ; P: 0.6695 ; R: 0.8515 ; F1: 0.7496 ; Acc: 0.9834\n",
      "           Label 2 loss: 665.4018 ; P: 0.9296 ; R: 0.92 ; F1: 0.9248 ; Acc: 0.9342\n",
      "2023-01-25 08:27:12.913871\n",
      "counter:  23\n",
      "2023-01-25 08:27:12.914865\n",
      "EPOCH 157\n",
      "TAG_LOSS_WEIGHT:  0.5111104879054662\n",
      "CLS_LOSS_WEIGHT:  0.48888951209453385\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1620\n",
      "fn:  130\n",
      "tn:  2099\n",
      "fp:  135\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3719\n",
      "EPOCH 157\n",
      "   TRAIN | Label 1 loss: 27.431 ; P: 0.8159 ; R: 0.853 ; F1: 0.834 ; Acc: 0.9901\n",
      "           Label 2 loss: 1.1865 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 63.5709 ; P: 0.6713 ; R: 0.851 ; F1: 0.7506 ; Acc: 0.9835\n",
      "           Label 2 loss: 690.1704 ; P: 0.9231 ; R: 0.9257 ; F1: 0.9244 ; Acc: 0.9335\n",
      "2023-01-25 08:31:20.305317\n",
      "counter:  24\n",
      "2023-01-25 08:31:20.306316\n",
      "EPOCH 158\n",
      "TAG_LOSS_WEIGHT:  0.5108582266603402\n",
      "CLS_LOSS_WEIGHT:  0.4891417733396597\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2209\n",
      "fp:  3\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3973\n",
      "tp:  1615\n",
      "fn:  135\n",
      "tn:  2106\n",
      "fp:  128\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3721\n",
      "EPOCH 158\n",
      "   TRAIN | Label 1 loss: 27.6956 ; P: 0.8081 ; R: 0.853 ; F1: 0.8299 ; Acc: 0.9898\n",
      "           Label 2 loss: 4.8919 ; P: 0.9983 ; R: 0.9989 ; F1: 0.9986 ; Acc: 0.9987\n",
      "    TEST | Label 1 loss: 62.7535 ; P: 0.6812 ; R: 0.8409 ; F1: 0.7527 ; Acc: 0.9839\n",
      "           Label 2 loss: 661.6615 ; P: 0.9266 ; R: 0.9229 ; F1: 0.9247 ; Acc: 0.934\n",
      "2023-01-25 08:35:27.473937\n",
      "counter:  25\n",
      "2023-01-25 08:35:27.473937\n",
      "EPOCH 159\n",
      "TAG_LOSS_WEIGHT:  0.5109261943579135\n",
      "CLS_LOSS_WEIGHT:  0.48907380564208647\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1604\n",
      "fn:  146\n",
      "tn:  2128\n",
      "fp:  106\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3732\n",
      "EPOCH 159\n",
      "   TRAIN | Label 1 loss: 26.9554 ; P: 0.8178 ; R: 0.8549 ; F1: 0.836 ; Acc: 0.9902\n",
      "           Label 2 loss: 3.4394 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 65.1999 ; P: 0.6622 ; R: 0.8566 ; F1: 0.747 ; Acc: 0.9831\n",
      "           Label 2 loss: 668.538 ; P: 0.938 ; R: 0.9166 ; F1: 0.9272 ; Acc: 0.9367\n",
      "2023-01-25 08:39:33.661088\n",
      "counter:  0\n",
      "2023-01-25 08:39:35.541759\n",
      "EPOCH 160\n",
      "TAG_LOSS_WEIGHT:  0.510528975212228\n",
      "CLS_LOSS_WEIGHT:  0.48947102478777205\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1616\n",
      "fn:  134\n",
      "tn:  2105\n",
      "fp:  129\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3721\n",
      "EPOCH 160\n",
      "   TRAIN | Label 1 loss: 26.6197 ; P: 0.8146 ; R: 0.8582 ; F1: 0.8358 ; Acc: 0.9901\n",
      "           Label 2 loss: 1.7889 ; P: 1.0 ; R: 0.9989 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 63.8015 ; P: 0.6701 ; R: 0.8503 ; F1: 0.7495 ; Acc: 0.9835\n",
      "           Label 2 loss: 662.3678 ; P: 0.9261 ; R: 0.9234 ; F1: 0.9247 ; Acc: 0.934\n",
      "2023-01-25 08:43:45.485403\n",
      "counter:  1\n",
      "2023-01-25 08:43:45.486412\n",
      "EPOCH 161\n",
      "TAG_LOSS_WEIGHT:  0.5103693435977298\n",
      "CLS_LOSS_WEIGHT:  0.4896306564022703\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1611\n",
      "fn:  139\n",
      "tn:  2114\n",
      "fp:  120\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3725\n",
      "EPOCH 161\n",
      "   TRAIN | Label 1 loss: 26.2302 ; P: 0.8217 ; R: 0.8611 ; F1: 0.8409 ; Acc: 0.9905\n",
      "           Label 2 loss: 1.2386 ; P: 0.9994 ; R: 1.0 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 64.589 ; P: 0.6803 ; R: 0.847 ; F1: 0.7546 ; Acc: 0.984\n",
      "           Label 2 loss: 677.8355 ; P: 0.9307 ; R: 0.9206 ; F1: 0.9256 ; Acc: 0.935\n",
      "2023-01-25 08:47:53.819400\n",
      "counter:  2\n",
      "2023-01-25 08:47:53.820565\n",
      "EPOCH 162\n",
      "TAG_LOSS_WEIGHT:  0.5101517053455396\n",
      "CLS_LOSS_WEIGHT:  0.48984829465446045\n",
      "tp:  1762\n",
      "fn:  4\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1632\n",
      "fn:  118\n",
      "tn:  2073\n",
      "fp:  161\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3705\n",
      "EPOCH 162\n",
      "   TRAIN | Label 1 loss: 26.2915 ; P: 0.82 ; R: 0.8611 ; F1: 0.84 ; Acc: 0.9904\n",
      "           Label 2 loss: 2.0559 ; P: 1.0 ; R: 0.9977 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 1 loss: 63.391 ; P: 0.6772 ; R: 0.8503 ; F1: 0.7539 ; Acc: 0.9838\n",
      "           Label 2 loss: 700.575 ; P: 0.9102 ; R: 0.9326 ; F1: 0.9213 ; Acc: 0.93\n",
      "2023-01-25 08:52:01.067695\n",
      "counter:  3\n",
      "2023-01-25 08:52:01.068615\n",
      "EPOCH 163\n",
      "TAG_LOSS_WEIGHT:  0.5101725811453842\n",
      "CLS_LOSS_WEIGHT:  0.48982741885461584\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1618\n",
      "fn:  132\n",
      "tn:  2099\n",
      "fp:  135\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3717\n",
      "EPOCH 163\n",
      "   TRAIN | Label 1 loss: 25.6131 ; P: 0.8225 ; R: 0.8591 ; F1: 0.8404 ; Acc: 0.9904\n",
      "           Label 2 loss: 1.0586 ; P: 0.9994 ; R: 1.0 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 66.1405 ; P: 0.6643 ; R: 0.8614 ; F1: 0.7501 ; Acc: 0.9833\n",
      "           Label 2 loss: 680.5068 ; P: 0.923 ; R: 0.9246 ; F1: 0.9238 ; Acc: 0.933\n",
      "2023-01-25 08:56:08.059854\n",
      "counter:  4\n",
      "2023-01-25 08:56:08.060849\n",
      "EPOCH 164\n",
      "TAG_LOSS_WEIGHT:  0.5097979323990236\n",
      "CLS_LOSS_WEIGHT:  0.4902020676009765\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1619\n",
      "fn:  131\n",
      "tn:  2099\n",
      "fp:  135\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3718\n",
      "EPOCH 164\n",
      "   TRAIN | Label 1 loss: 25.2161 ; P: 0.832 ; R: 0.8696 ; F1: 0.8504 ; Acc: 0.991\n",
      "           Label 2 loss: 1.111 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 64.7337 ; P: 0.6717 ; R: 0.8576 ; F1: 0.7533 ; Acc: 0.9837\n",
      "           Label 2 loss: 684.9716 ; P: 0.923 ; R: 0.9251 ; F1: 0.9241 ; Acc: 0.9332\n",
      "2023-01-25 09:00:14.420316\n",
      "counter:  5\n",
      "2023-01-25 09:00:14.420316\n",
      "EPOCH 165\n",
      "TAG_LOSS_WEIGHT:  0.5095700656016322\n",
      "CLS_LOSS_WEIGHT:  0.49042993439836785\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1590\n",
      "fn:  160\n",
      "tn:  2130\n",
      "fp:  104\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3720\n",
      "EPOCH 165\n",
      "   TRAIN | Label 1 loss: 24.5828 ; P: 0.8343 ; R: 0.8686 ; F1: 0.8511 ; Acc: 0.9911\n",
      "           Label 2 loss: 1.6702 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 67.764 ; P: 0.6724 ; R: 0.8551 ; F1: 0.7528 ; Acc: 0.9837\n",
      "           Label 2 loss: 690.204 ; P: 0.9386 ; R: 0.9086 ; F1: 0.9233 ; Acc: 0.9337\n",
      "2023-01-25 09:04:21.003022\n",
      "counter:  6\n",
      "2023-01-25 09:04:21.003022\n",
      "EPOCH 166\n",
      "TAG_LOSS_WEIGHT:  0.5092021894012141\n",
      "CLS_LOSS_WEIGHT:  0.49079781059878586\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1612\n",
      "fn:  138\n",
      "tn:  2108\n",
      "fp:  126\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3720\n",
      "EPOCH 166\n",
      "   TRAIN | Label 1 loss: 24.3822 ; P: 0.8303 ; R: 0.8752 ; F1: 0.8521 ; Acc: 0.9911\n",
      "           Label 2 loss: 1.954 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 65.6811 ; P: 0.6787 ; R: 0.8503 ; F1: 0.7549 ; Acc: 0.9839\n",
      "           Label 2 loss: 665.8931 ; P: 0.9275 ; R: 0.9211 ; F1: 0.9243 ; Acc: 0.9337\n",
      "2023-01-25 09:08:27.535163\n",
      "counter:  7\n",
      "2023-01-25 09:08:27.536205\n",
      "EPOCH 167\n",
      "TAG_LOSS_WEIGHT:  0.5090841676500266\n",
      "CLS_LOSS_WEIGHT:  0.4909158323499733\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1617\n",
      "fn:  133\n",
      "tn:  2098\n",
      "fp:  136\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3715\n",
      "EPOCH 167\n",
      "   TRAIN | Label 1 loss: 24.6769 ; P: 0.8314 ; R: 0.8717 ; F1: 0.851 ; Acc: 0.9911\n",
      "           Label 2 loss: 1.799 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 65.0359 ; P: 0.678 ; R: 0.851 ; F1: 0.7547 ; Acc: 0.9839\n",
      "           Label 2 loss: 667.3087 ; P: 0.9224 ; R: 0.924 ; F1: 0.9232 ; Acc: 0.9325\n",
      "2023-01-25 09:12:34.656000\n",
      "counter:  8\n",
      "2023-01-25 09:12:34.656991\n",
      "EPOCH 168\n",
      "TAG_LOSS_WEIGHT:  0.5092527875504274\n",
      "CLS_LOSS_WEIGHT:  0.49074721244957276\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1603\n",
      "fn:  147\n",
      "tn:  2119\n",
      "fp:  115\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3722\n",
      "EPOCH 168\n",
      "   TRAIN | Label 1 loss: 23.6393 ; P: 0.8404 ; R: 0.8789 ; F1: 0.8592 ; Acc: 0.9916\n",
      "           Label 2 loss: 1.6801 ; P: 0.9994 ; R: 1.0 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 69.6664 ; P: 0.6604 ; R: 0.8648 ; F1: 0.7489 ; Acc: 0.9831\n",
      "           Label 2 loss: 667.1477 ; P: 0.9331 ; R: 0.916 ; F1: 0.9245 ; Acc: 0.9342\n",
      "2023-01-25 09:16:41.859441\n",
      "counter:  9\n",
      "2023-01-25 09:16:41.859441\n",
      "EPOCH 169\n",
      "TAG_LOSS_WEIGHT:  0.508676298312771\n",
      "CLS_LOSS_WEIGHT:  0.4913237016872291\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1615\n",
      "fn:  135\n",
      "tn:  2106\n",
      "fp:  128\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3721\n",
      "EPOCH 169\n",
      "   TRAIN | Label 1 loss: 22.977 ; P: 0.8425 ; R: 0.8807 ; F1: 0.8612 ; Acc: 0.9917\n",
      "           Label 2 loss: 2.617 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 67.6928 ; P: 0.6745 ; R: 0.8547 ; F1: 0.754 ; Acc: 0.9838\n",
      "           Label 2 loss: 673.9986 ; P: 0.9266 ; R: 0.9229 ; F1: 0.9247 ; Acc: 0.934\n",
      "2023-01-25 09:20:48.523535\n",
      "counter:  10\n",
      "2023-01-25 09:20:48.524537\n",
      "EPOCH 170\n",
      "TAG_LOSS_WEIGHT:  0.5082941049740749\n",
      "CLS_LOSS_WEIGHT:  0.49170589502592504\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1610\n",
      "fn:  140\n",
      "tn:  2108\n",
      "fp:  126\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3718\n",
      "EPOCH 170\n",
      "   TRAIN | Label 1 loss: 22.5948 ; P: 0.8459 ; R: 0.8832 ; F1: 0.8642 ; Acc: 0.9919\n",
      "           Label 2 loss: 2.104 ; P: 0.9989 ; R: 0.9989 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 1 loss: 67.7616 ; P: 0.6864 ; R: 0.8455 ; F1: 0.7577 ; Acc: 0.9843\n",
      "           Label 2 loss: 665.5312 ; P: 0.9274 ; R: 0.92 ; F1: 0.9237 ; Acc: 0.9332\n",
      "2023-01-25 09:24:54.931685\n",
      "counter:  11\n",
      "2023-01-25 09:24:54.931685\n",
      "EPOCH 171\n",
      "TAG_LOSS_WEIGHT:  0.5080981888735745\n",
      "CLS_LOSS_WEIGHT:  0.49190181112642556\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1609\n",
      "fn:  141\n",
      "tn:  2109\n",
      "fp:  125\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3718\n",
      "EPOCH 171\n",
      "   TRAIN | Label 1 loss: 22.4296 ; P: 0.8512 ; R: 0.8871 ; F1: 0.8688 ; Acc: 0.9922\n",
      "           Label 2 loss: 0.4734 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 67.8632 ; P: 0.6799 ; R: 0.8508 ; F1: 0.7558 ; Acc: 0.984\n",
      "           Label 2 loss: 675.6887 ; P: 0.9279 ; R: 0.9194 ; F1: 0.9237 ; Acc: 0.9332\n",
      "2023-01-25 09:29:03.130782\n",
      "counter:  12\n",
      "2023-01-25 09:29:03.130782\n",
      "EPOCH 172\n",
      "TAG_LOSS_WEIGHT:  0.5080348951969164\n",
      "CLS_LOSS_WEIGHT:  0.49196510480308353\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1606\n",
      "fn:  144\n",
      "tn:  2111\n",
      "fp:  123\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3717\n",
      "EPOCH 172\n",
      "   TRAIN | Label 1 loss: 22.0498 ; P: 0.8471 ; R: 0.8842 ; F1: 0.8653 ; Acc: 0.9919\n",
      "           Label 2 loss: 0.4187 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 68.0797 ; P: 0.6827 ; R: 0.8506 ; F1: 0.7575 ; Acc: 0.9841\n",
      "           Label 2 loss: 684.0489 ; P: 0.9289 ; R: 0.9177 ; F1: 0.9233 ; Acc: 0.933\n",
      "2023-01-25 09:33:11.375332\n",
      "counter:  13\n",
      "2023-01-25 09:33:11.376351\n",
      "EPOCH 173\n",
      "TAG_LOSS_WEIGHT:  0.5078321512767676\n",
      "CLS_LOSS_WEIGHT:  0.4921678487232324\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1609\n",
      "fn:  141\n",
      "tn:  2116\n",
      "fp:  118\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3725\n",
      "EPOCH 173\n",
      "   TRAIN | Label 1 loss: 21.8363 ; P: 0.8504 ; R: 0.8859 ; F1: 0.8678 ; Acc: 0.9921\n",
      "           Label 2 loss: 2.1054 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 1 loss: 68.7184 ; P: 0.6879 ; R: 0.847 ; F1: 0.7592 ; Acc: 0.9844\n",
      "           Label 2 loss: 684.885 ; P: 0.9317 ; R: 0.9194 ; F1: 0.9255 ; Acc: 0.935\n",
      "2023-01-25 09:37:20.005914\n",
      "counter:  14\n",
      "2023-01-25 09:37:20.005914\n",
      "EPOCH 174\n",
      "TAG_LOSS_WEIGHT:  0.5076924529430392\n",
      "CLS_LOSS_WEIGHT:  0.49230754705696084\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1609\n",
      "fn:  141\n",
      "tn:  2116\n",
      "fp:  118\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3725\n",
      "EPOCH 174\n",
      "   TRAIN | Label 1 loss: 21.2221 ; P: 0.8502 ; R: 0.8895 ; F1: 0.8694 ; Acc: 0.9922\n",
      "           Label 2 loss: 1.6994 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 67.9441 ; P: 0.688 ; R: 0.8462 ; F1: 0.759 ; Acc: 0.9844\n",
      "           Label 2 loss: 686.5446 ; P: 0.9317 ; R: 0.9194 ; F1: 0.9255 ; Acc: 0.935\n",
      "2023-01-25 09:41:27.096259\n",
      "counter:  15\n",
      "2023-01-25 09:41:27.096259\n",
      "EPOCH 175\n",
      "TAG_LOSS_WEIGHT:  0.5073769370912575\n",
      "CLS_LOSS_WEIGHT:  0.4926230629087426\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1606\n",
      "fn:  144\n",
      "tn:  2113\n",
      "fp:  121\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3719\n",
      "EPOCH 175\n",
      "   TRAIN | Label 1 loss: 20.8749 ; P: 0.8558 ; R: 0.8899 ; F1: 0.8725 ; Acc: 0.9924\n",
      "           Label 2 loss: 1.0655 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 70.4463 ; P: 0.6789 ; R: 0.8566 ; F1: 0.7575 ; Acc: 0.984\n",
      "           Label 2 loss: 689.6104 ; P: 0.9299 ; R: 0.9177 ; F1: 0.9238 ; Acc: 0.9335\n",
      "2023-01-25 09:45:34.693846\n",
      "counter:  16\n",
      "2023-01-25 09:45:34.694853\n",
      "EPOCH 176\n",
      "TAG_LOSS_WEIGHT:  0.5072066607635207\n",
      "CLS_LOSS_WEIGHT:  0.4927933392364793\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1599\n",
      "fn:  151\n",
      "tn:  2122\n",
      "fp:  112\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3721\n",
      "EPOCH 176\n",
      "   TRAIN | Label 1 loss: 20.7365 ; P: 0.8561 ; R: 0.8932 ; F1: 0.8743 ; Acc: 0.9925\n",
      "           Label 2 loss: 3.9098 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 1 loss: 70.7326 ; P: 0.6857 ; R: 0.8518 ; F1: 0.7598 ; Acc: 0.9843\n",
      "           Label 2 loss: 700.1797 ; P: 0.9345 ; R: 0.9137 ; F1: 0.924 ; Acc: 0.934\n",
      "2023-01-25 09:49:42.375396\n",
      "counter:  17\n",
      "2023-01-25 09:49:42.377393\n",
      "EPOCH 177\n",
      "TAG_LOSS_WEIGHT:  0.5070726060709669\n",
      "CLS_LOSS_WEIGHT:  0.49292739392903306\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1609\n",
      "fn:  141\n",
      "tn:  2106\n",
      "fp:  128\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3715\n",
      "EPOCH 177\n",
      "   TRAIN | Label 1 loss: 20.2232 ; P: 0.8575 ; R: 0.8959 ; F1: 0.8763 ; Acc: 0.9926\n",
      "           Label 2 loss: 2.9579 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 69.3056 ; P: 0.6872 ; R: 0.8525 ; F1: 0.761 ; Acc: 0.9844\n",
      "           Label 2 loss: 697.8966 ; P: 0.9263 ; R: 0.9194 ; F1: 0.9229 ; Acc: 0.9325\n",
      "2023-01-25 09:53:49.198355\n",
      "counter:  18\n",
      "2023-01-25 09:53:49.199367\n",
      "EPOCH 178\n",
      "TAG_LOSS_WEIGHT:  0.5068338619122305\n",
      "CLS_LOSS_WEIGHT:  0.4931661380877696\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1605\n",
      "fn:  145\n",
      "tn:  2110\n",
      "fp:  124\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3715\n",
      "EPOCH 178\n",
      "   TRAIN | Label 1 loss: 19.4629 ; P: 0.8644 ; R: 0.8994 ; F1: 0.8815 ; Acc: 0.9929\n",
      "           Label 2 loss: 0.3269 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 72.157 ; P: 0.6851 ; R: 0.8537 ; F1: 0.7602 ; Acc: 0.9843\n",
      "           Label 2 loss: 711.1891 ; P: 0.9283 ; R: 0.9171 ; F1: 0.9227 ; Acc: 0.9325\n",
      "2023-01-25 09:57:56.829686\n",
      "counter:  19\n",
      "2023-01-25 09:57:56.831791\n",
      "EPOCH 179\n",
      "TAG_LOSS_WEIGHT:  0.5064956149922825\n",
      "CLS_LOSS_WEIGHT:  0.49350438500771754\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1609\n",
      "fn:  141\n",
      "tn:  2109\n",
      "fp:  125\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3718\n",
      "EPOCH 179\n",
      "   TRAIN | Label 1 loss: 19.2909 ; P: 0.8604 ; R: 0.8996 ; F1: 0.8796 ; Acc: 0.9928\n",
      "           Label 2 loss: 1.6156 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 71.3483 ; P: 0.6933 ; R: 0.8445 ; F1: 0.7615 ; Acc: 0.9846\n",
      "           Label 2 loss: 711.5718 ; P: 0.9279 ; R: 0.9194 ; F1: 0.9237 ; Acc: 0.9332\n",
      "2023-01-25 10:02:04.648069\n",
      "counter:  20\n",
      "2023-01-25 10:02:04.649071\n",
      "EPOCH 180\n",
      "TAG_LOSS_WEIGHT:  0.5063921169127352\n",
      "CLS_LOSS_WEIGHT:  0.4936078830872646\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1604\n",
      "fn:  146\n",
      "tn:  2117\n",
      "fp:  117\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3721\n",
      "EPOCH 180\n",
      "   TRAIN | Label 1 loss: 18.7834 ; P: 0.8647 ; R: 0.9003 ; F1: 0.8822 ; Acc: 0.993\n",
      "           Label 2 loss: 0.4847 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 73.4872 ; P: 0.6771 ; R: 0.8617 ; F1: 0.7583 ; Acc: 0.984\n",
      "           Label 2 loss: 709.2385 ; P: 0.932 ; R: 0.9166 ; F1: 0.9242 ; Acc: 0.934\n",
      "2023-01-25 10:06:11.921893\n",
      "counter:  21\n",
      "2023-01-25 10:06:11.922898\n",
      "EPOCH 181\n",
      "TAG_LOSS_WEIGHT:  0.5061569602914379\n",
      "CLS_LOSS_WEIGHT:  0.49384303970856225\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1610\n",
      "fn:  140\n",
      "tn:  2110\n",
      "fp:  124\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3720\n",
      "EPOCH 181\n",
      "   TRAIN | Label 1 loss: 18.673 ; P: 0.8644 ; R: 0.9032 ; F1: 0.8834 ; Acc: 0.993\n",
      "           Label 2 loss: 0.2789 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 72.5797 ; P: 0.6901 ; R: 0.8532 ; F1: 0.763 ; Acc: 0.9846\n",
      "           Label 2 loss: 707.2008 ; P: 0.9285 ; R: 0.92 ; F1: 0.9242 ; Acc: 0.9337\n",
      "2023-01-25 10:10:17.862814\n",
      "counter:  22\n",
      "2023-01-25 10:10:17.864805\n",
      "EPOCH 182\n",
      "TAG_LOSS_WEIGHT:  0.506104525846479\n",
      "CLS_LOSS_WEIGHT:  0.49389547415352086\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1620\n",
      "fn:  130\n",
      "tn:  2099\n",
      "fp:  135\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3719\n",
      "EPOCH 182\n",
      "   TRAIN | Label 1 loss: 18.5803 ; P: 0.8708 ; R: 0.9044 ; F1: 0.8873 ; Acc: 0.9933\n",
      "           Label 2 loss: 6.842 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 1 loss: 71.4272 ; P: 0.6995 ; R: 0.845 ; F1: 0.7654 ; Acc: 0.9849\n",
      "           Label 2 loss: 683.4995 ; P: 0.9231 ; R: 0.9257 ; F1: 0.9244 ; Acc: 0.9335\n",
      "2023-01-25 10:14:25.005198\n",
      "counter:  23\n",
      "2023-01-25 10:14:25.005198\n",
      "EPOCH 183\n",
      "TAG_LOSS_WEIGHT:  0.5058920537411865\n",
      "CLS_LOSS_WEIGHT:  0.49410794625881344\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1603\n",
      "fn:  147\n",
      "tn:  2120\n",
      "fp:  114\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3723\n",
      "EPOCH 183\n",
      "   TRAIN | Label 1 loss: 17.7445 ; P: 0.8771 ; R: 0.9084 ; F1: 0.8925 ; Acc: 0.9936\n",
      "           Label 2 loss: 0.4475 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 72.2073 ; P: 0.7031 ; R: 0.8395 ; F1: 0.7652 ; Acc: 0.985\n",
      "           Label 2 loss: 697.986 ; P: 0.9336 ; R: 0.916 ; F1: 0.9247 ; Acc: 0.9345\n",
      "2023-01-25 10:18:31.413460\n",
      "counter:  24\n",
      "2023-01-25 10:18:31.415455\n",
      "EPOCH 184\n",
      "TAG_LOSS_WEIGHT:  0.5056534261000899\n",
      "CLS_LOSS_WEIGHT:  0.4943465738999101\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1609\n",
      "fn:  141\n",
      "tn:  2119\n",
      "fp:  115\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3728\n",
      "EPOCH 184\n",
      "   TRAIN | Label 1 loss: 17.35 ; P: 0.8757 ; R: 0.9137 ; F1: 0.8943 ; Acc: 0.9937\n",
      "           Label 2 loss: 1.2065 ; P: 0.9994 ; R: 1.0 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 72.9024 ; P: 0.7045 ; R: 0.8383 ; F1: 0.7656 ; Acc: 0.9851\n",
      "           Label 2 loss: 696.0876 ; P: 0.9333 ; R: 0.9194 ; F1: 0.9263 ; Acc: 0.9357\n",
      "2023-01-25 10:22:40.298245\n",
      "counter:  25\n",
      "2023-01-25 10:22:40.298245\n",
      "EPOCH 185\n",
      "TAG_LOSS_WEIGHT:  0.5054562110165383\n",
      "CLS_LOSS_WEIGHT:  0.4945437889834618\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1623\n",
      "fn:  127\n",
      "tn:  2099\n",
      "fp:  135\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3722\n",
      "EPOCH 185\n",
      "   TRAIN | Label 1 loss: 16.8838 ; P: 0.8799 ; R: 0.9125 ; F1: 0.8959 ; Acc: 0.9938\n",
      "           Label 2 loss: 1.6914 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 73.6875 ; P: 0.6814 ; R: 0.8592 ; F1: 0.76 ; Acc: 0.9842\n",
      "           Label 2 loss: 682.1374 ; P: 0.9232 ; R: 0.9274 ; F1: 0.9253 ; Acc: 0.9342\n",
      "2023-01-25 10:26:48.168009\n",
      "counter:  26\n",
      "2023-01-25 10:26:48.168009\n",
      "EPOCH 186\n",
      "TAG_LOSS_WEIGHT:  0.5052290653393238\n",
      "CLS_LOSS_WEIGHT:  0.4947709346606763\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1595\n",
      "fn:  155\n",
      "tn:  2122\n",
      "fp:  112\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3717\n",
      "EPOCH 186\n",
      "   TRAIN | Label 1 loss: 16.6615 ; P: 0.8771 ; R: 0.9165 ; F1: 0.8963 ; Acc: 0.9938\n",
      "           Label 2 loss: 2.122 ; P: 0.9989 ; R: 1.0 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 74.4904 ; P: 0.7045 ; R: 0.8395 ; F1: 0.7661 ; Acc: 0.9851\n",
      "           Label 2 loss: 715.0585 ; P: 0.9344 ; R: 0.9114 ; F1: 0.9228 ; Acc: 0.933\n",
      "2023-01-25 10:30:54.786400\n",
      "counter:  27\n",
      "2023-01-25 10:30:54.787405\n",
      "EPOCH 187\n",
      "TAG_LOSS_WEIGHT:  0.505117342688896\n",
      "CLS_LOSS_WEIGHT:  0.49488265731110404\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1590\n",
      "fn:  160\n",
      "tn:  2127\n",
      "fp:  107\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3717\n",
      "EPOCH 187\n",
      "   TRAIN | Label 1 loss: 16.4882 ; P: 0.8817 ; R: 0.9162 ; F1: 0.8986 ; Acc: 0.9939\n",
      "           Label 2 loss: 2.4252 ; P: 0.9994 ; R: 1.0 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 77.0228 ; P: 0.7015 ; R: 0.839 ; F1: 0.7641 ; Acc: 0.9849\n",
      "           Label 2 loss: 716.3981 ; P: 0.9369 ; R: 0.9086 ; F1: 0.9225 ; Acc: 0.933\n",
      "2023-01-25 10:35:02.099543\n",
      "counter:  28\n",
      "2023-01-25 10:35:02.099543\n",
      "EPOCH 188\n",
      "TAG_LOSS_WEIGHT:  0.5050308095894069\n",
      "CLS_LOSS_WEIGHT:  0.494969190410593\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1623\n",
      "fn:  127\n",
      "tn:  2079\n",
      "fp:  155\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3702\n",
      "EPOCH 188\n",
      "   TRAIN | Label 1 loss: 16.0403 ; P: 0.8847 ; R: 0.9167 ; F1: 0.9004 ; Acc: 0.9941\n",
      "           Label 2 loss: 1.3357 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 71.6807 ; P: 0.6983 ; R: 0.8383 ; F1: 0.7619 ; Acc: 0.9848\n",
      "           Label 2 loss: 706.3905 ; P: 0.9128 ; R: 0.9274 ; F1: 0.9201 ; Acc: 0.9292\n",
      "2023-01-25 10:39:11.077882\n",
      "counter:  29\n",
      "2023-01-25 10:39:11.077882\n",
      "EPOCH 189\n",
      "TAG_LOSS_WEIGHT:  0.50484680990172\n",
      "CLS_LOSS_WEIGHT:  0.49515319009827985\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1611\n",
      "fn:  139\n",
      "tn:  2103\n",
      "fp:  131\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3714\n",
      "EPOCH 189\n",
      "   TRAIN | Label 1 loss: 15.9676 ; P: 0.8863 ; R: 0.9168 ; F1: 0.9013 ; Acc: 0.9941\n",
      "           Label 2 loss: 0.6191 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 74.2228 ; P: 0.6992 ; R: 0.846 ; F1: 0.7656 ; Acc: 0.9849\n",
      "           Label 2 loss: 704.2295 ; P: 0.9248 ; R: 0.9206 ; F1: 0.9227 ; Acc: 0.9322\n",
      "2023-01-25 10:43:18.642959\n",
      "counter:  30\n",
      "2023-01-25 10:43:18.642959\n",
      "EPOCH 190\n",
      "TAG_LOSS_WEIGHT:  0.5048237449822048\n",
      "CLS_LOSS_WEIGHT:  0.49517625501779516\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1599\n",
      "fn:  151\n",
      "tn:  2124\n",
      "fp:  110\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3723\n",
      "EPOCH 190\n",
      "   TRAIN | Label 1 loss: 15.3323 ; P: 0.8908 ; R: 0.922 ; F1: 0.9061 ; Acc: 0.9944\n",
      "           Label 2 loss: 0.3637 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 76.7538 ; P: 0.7016 ; R: 0.8445 ; F1: 0.7665 ; Acc: 0.985\n",
      "           Label 2 loss: 705.6679 ; P: 0.9356 ; R: 0.9137 ; F1: 0.9245 ; Acc: 0.9345\n",
      "2023-01-25 10:47:26.606222\n",
      "counter:  31\n",
      "2023-01-25 10:47:26.606222\n",
      "EPOCH 191\n",
      "TAG_LOSS_WEIGHT:  0.5045410114469897\n",
      "CLS_LOSS_WEIGHT:  0.4954589885530103\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1609\n",
      "fn:  141\n",
      "tn:  2113\n",
      "fp:  121\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3722\n",
      "EPOCH 191\n",
      "   TRAIN | Label 1 loss: 14.8679 ; P: 0.8927 ; R: 0.9256 ; F1: 0.9089 ; Acc: 0.9946\n",
      "           Label 2 loss: 1.3678 ; P: 0.9989 ; R: 0.9994 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 1 loss: 76.916 ; P: 0.6984 ; R: 0.8479 ; F1: 0.7659 ; Acc: 0.9849\n",
      "           Label 2 loss: 710.2376 ; P: 0.9301 ; R: 0.9194 ; F1: 0.9247 ; Acc: 0.9342\n",
      "2023-01-25 10:51:33.157490\n",
      "counter:  32\n",
      "2023-01-25 10:51:33.158491\n",
      "EPOCH 192\n",
      "TAG_LOSS_WEIGHT:  0.5043231918659388\n",
      "CLS_LOSS_WEIGHT:  0.4956768081340613\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1600\n",
      "fn:  150\n",
      "tn:  2124\n",
      "fp:  110\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3724\n",
      "EPOCH 192\n",
      "   TRAIN | Label 1 loss: 14.643 ; P: 0.8952 ; R: 0.9213 ; F1: 0.9081 ; Acc: 0.9945\n",
      "           Label 2 loss: 0.4199 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 78.8715 ; P: 0.7007 ; R: 0.8424 ; F1: 0.765 ; Acc: 0.9849\n",
      "           Label 2 loss: 712.5092 ; P: 0.9357 ; R: 0.9143 ; F1: 0.9249 ; Acc: 0.9347\n",
      "2023-01-25 10:55:41.083545\n",
      "counter:  33\n",
      "2023-01-25 10:55:41.084535\n",
      "EPOCH 193\n",
      "TAG_LOSS_WEIGHT:  0.5042376323101291\n",
      "CLS_LOSS_WEIGHT:  0.49576236768987086\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1603\n",
      "fn:  147\n",
      "tn:  2121\n",
      "fp:  113\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3724\n",
      "EPOCH 193\n",
      "   TRAIN | Label 1 loss: 14.2536 ; P: 0.8935 ; R: 0.9253 ; F1: 0.9091 ; Acc: 0.9946\n",
      "           Label 2 loss: 1.3122 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 77.7567 ; P: 0.719 ; R: 0.825 ; F1: 0.7684 ; Acc: 0.9855\n",
      "           Label 2 loss: 723.0131 ; P: 0.9341 ; R: 0.916 ; F1: 0.925 ; Acc: 0.9347\n",
      "2023-01-25 10:59:49.183703\n",
      "counter:  34\n",
      "2023-01-25 10:59:49.185780\n",
      "EPOCH 194\n",
      "TAG_LOSS_WEIGHT:  0.5040580427622248\n",
      "CLS_LOSS_WEIGHT:  0.4959419572377753\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1608\n",
      "fn:  142\n",
      "tn:  2119\n",
      "fp:  115\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3727\n",
      "EPOCH 194\n",
      "   TRAIN | Label 1 loss: 13.6115 ; P: 0.9031 ; R: 0.9287 ; F1: 0.9157 ; Acc: 0.995\n",
      "           Label 2 loss: 0.2679 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 81.5288 ; P: 0.6947 ; R: 0.8491 ; F1: 0.7642 ; Acc: 0.9848\n",
      "           Label 2 loss: 724.7412 ; P: 0.9333 ; R: 0.9189 ; F1: 0.926 ; Acc: 0.9355\n",
      "2023-01-25 11:03:57.002510\n",
      "counter:  35\n",
      "2023-01-25 11:03:57.002510\n",
      "EPOCH 195\n",
      "TAG_LOSS_WEIGHT:  0.503798852422467\n",
      "CLS_LOSS_WEIGHT:  0.49620114757753286\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1574\n",
      "fn:  176\n",
      "tn:  2133\n",
      "fp:  101\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3707\n",
      "EPOCH 195\n",
      "   TRAIN | Label 1 loss: 13.3314 ; P: 0.9036 ; R: 0.9271 ; F1: 0.9152 ; Acc: 0.995\n",
      "           Label 2 loss: 1.0881 ; P: 0.9994 ; R: 1.0 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 81.4441 ; P: 0.708 ; R: 0.8359 ; F1: 0.7667 ; Acc: 0.9852\n",
      "           Label 2 loss: 746.4745 ; P: 0.9397 ; R: 0.8994 ; F1: 0.9191 ; Acc: 0.9305\n",
      "2023-01-25 11:08:04.603764\n",
      "counter:  36\n",
      "2023-01-25 11:08:04.604768\n",
      "EPOCH 196\n",
      "TAG_LOSS_WEIGHT:  0.5036727827919095\n",
      "CLS_LOSS_WEIGHT:  0.4963272172080905\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2210\n",
      "fp:  2\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3974\n",
      "tp:  1613\n",
      "fn:  137\n",
      "tn:  2109\n",
      "fp:  125\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3722\n",
      "EPOCH 196\n",
      "   TRAIN | Label 1 loss: 13.0405 ; P: 0.9076 ; R: 0.9312 ; F1: 0.9192 ; Acc: 0.9952\n",
      "           Label 2 loss: 2.7232 ; P: 0.9989 ; R: 0.9989 ; F1: 0.9989 ; Acc: 0.999\n",
      "    TEST | Label 1 loss: 78.936 ; P: 0.6903 ; R: 0.8549 ; F1: 0.7639 ; Acc: 0.9846\n",
      "           Label 2 loss: 735.1287 ; P: 0.9281 ; R: 0.9217 ; F1: 0.9249 ; Acc: 0.9342\n",
      "2023-01-25 11:12:11.187221\n",
      "counter:  37\n",
      "2023-01-25 11:12:11.188221\n",
      "EPOCH 197\n",
      "TAG_LOSS_WEIGHT:  0.5035212658406978\n",
      "CLS_LOSS_WEIGHT:  0.49647873415930227\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1613\n",
      "fn:  137\n",
      "tn:  2096\n",
      "fp:  138\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3709\n",
      "EPOCH 197\n",
      "   TRAIN | Label 1 loss: 13.0961 ; P: 0.9069 ; R: 0.9271 ; F1: 0.9169 ; Acc: 0.9951\n",
      "           Label 2 loss: 0.8131 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 82.0391 ; P: 0.7058 ; R: 0.8373 ; F1: 0.766 ; Acc: 0.9851\n",
      "           Label 2 loss: 734.903 ; P: 0.9212 ; R: 0.9217 ; F1: 0.9215 ; Acc: 0.931\n",
      "2023-01-25 11:16:18.123130\n",
      "counter:  38\n",
      "2023-01-25 11:16:18.124219\n",
      "EPOCH 198\n",
      "TAG_LOSS_WEIGHT:  0.5035794801309758\n",
      "CLS_LOSS_WEIGHT:  0.49642051986902413\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1581\n",
      "fn:  169\n",
      "tn:  2130\n",
      "fp:  104\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3711\n",
      "EPOCH 198\n",
      "   TRAIN | Label 1 loss: 12.5062 ; P: 0.9105 ; R: 0.9342 ; F1: 0.9222 ; Acc: 0.9954\n",
      "           Label 2 loss: 1.7736 ; P: 0.9994 ; R: 1.0 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 83.7554 ; P: 0.7061 ; R: 0.838 ; F1: 0.7664 ; Acc: 0.9851\n",
      "           Label 2 loss: 734.405 ; P: 0.9383 ; R: 0.9034 ; F1: 0.9205 ; Acc: 0.9315\n",
      "2023-01-25 11:20:24.949436\n",
      "counter:  39\n",
      "2023-01-25 11:20:24.950450\n",
      "EPOCH 199\n",
      "TAG_LOSS_WEIGHT:  0.5033245872053329\n",
      "CLS_LOSS_WEIGHT:  0.49667541279466704\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1602\n",
      "fn:  148\n",
      "tn:  2117\n",
      "fp:  117\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3719\n",
      "EPOCH 199\n",
      "   TRAIN | Label 1 loss: 12.31 ; P: 0.914 ; R: 0.9395 ; F1: 0.9266 ; Acc: 0.9956\n",
      "           Label 2 loss: 0.2991 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 83.4553 ; P: 0.7181 ; R: 0.8241 ; F1: 0.7675 ; Acc: 0.9855\n",
      "           Label 2 loss: 734.5079 ; P: 0.9319 ; R: 0.9154 ; F1: 0.9236 ; Acc: 0.9335\n",
      "2023-01-25 11:24:31.693741\n",
      "counter:  40\n",
      "2023-01-25 11:24:31.693741\n",
      "EPOCH 200\n",
      "TAG_LOSS_WEIGHT:  0.5032668352780736\n",
      "CLS_LOSS_WEIGHT:  0.4967331647219264\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1602\n",
      "fn:  148\n",
      "tn:  2113\n",
      "fp:  121\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3715\n",
      "EPOCH 200\n",
      "   TRAIN | Label 1 loss: 11.6572 ; P: 0.9134 ; R: 0.9384 ; F1: 0.9258 ; Acc: 0.9956\n",
      "           Label 2 loss: 0.2217 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 85.7204 ; P: 0.7102 ; R: 0.8383 ; F1: 0.769 ; Acc: 0.9853\n",
      "           Label 2 loss: 741.0395 ; P: 0.9298 ; R: 0.9154 ; F1: 0.9225 ; Acc: 0.9325\n",
      "2023-01-25 11:28:37.075645\n",
      "counter:  41\n",
      "2023-01-25 11:28:37.075645\n",
      "EPOCH 201\n",
      "TAG_LOSS_WEIGHT:  0.5030108935604286\n",
      "CLS_LOSS_WEIGHT:  0.4969891064395714\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1588\n",
      "fn:  162\n",
      "tn:  2119\n",
      "fp:  115\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3707\n",
      "EPOCH 201\n",
      "   TRAIN | Label 1 loss: 11.6501 ; P: 0.9163 ; R: 0.9371 ; F1: 0.9266 ; Acc: 0.9957\n",
      "           Label 2 loss: 2.5584 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 86.6888 ; P: 0.72 ; R: 0.8282 ; F1: 0.7703 ; Acc: 0.9856\n",
      "           Label 2 loss: 779.8424 ; P: 0.9325 ; R: 0.9074 ; F1: 0.9198 ; Acc: 0.9305\n",
      "2023-01-25 11:32:44.362560\n",
      "counter:  42\n",
      "2023-01-25 11:32:44.362560\n",
      "EPOCH 202\n",
      "TAG_LOSS_WEIGHT:  0.5029706039343684\n",
      "CLS_LOSS_WEIGHT:  0.49702939606563173\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1609\n",
      "fn:  141\n",
      "tn:  2106\n",
      "fp:  128\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3715\n",
      "EPOCH 202\n",
      "   TRAIN | Label 1 loss: 11.2119 ; P: 0.9159 ; R: 0.94 ; F1: 0.9278 ; Acc: 0.9957\n",
      "           Label 2 loss: 0.4798 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 86.8765 ; P: 0.7081 ; R: 0.8421 ; F1: 0.7693 ; Acc: 0.9853\n",
      "           Label 2 loss: 762.3765 ; P: 0.9263 ; R: 0.9194 ; F1: 0.9229 ; Acc: 0.9325\n",
      "2023-01-25 11:36:51.007018\n",
      "counter:  43\n",
      "2023-01-25 11:36:51.008121\n",
      "EPOCH 203\n",
      "TAG_LOSS_WEIGHT:  0.5028378316762588\n",
      "CLS_LOSS_WEIGHT:  0.49716216832374116\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1591\n",
      "fn:  159\n",
      "tn:  2127\n",
      "fp:  107\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3718\n",
      "EPOCH 203\n",
      "   TRAIN | Label 1 loss: 10.7331 ; P: 0.9214 ; R: 0.9426 ; F1: 0.9319 ; Acc: 0.996\n",
      "           Label 2 loss: 0.3594 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 87.3464 ; P: 0.7187 ; R: 0.8315 ; F1: 0.771 ; Acc: 0.9856\n",
      "           Label 2 loss: 756.1092 ; P: 0.937 ; R: 0.9091 ; F1: 0.9229 ; Acc: 0.9332\n",
      "2023-01-25 11:40:57.740536\n",
      "counter:  44\n",
      "2023-01-25 11:40:57.741610\n",
      "EPOCH 204\n",
      "TAG_LOSS_WEIGHT:  0.5026589091980569\n",
      "CLS_LOSS_WEIGHT:  0.4973410908019432\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1602\n",
      "fn:  148\n",
      "tn:  2114\n",
      "fp:  120\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3716\n",
      "EPOCH 204\n",
      "   TRAIN | Label 1 loss: 10.7131 ; P: 0.9257 ; R: 0.9443 ; F1: 0.9349 ; Acc: 0.9962\n",
      "           Label 2 loss: 0.3693 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 87.5288 ; P: 0.7119 ; R: 0.838 ; F1: 0.7698 ; Acc: 0.9854\n",
      "           Label 2 loss: 757.4961 ; P: 0.9303 ; R: 0.9154 ; F1: 0.9228 ; Acc: 0.9327\n",
      "2023-01-25 11:45:05.365738\n",
      "counter:  45\n",
      "2023-01-25 11:45:05.365738\n",
      "EPOCH 205\n",
      "TAG_LOSS_WEIGHT:  0.5026513908604293\n",
      "CLS_LOSS_WEIGHT:  0.4973486091395707\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1595\n",
      "fn:  155\n",
      "tn:  2124\n",
      "fp:  110\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3719\n",
      "EPOCH 205\n",
      "   TRAIN | Label 1 loss: 10.6227 ; P: 0.9222 ; R: 0.9446 ; F1: 0.9333 ; Acc: 0.996\n",
      "           Label 2 loss: 0.1459 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 85.8307 ; P: 0.7316 ; R: 0.8173 ; F1: 0.7721 ; Acc: 0.986\n",
      "           Label 2 loss: 763.7069 ; P: 0.9355 ; R: 0.9114 ; F1: 0.9233 ; Acc: 0.9335\n",
      "2023-01-25 11:49:12.698946\n",
      "counter:  46\n",
      "2023-01-25 11:49:12.698946\n",
      "EPOCH 206\n",
      "TAG_LOSS_WEIGHT:  0.5026194639739032\n",
      "CLS_LOSS_WEIGHT:  0.4973805360260967\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1590\n",
      "fn:  160\n",
      "tn:  2127\n",
      "fp:  107\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3717\n",
      "EPOCH 206\n",
      "   TRAIN | Label 1 loss: 9.8489 ; P: 0.9274 ; R: 0.9431 ; F1: 0.9352 ; Acc: 0.9962\n",
      "           Label 2 loss: 0.3474 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 88.8132 ; P: 0.7249 ; R: 0.8238 ; F1: 0.7712 ; Acc: 0.9858\n",
      "           Label 2 loss: 778.6643 ; P: 0.9369 ; R: 0.9086 ; F1: 0.9225 ; Acc: 0.933\n",
      "2023-01-25 11:53:19.666938\n",
      "counter:  47\n",
      "2023-01-25 11:53:19.667936\n",
      "EPOCH 207\n",
      "TAG_LOSS_WEIGHT:  0.5023370681820247\n",
      "CLS_LOSS_WEIGHT:  0.4976629318179753\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1603\n",
      "fn:  147\n",
      "tn:  2121\n",
      "fp:  113\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3724\n",
      "EPOCH 207\n",
      "   TRAIN | Label 1 loss: 9.68 ; P: 0.9289 ; R: 0.9519 ; F1: 0.9402 ; Acc: 0.9965\n",
      "           Label 2 loss: 1.0518 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 89.291 ; P: 0.7203 ; R: 0.8313 ; F1: 0.7718 ; Acc: 0.9857\n",
      "           Label 2 loss: 751.9304 ; P: 0.9341 ; R: 0.916 ; F1: 0.925 ; Acc: 0.9347\n",
      "2023-01-25 11:57:27.405065\n",
      "counter:  48\n",
      "2023-01-25 11:57:27.406146\n",
      "EPOCH 208\n",
      "TAG_LOSS_WEIGHT:  0.5022689332871428\n",
      "CLS_LOSS_WEIGHT:  0.49773106671285705\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1599\n",
      "fn:  151\n",
      "tn:  2126\n",
      "fp:  108\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3725\n",
      "EPOCH 208\n",
      "   TRAIN | Label 1 loss: 9.1723 ; P: 0.9332 ; R: 0.9488 ; F1: 0.9409 ; Acc: 0.9965\n",
      "           Label 2 loss: 0.2743 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 89.6317 ; P: 0.721 ; R: 0.8332 ; F1: 0.773 ; Acc: 0.9858\n",
      "           Label 2 loss: 749.4077 ; P: 0.9367 ; R: 0.9137 ; F1: 0.9251 ; Acc: 0.935\n",
      "2023-01-25 12:01:34.607787\n",
      "counter:  49\n",
      "2023-01-25 12:01:34.607787\n",
      "EPOCH 209\n",
      "TAG_LOSS_WEIGHT:  0.5021008078689504\n",
      "CLS_LOSS_WEIGHT:  0.49789919213104944\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1593\n",
      "fn:  157\n",
      "tn:  2125\n",
      "fp:  109\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3718\n",
      "EPOCH 209\n",
      "   TRAIN | Label 1 loss: 9.2428 ; P: 0.934 ; R: 0.9529 ; F1: 0.9433 ; Acc: 0.9966\n",
      "           Label 2 loss: 0.968 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 91.0482 ; P: 0.726 ; R: 0.8253 ; F1: 0.7725 ; Acc: 0.9859\n",
      "           Label 2 loss: 760.0232 ; P: 0.936 ; R: 0.9103 ; F1: 0.9229 ; Acc: 0.9332\n",
      "2023-01-25 12:05:42.634517\n",
      "counter:  50\n",
      "2023-01-25 12:05:42.635554\n",
      "EPOCH 210\n",
      "TAG_LOSS_WEIGHT:  0.5021174774999972\n",
      "CLS_LOSS_WEIGHT:  0.49788252250000287\n",
      "tp:  1764\n",
      "fn:  2\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3975\n",
      "tp:  1608\n",
      "fn:  142\n",
      "tn:  2103\n",
      "fp:  131\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3711\n",
      "EPOCH 210\n",
      "   TRAIN | Label 1 loss: 9.5394 ; P: 0.936 ; R: 0.951 ; F1: 0.9434 ; Acc: 0.9967\n",
      "           Label 2 loss: 5.0503 ; P: 0.9994 ; R: 0.9989 ; F1: 0.9992 ; Acc: 0.9992\n",
      "    TEST | Label 1 loss: 92.3428 ; P: 0.7193 ; R: 0.8337 ; F1: 0.7723 ; Acc: 0.9857\n",
      "           Label 2 loss: 743.397 ; P: 0.9247 ; R: 0.9189 ; F1: 0.9218 ; Acc: 0.9315\n",
      "2023-01-25 12:09:49.226519\n",
      "counter:  51\n",
      "2023-01-25 12:09:49.226519\n",
      "EPOCH 211\n",
      "TAG_LOSS_WEIGHT:  0.5021227753008543\n",
      "CLS_LOSS_WEIGHT:  0.4978772246991456\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2211\n",
      "fp:  1\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3976\n",
      "tp:  1599\n",
      "fn:  151\n",
      "tn:  2126\n",
      "fp:  108\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3725\n",
      "EPOCH 211\n",
      "   TRAIN | Label 1 loss: 8.8479 ; P: 0.94 ; R: 0.951 ; F1: 0.9454 ; Acc: 0.9968\n",
      "           Label 2 loss: 3.075 ; P: 0.9994 ; R: 0.9994 ; F1: 0.9994 ; Acc: 0.9995\n",
      "    TEST | Label 1 loss: 92.3412 ; P: 0.7263 ; R: 0.8269 ; F1: 0.7734 ; Acc: 0.9859\n",
      "           Label 2 loss: 717.2786 ; P: 0.9367 ; R: 0.9137 ; F1: 0.9251 ; Acc: 0.935\n",
      "2023-01-25 12:13:56.571026\n",
      "counter:  52\n",
      "2023-01-25 12:13:56.571026\n",
      "EPOCH 212\n",
      "TAG_LOSS_WEIGHT:  0.5019408714940152\n",
      "CLS_LOSS_WEIGHT:  0.4980591285059848\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1609\n",
      "fn:  141\n",
      "tn:  2104\n",
      "fp:  130\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3713\n",
      "EPOCH 212\n",
      "   TRAIN | Label 1 loss: 8.3191 ; P: 0.9394 ; R: 0.9541 ; F1: 0.9467 ; Acc: 0.9969\n",
      "           Label 2 loss: 0.8013 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 94.8843 ; P: 0.7097 ; R: 0.8445 ; F1: 0.7713 ; Acc: 0.9854\n",
      "           Label 2 loss: 722.7854 ; P: 0.9252 ; R: 0.9194 ; F1: 0.9223 ; Acc: 0.932\n",
      "2023-01-25 12:18:03.846818\n",
      "counter:  53\n",
      "2023-01-25 12:18:03.846818\n",
      "EPOCH 213\n",
      "TAG_LOSS_WEIGHT:  0.5018090293287241\n",
      "CLS_LOSS_WEIGHT:  0.49819097067127605\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1598\n",
      "fn:  152\n",
      "tn:  2125\n",
      "fp:  109\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3723\n",
      "EPOCH 213\n",
      "   TRAIN | Label 1 loss: 8.353 ; P: 0.9395 ; R: 0.9519 ; F1: 0.9456 ; Acc: 0.9968\n",
      "           Label 2 loss: 0.3379 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 94.7395 ; P: 0.7195 ; R: 0.8376 ; F1: 0.774 ; Acc: 0.9858\n",
      "           Label 2 loss: 730.5356 ; P: 0.9361 ; R: 0.9131 ; F1: 0.9245 ; Acc: 0.9345\n",
      "2023-01-25 12:22:09.846750\n",
      "counter:  54\n",
      "2023-01-25 12:22:09.847798\n",
      "EPOCH 214\n",
      "TAG_LOSS_WEIGHT:  0.5018250426318824\n",
      "CLS_LOSS_WEIGHT:  0.4981749573681174\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1601\n",
      "fn:  149\n",
      "tn:  2123\n",
      "fp:  111\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3724\n",
      "EPOCH 214\n",
      "   TRAIN | Label 1 loss: 7.5584 ; P: 0.9438 ; R: 0.9584 ; F1: 0.951 ; Acc: 0.9971\n",
      "           Label 2 loss: 0.1636 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 95.5427 ; P: 0.7231 ; R: 0.8359 ; F1: 0.7754 ; Acc: 0.9859\n",
      "           Label 2 loss: 737.988 ; P: 0.9352 ; R: 0.9149 ; F1: 0.9249 ; Acc: 0.9347\n",
      "2023-01-25 12:26:17.563773\n",
      "counter:  55\n",
      "2023-01-25 12:26:17.564773\n",
      "EPOCH 215\n",
      "TAG_LOSS_WEIGHT:  0.5015718905481226\n",
      "CLS_LOSS_WEIGHT:  0.49842810945187727\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1597\n",
      "fn:  153\n",
      "tn:  2126\n",
      "fp:  108\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3723\n",
      "EPOCH 215\n",
      "   TRAIN | Label 1 loss: 7.4853 ; P: 0.9435 ; R: 0.9587 ; F1: 0.951 ; Acc: 0.9971\n",
      "           Label 2 loss: 0.1152 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 98.4851 ; P: 0.7237 ; R: 0.8308 ; F1: 0.7736 ; Acc: 0.9858\n",
      "           Label 2 loss: 747.3595 ; P: 0.9367 ; R: 0.9126 ; F1: 0.9245 ; Acc: 0.9345\n",
      "2023-01-25 12:30:25.836217\n",
      "counter:  56\n",
      "2023-01-25 12:30:25.837259\n",
      "EPOCH 216\n",
      "TAG_LOSS_WEIGHT:  0.501549388272836\n",
      "CLS_LOSS_WEIGHT:  0.498450611727164\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1596\n",
      "fn:  154\n",
      "tn:  2126\n",
      "fp:  108\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3722\n",
      "EPOCH 216\n",
      "   TRAIN | Label 1 loss: 7.3875 ; P: 0.9486 ; R: 0.9605 ; F1: 0.9545 ; Acc: 0.9973\n",
      "           Label 2 loss: 0.0884 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 97.8932 ; P: 0.7275 ; R: 0.8289 ; F1: 0.7749 ; Acc: 0.986\n",
      "           Label 2 loss: 751.1291 ; P: 0.9366 ; R: 0.912 ; F1: 0.9241 ; Acc: 0.9342\n",
      "2023-01-25 12:34:32.462485\n",
      "counter:  57\n",
      "2023-01-25 12:34:32.462485\n",
      "EPOCH 217\n",
      "TAG_LOSS_WEIGHT:  0.5015192357772514\n",
      "CLS_LOSS_WEIGHT:  0.49848076422274856\n",
      "tp:  1765\n",
      "fn:  1\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3977\n",
      "tp:  1608\n",
      "fn:  142\n",
      "tn:  2115\n",
      "fp:  119\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3723\n",
      "EPOCH 217\n",
      "   TRAIN | Label 1 loss: 7.1038 ; P: 0.9474 ; R: 0.9607 ; F1: 0.954 ; Acc: 0.9973\n",
      "           Label 2 loss: 2.2169 ; P: 1.0 ; R: 0.9994 ; F1: 0.9997 ; Acc: 0.9997\n",
      "    TEST | Label 1 loss: 98.877 ; P: 0.7251 ; R: 0.8392 ; F1: 0.778 ; Acc: 0.9861\n",
      "           Label 2 loss: 728.8969 ; P: 0.9311 ; R: 0.9189 ; F1: 0.9249 ; Acc: 0.9345\n",
      "2023-01-25 12:38:39.204093\n",
      "counter:  58\n",
      "2023-01-25 12:38:39.205046\n",
      "EPOCH 218\n",
      "TAG_LOSS_WEIGHT:  0.5014017284964974\n",
      "CLS_LOSS_WEIGHT:  0.49859827150350255\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1598\n",
      "fn:  152\n",
      "tn:  2126\n",
      "fp:  108\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3724\n",
      "EPOCH 218\n",
      "   TRAIN | Label 1 loss: 7.004 ; P: 0.9472 ; R: 0.9604 ; F1: 0.9537 ; Acc: 0.9973\n",
      "           Label 2 loss: 0.2575 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 101.1433 ; P: 0.7133 ; R: 0.8496 ; F1: 0.7755 ; Acc: 0.9857\n",
      "           Label 2 loss: 740.4809 ; P: 0.9367 ; R: 0.9131 ; F1: 0.9248 ; Acc: 0.9347\n",
      "2023-01-25 12:42:46.606681\n",
      "counter:  59\n",
      "2023-01-25 12:42:46.607624\n",
      "EPOCH 219\n",
      "TAG_LOSS_WEIGHT:  0.5014014837314064\n",
      "CLS_LOSS_WEIGHT:  0.49859851626859353\n",
      "tp:  1766\n",
      "fn:  0\n",
      "tn:  2212\n",
      "fp:  0\n",
      "length of iterator:  995\n",
      "train set pred label2 length:  3978\n",
      "train set true label2 length:  3978\n",
      "match number:  3978\n",
      "tp:  1598\n",
      "fn:  152\n",
      "tn:  2126\n",
      "fp:  108\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "match number:  3724\n",
      "EPOCH 219\n",
      "   TRAIN | Label 1 loss: 6.5383 ; P: 0.9524 ; R: 0.9651 ; F1: 0.9587 ; Acc: 0.9976\n",
      "           Label 2 loss: 0.1145 ; P: 1.0 ; R: 1.0 ; F1: 1.0 ; Acc: 1.0\n",
      "    TEST | Label 1 loss: 100.6221 ; P: 0.7252 ; R: 0.8376 ; F1: 0.7773 ; Acc: 0.986\n",
      "           Label 2 loss: 751.4475 ; P: 0.9367 ; R: 0.9131 ; F1: 0.9248 ; Acc: 0.9347\n",
      "2023-01-25 12:46:54.651487\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os, shutil\n",
    "import datetime\n",
    "\n",
    "def softmax(xs):\n",
    "    return np.exp(xs) / sum(np.exp(xs))\n",
    "\n",
    "OUTPUT_PATH = './checkpoint'\n",
    "OUTPUT_PATH =os.path.join(OUTPUT_PATH, BERT_PATH[2:])\n",
    "\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)\n",
    "\n",
    "\n",
    "label1_loss_train_list=[]\n",
    "# label1_loss_validation_list=[]\n",
    "label1_loss_test_list=[]\n",
    "\n",
    "label2_loss_train_list=[]\n",
    "# label2_loss_validation_list=[]\n",
    "label2_loss_test_list=[]\n",
    "\n",
    "label1_f1_train_list=[]\n",
    "# label1_f1_validation_list=[]\n",
    "label1_f1_test_list=[]\n",
    "\n",
    "label2_f1_train_list=[]\n",
    "# label2_f1_validation_list=[]\n",
    "label2_f1_test_list=[]\n",
    "\n",
    "label1_acc_train_list=[]\n",
    "# label1_acc_validation_list=[]\n",
    "label1_acc_test_list=[]\n",
    "\n",
    "label2_acc_train_list=[]\n",
    "# label2_acc_validation_list=[]\n",
    "label2_acc_test_list=[]\n",
    "\n",
    "best_label2_acc_va=-1\n",
    "best_label2_acc_te=-1\n",
    "\n",
    "epoch_num = 0\n",
    "min_validation_loss = np.inf\n",
    "max_validation_f = 0\n",
    "patience = 60\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(datetime.datetime.now())\n",
    "    print('EPOCH', epoch_num)\n",
    "    print('TAG_LOSS_WEIGHT: ', TAG_LOSS_WEIGTH)\n",
    "    print('CLS_LOSS_WEIGHT: ', CLS_LOSS_WEIGTH)\n",
    "    \n",
    "    loss_label1_tr, loss_label2_tr, p_label1_tr, r_label1_tr, f_label1_tr, acc_label1_tr, p_label2_tr,\\\n",
    "    r_label2_tr, f_label2_tr, acc_label2_tr = \\\n",
    "    train(model, train_iterator, optimizer, scheduler, criterion_tag, criterion_cls, \n",
    "          TAG_PAD_IDX, TAG_LOSS_WEIGTH, CLS_LOSS_WEIGTH)\n",
    "    # ######## for softmax trust level ###########\n",
    "    # loss_label1_tr, loss_label2_tr, p_label1_tr, r_label1_tr, f_label1_tr, acc_label1_tr, p_label2_tr,\\\n",
    "    # r_label2_tr, f_label2_tr, acc_label2_tr, rmsd_tag_signal, rmsd_cls_signal = \\\n",
    "    # train(model, train_iterator, optimizer, scheduler, criterion_tag, criterion_cls, \n",
    "    #       TAG_PAD_IDX, TAG_LOSS_WEIGTH, CLS_LOSS_WEIGTH)\n",
    "    if epoch_num==0:\n",
    "        first_epoch_loss_tag = loss_label1_tr\n",
    "        first_epoch_loss_cls = loss_label2_tr\n",
    "    if epoch_num != 0:\n",
    "        TAG_LOSS_WEIGTH = (loss_label1_tr/first_epoch_loss_tag)**1.5\n",
    "        CLS_LOSS_WEIGTH = (loss_label2_tr/first_epoch_loss_cls)**1.5\n",
    "    # TAG_LOSS_WEIGTH = TAG_LOSS_WEIGTH/(rmsd_tag_signal+1e-9)\n",
    "    # CLS_LOSS_WEIGTH = CLS_LOSS_WEIGTH/(rmsd_cls_signal+1e-9)\n",
    "    sum=(np.exp(TAG_LOSS_WEIGTH)+np.exp(CLS_LOSS_WEIGTH))\n",
    "    TAG_LOSS_WEIGTH=np.exp(TAG_LOSS_WEIGTH)/sum\n",
    "    CLS_LOSS_WEIGTH =np.exp(CLS_LOSS_WEIGTH)/sum\n",
    "    # coef=1/(TAG_LOSS_WEIGTH+CLS_LOSS_WEIGTH)\n",
    "    # TAG_LOSS_WEIGTH = coef*TAG_LOSS_WEIGTH\n",
    "    # CLS_LOSS_WEIGTH = coef*CLS_LOSS_WEIGTH\n",
    "    # if CLS_LOSS_WEIGTH>0.9:\n",
    "    #     TAG_LOSS_WEIGTH = 0.1\n",
    "    #     CLS_LOSS_WEIGTH = 0.9\n",
    "    # loss_label1_va, loss_label2_va, p_label1_va, r_label1_va, f_label1_va, acc_label1_va, p_label2_va, r_label2_va, f_label2_va, acc_label2_va = evaluate(model, valid_iterator, criterion_tag, criterion_cls, TAG_PAD_IDX)\n",
    "    loss_label1_te, loss_label2_te, p_label1_te, r_label1_te, f_label1_te, acc_label1_te, p_label2_te, \\\n",
    "    r_label2_te, f_label2_te, acc_label2_te = evaluate(model, test_iterator, criterion_tag, \n",
    "                                                       criterion_cls, TAG_PAD_IDX)\n",
    "    print('EPOCH', epoch)\n",
    "    print('   TRAIN | Label 1 loss:', loss_label1_tr, '; P:', p_label1_tr, '; R:', r_label1_tr, '; F1:', f_label1_tr, '; Acc:', acc_label1_tr)\n",
    "    print('           Label 2 loss:', loss_label2_tr, '; P:', p_label2_tr, '; R:', r_label2_tr, '; F1:', f_label2_tr, '; Acc:', acc_label2_tr)\n",
    "    # print('   VALID | Label 1 loss:', loss_label1_va, '; P:', p_label1_va, '; R:', r_label1_va, '; F1:', f_label1_va, '; Acc:', acc_label1_va)\n",
    "    # print('           Label 2 loss:', loss_label2_va, '; P:', p_label2_va, '; R:', r_label2_va, '; F1:', f_label2_va, '; Acc:', acc_label2_va)\n",
    "    print('    TEST | Label 1 loss:', loss_label1_te, '; P:', p_label1_te, '; R:', r_label1_te, '; F1:', f_label1_te, '; Acc:', acc_label1_te)\n",
    "    print('           Label 2 loss:', loss_label2_te, '; P:', p_label2_te, '; R:', r_label2_te, '; F1:', f_label2_te, '; Acc:', acc_label2_te)\n",
    "    print(datetime.datetime.now())\n",
    "    epoch_num +=1\n",
    "    # if loss_label1_tr < 180:\n",
    "    #     TAG_LOSS_WEIGTH =0.1*TAG_LOSS_WEIGTH\n",
    "    \n",
    "    #print(\"Tag loss weight: \", TAG_LOSS_WEIGTH)\n",
    "    \n",
    "    label1_loss_train_list.append(loss_label1_tr)\n",
    "    # label1_loss_validation_list.append(loss_label1_va)\n",
    "    label1_loss_test_list.append(loss_label1_te)\n",
    "    \n",
    "    label2_loss_train_list.append(loss_label2_tr)\n",
    "    # label2_loss_validation_list.append(loss_label2_va)\n",
    "    label2_loss_test_list.append(loss_label2_te)\n",
    "    \n",
    "    label1_f1_train_list.append(f_label1_tr)\n",
    "    # label1_f1_validation_list.append(f_label1_va)\n",
    "    label1_f1_test_list.append(f_label1_te)\n",
    "    \n",
    "    label2_f1_train_list.append(f_label2_tr)\n",
    "    # label2_f1_validation_list.append(f_label2_va)\n",
    "    label2_f1_test_list.append(f_label2_te)\n",
    "    \n",
    "    label1_acc_train_list.append(acc_label1_tr)\n",
    "    # label1_f1_validation_list.append(f_label1_va)\n",
    "    label1_acc_test_list.append(acc_label1_te)\n",
    "    \n",
    "    label2_acc_train_list.append(acc_label2_tr)\n",
    "    # label2_f1_validation_list.append(f_label2_va)\n",
    "    label2_acc_test_list.append(acc_label2_te)\n",
    "    \n",
    "    \n",
    "    # OUTPUT_PATH_validation =os.path.join(OUTPUT_PATH, 'validation')\n",
    "    # if not os.path.exists(OUTPUT_PATH_validation):\n",
    "    #     os.makedirs(OUTPUT_PATH_validation)\n",
    "    # if f_label2_va>best_label2_f1_va:\n",
    "    #     best_label2_f1_va=f_label2_va\n",
    "    #     output_dir_validation = os.path.join(OUTPUT_PATH_validation, 'checkpoint_epoch{}.pt'.format(epoch))\n",
    "    #     # clear the content of folder\n",
    "    #     for files in os.listdir(OUTPUT_PATH_validation):\n",
    "    #         path = os.path.join(OUTPUT_PATH_validation, files)\n",
    "    #         try:\n",
    "    #             shutil.rmtree(path)\n",
    "    #         except OSError:\n",
    "    #             os.remove(path)\n",
    "    #     # if not os.path.exists(output_dir):\n",
    "    #     #     os.makedirs(output_dir)\n",
    "    #     torch.save(model.state_dict(), output_dir_validation)\n",
    "        \n",
    "    OUTPUT_PATH_test =os.path.join(OUTPUT_PATH, 'test/')\n",
    "    if not os.path.exists(OUTPUT_PATH_test):\n",
    "        os.makedirs(OUTPUT_PATH_test)\n",
    "    if acc_label2_te>best_label2_acc_te:\n",
    "        best_label2_acc_te=acc_label2_te\n",
    "        output_dir_test = os.path.join(OUTPUT_PATH_test, 'checkpoint_epoch{}.pt'.format(epoch))\n",
    "        # clear the content of folder\n",
    "        for files in os.listdir(OUTPUT_PATH_test):\n",
    "            path = os.path.join(OUTPUT_PATH_test, files)\n",
    "            try:\n",
    "                shutil.rmtree(path)\n",
    "            except OSError:\n",
    "                os.remove(path)\n",
    "        # if not os.path.exists(output_dir):\n",
    "        #     os.makedirs(output_dir)\n",
    "        torch.save(model.state_dict(), output_dir_test)\n",
    "    # early stop\n",
    "    if f_label2_te > max_validation_f:\n",
    "            max_validation_f = f_label2_te\n",
    "            counter = 0\n",
    "    elif f_label2_te <= max_validation_f:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                break\n",
    "    print('counter: ',counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f79fb2cb-f0b5-4160-89b4-a0ee837e75bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "751.4475"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_label2_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c30610c8-c166-4260-87d3-f28faac8e9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "798ea626-65be-4f9d-8b05-e87eba8a4665",
   "metadata": {},
   "outputs": [],
   "source": [
    "label1_loss_df = pd.DataFrame(\n",
    "    {'label1_loss_train': label1_loss_train_list,\n",
    "     # 'label1_loss_validation': label1_loss_validation_list,\n",
    "     'label1_loss_test': label1_loss_test_list\n",
    "    })\n",
    "label2_loss_df = pd.DataFrame(\n",
    "    {'label2_loss_train': label2_loss_train_list,\n",
    "     # 'label2_loss_validation': label2_loss_validation_list,\n",
    "     'label2_loss_test': label2_loss_test_list\n",
    "    })\n",
    "label1_f1_df = pd.DataFrame(\n",
    "    {'label1_f1_train': label1_f1_train_list,\n",
    "     # 'label1_f1_validation': label1_f1_validation_list,\n",
    "     'label1_f1_test': label1_f1_test_list\n",
    "    })\n",
    "label2_f1_df = pd.DataFrame(\n",
    "    {'label2_f1_train': label2_f1_train_list,\n",
    "     # 'label2_f1_validation': label2_f1_validation_list,\n",
    "     'label2_f1_test': label2_f1_test_list\n",
    "    })\n",
    "label1_acc_df = pd.DataFrame(\n",
    "    {'label1_f1_train': label1_acc_train_list,\n",
    "     # 'label1_f1_validation': label1_f1_validation_list,\n",
    "     'label1_f1_test': label1_acc_test_list\n",
    "    })\n",
    "label2_acc_df = pd.DataFrame(\n",
    "    {'label2_f1_train': label2_acc_train_list,\n",
    "     # 'label2_f1_validation': label2_f1_validation_list,\n",
    "     'label2_f1_test': label2_acc_test_list\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "777e5eb2-8d49-46c7-9d9e-7d9ce323fc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./checkpoint\\\\bert-large-uncased\\\\test/checkpoint_epoch159.pt'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5918fbda-c096-42f6-b749-32b7c14a9176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'label2 acc'}, xlabel='epochs', ylabel='acc'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label1_loss_df.plot(title=\"label1 losses\",xlabel=\"epochs\",ylabel=\"loss\")\n",
    "label2_loss_df.plot(title=\"label2 losses\",xlabel=\"epochs\",ylabel=\"loss\")\n",
    "label1_f1_df.plot(title=\"label1 f1\",xlabel=\"epochs\",ylabel=\"f1\")\n",
    "label2_f1_df.plot(title=\"label2 f1\",xlabel=\"epochs\",ylabel=\"f1\")\n",
    "label1_acc_df.plot(title=\"label1 acc\",xlabel=\"epochs\",ylabel=\"acc\")\n",
    "label2_acc_df.plot(title=\"label2 acc\",xlabel=\"epochs\",ylabel=\"acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6591fe4a-1a14-41c6-a43d-563c0b1d6af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9272"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(label2_f1_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2629b306-c507-4e4e-bb1a-b671725d8a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9367"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(label2_acc_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6faa13c9-8697-4d0b-a206-67cbd793d1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(output_dir_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73adc569-a586-4b78-9f1e-81189c911538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoint\\bert-large-uncased\\test/checkpoint_epoch159.pt\n"
     ]
    }
   ],
   "source": [
    "print(output_dir_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6186dc67-83c0-45c0-84e6-a9a15a0f633a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp:  1604\n",
      "fn:  146\n",
      "tn:  2128\n",
      "fp:  106\n",
      "pred label2 length:  3984\n",
      "true label2 length:  3984\n",
      "token_idx_list length:  3984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match number:  3732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_4400\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "loss_label1_te, loss_label2_te, p_label1_te, r_label1_te, f_label1_te, acc_label1_te, p_label2_te, r_label2_te, f_label2_te, acc_label2_te, comparison_df_te = evaluate_output_difference(model, test_iterator, criterion_tag, criterion_cls, TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c234d212-0030-4137-9cf5-102091a1845d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9272"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_label2_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "722463cb-a2e4-4eaf-9e44-dc08413107a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9367"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_label2_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a2b8ddc-2236-4252-b626-e33e9a136bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_female = data.TabularDataset(\n",
    "                                    path = DATA_PATH+'gap_test_female_bert_2mask.csv',\n",
    "                                    format = 'csv',\n",
    "                                    fields = fields,\n",
    "                                    skip_header = True)\n",
    "test_data_male = data.TabularDataset(\n",
    "                                    path = DATA_PATH+'gap_test_male_bert_2mask.csv',\n",
    "                                    format = 'csv',\n",
    "                                    fields = fields,\n",
    "                                    skip_header = True)\n",
    "\n",
    "TOKEN.build_vocab(test_data_female, test_data_male)\n",
    "LABEL1.build_vocab(test_data_female, test_data_male)\n",
    "FT_TAGS.build_vocab(test_data_female, test_data_male)\n",
    "SEQ.build_vocab(test_data_female, test_data_male)\n",
    "LABEL2.build_vocab(test_data_female, test_data_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "085e0238-ff9d-4246-a09b-ad82ea7b64b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.legacy.data.dataset.TabularDataset object at 0x0000027BB99C8E20>\n",
      "<torchtext.legacy.data.dataset.TabularDataset object at 0x0000027BB99C8F10>\n"
     ]
    }
   ],
   "source": [
    "print(test_data_female)\n",
    "print(test_data_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3e2cd5d-8249-4d15-a23e-adc3dd70d0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_female_iterator = data.BucketIterator(\n",
    "    test_data_female, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    shuffle = True,\n",
    "    sort=False)\n",
    "test_male_iterator = data.BucketIterator(\n",
    "    test_data_male, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    shuffle = True,\n",
    "    sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef1828bb-eebc-4cb9-96fb-5cd6e6a17b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.legacy.data.iterator.BucketIterator'>\n",
      "<class 'torchtext.legacy.data.iterator.BucketIterator'>\n"
     ]
    }
   ],
   "source": [
    "print(type(test_female_iterator))\n",
    "print(type(test_male_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bfb5a8fd-6148-4f46-9478-a6b9f9097b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp:  792\n",
      "fn:  78\n",
      "tn:  1066\n",
      "fp:  58\n",
      "pred label2 length:  1994\n",
      "true label2 length:  1994\n",
      "match number:  1858\n"
     ]
    }
   ],
   "source": [
    "loss_label1_te_female, loss_label2_te_female, p_label1_te_female, r_label1_te_female,f_label1_te_female, acc_label1_te_female, p_label2_te_female,r_label2_te_female, f_label2_te_female, acc_label2_te_female = evaluate(model, test_female_iterator, criterion_tag, criterion_cls, TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0f30f234-6a37-450c-b514-82621b4b3e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9209"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_label2_te_female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b4fe4f6-5eeb-4f6d-a2ef-8e50fcc8583f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp:  808\n",
      "fn:  72\n",
      "tn:  1057\n",
      "fp:  53\n",
      "pred label2 length:  1990\n",
      "true label2 length:  1990\n",
      "match number:  1865\n"
     ]
    }
   ],
   "source": [
    "loss_label1_te_male, loss_label2_te_male, p_label1_te_male, r_label1_te_male, f_label1_te_male, acc_label1_te_male, p_label2_te_male, r_label2_te_male, f_label2_te_male, acc_label2_te_male = evaluate(model, test_male_iterator, criterion_tag, criterion_cls, TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7f9457b3-9a99-44d9-b44e-4e566f215340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9282"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_label2_te_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "652e6a64-be35-4f00-8428-286b53ed653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bias=f_label2_te_female/f_label2_te_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f8a37c55-6239-4224-813e-18d15af07b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9921353156647275"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "225b213f-7eca-4114-9072-7e0d776ee4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('E:/Google Drive/Continental/coref-multitask/winogender')\n",
    "os.chdir('./gap')\n",
    "comparison_df_te.to_csv(\"comparison_gap_bert_multitask_lbwb_gap.csv\", index=False,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f2fe52-6690-49fc-995a-411cacc054b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "53560c29-27ac-4364-9fd9-95dd05de2cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('E:/Google Drive/Continental/coref-multitask')\n",
    "# DATA_PATH = './winogender/'\n",
    "# winogender_df = data.TabularDataset(\n",
    "#                                     path = DATA_PATH+'winogender_df_new_spanbert.csv',\n",
    "#                                     format = 'csv',\n",
    "#                                     fields = fields,\n",
    "#                                     skip_header = True)\n",
    "\n",
    "# TOKEN.build_vocab(winogender_df)\n",
    "# LABEL1.build_vocab(winogender_df)\n",
    "# FT_TAGS.build_vocab(winogender_df)\n",
    "# SEQ.build_vocab(winogender_df)\n",
    "# LABEL2.build_vocab(winogender_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b2106030-16b4-437b-b1be-1e3ba48ff0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(winogender_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "93cc74f5-808b-468c-b2f6-debac9c7dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# winogender_iterator = data.BucketIterator(\n",
    "#     winogender_df, \n",
    "#     batch_size = BATCH_SIZE,\n",
    "#     device = device,\n",
    "#     shuffle = True,\n",
    "#     sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b7fa9392-49c1-48db-bfda-4e751e79a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_label1_winogender, loss_label2_winogender, p_label1_winogender, r_label1_winogender,f_label1_winogender, acc_label1_winogender, p_label2_winogender,r_label2_winogender, f_label2_winogender, acc_label2_winogender = evaluate(model, winogender_iterator, criterion_tag, criterion_cls, TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ed9234cf-f68d-43a6-965e-9dcd1e721bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_label2_winogender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649a08e4-fef1-4930-923a-5b6ee6f83b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
