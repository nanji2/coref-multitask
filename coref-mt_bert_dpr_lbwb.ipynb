{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5544d3ec-a275-43af-9704-32cfe4747c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da81ce68-01b4-45ee-96f2-5ccd272d97aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a97e1236-837f-461b-8dec-57273845ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99309099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.legacy import data\n",
    "#from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "#from transformers import RobertaTokenizer, RobertaModel\n",
    "#from transformers import BertTokenizer, BertModel\n",
    "#from transformers import LongformerTokenizer, LongformerModel\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import statistics\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random\n",
    "import functools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf54be0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters & setup\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "DROPOUT = 0.2\n",
    "N_EPOCHS = 610\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-6\n",
    "NO_HEAD_TRANS = 16\n",
    "\n",
    "TAG_LOSS_WEIGTH = 0.5\n",
    "CLS_LOSS_WEIGTH = 0.5\n",
    "\n",
    "BERT_PATH = './bert-large-uncased' # the path of your downloaded pre-trained language model\n",
    "DATA_PATH = './dpr/'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_PATH)\n",
    "bert = AutoModel.from_pretrained(BERT_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "681d50c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pre-processing\n",
    "\n",
    "def read_token_idx_list_n_cut_to_max_length(tokens, max_input_length):\n",
    "    \n",
    "    tokens =  tokens[:max_input_length-1]\n",
    "    tokens_list = []\n",
    "    for i in tokens:\n",
    "        tokens_list.append(int(i))\n",
    "    return torch.tensor(tokens_list)\n",
    "\n",
    "def cut_to_max_length(tokens, max_input_length):\n",
    "    tokens = tokens[:max_input_length-1]\n",
    "    return tokens\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "pad_token = tokenizer.pad_token\n",
    "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
    "max_input_length = tokenizer.max_model_input_sizes['bert-large-cased']\n",
    "text_id_preprocessor = functools.partial(read_token_idx_list_n_cut_to_max_length,max_input_length = max_input_length)\n",
    "tag_preprocessor = functools.partial(cut_to_max_length, max_input_length = max_input_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e0231b7-347d-401b-80f2-18c1cf067f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert-base-uncased': 512,\n",
       " 'bert-large-uncased': 512,\n",
       " 'bert-base-cased': 512,\n",
       " 'bert-large-cased': 512,\n",
       " 'bert-base-multilingual-uncased': 512,\n",
       " 'bert-base-multilingual-cased': 512,\n",
       " 'bert-base-chinese': 512,\n",
       " 'bert-base-german-cased': 512,\n",
       " 'bert-large-uncased-whole-word-masking': 512,\n",
       " 'bert-large-cased-whole-word-masking': 512,\n",
       " 'bert-large-uncased-whole-word-masking-finetuned-squad': 512,\n",
       " 'bert-large-cased-whole-word-masking-finetuned-squad': 512,\n",
       " 'bert-base-cased-finetuned-mrpc': 512,\n",
       " 'bert-base-german-dbmdz-cased': 512,\n",
       " 'bert-base-german-dbmdz-uncased': 512,\n",
       " 'TurkuNLP/bert-base-finnish-cased-v1': 512,\n",
       " 'TurkuNLP/bert-base-finnish-uncased-v1': 512,\n",
       " 'wietsedv/bert-base-dutch-cased': 512}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.max_model_input_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db3a44be-f250-4727-b2f1-a75d8c7482e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b13fb8a6-446f-4e68-a1d9-7d026df063cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-large-uncased'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT_PATH[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2778ba5-e654-43f2-96b9-d0aa7cf2529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "\n",
    "TOKEN = data.Field(batch_first = True)\n",
    "TOKEN_ID = data.Field(batch_first = True,\n",
    "                     use_vocab = False,\n",
    "                     dtype=torch.int64,\n",
    "                     pad_token = pad_token_idx,\n",
    "                     preprocessing = text_id_preprocessor)\n",
    "LABEL1 = data.Field(batch_first = True,\n",
    "                    unk_token = None,\n",
    "                    preprocessing = tag_preprocessor)\n",
    "MASK_AB = data.Field(batch_first = True,\n",
    "                     use_vocab = False,\n",
    "                     dtype=torch.int64,\n",
    "                     pad_token = pad_token_idx,\n",
    "                     preprocessing = text_id_preprocessor)\n",
    "MASK_P = data.Field(batch_first = True,\n",
    "                     use_vocab = False,\n",
    "                     dtype=torch.int64,\n",
    "                     pad_token = pad_token_idx,\n",
    "                     preprocessing = text_id_preprocessor)\n",
    "FT_TAGS = data.Field(batch_first = True,\n",
    "                     use_vocab = False,\n",
    "                     dtype=torch.int64,\n",
    "                     pad_token = pad_token_idx,\n",
    "                     preprocessing = text_id_preprocessor)\n",
    "SEQ = data.Field(batch_first = True)\n",
    "LABEL2 = data.Field(batch_first = True,\n",
    "                    unk_token = None,\n",
    "                    #pad_token = None,\n",
    "                    preprocessing = tag_preprocessor)\n",
    "\n",
    "fields = ((\"token\", TOKEN),\n",
    "          ('token_id', TOKEN_ID),\n",
    "          ('label1', LABEL1),\n",
    "          ('mask_ab', MASK_AB),\n",
    "          ('mask_p', MASK_P),\n",
    "          ('first_token', FT_TAGS),\n",
    "          ('seq', SEQ),\n",
    "          ('label2', LABEL2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "201d6f0a-9b53-49d1-b8fd-a8f21513de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data.TabularDataset.splits(\n",
    "                                    path = DATA_PATH,\n",
    "                                    train = 'dpr_train_bert_2mask.csv',\n",
    "                                    validation = None,\n",
    "                                    test = 'dpr_test_bert_2mask.csv',\n",
    "                                    format = 'csv',\n",
    "                                    fields = fields,\n",
    "                                    skip_header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a188fd46-c10e-481b-bba6-29a8fff620ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN.build_vocab(train_data, test_data)\n",
    "LABEL1.build_vocab(train_data, test_data)\n",
    "FT_TAGS.build_vocab(train_data, test_data)\n",
    "SEQ.build_vocab(train_data, test_data)\n",
    "LABEL2.build_vocab(train_data, test_data)\n",
    "\n",
    "# if you want to prepare a big vocabulary that covers words that never appear in your dataset:\n",
    "\n",
    "#word_list = [['<unk>', '<pad>', 'I', 'great', \"it's\", 'like', 'swimming', '.', ',', 'BBBBBBB']]\n",
    "#TOKEN.build_vocab(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4454779e-ee86-4d6e-a264-bcf14b48571f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.legacy.data.dataset.TabularDataset'>\n",
      "<torchtext.legacy.data.dataset.TabularDataset object at 0x000001A0F92B9A30>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09b8cde6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: {'token': ['[CLS]', 'the', 'sniper', 'shot', 'the', 'terrorist', 'because', 'he', 'had', 'orders', '.', '[SEP]'], 'token_id': tensor([  101,  1996, 17515,  2915,  1996,  9452,  2138,  2002,  2018,  4449,\n",
      "         1012,   102]), 'label1': ['0', '1', '1', '0', '0', '0', '0', '1', '0', '0', '0', '0'], 'mask_ab': tensor([0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'mask_p': tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]), 'first_token': tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'seq': ['The', 'sniper', 'shot', 'the', 'terrorist', 'because', 'he', 'had', 'orders.'], 'label2': ['1.0']}\n",
      "Label1 vocab ['<pad>', '0', '1']\n",
      "Label2 vocab ['<pad>', '0.0', '1.0']\n"
     ]
    }
   ],
   "source": [
    "print('Example:', vars(test_data.examples[2]))\n",
    "print('Label1 vocab', LABEL1.vocab.itos)\n",
    "print('Label2 vocab', LABEL2.vocab.itos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9491f7ad-bd7e-42c1-954b-7c08e137de3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: {'token': ['[CLS]', 'the', 'sniper', 'shot', 'the', 'terrorist', 'because', 'he', 'had', 'orders', '.', '[SEP]'], 'token_id': tensor([  101,  1996, 17515,  2915,  1996,  9452,  2138,  2002,  2018,  4449,\n",
      "         1012,   102]), 'label1': ['0', '1', '1', '0', '0', '0', '0', '1', '0', '0', '0', '0'], 'mask_ab': tensor([0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'mask_p': tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]), 'first_token': tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'seq': ['The', 'sniper', 'shot', 'the', 'terrorist', 'because', 'he', 'had', 'orders.'], 'label2': ['1.0']}\n"
     ]
    }
   ],
   "source": [
    "print('Example:', vars(test_data.examples[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "601a08eb-25da-4717-8cca-a36accc7ef88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.legacy.data.dataset.TabularDataset"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "770e518b-8b92-4f39-8703-e8eeb68154ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2644"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5d813a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# train_iterator, test_iterator = data.BucketIterator.splits(\n",
    "#     (train_data, test_data), \n",
    "#     batch_size = BATCH_SIZE,\n",
    "#     device = device,\n",
    "#     shuffle = True,\n",
    "#     sort=False)\n",
    "train_iterator = data.BucketIterator(\n",
    "    train_data, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    shuffle = True,\n",
    "    sort=False)\n",
    "test_iterator = data.BucketIterator(\n",
    "    test_data, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    shuffle = False,\n",
    "    sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebd6678c-1ab6-4ff6-98cc-034f1f400fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.config.to_dict()['hidden_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "868bef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTL(nn.Module):\n",
    "    def __init__(self,bert,label1_output_dim,label2_output_dim,dropout,no_head_trans):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        # embedding_dim = 1024\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.tag_layer1 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        self.cls_layer1 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        self.tag_layer2 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        self.cls_layer2 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        # self.tag_layer3 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        # self.cls_layer3 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        # self.tag_layer4 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        # self.cls_layer4 = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = no_head_trans)\n",
    "        \n",
    "        self.fc_tag = nn.Linear(embedding_dim, label1_output_dim)\n",
    "        self.fc_cls = nn.Linear(embedding_dim, label2_output_dim)\n",
    "        # self.fc_cls = nn.Linear(embedding_dim*2, label2_output_dim)\n",
    "        self.fc_layernorm_cls = nn.LayerNorm(label2_output_dim)\n",
    "        \n",
    "    def forward(self, token_id, mask_ab, mask_p):\n",
    "        \n",
    "        emb_share = self.dropout(self.bert(token_id)[0]) # [batch size, seq len, emb dim]\n",
    "        \n",
    "        tag1 = self.dropout(self.tag_layer1(emb_share))  # [batch size, seq len, emb dim]\n",
    "        cls1 = self.dropout(self.cls_layer1(emb_share))    # [batch size, seq len, emb dim]\n",
    "        tag2 = self.dropout(self.tag_layer2(tag1))  # [batch size, seq len, emb dim]\n",
    "        cls2 = self.dropout(self.cls_layer2(cls1))    # [batch size, seq len, emb dim]\n",
    "        # tag3 = self.dropout(self.tag_layer3(tag2))  # [batch size, seq len, emb dim]\n",
    "        # cls3 = self.dropout(self.cls_layer3(cls2))    # [batch size, seq len, emb dim]\n",
    "        # tag4 = self.dropout(self.tag_layer4(tag2))  # [batch size, seq len, emb dim]\n",
    "        # cls4 = self.dropout(self.cls_layer4(cls3))    # [batch size, seq len, emb dim]\n",
    "        \n",
    "        tag_pred = self.fc_tag(tag2) # [batch size, seq len, output dim 1]\n",
    "        \n",
    "        \n",
    "        # get the average for candidate\n",
    "        cls_mask_ab = torch.sum(cls2*mask_ab.unsqueeze(2),1)/torch.sum(mask_ab.unsqueeze(2),1) # [batch size, emb dim]\n",
    "        # cls_mask_ab = torch.sum(cls4*mask_ab.unsqueeze(2),1) # [batch size, emb dim]\n",
    "        # get the average for pronoun\n",
    "        cls_mask_p = torch.sum(cls2*mask_p.unsqueeze(2),1)/torch.sum(mask_p.unsqueeze(2),1) # [batch size, emb dim]\n",
    "        \n",
    "        # element wise product\n",
    "        cls_fusion= cls_mask_ab * cls_mask_p # [batch size, emb dim]\n",
    "        \n",
    "        # # element-wise addition\n",
    "        # cls_fusion= torch.add(cls_mask_ab, cls_mask_p) # [batch size, emb dim]\n",
    "        \n",
    "        # # element-wise square of difference\n",
    "        # cls_fusion= torch.square(torch.sub(cls_mask_ab, cls_mask_p)) # [batch size, emb dim]\n",
    "        \n",
    "        # # concatenation\n",
    "        # cls_fusion= torch.cat((cls_mask_ab,cls_mask_p),dim=1) # [batch size, emb dim*2]\n",
    "                               \n",
    "        cls_pred = self.fc_layernorm_cls(self.fc_cls(cls_fusion)) # [batch size, output dim 2]\n",
    "        \n",
    "        \n",
    "        return tag_pred, cls_pred\n",
    "    \n",
    "# ############## for softmax trust level ############\n",
    "#         tag_signal = F.softmax(tag_pred,dim=2)[:,:,2] # [batch size, seq len]\n",
    "#         point_five = torch.full(tag_signal.size(), 0.5).cuda() # [batch size, seq len]\n",
    "#         tag_signal = torch.mean(torch.square(tag_signal-point_five), 1) # [batch size]\n",
    "        \n",
    "#         cls_signal = F.softmax(cls_pred,dim=1)[:,2] # [batch size]\n",
    "#         point_five = torch.full(cls_signal.size(), 0.5).cuda() # [batch size]\n",
    "#         cls_signal = torch.square(cls_signal-point_five) # [batch size]\n",
    "        \n",
    "        \n",
    "#         return tag_pred, cls_pred, tag_signal, cls_signal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2f2566a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 368,747,532 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIM_TAGGING = len(LABEL1.vocab)\n",
    "OUTPUT_DIM_CLASSIFICATION = len(LABEL2.vocab)\n",
    "\n",
    "model = MTL(bert,\n",
    "            OUTPUT_DIM_TAGGING, \n",
    "            OUTPUT_DIM_CLASSIFICATION, \n",
    "            DROPOUT,\n",
    "            NO_HEAD_TRANS)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e89581b7-4e6d-4f2c-8afe-b53543b9f54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(OUTPUT_DIM_TAGGING)\n",
    "print(OUTPUT_DIM_CLASSIFICATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cff96df-2b10-45dd-835d-8ab3cbeb316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_params = []\n",
    "other_params = []\n",
    "for name, param in model.named_parameters():\n",
    "  if name.startswith(\"bert\"):\n",
    "    bert_params.append(param)\n",
    "  else:\n",
    "    other_params.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88a34620-9de1-4681-974a-4466b7bdc3b6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66678321-1cb9-4e0c-bb8e-5ac474707dd4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(other_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8323a48a-8550-457e-9add-670b264ecc59",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight\n",
      "bert.embeddings.position_embeddings.weight\n",
      "bert.embeddings.token_type_embeddings.weight\n",
      "bert.embeddings.LayerNorm.weight\n",
      "bert.embeddings.LayerNorm.bias\n",
      "bert.encoder.layer.0.attention.self.query.weight\n",
      "bert.encoder.layer.0.attention.self.query.bias\n",
      "bert.encoder.layer.0.attention.self.key.weight\n",
      "bert.encoder.layer.0.attention.self.key.bias\n",
      "bert.encoder.layer.0.attention.self.value.weight\n",
      "bert.encoder.layer.0.attention.self.value.bias\n",
      "bert.encoder.layer.0.attention.output.dense.weight\n",
      "bert.encoder.layer.0.attention.output.dense.bias\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.0.intermediate.dense.weight\n",
      "bert.encoder.layer.0.intermediate.dense.bias\n",
      "bert.encoder.layer.0.output.dense.weight\n",
      "bert.encoder.layer.0.output.dense.bias\n",
      "bert.encoder.layer.0.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.attention.self.query.weight\n",
      "bert.encoder.layer.1.attention.self.query.bias\n",
      "bert.encoder.layer.1.attention.self.key.weight\n",
      "bert.encoder.layer.1.attention.self.key.bias\n",
      "bert.encoder.layer.1.attention.self.value.weight\n",
      "bert.encoder.layer.1.attention.self.value.bias\n",
      "bert.encoder.layer.1.attention.output.dense.weight\n",
      "bert.encoder.layer.1.attention.output.dense.bias\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.intermediate.dense.weight\n",
      "bert.encoder.layer.1.intermediate.dense.bias\n",
      "bert.encoder.layer.1.output.dense.weight\n",
      "bert.encoder.layer.1.output.dense.bias\n",
      "bert.encoder.layer.1.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.attention.self.query.weight\n",
      "bert.encoder.layer.2.attention.self.query.bias\n",
      "bert.encoder.layer.2.attention.self.key.weight\n",
      "bert.encoder.layer.2.attention.self.key.bias\n",
      "bert.encoder.layer.2.attention.self.value.weight\n",
      "bert.encoder.layer.2.attention.self.value.bias\n",
      "bert.encoder.layer.2.attention.output.dense.weight\n",
      "bert.encoder.layer.2.attention.output.dense.bias\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.intermediate.dense.weight\n",
      "bert.encoder.layer.2.intermediate.dense.bias\n",
      "bert.encoder.layer.2.output.dense.weight\n",
      "bert.encoder.layer.2.output.dense.bias\n",
      "bert.encoder.layer.2.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.attention.self.query.weight\n",
      "bert.encoder.layer.3.attention.self.query.bias\n",
      "bert.encoder.layer.3.attention.self.key.weight\n",
      "bert.encoder.layer.3.attention.self.key.bias\n",
      "bert.encoder.layer.3.attention.self.value.weight\n",
      "bert.encoder.layer.3.attention.self.value.bias\n",
      "bert.encoder.layer.3.attention.output.dense.weight\n",
      "bert.encoder.layer.3.attention.output.dense.bias\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.intermediate.dense.weight\n",
      "bert.encoder.layer.3.intermediate.dense.bias\n",
      "bert.encoder.layer.3.output.dense.weight\n",
      "bert.encoder.layer.3.output.dense.bias\n",
      "bert.encoder.layer.3.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.attention.self.query.weight\n",
      "bert.encoder.layer.4.attention.self.query.bias\n",
      "bert.encoder.layer.4.attention.self.key.weight\n",
      "bert.encoder.layer.4.attention.self.key.bias\n",
      "bert.encoder.layer.4.attention.self.value.weight\n",
      "bert.encoder.layer.4.attention.self.value.bias\n",
      "bert.encoder.layer.4.attention.output.dense.weight\n",
      "bert.encoder.layer.4.attention.output.dense.bias\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.intermediate.dense.weight\n",
      "bert.encoder.layer.4.intermediate.dense.bias\n",
      "bert.encoder.layer.4.output.dense.weight\n",
      "bert.encoder.layer.4.output.dense.bias\n",
      "bert.encoder.layer.4.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.attention.self.query.weight\n",
      "bert.encoder.layer.5.attention.self.query.bias\n",
      "bert.encoder.layer.5.attention.self.key.weight\n",
      "bert.encoder.layer.5.attention.self.key.bias\n",
      "bert.encoder.layer.5.attention.self.value.weight\n",
      "bert.encoder.layer.5.attention.self.value.bias\n",
      "bert.encoder.layer.5.attention.output.dense.weight\n",
      "bert.encoder.layer.5.attention.output.dense.bias\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.intermediate.dense.weight\n",
      "bert.encoder.layer.5.intermediate.dense.bias\n",
      "bert.encoder.layer.5.output.dense.weight\n",
      "bert.encoder.layer.5.output.dense.bias\n",
      "bert.encoder.layer.5.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.attention.self.query.weight\n",
      "bert.encoder.layer.6.attention.self.query.bias\n",
      "bert.encoder.layer.6.attention.self.key.weight\n",
      "bert.encoder.layer.6.attention.self.key.bias\n",
      "bert.encoder.layer.6.attention.self.value.weight\n",
      "bert.encoder.layer.6.attention.self.value.bias\n",
      "bert.encoder.layer.6.attention.output.dense.weight\n",
      "bert.encoder.layer.6.attention.output.dense.bias\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.intermediate.dense.weight\n",
      "bert.encoder.layer.6.intermediate.dense.bias\n",
      "bert.encoder.layer.6.output.dense.weight\n",
      "bert.encoder.layer.6.output.dense.bias\n",
      "bert.encoder.layer.6.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.attention.self.query.weight\n",
      "bert.encoder.layer.7.attention.self.query.bias\n",
      "bert.encoder.layer.7.attention.self.key.weight\n",
      "bert.encoder.layer.7.attention.self.key.bias\n",
      "bert.encoder.layer.7.attention.self.value.weight\n",
      "bert.encoder.layer.7.attention.self.value.bias\n",
      "bert.encoder.layer.7.attention.output.dense.weight\n",
      "bert.encoder.layer.7.attention.output.dense.bias\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.intermediate.dense.weight\n",
      "bert.encoder.layer.7.intermediate.dense.bias\n",
      "bert.encoder.layer.7.output.dense.weight\n",
      "bert.encoder.layer.7.output.dense.bias\n",
      "bert.encoder.layer.7.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.attention.self.query.weight\n",
      "bert.encoder.layer.8.attention.self.query.bias\n",
      "bert.encoder.layer.8.attention.self.key.weight\n",
      "bert.encoder.layer.8.attention.self.key.bias\n",
      "bert.encoder.layer.8.attention.self.value.weight\n",
      "bert.encoder.layer.8.attention.self.value.bias\n",
      "bert.encoder.layer.8.attention.output.dense.weight\n",
      "bert.encoder.layer.8.attention.output.dense.bias\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.intermediate.dense.weight\n",
      "bert.encoder.layer.8.intermediate.dense.bias\n",
      "bert.encoder.layer.8.output.dense.weight\n",
      "bert.encoder.layer.8.output.dense.bias\n",
      "bert.encoder.layer.8.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.attention.self.query.weight\n",
      "bert.encoder.layer.9.attention.self.query.bias\n",
      "bert.encoder.layer.9.attention.self.key.weight\n",
      "bert.encoder.layer.9.attention.self.key.bias\n",
      "bert.encoder.layer.9.attention.self.value.weight\n",
      "bert.encoder.layer.9.attention.self.value.bias\n",
      "bert.encoder.layer.9.attention.output.dense.weight\n",
      "bert.encoder.layer.9.attention.output.dense.bias\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.intermediate.dense.weight\n",
      "bert.encoder.layer.9.intermediate.dense.bias\n",
      "bert.encoder.layer.9.output.dense.weight\n",
      "bert.encoder.layer.9.output.dense.bias\n",
      "bert.encoder.layer.9.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.attention.self.query.weight\n",
      "bert.encoder.layer.10.attention.self.query.bias\n",
      "bert.encoder.layer.10.attention.self.key.weight\n",
      "bert.encoder.layer.10.attention.self.key.bias\n",
      "bert.encoder.layer.10.attention.self.value.weight\n",
      "bert.encoder.layer.10.attention.self.value.bias\n",
      "bert.encoder.layer.10.attention.output.dense.weight\n",
      "bert.encoder.layer.10.attention.output.dense.bias\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.intermediate.dense.weight\n",
      "bert.encoder.layer.10.intermediate.dense.bias\n",
      "bert.encoder.layer.10.output.dense.weight\n",
      "bert.encoder.layer.10.output.dense.bias\n",
      "bert.encoder.layer.10.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.attention.self.query.weight\n",
      "bert.encoder.layer.11.attention.self.query.bias\n",
      "bert.encoder.layer.11.attention.self.key.weight\n",
      "bert.encoder.layer.11.attention.self.key.bias\n",
      "bert.encoder.layer.11.attention.self.value.weight\n",
      "bert.encoder.layer.11.attention.self.value.bias\n",
      "bert.encoder.layer.11.attention.output.dense.weight\n",
      "bert.encoder.layer.11.attention.output.dense.bias\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.intermediate.dense.weight\n",
      "bert.encoder.layer.11.intermediate.dense.bias\n",
      "bert.encoder.layer.11.output.dense.weight\n",
      "bert.encoder.layer.11.output.dense.bias\n",
      "bert.encoder.layer.11.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.output.LayerNorm.bias\n",
      "bert.encoder.layer.12.attention.self.query.weight\n",
      "bert.encoder.layer.12.attention.self.query.bias\n",
      "bert.encoder.layer.12.attention.self.key.weight\n",
      "bert.encoder.layer.12.attention.self.key.bias\n",
      "bert.encoder.layer.12.attention.self.value.weight\n",
      "bert.encoder.layer.12.attention.self.value.bias\n",
      "bert.encoder.layer.12.attention.output.dense.weight\n",
      "bert.encoder.layer.12.attention.output.dense.bias\n",
      "bert.encoder.layer.12.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.12.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.12.intermediate.dense.weight\n",
      "bert.encoder.layer.12.intermediate.dense.bias\n",
      "bert.encoder.layer.12.output.dense.weight\n",
      "bert.encoder.layer.12.output.dense.bias\n",
      "bert.encoder.layer.12.output.LayerNorm.weight\n",
      "bert.encoder.layer.12.output.LayerNorm.bias\n",
      "bert.encoder.layer.13.attention.self.query.weight\n",
      "bert.encoder.layer.13.attention.self.query.bias\n",
      "bert.encoder.layer.13.attention.self.key.weight\n",
      "bert.encoder.layer.13.attention.self.key.bias\n",
      "bert.encoder.layer.13.attention.self.value.weight\n",
      "bert.encoder.layer.13.attention.self.value.bias\n",
      "bert.encoder.layer.13.attention.output.dense.weight\n",
      "bert.encoder.layer.13.attention.output.dense.bias\n",
      "bert.encoder.layer.13.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.13.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.13.intermediate.dense.weight\n",
      "bert.encoder.layer.13.intermediate.dense.bias\n",
      "bert.encoder.layer.13.output.dense.weight\n",
      "bert.encoder.layer.13.output.dense.bias\n",
      "bert.encoder.layer.13.output.LayerNorm.weight\n",
      "bert.encoder.layer.13.output.LayerNorm.bias\n",
      "bert.encoder.layer.14.attention.self.query.weight\n",
      "bert.encoder.layer.14.attention.self.query.bias\n",
      "bert.encoder.layer.14.attention.self.key.weight\n",
      "bert.encoder.layer.14.attention.self.key.bias\n",
      "bert.encoder.layer.14.attention.self.value.weight\n",
      "bert.encoder.layer.14.attention.self.value.bias\n",
      "bert.encoder.layer.14.attention.output.dense.weight\n",
      "bert.encoder.layer.14.attention.output.dense.bias\n",
      "bert.encoder.layer.14.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.14.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.14.intermediate.dense.weight\n",
      "bert.encoder.layer.14.intermediate.dense.bias\n",
      "bert.encoder.layer.14.output.dense.weight\n",
      "bert.encoder.layer.14.output.dense.bias\n",
      "bert.encoder.layer.14.output.LayerNorm.weight\n",
      "bert.encoder.layer.14.output.LayerNorm.bias\n",
      "bert.encoder.layer.15.attention.self.query.weight\n",
      "bert.encoder.layer.15.attention.self.query.bias\n",
      "bert.encoder.layer.15.attention.self.key.weight\n",
      "bert.encoder.layer.15.attention.self.key.bias\n",
      "bert.encoder.layer.15.attention.self.value.weight\n",
      "bert.encoder.layer.15.attention.self.value.bias\n",
      "bert.encoder.layer.15.attention.output.dense.weight\n",
      "bert.encoder.layer.15.attention.output.dense.bias\n",
      "bert.encoder.layer.15.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.15.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.15.intermediate.dense.weight\n",
      "bert.encoder.layer.15.intermediate.dense.bias\n",
      "bert.encoder.layer.15.output.dense.weight\n",
      "bert.encoder.layer.15.output.dense.bias\n",
      "bert.encoder.layer.15.output.LayerNorm.weight\n",
      "bert.encoder.layer.15.output.LayerNorm.bias\n",
      "bert.encoder.layer.16.attention.self.query.weight\n",
      "bert.encoder.layer.16.attention.self.query.bias\n",
      "bert.encoder.layer.16.attention.self.key.weight\n",
      "bert.encoder.layer.16.attention.self.key.bias\n",
      "bert.encoder.layer.16.attention.self.value.weight\n",
      "bert.encoder.layer.16.attention.self.value.bias\n",
      "bert.encoder.layer.16.attention.output.dense.weight\n",
      "bert.encoder.layer.16.attention.output.dense.bias\n",
      "bert.encoder.layer.16.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.16.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.16.intermediate.dense.weight\n",
      "bert.encoder.layer.16.intermediate.dense.bias\n",
      "bert.encoder.layer.16.output.dense.weight\n",
      "bert.encoder.layer.16.output.dense.bias\n",
      "bert.encoder.layer.16.output.LayerNorm.weight\n",
      "bert.encoder.layer.16.output.LayerNorm.bias\n",
      "bert.encoder.layer.17.attention.self.query.weight\n",
      "bert.encoder.layer.17.attention.self.query.bias\n",
      "bert.encoder.layer.17.attention.self.key.weight\n",
      "bert.encoder.layer.17.attention.self.key.bias\n",
      "bert.encoder.layer.17.attention.self.value.weight\n",
      "bert.encoder.layer.17.attention.self.value.bias\n",
      "bert.encoder.layer.17.attention.output.dense.weight\n",
      "bert.encoder.layer.17.attention.output.dense.bias\n",
      "bert.encoder.layer.17.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.17.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.17.intermediate.dense.weight\n",
      "bert.encoder.layer.17.intermediate.dense.bias\n",
      "bert.encoder.layer.17.output.dense.weight\n",
      "bert.encoder.layer.17.output.dense.bias\n",
      "bert.encoder.layer.17.output.LayerNorm.weight\n",
      "bert.encoder.layer.17.output.LayerNorm.bias\n",
      "bert.encoder.layer.18.attention.self.query.weight\n",
      "bert.encoder.layer.18.attention.self.query.bias\n",
      "bert.encoder.layer.18.attention.self.key.weight\n",
      "bert.encoder.layer.18.attention.self.key.bias\n",
      "bert.encoder.layer.18.attention.self.value.weight\n",
      "bert.encoder.layer.18.attention.self.value.bias\n",
      "bert.encoder.layer.18.attention.output.dense.weight\n",
      "bert.encoder.layer.18.attention.output.dense.bias\n",
      "bert.encoder.layer.18.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.18.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.18.intermediate.dense.weight\n",
      "bert.encoder.layer.18.intermediate.dense.bias\n",
      "bert.encoder.layer.18.output.dense.weight\n",
      "bert.encoder.layer.18.output.dense.bias\n",
      "bert.encoder.layer.18.output.LayerNorm.weight\n",
      "bert.encoder.layer.18.output.LayerNorm.bias\n",
      "bert.encoder.layer.19.attention.self.query.weight\n",
      "bert.encoder.layer.19.attention.self.query.bias\n",
      "bert.encoder.layer.19.attention.self.key.weight\n",
      "bert.encoder.layer.19.attention.self.key.bias\n",
      "bert.encoder.layer.19.attention.self.value.weight\n",
      "bert.encoder.layer.19.attention.self.value.bias\n",
      "bert.encoder.layer.19.attention.output.dense.weight\n",
      "bert.encoder.layer.19.attention.output.dense.bias\n",
      "bert.encoder.layer.19.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.19.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.19.intermediate.dense.weight\n",
      "bert.encoder.layer.19.intermediate.dense.bias\n",
      "bert.encoder.layer.19.output.dense.weight\n",
      "bert.encoder.layer.19.output.dense.bias\n",
      "bert.encoder.layer.19.output.LayerNorm.weight\n",
      "bert.encoder.layer.19.output.LayerNorm.bias\n",
      "bert.encoder.layer.20.attention.self.query.weight\n",
      "bert.encoder.layer.20.attention.self.query.bias\n",
      "bert.encoder.layer.20.attention.self.key.weight\n",
      "bert.encoder.layer.20.attention.self.key.bias\n",
      "bert.encoder.layer.20.attention.self.value.weight\n",
      "bert.encoder.layer.20.attention.self.value.bias\n",
      "bert.encoder.layer.20.attention.output.dense.weight\n",
      "bert.encoder.layer.20.attention.output.dense.bias\n",
      "bert.encoder.layer.20.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.20.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.20.intermediate.dense.weight\n",
      "bert.encoder.layer.20.intermediate.dense.bias\n",
      "bert.encoder.layer.20.output.dense.weight\n",
      "bert.encoder.layer.20.output.dense.bias\n",
      "bert.encoder.layer.20.output.LayerNorm.weight\n",
      "bert.encoder.layer.20.output.LayerNorm.bias\n",
      "bert.encoder.layer.21.attention.self.query.weight\n",
      "bert.encoder.layer.21.attention.self.query.bias\n",
      "bert.encoder.layer.21.attention.self.key.weight\n",
      "bert.encoder.layer.21.attention.self.key.bias\n",
      "bert.encoder.layer.21.attention.self.value.weight\n",
      "bert.encoder.layer.21.attention.self.value.bias\n",
      "bert.encoder.layer.21.attention.output.dense.weight\n",
      "bert.encoder.layer.21.attention.output.dense.bias\n",
      "bert.encoder.layer.21.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.21.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.21.intermediate.dense.weight\n",
      "bert.encoder.layer.21.intermediate.dense.bias\n",
      "bert.encoder.layer.21.output.dense.weight\n",
      "bert.encoder.layer.21.output.dense.bias\n",
      "bert.encoder.layer.21.output.LayerNorm.weight\n",
      "bert.encoder.layer.21.output.LayerNorm.bias\n",
      "bert.encoder.layer.22.attention.self.query.weight\n",
      "bert.encoder.layer.22.attention.self.query.bias\n",
      "bert.encoder.layer.22.attention.self.key.weight\n",
      "bert.encoder.layer.22.attention.self.key.bias\n",
      "bert.encoder.layer.22.attention.self.value.weight\n",
      "bert.encoder.layer.22.attention.self.value.bias\n",
      "bert.encoder.layer.22.attention.output.dense.weight\n",
      "bert.encoder.layer.22.attention.output.dense.bias\n",
      "bert.encoder.layer.22.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.22.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.22.intermediate.dense.weight\n",
      "bert.encoder.layer.22.intermediate.dense.bias\n",
      "bert.encoder.layer.22.output.dense.weight\n",
      "bert.encoder.layer.22.output.dense.bias\n",
      "bert.encoder.layer.22.output.LayerNorm.weight\n",
      "bert.encoder.layer.22.output.LayerNorm.bias\n",
      "bert.encoder.layer.23.attention.self.query.weight\n",
      "bert.encoder.layer.23.attention.self.query.bias\n",
      "bert.encoder.layer.23.attention.self.key.weight\n",
      "bert.encoder.layer.23.attention.self.key.bias\n",
      "bert.encoder.layer.23.attention.self.value.weight\n",
      "bert.encoder.layer.23.attention.self.value.bias\n",
      "bert.encoder.layer.23.attention.output.dense.weight\n",
      "bert.encoder.layer.23.attention.output.dense.bias\n",
      "bert.encoder.layer.23.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.23.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.23.intermediate.dense.weight\n",
      "bert.encoder.layer.23.intermediate.dense.bias\n",
      "bert.encoder.layer.23.output.dense.weight\n",
      "bert.encoder.layer.23.output.dense.bias\n",
      "bert.encoder.layer.23.output.LayerNorm.weight\n",
      "bert.encoder.layer.23.output.LayerNorm.bias\n",
      "bert.pooler.dense.weight\n",
      "bert.pooler.dense.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if param.requires_grad:\n",
    "        if name.startswith(\"bert\"):\n",
    "            print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa8face5-f407-4596-bba9-13b73adec0ec",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag_layer1.self_attn.in_proj_weight\n",
      "tag_layer1.self_attn.in_proj_bias\n",
      "tag_layer1.self_attn.out_proj.weight\n",
      "tag_layer1.self_attn.out_proj.bias\n",
      "tag_layer1.linear1.weight\n",
      "tag_layer1.linear1.bias\n",
      "tag_layer1.linear2.weight\n",
      "tag_layer1.linear2.bias\n",
      "tag_layer1.norm1.weight\n",
      "tag_layer1.norm1.bias\n",
      "tag_layer1.norm2.weight\n",
      "tag_layer1.norm2.bias\n",
      "cls_layer1.self_attn.in_proj_weight\n",
      "cls_layer1.self_attn.in_proj_bias\n",
      "cls_layer1.self_attn.out_proj.weight\n",
      "cls_layer1.self_attn.out_proj.bias\n",
      "cls_layer1.linear1.weight\n",
      "cls_layer1.linear1.bias\n",
      "cls_layer1.linear2.weight\n",
      "cls_layer1.linear2.bias\n",
      "cls_layer1.norm1.weight\n",
      "cls_layer1.norm1.bias\n",
      "cls_layer1.norm2.weight\n",
      "cls_layer1.norm2.bias\n",
      "tag_layer2.self_attn.in_proj_weight\n",
      "tag_layer2.self_attn.in_proj_bias\n",
      "tag_layer2.self_attn.out_proj.weight\n",
      "tag_layer2.self_attn.out_proj.bias\n",
      "tag_layer2.linear1.weight\n",
      "tag_layer2.linear1.bias\n",
      "tag_layer2.linear2.weight\n",
      "tag_layer2.linear2.bias\n",
      "tag_layer2.norm1.weight\n",
      "tag_layer2.norm1.bias\n",
      "tag_layer2.norm2.weight\n",
      "tag_layer2.norm2.bias\n",
      "cls_layer2.self_attn.in_proj_weight\n",
      "cls_layer2.self_attn.in_proj_bias\n",
      "cls_layer2.self_attn.out_proj.weight\n",
      "cls_layer2.self_attn.out_proj.bias\n",
      "cls_layer2.linear1.weight\n",
      "cls_layer2.linear1.bias\n",
      "cls_layer2.linear2.weight\n",
      "cls_layer2.linear2.bias\n",
      "cls_layer2.norm1.weight\n",
      "cls_layer2.norm1.bias\n",
      "cls_layer2.norm2.weight\n",
      "cls_layer2.norm2.bias\n",
      "fc_tag.weight\n",
      "fc_tag.bias\n",
      "fc_cls.weight\n",
      "fc_cls.bias\n",
      "fc_layernorm_cls.weight\n",
      "fc_layernorm_cls.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if param.requires_grad:\n",
    "        if not name.startswith(\"bert\"):\n",
    "            print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a75a5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50401\n"
     ]
    }
   ],
   "source": [
    "from transformers.optimization import (\n",
    "    get_linear_schedule_with_warmup, get_constant_schedule, get_constant_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup,\n",
    "get_cosine_schedule_with_warmup)\n",
    "\n",
    "TAG_PAD_IDX = LABEL1.vocab.stoi[LABEL1.pad_token]\n",
    "\n",
    "criterion_tag = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
    "criterion_cls = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
    "\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "criterion_tag = criterion_tag.to(device)\n",
    "criterion_cls = criterion_cls.to(device)\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    [\n",
    "        {\"params\": bert_params, \"lr\": 0.5*LEARNING_RATE},\n",
    "        {\"params\": other_params}\n",
    "    ],\n",
    "    lr=LEARNING_RATE,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "num_train_steps = int(\n",
    "            len(train_data) / BATCH_SIZE  * N_EPOCHS)\n",
    "\n",
    "print(num_train_steps)\n",
    "\n",
    "# scheduler = get_constant_schedule_with_warmup(\n",
    "#                 optimizer,\n",
    "#                 num_warmup_steps = 15)\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "#                 optimizer,\n",
    "#                 num_warmup_steps = 15,\n",
    "#                 num_training_steps = num_train_steps*2)\n",
    "\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "#                 optimizer,\n",
    "#                 num_warmup_steps = num_train_steps*0.1,\n",
    "#                 num_training_steps = num_train_steps*2)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer,\n",
    "                num_warmup_steps = 10,\n",
    "                num_training_steps = num_train_steps,\n",
    "                num_cycles = 6)\n",
    "\n",
    "# scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(\n",
    "#                 optimizer,\n",
    "#                 num_warmup_steps = num_train_steps*0.2,\n",
    "#                 num_training_steps = num_train_steps,\n",
    "#                 num_cycles = 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f916de3-69e4-499f-af5d-32cb19956d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.bert.named_parameters():                \n",
    "#     if name.startswith('embeddings'):\n",
    "#         param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdfb3735-b997-4630-a493-8880fa71ea15",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight\n",
      "bert.embeddings.position_embeddings.weight\n",
      "bert.embeddings.token_type_embeddings.weight\n",
      "bert.embeddings.LayerNorm.weight\n",
      "bert.embeddings.LayerNorm.bias\n",
      "bert.encoder.layer.0.attention.self.query.weight\n",
      "bert.encoder.layer.0.attention.self.query.bias\n",
      "bert.encoder.layer.0.attention.self.key.weight\n",
      "bert.encoder.layer.0.attention.self.key.bias\n",
      "bert.encoder.layer.0.attention.self.value.weight\n",
      "bert.encoder.layer.0.attention.self.value.bias\n",
      "bert.encoder.layer.0.attention.output.dense.weight\n",
      "bert.encoder.layer.0.attention.output.dense.bias\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.0.intermediate.dense.weight\n",
      "bert.encoder.layer.0.intermediate.dense.bias\n",
      "bert.encoder.layer.0.output.dense.weight\n",
      "bert.encoder.layer.0.output.dense.bias\n",
      "bert.encoder.layer.0.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.attention.self.query.weight\n",
      "bert.encoder.layer.1.attention.self.query.bias\n",
      "bert.encoder.layer.1.attention.self.key.weight\n",
      "bert.encoder.layer.1.attention.self.key.bias\n",
      "bert.encoder.layer.1.attention.self.value.weight\n",
      "bert.encoder.layer.1.attention.self.value.bias\n",
      "bert.encoder.layer.1.attention.output.dense.weight\n",
      "bert.encoder.layer.1.attention.output.dense.bias\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.intermediate.dense.weight\n",
      "bert.encoder.layer.1.intermediate.dense.bias\n",
      "bert.encoder.layer.1.output.dense.weight\n",
      "bert.encoder.layer.1.output.dense.bias\n",
      "bert.encoder.layer.1.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.attention.self.query.weight\n",
      "bert.encoder.layer.2.attention.self.query.bias\n",
      "bert.encoder.layer.2.attention.self.key.weight\n",
      "bert.encoder.layer.2.attention.self.key.bias\n",
      "bert.encoder.layer.2.attention.self.value.weight\n",
      "bert.encoder.layer.2.attention.self.value.bias\n",
      "bert.encoder.layer.2.attention.output.dense.weight\n",
      "bert.encoder.layer.2.attention.output.dense.bias\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.intermediate.dense.weight\n",
      "bert.encoder.layer.2.intermediate.dense.bias\n",
      "bert.encoder.layer.2.output.dense.weight\n",
      "bert.encoder.layer.2.output.dense.bias\n",
      "bert.encoder.layer.2.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.attention.self.query.weight\n",
      "bert.encoder.layer.3.attention.self.query.bias\n",
      "bert.encoder.layer.3.attention.self.key.weight\n",
      "bert.encoder.layer.3.attention.self.key.bias\n",
      "bert.encoder.layer.3.attention.self.value.weight\n",
      "bert.encoder.layer.3.attention.self.value.bias\n",
      "bert.encoder.layer.3.attention.output.dense.weight\n",
      "bert.encoder.layer.3.attention.output.dense.bias\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.intermediate.dense.weight\n",
      "bert.encoder.layer.3.intermediate.dense.bias\n",
      "bert.encoder.layer.3.output.dense.weight\n",
      "bert.encoder.layer.3.output.dense.bias\n",
      "bert.encoder.layer.3.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.attention.self.query.weight\n",
      "bert.encoder.layer.4.attention.self.query.bias\n",
      "bert.encoder.layer.4.attention.self.key.weight\n",
      "bert.encoder.layer.4.attention.self.key.bias\n",
      "bert.encoder.layer.4.attention.self.value.weight\n",
      "bert.encoder.layer.4.attention.self.value.bias\n",
      "bert.encoder.layer.4.attention.output.dense.weight\n",
      "bert.encoder.layer.4.attention.output.dense.bias\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.intermediate.dense.weight\n",
      "bert.encoder.layer.4.intermediate.dense.bias\n",
      "bert.encoder.layer.4.output.dense.weight\n",
      "bert.encoder.layer.4.output.dense.bias\n",
      "bert.encoder.layer.4.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.attention.self.query.weight\n",
      "bert.encoder.layer.5.attention.self.query.bias\n",
      "bert.encoder.layer.5.attention.self.key.weight\n",
      "bert.encoder.layer.5.attention.self.key.bias\n",
      "bert.encoder.layer.5.attention.self.value.weight\n",
      "bert.encoder.layer.5.attention.self.value.bias\n",
      "bert.encoder.layer.5.attention.output.dense.weight\n",
      "bert.encoder.layer.5.attention.output.dense.bias\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.intermediate.dense.weight\n",
      "bert.encoder.layer.5.intermediate.dense.bias\n",
      "bert.encoder.layer.5.output.dense.weight\n",
      "bert.encoder.layer.5.output.dense.bias\n",
      "bert.encoder.layer.5.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.attention.self.query.weight\n",
      "bert.encoder.layer.6.attention.self.query.bias\n",
      "bert.encoder.layer.6.attention.self.key.weight\n",
      "bert.encoder.layer.6.attention.self.key.bias\n",
      "bert.encoder.layer.6.attention.self.value.weight\n",
      "bert.encoder.layer.6.attention.self.value.bias\n",
      "bert.encoder.layer.6.attention.output.dense.weight\n",
      "bert.encoder.layer.6.attention.output.dense.bias\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.intermediate.dense.weight\n",
      "bert.encoder.layer.6.intermediate.dense.bias\n",
      "bert.encoder.layer.6.output.dense.weight\n",
      "bert.encoder.layer.6.output.dense.bias\n",
      "bert.encoder.layer.6.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.attention.self.query.weight\n",
      "bert.encoder.layer.7.attention.self.query.bias\n",
      "bert.encoder.layer.7.attention.self.key.weight\n",
      "bert.encoder.layer.7.attention.self.key.bias\n",
      "bert.encoder.layer.7.attention.self.value.weight\n",
      "bert.encoder.layer.7.attention.self.value.bias\n",
      "bert.encoder.layer.7.attention.output.dense.weight\n",
      "bert.encoder.layer.7.attention.output.dense.bias\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.intermediate.dense.weight\n",
      "bert.encoder.layer.7.intermediate.dense.bias\n",
      "bert.encoder.layer.7.output.dense.weight\n",
      "bert.encoder.layer.7.output.dense.bias\n",
      "bert.encoder.layer.7.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.attention.self.query.weight\n",
      "bert.encoder.layer.8.attention.self.query.bias\n",
      "bert.encoder.layer.8.attention.self.key.weight\n",
      "bert.encoder.layer.8.attention.self.key.bias\n",
      "bert.encoder.layer.8.attention.self.value.weight\n",
      "bert.encoder.layer.8.attention.self.value.bias\n",
      "bert.encoder.layer.8.attention.output.dense.weight\n",
      "bert.encoder.layer.8.attention.output.dense.bias\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.intermediate.dense.weight\n",
      "bert.encoder.layer.8.intermediate.dense.bias\n",
      "bert.encoder.layer.8.output.dense.weight\n",
      "bert.encoder.layer.8.output.dense.bias\n",
      "bert.encoder.layer.8.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.attention.self.query.weight\n",
      "bert.encoder.layer.9.attention.self.query.bias\n",
      "bert.encoder.layer.9.attention.self.key.weight\n",
      "bert.encoder.layer.9.attention.self.key.bias\n",
      "bert.encoder.layer.9.attention.self.value.weight\n",
      "bert.encoder.layer.9.attention.self.value.bias\n",
      "bert.encoder.layer.9.attention.output.dense.weight\n",
      "bert.encoder.layer.9.attention.output.dense.bias\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.intermediate.dense.weight\n",
      "bert.encoder.layer.9.intermediate.dense.bias\n",
      "bert.encoder.layer.9.output.dense.weight\n",
      "bert.encoder.layer.9.output.dense.bias\n",
      "bert.encoder.layer.9.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.attention.self.query.weight\n",
      "bert.encoder.layer.10.attention.self.query.bias\n",
      "bert.encoder.layer.10.attention.self.key.weight\n",
      "bert.encoder.layer.10.attention.self.key.bias\n",
      "bert.encoder.layer.10.attention.self.value.weight\n",
      "bert.encoder.layer.10.attention.self.value.bias\n",
      "bert.encoder.layer.10.attention.output.dense.weight\n",
      "bert.encoder.layer.10.attention.output.dense.bias\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.intermediate.dense.weight\n",
      "bert.encoder.layer.10.intermediate.dense.bias\n",
      "bert.encoder.layer.10.output.dense.weight\n",
      "bert.encoder.layer.10.output.dense.bias\n",
      "bert.encoder.layer.10.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.attention.self.query.weight\n",
      "bert.encoder.layer.11.attention.self.query.bias\n",
      "bert.encoder.layer.11.attention.self.key.weight\n",
      "bert.encoder.layer.11.attention.self.key.bias\n",
      "bert.encoder.layer.11.attention.self.value.weight\n",
      "bert.encoder.layer.11.attention.self.value.bias\n",
      "bert.encoder.layer.11.attention.output.dense.weight\n",
      "bert.encoder.layer.11.attention.output.dense.bias\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.intermediate.dense.weight\n",
      "bert.encoder.layer.11.intermediate.dense.bias\n",
      "bert.encoder.layer.11.output.dense.weight\n",
      "bert.encoder.layer.11.output.dense.bias\n",
      "bert.encoder.layer.11.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.output.LayerNorm.bias\n",
      "bert.encoder.layer.12.attention.self.query.weight\n",
      "bert.encoder.layer.12.attention.self.query.bias\n",
      "bert.encoder.layer.12.attention.self.key.weight\n",
      "bert.encoder.layer.12.attention.self.key.bias\n",
      "bert.encoder.layer.12.attention.self.value.weight\n",
      "bert.encoder.layer.12.attention.self.value.bias\n",
      "bert.encoder.layer.12.attention.output.dense.weight\n",
      "bert.encoder.layer.12.attention.output.dense.bias\n",
      "bert.encoder.layer.12.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.12.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.12.intermediate.dense.weight\n",
      "bert.encoder.layer.12.intermediate.dense.bias\n",
      "bert.encoder.layer.12.output.dense.weight\n",
      "bert.encoder.layer.12.output.dense.bias\n",
      "bert.encoder.layer.12.output.LayerNorm.weight\n",
      "bert.encoder.layer.12.output.LayerNorm.bias\n",
      "bert.encoder.layer.13.attention.self.query.weight\n",
      "bert.encoder.layer.13.attention.self.query.bias\n",
      "bert.encoder.layer.13.attention.self.key.weight\n",
      "bert.encoder.layer.13.attention.self.key.bias\n",
      "bert.encoder.layer.13.attention.self.value.weight\n",
      "bert.encoder.layer.13.attention.self.value.bias\n",
      "bert.encoder.layer.13.attention.output.dense.weight\n",
      "bert.encoder.layer.13.attention.output.dense.bias\n",
      "bert.encoder.layer.13.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.13.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.13.intermediate.dense.weight\n",
      "bert.encoder.layer.13.intermediate.dense.bias\n",
      "bert.encoder.layer.13.output.dense.weight\n",
      "bert.encoder.layer.13.output.dense.bias\n",
      "bert.encoder.layer.13.output.LayerNorm.weight\n",
      "bert.encoder.layer.13.output.LayerNorm.bias\n",
      "bert.encoder.layer.14.attention.self.query.weight\n",
      "bert.encoder.layer.14.attention.self.query.bias\n",
      "bert.encoder.layer.14.attention.self.key.weight\n",
      "bert.encoder.layer.14.attention.self.key.bias\n",
      "bert.encoder.layer.14.attention.self.value.weight\n",
      "bert.encoder.layer.14.attention.self.value.bias\n",
      "bert.encoder.layer.14.attention.output.dense.weight\n",
      "bert.encoder.layer.14.attention.output.dense.bias\n",
      "bert.encoder.layer.14.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.14.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.14.intermediate.dense.weight\n",
      "bert.encoder.layer.14.intermediate.dense.bias\n",
      "bert.encoder.layer.14.output.dense.weight\n",
      "bert.encoder.layer.14.output.dense.bias\n",
      "bert.encoder.layer.14.output.LayerNorm.weight\n",
      "bert.encoder.layer.14.output.LayerNorm.bias\n",
      "bert.encoder.layer.15.attention.self.query.weight\n",
      "bert.encoder.layer.15.attention.self.query.bias\n",
      "bert.encoder.layer.15.attention.self.key.weight\n",
      "bert.encoder.layer.15.attention.self.key.bias\n",
      "bert.encoder.layer.15.attention.self.value.weight\n",
      "bert.encoder.layer.15.attention.self.value.bias\n",
      "bert.encoder.layer.15.attention.output.dense.weight\n",
      "bert.encoder.layer.15.attention.output.dense.bias\n",
      "bert.encoder.layer.15.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.15.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.15.intermediate.dense.weight\n",
      "bert.encoder.layer.15.intermediate.dense.bias\n",
      "bert.encoder.layer.15.output.dense.weight\n",
      "bert.encoder.layer.15.output.dense.bias\n",
      "bert.encoder.layer.15.output.LayerNorm.weight\n",
      "bert.encoder.layer.15.output.LayerNorm.bias\n",
      "bert.encoder.layer.16.attention.self.query.weight\n",
      "bert.encoder.layer.16.attention.self.query.bias\n",
      "bert.encoder.layer.16.attention.self.key.weight\n",
      "bert.encoder.layer.16.attention.self.key.bias\n",
      "bert.encoder.layer.16.attention.self.value.weight\n",
      "bert.encoder.layer.16.attention.self.value.bias\n",
      "bert.encoder.layer.16.attention.output.dense.weight\n",
      "bert.encoder.layer.16.attention.output.dense.bias\n",
      "bert.encoder.layer.16.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.16.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.16.intermediate.dense.weight\n",
      "bert.encoder.layer.16.intermediate.dense.bias\n",
      "bert.encoder.layer.16.output.dense.weight\n",
      "bert.encoder.layer.16.output.dense.bias\n",
      "bert.encoder.layer.16.output.LayerNorm.weight\n",
      "bert.encoder.layer.16.output.LayerNorm.bias\n",
      "bert.encoder.layer.17.attention.self.query.weight\n",
      "bert.encoder.layer.17.attention.self.query.bias\n",
      "bert.encoder.layer.17.attention.self.key.weight\n",
      "bert.encoder.layer.17.attention.self.key.bias\n",
      "bert.encoder.layer.17.attention.self.value.weight\n",
      "bert.encoder.layer.17.attention.self.value.bias\n",
      "bert.encoder.layer.17.attention.output.dense.weight\n",
      "bert.encoder.layer.17.attention.output.dense.bias\n",
      "bert.encoder.layer.17.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.17.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.17.intermediate.dense.weight\n",
      "bert.encoder.layer.17.intermediate.dense.bias\n",
      "bert.encoder.layer.17.output.dense.weight\n",
      "bert.encoder.layer.17.output.dense.bias\n",
      "bert.encoder.layer.17.output.LayerNorm.weight\n",
      "bert.encoder.layer.17.output.LayerNorm.bias\n",
      "bert.encoder.layer.18.attention.self.query.weight\n",
      "bert.encoder.layer.18.attention.self.query.bias\n",
      "bert.encoder.layer.18.attention.self.key.weight\n",
      "bert.encoder.layer.18.attention.self.key.bias\n",
      "bert.encoder.layer.18.attention.self.value.weight\n",
      "bert.encoder.layer.18.attention.self.value.bias\n",
      "bert.encoder.layer.18.attention.output.dense.weight\n",
      "bert.encoder.layer.18.attention.output.dense.bias\n",
      "bert.encoder.layer.18.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.18.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.18.intermediate.dense.weight\n",
      "bert.encoder.layer.18.intermediate.dense.bias\n",
      "bert.encoder.layer.18.output.dense.weight\n",
      "bert.encoder.layer.18.output.dense.bias\n",
      "bert.encoder.layer.18.output.LayerNorm.weight\n",
      "bert.encoder.layer.18.output.LayerNorm.bias\n",
      "bert.encoder.layer.19.attention.self.query.weight\n",
      "bert.encoder.layer.19.attention.self.query.bias\n",
      "bert.encoder.layer.19.attention.self.key.weight\n",
      "bert.encoder.layer.19.attention.self.key.bias\n",
      "bert.encoder.layer.19.attention.self.value.weight\n",
      "bert.encoder.layer.19.attention.self.value.bias\n",
      "bert.encoder.layer.19.attention.output.dense.weight\n",
      "bert.encoder.layer.19.attention.output.dense.bias\n",
      "bert.encoder.layer.19.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.19.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.19.intermediate.dense.weight\n",
      "bert.encoder.layer.19.intermediate.dense.bias\n",
      "bert.encoder.layer.19.output.dense.weight\n",
      "bert.encoder.layer.19.output.dense.bias\n",
      "bert.encoder.layer.19.output.LayerNorm.weight\n",
      "bert.encoder.layer.19.output.LayerNorm.bias\n",
      "bert.encoder.layer.20.attention.self.query.weight\n",
      "bert.encoder.layer.20.attention.self.query.bias\n",
      "bert.encoder.layer.20.attention.self.key.weight\n",
      "bert.encoder.layer.20.attention.self.key.bias\n",
      "bert.encoder.layer.20.attention.self.value.weight\n",
      "bert.encoder.layer.20.attention.self.value.bias\n",
      "bert.encoder.layer.20.attention.output.dense.weight\n",
      "bert.encoder.layer.20.attention.output.dense.bias\n",
      "bert.encoder.layer.20.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.20.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.20.intermediate.dense.weight\n",
      "bert.encoder.layer.20.intermediate.dense.bias\n",
      "bert.encoder.layer.20.output.dense.weight\n",
      "bert.encoder.layer.20.output.dense.bias\n",
      "bert.encoder.layer.20.output.LayerNorm.weight\n",
      "bert.encoder.layer.20.output.LayerNorm.bias\n",
      "bert.encoder.layer.21.attention.self.query.weight\n",
      "bert.encoder.layer.21.attention.self.query.bias\n",
      "bert.encoder.layer.21.attention.self.key.weight\n",
      "bert.encoder.layer.21.attention.self.key.bias\n",
      "bert.encoder.layer.21.attention.self.value.weight\n",
      "bert.encoder.layer.21.attention.self.value.bias\n",
      "bert.encoder.layer.21.attention.output.dense.weight\n",
      "bert.encoder.layer.21.attention.output.dense.bias\n",
      "bert.encoder.layer.21.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.21.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.21.intermediate.dense.weight\n",
      "bert.encoder.layer.21.intermediate.dense.bias\n",
      "bert.encoder.layer.21.output.dense.weight\n",
      "bert.encoder.layer.21.output.dense.bias\n",
      "bert.encoder.layer.21.output.LayerNorm.weight\n",
      "bert.encoder.layer.21.output.LayerNorm.bias\n",
      "bert.encoder.layer.22.attention.self.query.weight\n",
      "bert.encoder.layer.22.attention.self.query.bias\n",
      "bert.encoder.layer.22.attention.self.key.weight\n",
      "bert.encoder.layer.22.attention.self.key.bias\n",
      "bert.encoder.layer.22.attention.self.value.weight\n",
      "bert.encoder.layer.22.attention.self.value.bias\n",
      "bert.encoder.layer.22.attention.output.dense.weight\n",
      "bert.encoder.layer.22.attention.output.dense.bias\n",
      "bert.encoder.layer.22.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.22.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.22.intermediate.dense.weight\n",
      "bert.encoder.layer.22.intermediate.dense.bias\n",
      "bert.encoder.layer.22.output.dense.weight\n",
      "bert.encoder.layer.22.output.dense.bias\n",
      "bert.encoder.layer.22.output.LayerNorm.weight\n",
      "bert.encoder.layer.22.output.LayerNorm.bias\n",
      "bert.encoder.layer.23.attention.self.query.weight\n",
      "bert.encoder.layer.23.attention.self.query.bias\n",
      "bert.encoder.layer.23.attention.self.key.weight\n",
      "bert.encoder.layer.23.attention.self.key.bias\n",
      "bert.encoder.layer.23.attention.self.value.weight\n",
      "bert.encoder.layer.23.attention.self.value.bias\n",
      "bert.encoder.layer.23.attention.output.dense.weight\n",
      "bert.encoder.layer.23.attention.output.dense.bias\n",
      "bert.encoder.layer.23.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.23.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.23.intermediate.dense.weight\n",
      "bert.encoder.layer.23.intermediate.dense.bias\n",
      "bert.encoder.layer.23.output.dense.weight\n",
      "bert.encoder.layer.23.output.dense.bias\n",
      "bert.encoder.layer.23.output.LayerNorm.weight\n",
      "bert.encoder.layer.23.output.LayerNorm.bias\n",
      "bert.pooler.dense.weight\n",
      "bert.pooler.dense.bias\n",
      "tag_layer1.self_attn.in_proj_weight\n",
      "tag_layer1.self_attn.in_proj_bias\n",
      "tag_layer1.self_attn.out_proj.weight\n",
      "tag_layer1.self_attn.out_proj.bias\n",
      "tag_layer1.linear1.weight\n",
      "tag_layer1.linear1.bias\n",
      "tag_layer1.linear2.weight\n",
      "tag_layer1.linear2.bias\n",
      "tag_layer1.norm1.weight\n",
      "tag_layer1.norm1.bias\n",
      "tag_layer1.norm2.weight\n",
      "tag_layer1.norm2.bias\n",
      "cls_layer1.self_attn.in_proj_weight\n",
      "cls_layer1.self_attn.in_proj_bias\n",
      "cls_layer1.self_attn.out_proj.weight\n",
      "cls_layer1.self_attn.out_proj.bias\n",
      "cls_layer1.linear1.weight\n",
      "cls_layer1.linear1.bias\n",
      "cls_layer1.linear2.weight\n",
      "cls_layer1.linear2.bias\n",
      "cls_layer1.norm1.weight\n",
      "cls_layer1.norm1.bias\n",
      "cls_layer1.norm2.weight\n",
      "cls_layer1.norm2.bias\n",
      "tag_layer2.self_attn.in_proj_weight\n",
      "tag_layer2.self_attn.in_proj_bias\n",
      "tag_layer2.self_attn.out_proj.weight\n",
      "tag_layer2.self_attn.out_proj.bias\n",
      "tag_layer2.linear1.weight\n",
      "tag_layer2.linear1.bias\n",
      "tag_layer2.linear2.weight\n",
      "tag_layer2.linear2.bias\n",
      "tag_layer2.norm1.weight\n",
      "tag_layer2.norm1.bias\n",
      "tag_layer2.norm2.weight\n",
      "tag_layer2.norm2.bias\n",
      "cls_layer2.self_attn.in_proj_weight\n",
      "cls_layer2.self_attn.in_proj_bias\n",
      "cls_layer2.self_attn.out_proj.weight\n",
      "cls_layer2.self_attn.out_proj.bias\n",
      "cls_layer2.linear1.weight\n",
      "cls_layer2.linear1.bias\n",
      "cls_layer2.linear2.weight\n",
      "cls_layer2.linear2.bias\n",
      "cls_layer2.norm1.weight\n",
      "cls_layer2.norm1.bias\n",
      "cls_layer2.norm2.weight\n",
      "cls_layer2.norm2.bias\n",
      "fc_tag.weight\n",
      "fc_tag.bias\n",
      "fc_cls.weight\n",
      "fc_cls.bias\n",
      "fc_layernorm_cls.weight\n",
      "fc_layernorm_cls.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a491051-4c10-4b28-8878-e78baa48e52f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight\n",
      "embeddings.position_embeddings.weight\n",
      "embeddings.token_type_embeddings.weight\n",
      "embeddings.LayerNorm.weight\n",
      "embeddings.LayerNorm.bias\n",
      "encoder.layer.0.attention.self.query.weight\n",
      "encoder.layer.0.attention.self.query.bias\n",
      "encoder.layer.0.attention.self.key.weight\n",
      "encoder.layer.0.attention.self.key.bias\n",
      "encoder.layer.0.attention.self.value.weight\n",
      "encoder.layer.0.attention.self.value.bias\n",
      "encoder.layer.0.attention.output.dense.weight\n",
      "encoder.layer.0.attention.output.dense.bias\n",
      "encoder.layer.0.attention.output.LayerNorm.weight\n",
      "encoder.layer.0.attention.output.LayerNorm.bias\n",
      "encoder.layer.0.intermediate.dense.weight\n",
      "encoder.layer.0.intermediate.dense.bias\n",
      "encoder.layer.0.output.dense.weight\n",
      "encoder.layer.0.output.dense.bias\n",
      "encoder.layer.0.output.LayerNorm.weight\n",
      "encoder.layer.0.output.LayerNorm.bias\n",
      "encoder.layer.1.attention.self.query.weight\n",
      "encoder.layer.1.attention.self.query.bias\n",
      "encoder.layer.1.attention.self.key.weight\n",
      "encoder.layer.1.attention.self.key.bias\n",
      "encoder.layer.1.attention.self.value.weight\n",
      "encoder.layer.1.attention.self.value.bias\n",
      "encoder.layer.1.attention.output.dense.weight\n",
      "encoder.layer.1.attention.output.dense.bias\n",
      "encoder.layer.1.attention.output.LayerNorm.weight\n",
      "encoder.layer.1.attention.output.LayerNorm.bias\n",
      "encoder.layer.1.intermediate.dense.weight\n",
      "encoder.layer.1.intermediate.dense.bias\n",
      "encoder.layer.1.output.dense.weight\n",
      "encoder.layer.1.output.dense.bias\n",
      "encoder.layer.1.output.LayerNorm.weight\n",
      "encoder.layer.1.output.LayerNorm.bias\n",
      "encoder.layer.2.attention.self.query.weight\n",
      "encoder.layer.2.attention.self.query.bias\n",
      "encoder.layer.2.attention.self.key.weight\n",
      "encoder.layer.2.attention.self.key.bias\n",
      "encoder.layer.2.attention.self.value.weight\n",
      "encoder.layer.2.attention.self.value.bias\n",
      "encoder.layer.2.attention.output.dense.weight\n",
      "encoder.layer.2.attention.output.dense.bias\n",
      "encoder.layer.2.attention.output.LayerNorm.weight\n",
      "encoder.layer.2.attention.output.LayerNorm.bias\n",
      "encoder.layer.2.intermediate.dense.weight\n",
      "encoder.layer.2.intermediate.dense.bias\n",
      "encoder.layer.2.output.dense.weight\n",
      "encoder.layer.2.output.dense.bias\n",
      "encoder.layer.2.output.LayerNorm.weight\n",
      "encoder.layer.2.output.LayerNorm.bias\n",
      "encoder.layer.3.attention.self.query.weight\n",
      "encoder.layer.3.attention.self.query.bias\n",
      "encoder.layer.3.attention.self.key.weight\n",
      "encoder.layer.3.attention.self.key.bias\n",
      "encoder.layer.3.attention.self.value.weight\n",
      "encoder.layer.3.attention.self.value.bias\n",
      "encoder.layer.3.attention.output.dense.weight\n",
      "encoder.layer.3.attention.output.dense.bias\n",
      "encoder.layer.3.attention.output.LayerNorm.weight\n",
      "encoder.layer.3.attention.output.LayerNorm.bias\n",
      "encoder.layer.3.intermediate.dense.weight\n",
      "encoder.layer.3.intermediate.dense.bias\n",
      "encoder.layer.3.output.dense.weight\n",
      "encoder.layer.3.output.dense.bias\n",
      "encoder.layer.3.output.LayerNorm.weight\n",
      "encoder.layer.3.output.LayerNorm.bias\n",
      "encoder.layer.4.attention.self.query.weight\n",
      "encoder.layer.4.attention.self.query.bias\n",
      "encoder.layer.4.attention.self.key.weight\n",
      "encoder.layer.4.attention.self.key.bias\n",
      "encoder.layer.4.attention.self.value.weight\n",
      "encoder.layer.4.attention.self.value.bias\n",
      "encoder.layer.4.attention.output.dense.weight\n",
      "encoder.layer.4.attention.output.dense.bias\n",
      "encoder.layer.4.attention.output.LayerNorm.weight\n",
      "encoder.layer.4.attention.output.LayerNorm.bias\n",
      "encoder.layer.4.intermediate.dense.weight\n",
      "encoder.layer.4.intermediate.dense.bias\n",
      "encoder.layer.4.output.dense.weight\n",
      "encoder.layer.4.output.dense.bias\n",
      "encoder.layer.4.output.LayerNorm.weight\n",
      "encoder.layer.4.output.LayerNorm.bias\n",
      "encoder.layer.5.attention.self.query.weight\n",
      "encoder.layer.5.attention.self.query.bias\n",
      "encoder.layer.5.attention.self.key.weight\n",
      "encoder.layer.5.attention.self.key.bias\n",
      "encoder.layer.5.attention.self.value.weight\n",
      "encoder.layer.5.attention.self.value.bias\n",
      "encoder.layer.5.attention.output.dense.weight\n",
      "encoder.layer.5.attention.output.dense.bias\n",
      "encoder.layer.5.attention.output.LayerNorm.weight\n",
      "encoder.layer.5.attention.output.LayerNorm.bias\n",
      "encoder.layer.5.intermediate.dense.weight\n",
      "encoder.layer.5.intermediate.dense.bias\n",
      "encoder.layer.5.output.dense.weight\n",
      "encoder.layer.5.output.dense.bias\n",
      "encoder.layer.5.output.LayerNorm.weight\n",
      "encoder.layer.5.output.LayerNorm.bias\n",
      "encoder.layer.6.attention.self.query.weight\n",
      "encoder.layer.6.attention.self.query.bias\n",
      "encoder.layer.6.attention.self.key.weight\n",
      "encoder.layer.6.attention.self.key.bias\n",
      "encoder.layer.6.attention.self.value.weight\n",
      "encoder.layer.6.attention.self.value.bias\n",
      "encoder.layer.6.attention.output.dense.weight\n",
      "encoder.layer.6.attention.output.dense.bias\n",
      "encoder.layer.6.attention.output.LayerNorm.weight\n",
      "encoder.layer.6.attention.output.LayerNorm.bias\n",
      "encoder.layer.6.intermediate.dense.weight\n",
      "encoder.layer.6.intermediate.dense.bias\n",
      "encoder.layer.6.output.dense.weight\n",
      "encoder.layer.6.output.dense.bias\n",
      "encoder.layer.6.output.LayerNorm.weight\n",
      "encoder.layer.6.output.LayerNorm.bias\n",
      "encoder.layer.7.attention.self.query.weight\n",
      "encoder.layer.7.attention.self.query.bias\n",
      "encoder.layer.7.attention.self.key.weight\n",
      "encoder.layer.7.attention.self.key.bias\n",
      "encoder.layer.7.attention.self.value.weight\n",
      "encoder.layer.7.attention.self.value.bias\n",
      "encoder.layer.7.attention.output.dense.weight\n",
      "encoder.layer.7.attention.output.dense.bias\n",
      "encoder.layer.7.attention.output.LayerNorm.weight\n",
      "encoder.layer.7.attention.output.LayerNorm.bias\n",
      "encoder.layer.7.intermediate.dense.weight\n",
      "encoder.layer.7.intermediate.dense.bias\n",
      "encoder.layer.7.output.dense.weight\n",
      "encoder.layer.7.output.dense.bias\n",
      "encoder.layer.7.output.LayerNorm.weight\n",
      "encoder.layer.7.output.LayerNorm.bias\n",
      "encoder.layer.8.attention.self.query.weight\n",
      "encoder.layer.8.attention.self.query.bias\n",
      "encoder.layer.8.attention.self.key.weight\n",
      "encoder.layer.8.attention.self.key.bias\n",
      "encoder.layer.8.attention.self.value.weight\n",
      "encoder.layer.8.attention.self.value.bias\n",
      "encoder.layer.8.attention.output.dense.weight\n",
      "encoder.layer.8.attention.output.dense.bias\n",
      "encoder.layer.8.attention.output.LayerNorm.weight\n",
      "encoder.layer.8.attention.output.LayerNorm.bias\n",
      "encoder.layer.8.intermediate.dense.weight\n",
      "encoder.layer.8.intermediate.dense.bias\n",
      "encoder.layer.8.output.dense.weight\n",
      "encoder.layer.8.output.dense.bias\n",
      "encoder.layer.8.output.LayerNorm.weight\n",
      "encoder.layer.8.output.LayerNorm.bias\n",
      "encoder.layer.9.attention.self.query.weight\n",
      "encoder.layer.9.attention.self.query.bias\n",
      "encoder.layer.9.attention.self.key.weight\n",
      "encoder.layer.9.attention.self.key.bias\n",
      "encoder.layer.9.attention.self.value.weight\n",
      "encoder.layer.9.attention.self.value.bias\n",
      "encoder.layer.9.attention.output.dense.weight\n",
      "encoder.layer.9.attention.output.dense.bias\n",
      "encoder.layer.9.attention.output.LayerNorm.weight\n",
      "encoder.layer.9.attention.output.LayerNorm.bias\n",
      "encoder.layer.9.intermediate.dense.weight\n",
      "encoder.layer.9.intermediate.dense.bias\n",
      "encoder.layer.9.output.dense.weight\n",
      "encoder.layer.9.output.dense.bias\n",
      "encoder.layer.9.output.LayerNorm.weight\n",
      "encoder.layer.9.output.LayerNorm.bias\n",
      "encoder.layer.10.attention.self.query.weight\n",
      "encoder.layer.10.attention.self.query.bias\n",
      "encoder.layer.10.attention.self.key.weight\n",
      "encoder.layer.10.attention.self.key.bias\n",
      "encoder.layer.10.attention.self.value.weight\n",
      "encoder.layer.10.attention.self.value.bias\n",
      "encoder.layer.10.attention.output.dense.weight\n",
      "encoder.layer.10.attention.output.dense.bias\n",
      "encoder.layer.10.attention.output.LayerNorm.weight\n",
      "encoder.layer.10.attention.output.LayerNorm.bias\n",
      "encoder.layer.10.intermediate.dense.weight\n",
      "encoder.layer.10.intermediate.dense.bias\n",
      "encoder.layer.10.output.dense.weight\n",
      "encoder.layer.10.output.dense.bias\n",
      "encoder.layer.10.output.LayerNorm.weight\n",
      "encoder.layer.10.output.LayerNorm.bias\n",
      "encoder.layer.11.attention.self.query.weight\n",
      "encoder.layer.11.attention.self.query.bias\n",
      "encoder.layer.11.attention.self.key.weight\n",
      "encoder.layer.11.attention.self.key.bias\n",
      "encoder.layer.11.attention.self.value.weight\n",
      "encoder.layer.11.attention.self.value.bias\n",
      "encoder.layer.11.attention.output.dense.weight\n",
      "encoder.layer.11.attention.output.dense.bias\n",
      "encoder.layer.11.attention.output.LayerNorm.weight\n",
      "encoder.layer.11.attention.output.LayerNorm.bias\n",
      "encoder.layer.11.intermediate.dense.weight\n",
      "encoder.layer.11.intermediate.dense.bias\n",
      "encoder.layer.11.output.dense.weight\n",
      "encoder.layer.11.output.dense.bias\n",
      "encoder.layer.11.output.LayerNorm.weight\n",
      "encoder.layer.11.output.LayerNorm.bias\n",
      "encoder.layer.12.attention.self.query.weight\n",
      "encoder.layer.12.attention.self.query.bias\n",
      "encoder.layer.12.attention.self.key.weight\n",
      "encoder.layer.12.attention.self.key.bias\n",
      "encoder.layer.12.attention.self.value.weight\n",
      "encoder.layer.12.attention.self.value.bias\n",
      "encoder.layer.12.attention.output.dense.weight\n",
      "encoder.layer.12.attention.output.dense.bias\n",
      "encoder.layer.12.attention.output.LayerNorm.weight\n",
      "encoder.layer.12.attention.output.LayerNorm.bias\n",
      "encoder.layer.12.intermediate.dense.weight\n",
      "encoder.layer.12.intermediate.dense.bias\n",
      "encoder.layer.12.output.dense.weight\n",
      "encoder.layer.12.output.dense.bias\n",
      "encoder.layer.12.output.LayerNorm.weight\n",
      "encoder.layer.12.output.LayerNorm.bias\n",
      "encoder.layer.13.attention.self.query.weight\n",
      "encoder.layer.13.attention.self.query.bias\n",
      "encoder.layer.13.attention.self.key.weight\n",
      "encoder.layer.13.attention.self.key.bias\n",
      "encoder.layer.13.attention.self.value.weight\n",
      "encoder.layer.13.attention.self.value.bias\n",
      "encoder.layer.13.attention.output.dense.weight\n",
      "encoder.layer.13.attention.output.dense.bias\n",
      "encoder.layer.13.attention.output.LayerNorm.weight\n",
      "encoder.layer.13.attention.output.LayerNorm.bias\n",
      "encoder.layer.13.intermediate.dense.weight\n",
      "encoder.layer.13.intermediate.dense.bias\n",
      "encoder.layer.13.output.dense.weight\n",
      "encoder.layer.13.output.dense.bias\n",
      "encoder.layer.13.output.LayerNorm.weight\n",
      "encoder.layer.13.output.LayerNorm.bias\n",
      "encoder.layer.14.attention.self.query.weight\n",
      "encoder.layer.14.attention.self.query.bias\n",
      "encoder.layer.14.attention.self.key.weight\n",
      "encoder.layer.14.attention.self.key.bias\n",
      "encoder.layer.14.attention.self.value.weight\n",
      "encoder.layer.14.attention.self.value.bias\n",
      "encoder.layer.14.attention.output.dense.weight\n",
      "encoder.layer.14.attention.output.dense.bias\n",
      "encoder.layer.14.attention.output.LayerNorm.weight\n",
      "encoder.layer.14.attention.output.LayerNorm.bias\n",
      "encoder.layer.14.intermediate.dense.weight\n",
      "encoder.layer.14.intermediate.dense.bias\n",
      "encoder.layer.14.output.dense.weight\n",
      "encoder.layer.14.output.dense.bias\n",
      "encoder.layer.14.output.LayerNorm.weight\n",
      "encoder.layer.14.output.LayerNorm.bias\n",
      "encoder.layer.15.attention.self.query.weight\n",
      "encoder.layer.15.attention.self.query.bias\n",
      "encoder.layer.15.attention.self.key.weight\n",
      "encoder.layer.15.attention.self.key.bias\n",
      "encoder.layer.15.attention.self.value.weight\n",
      "encoder.layer.15.attention.self.value.bias\n",
      "encoder.layer.15.attention.output.dense.weight\n",
      "encoder.layer.15.attention.output.dense.bias\n",
      "encoder.layer.15.attention.output.LayerNorm.weight\n",
      "encoder.layer.15.attention.output.LayerNorm.bias\n",
      "encoder.layer.15.intermediate.dense.weight\n",
      "encoder.layer.15.intermediate.dense.bias\n",
      "encoder.layer.15.output.dense.weight\n",
      "encoder.layer.15.output.dense.bias\n",
      "encoder.layer.15.output.LayerNorm.weight\n",
      "encoder.layer.15.output.LayerNorm.bias\n",
      "encoder.layer.16.attention.self.query.weight\n",
      "encoder.layer.16.attention.self.query.bias\n",
      "encoder.layer.16.attention.self.key.weight\n",
      "encoder.layer.16.attention.self.key.bias\n",
      "encoder.layer.16.attention.self.value.weight\n",
      "encoder.layer.16.attention.self.value.bias\n",
      "encoder.layer.16.attention.output.dense.weight\n",
      "encoder.layer.16.attention.output.dense.bias\n",
      "encoder.layer.16.attention.output.LayerNorm.weight\n",
      "encoder.layer.16.attention.output.LayerNorm.bias\n",
      "encoder.layer.16.intermediate.dense.weight\n",
      "encoder.layer.16.intermediate.dense.bias\n",
      "encoder.layer.16.output.dense.weight\n",
      "encoder.layer.16.output.dense.bias\n",
      "encoder.layer.16.output.LayerNorm.weight\n",
      "encoder.layer.16.output.LayerNorm.bias\n",
      "encoder.layer.17.attention.self.query.weight\n",
      "encoder.layer.17.attention.self.query.bias\n",
      "encoder.layer.17.attention.self.key.weight\n",
      "encoder.layer.17.attention.self.key.bias\n",
      "encoder.layer.17.attention.self.value.weight\n",
      "encoder.layer.17.attention.self.value.bias\n",
      "encoder.layer.17.attention.output.dense.weight\n",
      "encoder.layer.17.attention.output.dense.bias\n",
      "encoder.layer.17.attention.output.LayerNorm.weight\n",
      "encoder.layer.17.attention.output.LayerNorm.bias\n",
      "encoder.layer.17.intermediate.dense.weight\n",
      "encoder.layer.17.intermediate.dense.bias\n",
      "encoder.layer.17.output.dense.weight\n",
      "encoder.layer.17.output.dense.bias\n",
      "encoder.layer.17.output.LayerNorm.weight\n",
      "encoder.layer.17.output.LayerNorm.bias\n",
      "encoder.layer.18.attention.self.query.weight\n",
      "encoder.layer.18.attention.self.query.bias\n",
      "encoder.layer.18.attention.self.key.weight\n",
      "encoder.layer.18.attention.self.key.bias\n",
      "encoder.layer.18.attention.self.value.weight\n",
      "encoder.layer.18.attention.self.value.bias\n",
      "encoder.layer.18.attention.output.dense.weight\n",
      "encoder.layer.18.attention.output.dense.bias\n",
      "encoder.layer.18.attention.output.LayerNorm.weight\n",
      "encoder.layer.18.attention.output.LayerNorm.bias\n",
      "encoder.layer.18.intermediate.dense.weight\n",
      "encoder.layer.18.intermediate.dense.bias\n",
      "encoder.layer.18.output.dense.weight\n",
      "encoder.layer.18.output.dense.bias\n",
      "encoder.layer.18.output.LayerNorm.weight\n",
      "encoder.layer.18.output.LayerNorm.bias\n",
      "encoder.layer.19.attention.self.query.weight\n",
      "encoder.layer.19.attention.self.query.bias\n",
      "encoder.layer.19.attention.self.key.weight\n",
      "encoder.layer.19.attention.self.key.bias\n",
      "encoder.layer.19.attention.self.value.weight\n",
      "encoder.layer.19.attention.self.value.bias\n",
      "encoder.layer.19.attention.output.dense.weight\n",
      "encoder.layer.19.attention.output.dense.bias\n",
      "encoder.layer.19.attention.output.LayerNorm.weight\n",
      "encoder.layer.19.attention.output.LayerNorm.bias\n",
      "encoder.layer.19.intermediate.dense.weight\n",
      "encoder.layer.19.intermediate.dense.bias\n",
      "encoder.layer.19.output.dense.weight\n",
      "encoder.layer.19.output.dense.bias\n",
      "encoder.layer.19.output.LayerNorm.weight\n",
      "encoder.layer.19.output.LayerNorm.bias\n",
      "encoder.layer.20.attention.self.query.weight\n",
      "encoder.layer.20.attention.self.query.bias\n",
      "encoder.layer.20.attention.self.key.weight\n",
      "encoder.layer.20.attention.self.key.bias\n",
      "encoder.layer.20.attention.self.value.weight\n",
      "encoder.layer.20.attention.self.value.bias\n",
      "encoder.layer.20.attention.output.dense.weight\n",
      "encoder.layer.20.attention.output.dense.bias\n",
      "encoder.layer.20.attention.output.LayerNorm.weight\n",
      "encoder.layer.20.attention.output.LayerNorm.bias\n",
      "encoder.layer.20.intermediate.dense.weight\n",
      "encoder.layer.20.intermediate.dense.bias\n",
      "encoder.layer.20.output.dense.weight\n",
      "encoder.layer.20.output.dense.bias\n",
      "encoder.layer.20.output.LayerNorm.weight\n",
      "encoder.layer.20.output.LayerNorm.bias\n",
      "encoder.layer.21.attention.self.query.weight\n",
      "encoder.layer.21.attention.self.query.bias\n",
      "encoder.layer.21.attention.self.key.weight\n",
      "encoder.layer.21.attention.self.key.bias\n",
      "encoder.layer.21.attention.self.value.weight\n",
      "encoder.layer.21.attention.self.value.bias\n",
      "encoder.layer.21.attention.output.dense.weight\n",
      "encoder.layer.21.attention.output.dense.bias\n",
      "encoder.layer.21.attention.output.LayerNorm.weight\n",
      "encoder.layer.21.attention.output.LayerNorm.bias\n",
      "encoder.layer.21.intermediate.dense.weight\n",
      "encoder.layer.21.intermediate.dense.bias\n",
      "encoder.layer.21.output.dense.weight\n",
      "encoder.layer.21.output.dense.bias\n",
      "encoder.layer.21.output.LayerNorm.weight\n",
      "encoder.layer.21.output.LayerNorm.bias\n",
      "encoder.layer.22.attention.self.query.weight\n",
      "encoder.layer.22.attention.self.query.bias\n",
      "encoder.layer.22.attention.self.key.weight\n",
      "encoder.layer.22.attention.self.key.bias\n",
      "encoder.layer.22.attention.self.value.weight\n",
      "encoder.layer.22.attention.self.value.bias\n",
      "encoder.layer.22.attention.output.dense.weight\n",
      "encoder.layer.22.attention.output.dense.bias\n",
      "encoder.layer.22.attention.output.LayerNorm.weight\n",
      "encoder.layer.22.attention.output.LayerNorm.bias\n",
      "encoder.layer.22.intermediate.dense.weight\n",
      "encoder.layer.22.intermediate.dense.bias\n",
      "encoder.layer.22.output.dense.weight\n",
      "encoder.layer.22.output.dense.bias\n",
      "encoder.layer.22.output.LayerNorm.weight\n",
      "encoder.layer.22.output.LayerNorm.bias\n",
      "encoder.layer.23.attention.self.query.weight\n",
      "encoder.layer.23.attention.self.query.bias\n",
      "encoder.layer.23.attention.self.key.weight\n",
      "encoder.layer.23.attention.self.key.bias\n",
      "encoder.layer.23.attention.self.value.weight\n",
      "encoder.layer.23.attention.self.value.bias\n",
      "encoder.layer.23.attention.output.dense.weight\n",
      "encoder.layer.23.attention.output.dense.bias\n",
      "encoder.layer.23.attention.output.LayerNorm.weight\n",
      "encoder.layer.23.attention.output.LayerNorm.bias\n",
      "encoder.layer.23.intermediate.dense.weight\n",
      "encoder.layer.23.intermediate.dense.bias\n",
      "encoder.layer.23.output.dense.weight\n",
      "encoder.layer.23.output.dense.bias\n",
      "encoder.layer.23.output.LayerNorm.weight\n",
      "encoder.layer.23.output.LayerNorm.bias\n",
      "pooler.dense.weight\n",
      "pooler.dense.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.bert.named_parameters():                \n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41d0859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_tagging_pred_n_true(preds, y, tag_pad_idx, org_shap, fist_tokens, FT_TAGS):\n",
    "\n",
    "    max_preds_p = preds.argmax(dim = 1, keepdim = True).view(org_shap)\n",
    "    y_p = y.view(org_shap)\n",
    "    fist_tokens_p = fist_tokens.view(org_shap)\n",
    "   \n",
    "    preds_list = []\n",
    "    true_list = []\n",
    "    for i in range(len(y_p)):\n",
    "        seq_pred = []\n",
    "        seq_true = []\n",
    "        for j in range(len(y_p[i])):\n",
    "\n",
    "            if y_p[i][j].item() != tag_pad_idx and fist_tokens_p[i][j] == 1:\n",
    "                seq_pred.append(max_preds_p[i][j].item()-1)\n",
    "                seq_true.append(y_p[i][j].item()-1)\n",
    "\n",
    "        preds_list.append(seq_pred)\n",
    "        true_list.append(seq_true)\n",
    "\n",
    "    return preds_list, true_list\n",
    "\n",
    "def obtain_classification_pred_n_true(preds, y):\n",
    "\n",
    "    max_preds = preds.argmax(dim = 1)\n",
    "   \n",
    "    preds_list = []\n",
    "    true_list = []\n",
    "    for i in range(len(y)):\n",
    "        preds_list.append(max_preds[i].item()-1)\n",
    "        true_list.append(y[i].item()-1)\n",
    "\n",
    "    return preds_list, true_list\n",
    "\n",
    "def f1_score_tag(preds_list, true_list):\n",
    "    tp,tn,fp,fn = 0,0,0,0\n",
    "    for i in range(len(true_list)):\n",
    "        for j in range(len(true_list[i])):\n",
    "            if true_list[i][j] == 1:\n",
    "                if preds_list[i][j] == 1:\n",
    "                    tp+=1\n",
    "                elif preds_list[i][j] == 0:\n",
    "                    fn += 1\n",
    "            elif true_list[i][j] == 0:\n",
    "                if preds_list[i][j] == 0:\n",
    "                    tn += 1\n",
    "                elif preds_list[i][j] == 1:\n",
    "                    fp += 1\n",
    "               \n",
    "    recall = tp/(tp+fn+1e-9)\n",
    "    precision = tp/(tp+fp+1e-9)\n",
    "    f1 = 2*recall*precision/(recall+precision+1e-9)\n",
    "    acc = (tp+tn)/(tp+tn+fp+fn+1e-9)\n",
    "    return round(precision,4), round(recall,4), round(f1,4), round(acc,4)\n",
    "\n",
    "def f1_score_cls(preds_list, true_list):\n",
    "    tp,tn,fp,fn = 0,0,0,0\n",
    "    for i in range(len(true_list)):\n",
    "        if true_list[i] == 1:\n",
    "            if preds_list[i] == true_list[i]:\n",
    "                tp+=1\n",
    "            elif preds_list[i] != true_list[i]:\n",
    "                fn += 1\n",
    "        elif true_list[i] == 0:\n",
    "            if preds_list[i] == true_list[i]:\n",
    "                tn += 1\n",
    "            elif preds_list[i] != true_list[i]:\n",
    "                fp += 1\n",
    "               \n",
    "    print(\"tp: \",tp)\n",
    "    print(\"fn: \",fn)\n",
    "    print(\"tn: \",tn)\n",
    "    print(\"fp: \",fp)\n",
    "    \n",
    "    recall = tp/(tp+fn+1e-9)\n",
    "    precision = tp/(tp+fp+1e-9)\n",
    "    f1 = 2*recall*precision/(recall+precision+1e-9)\n",
    "    acc = (tp+tn)/(tp+tn+fp+fn+1e-9)\n",
    "    return round(precision,4), round(recall,4), round(f1,4), round(acc,4)\n",
    "\n",
    "def train(model, iterator, optimizer, scheduler, criterion_label, criterion_pos, tag_pad_idx, ori_tag_loss_weight, ori_cls_loss_weight):\n",
    "    \n",
    "    loss_label1 = 0\n",
    "    loss_label2 = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    pred_label1_list=[]\n",
    "    true_label1_list=[]\n",
    "    pred_label2_list=[]\n",
    "    true_label2_list=[]\n",
    "    \n",
    "    tag_signal_list=[]\n",
    "    cls_signal_list=[]\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        org_label1_shap = batch.label1.size() # [batch size, seq len]\n",
    "        org_label2_shap = batch.label2.size() # [batch size, 1]\n",
    "        \n",
    "        token_idx_ = batch.token_id # [batch size, seq len]\n",
    "        mask_ab = batch.mask_ab # [batch size, seq len]\n",
    "        mask_p = batch.mask_p # [batch size, seq len]\n",
    "        ft_tags = batch.first_token.view(-1) # [batch size * seq len]\n",
    "        tag_true = batch.label1.view(-1) # [batch size * seq len]\n",
    "        cls_true = batch.label2.view(-1) # [batch size]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # tag_pred:[batch size, seq len, label1 dim]\n",
    "        # cls_pred:[batch size, label2 dim]\n",
    "        \n",
    "        tag_pred, cls_pred = model(token_idx_,mask_ab, mask_p)\n",
    "        # ######## for softmax trust level ###########\n",
    "        # tag_pred, cls_pred, tag_signal, cls_signal = model(token_idx_,mask_ab, mask_p)\n",
    "\n",
    "        tag_pred = tag_pred.view(-1, tag_pred.shape[-1]) # [batch size * seq len, label1 dim]\n",
    "\n",
    "        loss_tag = criterion_tag(tag_pred, tag_true)\n",
    "        loss_cls = criterion_cls(cls_pred, cls_true)\n",
    "        \n",
    "        loss_label1 += loss_tag.item()\n",
    "        loss_label2 += loss_cls.item()\n",
    "        \n",
    "#         ######## for softmax trust level ###########\n",
    "#         # Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy().\n",
    "#         tag_signal = np.average(tag_signal.cpu().detach().numpy())\n",
    "#         cls_signal = np.average(cls_signal.cpu().detach().numpy())\n",
    "        \n",
    "#         tag_signal_list.append(tag_signal)\n",
    "#         cls_signal_list.append(cls_signal)\n",
    "        \n",
    "        # loss_tag is larger than loss_cls, so the overall loss is weighted summed up.\n",
    "        # if loss_cls > loss_tag*10:\n",
    "        #     cls_loss_weight=0.1\n",
    "        # elif loss_cls > loss_tag*5:\n",
    "        #     cls_loss_weight=0.2\n",
    "        # elif loss_cls > loss_tag*2:\n",
    "        #     cls_loss_weight=0.5\n",
    "        # elif loss_cls < loss_tag*0.5:\n",
    "        #     cls_loss_weight=2\n",
    "        \n",
    "        # tag_loss_weight=1\n",
    "        # cls_loss_weight=tag_loss_weight*loss_tag/loss_cls\n",
    "        \n",
    "        \n",
    "        # if loss_label2 < 500 and loss_label2 > 100 and loss_label2 > loss_label1*2:\n",
    "        #     tag_loss_weight=0\n",
    "        \n",
    "        # weight = F.softmax(torch.randn(2), dim=-1)\n",
    "        \n",
    "        # loss = tag_loss_weight*loss_tag + cls_loss_weight*loss_cls\n",
    "        #loss = weight[0]*loss_tag + weight[1]*loss_cls\n",
    "        loss = ori_tag_loss_weight*loss_tag + ori_cls_loss_weight*loss_cls\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        pred_label1, true_label1 = obtain_tagging_pred_n_true(tag_pred, tag_true, tag_pad_idx, org_label1_shap, ft_tags, FT_TAGS)\n",
    "        pred_label2, true_label2 = obtain_classification_pred_n_true(cls_pred, cls_true)\n",
    "        \n",
    "        \n",
    "        pred_label1_list.extend(pred_label1)\n",
    "        true_label1_list.extend(true_label1)\n",
    "        pred_label2_list.extend(pred_label2)\n",
    "        true_label2_list.extend(true_label2)\n",
    "            \n",
    "            \n",
    "    p_label1, r_label1, f_label1, acc_label1 = f1_score_tag(pred_label1_list, true_label1_list)\n",
    "    p_label2, r_label2, f_label2, acc_label2 = f1_score_cls(pred_label2_list, true_label2_list)\n",
    "    \n",
    "    print(\"train set pred label2 length: \",len(pred_label2_list))\n",
    "    print(\"train set true label2 length: \",len(true_label2_list))\n",
    "    match_number=0\n",
    "    for i in range(len(pred_label2_list)):\n",
    "        if pred_label2_list[i] == true_label2_list[i]:\n",
    "            match_number+=1\n",
    "    print(\"match number: \",match_number)   \n",
    "    \n",
    "    \n",
    "#     ######## for softmax trust level ###########\n",
    "#     avg_tag_signal=statistics.mean(tag_signal_list)\n",
    "#     avg_cls_signal=statistics.mean(cls_signal_list)\n",
    "    \n",
    "#     avg_tag_signal=math.sqrt(avg_tag_signal)\n",
    "#     avg_cls_signal=math.sqrt(avg_cls_signal)\n",
    "    \n",
    "#     print(\"tag signal: \",avg_tag_signal)\n",
    "#     print(\"cls signal: \",avg_cls_signal)\n",
    "        \n",
    "    return round(loss_label1,4), round(loss_label2,4), p_label1, r_label1, f_label1, \\\n",
    "acc_label1, p_label2, r_label2, f_label2, acc_label2\n",
    "\n",
    "#     ######## for softmax trust level ###########\n",
    "#     return round(loss_label1,4), round(loss_label2,4), p_label1, r_label1, f_label1, \\\n",
    "# acc_label1, p_label2, r_label2, f_label2, acc_label2, avg_tag_signal, avg_cls_signal\n",
    "\n",
    "def evaluate(model, iterator, criterion_label, criterion_pos, tag_pad_idx):\n",
    "    \n",
    "    loss_label1 = 0\n",
    "    loss_label2 = 0\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        pred_label1_list=[]\n",
    "        true_label1_list=[]\n",
    "        pred_label2_list=[]\n",
    "        true_label2_list=[]\n",
    "        \n",
    "        for batch in iterator:\n",
    "\n",
    "            org_label1_shap = batch.label1.size() # [batch size, seq len]\n",
    "            org_label2_shap = batch.label2.size() # [batch size, 1]\n",
    "\n",
    "            token_idx_ = batch.token_id # [batch size, seq len]\n",
    "            mask_ab = batch.mask_ab # [batch size, seq len]\n",
    "            mask_p = batch.mask_p # [batch size, seq len]\n",
    "            ft_tags = batch.first_token.view(-1) # [batch size * seq len]\n",
    "            tag_true = batch.label1.view(-1) # [batch size * seq len]\n",
    "            cls_true = batch.label2.view(-1) # [batch size]\n",
    "\n",
    "            # tag_pred:[batch size, seq len, label1 dim]\n",
    "            # cls_pred:[batch size, label2 dim]\n",
    "            \n",
    "            tag_pred, cls_pred = model(token_idx_,mask_ab,mask_p)\n",
    "            # ######## for softmax trust level ###########\n",
    "            # tag_pred, cls_pred, _, _ = model(token_idx_,mask_ab,mask_p)\n",
    "\n",
    "            tag_pred = tag_pred.view(-1, tag_pred.shape[-1]) # [batch size * seq len, label1 dim]\n",
    "\n",
    "            loss_tag = criterion_tag(tag_pred, tag_true)\n",
    "            loss_cls = criterion_cls(cls_pred, cls_true)\n",
    "\n",
    "            loss_label1 += loss_tag.item()\n",
    "            loss_label2 += loss_cls.item()\n",
    "\n",
    "            pred_label1, true_label1 = obtain_tagging_pred_n_true(tag_pred, tag_true, tag_pad_idx, org_label1_shap, ft_tags, FT_TAGS)\n",
    "            pred_label2, true_label2 = obtain_classification_pred_n_true(cls_pred, cls_true)\n",
    "            \n",
    "            pred_label1_list.extend(pred_label1)\n",
    "            true_label1_list.extend(true_label1)\n",
    "            pred_label2_list.extend(pred_label2)\n",
    "            true_label2_list.extend(true_label2)\n",
    "            \n",
    "            \n",
    "        p_label1, r_label1, f_label1, acc_label1 = f1_score_tag(pred_label1_list, true_label1_list)\n",
    "        p_label2, r_label2, f_label2, acc_label2 = f1_score_cls(pred_label2_list, true_label2_list)\n",
    "        \n",
    "        print(\"pred label2 length: \",len(pred_label2_list))\n",
    "        print(\"true label2 length: \",len(true_label2_list))\n",
    "        match_number=0\n",
    "        for i in range(len(pred_label2_list)):\n",
    "            if pred_label2_list[i] == true_label2_list[i]:\n",
    "                match_number+=1\n",
    "        print(\"match number: \",match_number)   \n",
    "        \n",
    "    return round(loss_label1,4), round(loss_label2,4), p_label1, r_label1, f_label1, acc_label1, \\\n",
    "p_label2, r_label2, f_label2, acc_label2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31736127-1666-4727-9871-4f4d0be936e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = F.softmax(torch.randn(2), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9dfb11e-fb5f-4e21-b989-d19832f3a2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0678)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13f38094-0574-46d3-a726-3c69537015bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_output_difference(model, iterator, criterion_label, criterion_pos, tag_pad_idx):\n",
    "    \n",
    "    loss_label1 = 0\n",
    "    loss_label2 = 0\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        pred_label1_list=[]\n",
    "        true_label1_list=[]\n",
    "        pred_label2_list=[]\n",
    "        true_label2_list=[]\n",
    "        token_idx_list=[]\n",
    "        \n",
    "        for batch in iterator:\n",
    "\n",
    "            org_label1_shap = batch.label1.size() # [batch size, seq len]\n",
    "            org_label2_shap = batch.label2.size() # [batch size, 1]\n",
    "\n",
    "            token_idx_ = batch.token_id # [batch size, seq len]\n",
    "            mask_ab = batch.mask_ab # [batch size, seq len]\n",
    "            mask_p = batch.mask_p # [batch size, seq len]\n",
    "            ft_tags = batch.first_token.view(-1) # [batch size * seq len]\n",
    "            tag_true = batch.label1.view(-1) # [batch size * seq len]\n",
    "            cls_true = batch.label2.view(-1) # [batch size]\n",
    "            #seq = batch.seq.view(-1) # [batch size]\n",
    "\n",
    "            # tag_pred:[batch size, seq len, label1 dim]\n",
    "            # cls_pred:[batch size, label2 dim]\n",
    "            \n",
    "            tag_pred, cls_pred = model(token_idx_,mask_ab,mask_p)\n",
    "            # ######## for softmax trust level ###########\n",
    "            # tag_pred, cls_pred, _, _ = model(token_idx_,mask_ab,mask_p)\n",
    "\n",
    "            tag_pred = tag_pred.view(-1, tag_pred.shape[-1]) # [batch size * seq len, label1 dim]\n",
    "\n",
    "            loss_tag = criterion_tag(tag_pred, tag_true)\n",
    "            loss_cls = criterion_cls(cls_pred, cls_true)\n",
    "\n",
    "            loss_label1 += loss_tag.item()\n",
    "            loss_label2 += loss_cls.item()\n",
    "\n",
    "            pred_label1, true_label1 = obtain_tagging_pred_n_true(tag_pred, tag_true, tag_pad_idx, org_label1_shap, ft_tags, FT_TAGS)\n",
    "            pred_label2, true_label2 = obtain_classification_pred_n_true(cls_pred, cls_true)\n",
    "            \n",
    "            pred_label1_list.extend(pred_label1)\n",
    "            true_label1_list.extend(true_label1)\n",
    "            pred_label2_list.extend(pred_label2)\n",
    "            true_label2_list.extend(true_label2)\n",
    "            \n",
    "            for i in range(len(batch.token_id.tolist())):\n",
    "                token_idx_list.append(batch.token_id.tolist()[i])\n",
    "            \n",
    "            \n",
    "        p_label1, r_label1, f_label1, acc_label1 = f1_score_tag(pred_label1_list, true_label1_list)\n",
    "        p_label2, r_label2, f_label2, acc_label2 = f1_score_cls(pred_label2_list, true_label2_list)\n",
    "        \n",
    "        print(\"pred label2 length: \",len(pred_label2_list))\n",
    "        print(\"true label2 length: \",len(true_label2_list))\n",
    "        print(\"token_idx_list length: \",len(true_label2_list))\n",
    "        match_number=0\n",
    "        comparison_df = pd.DataFrame(columns=['index', 'token_idx','pred_label2', 'true_label2'])\n",
    "        for i in range(len(pred_label2_list)):\n",
    "            if pred_label2_list[i] == true_label2_list[i]:\n",
    "                match_number+=1\n",
    "            elif pred_label2_list[i] != true_label2_list[i]:\n",
    "                df2={'index': i, 'token_idx':' '.join(str(e) for e in token_idx_list[i]), 'pred_label2': pred_label2_list[i], 'true_label2': true_label2_list[i]}\n",
    "                comparison_df = comparison_df.append(df2, ignore_index = True)\n",
    "        print(\"match number: \",match_number)   \n",
    "        \n",
    "    return round(loss_label1,4), round(loss_label2,4), p_label1, r_label1, f_label1, acc_label1, p_label2, r_label2, f_label2, acc_label2, comparison_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5d0749a-ae40-45c1-a76b-f2736d2322f1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for batch in test_iterator:\n",
    "#     print(batch.token_id.tolist()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91b20b0b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-29 12:21:15.315463\n",
      "EPOCH 0\n",
      "TAG_LOSS_WEIGHT:  0.5\n",
      "CLS_LOSS_WEIGHT:  0.5\n",
      "tp:  355\n",
      "fn:  967\n",
      "tn:  982\n",
      "fp:  340\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1337\n",
      "tp:  1\n",
      "fn:  563\n",
      "tn:  563\n",
      "fp:  1\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  564\n",
      "EPOCH 0\n",
      "   TRAIN | Label 1 loss: 49.4213 ; P: 0.2423 ; R: 0.0882 ; F1: 0.1294 ; Acc: 0.7808\n",
      "           Label 2 loss: 91.1091 ; P: 0.5108 ; R: 0.2685 ; F1: 0.352 ; Acc: 0.5057\n",
      "    TEST | Label 1 loss: 15.3315 ; P: 0.3143 ; R: 0.007 ; F1: 0.0136 ; Acc: 0.8019\n",
      "           Label 2 loss: 42.6351 ; P: 0.5 ; R: 0.0018 ; F1: 0.0035 ; Acc: 0.5\n",
      "2023-01-29 12:21:46.703576\n",
      "2023-01-29 12:21:48.293071\n",
      "EPOCH 1\n",
      "TAG_LOSS_WEIGHT:  0.5\n",
      "CLS_LOSS_WEIGHT:  0.5\n",
      "tp:  510\n",
      "fn:  812\n",
      "tn:  802\n",
      "fp:  520\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1312\n",
      "tp:  0\n",
      "fn:  564\n",
      "tn:  563\n",
      "fp:  1\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  563\n",
      "EPOCH 1\n",
      "   TRAIN | Label 1 loss: 35.1523 ; P: 0.4569 ; R: 0.0921 ; F1: 0.1533 ; Acc: 0.8126\n",
      "           Label 2 loss: 79.8828 ; P: 0.4951 ; R: 0.3858 ; F1: 0.4337 ; Acc: 0.4962\n",
      "    TEST | Label 1 loss: 13.1421 ; P: 0.7391 ; R: 0.129 ; F1: 0.2197 ; Acc: 0.8199\n",
      "           Label 2 loss: 32.4003 ; P: 0.0 ; R: 0.0 ; F1: 0.0 ; Acc: 0.4991\n",
      "2023-01-29 12:22:20.192869\n",
      "2023-01-29 12:22:20.193869\n",
      "EPOCH 2\n",
      "TAG_LOSS_WEIGHT:  0.39690239559563006\n",
      "CLS_LOSS_WEIGHT:  0.6030976044043699\n",
      "tp:  632\n",
      "fn:  690\n",
      "tn:  643\n",
      "fp:  679\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1275\n",
      "tp:  102\n",
      "fn:  462\n",
      "tn:  459\n",
      "fp:  105\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  561\n",
      "EPOCH 2\n",
      "   TRAIN | Label 1 loss: 31.4804 ; P: 0.557 ; R: 0.1462 ; F1: 0.2317 ; Acc: 0.8213\n",
      "           Label 2 loss: 71.0907 ; P: 0.4821 ; R: 0.4781 ; F1: 0.4801 ; Acc: 0.4822\n",
      "    TEST | Label 1 loss: 12.3618 ; P: 0.7526 ; R: 0.2789 ; F1: 0.407 ; Acc: 0.8403\n",
      "           Label 2 loss: 27.2555 ; P: 0.4928 ; R: 0.1809 ; F1: 0.2646 ; Acc: 0.4973\n",
      "2023-01-29 12:22:51.810034\n",
      "2023-01-29 12:22:51.810034\n",
      "EPOCH 3\n",
      "TAG_LOSS_WEIGHT:  0.39991232716717456\n",
      "CLS_LOSS_WEIGHT:  0.6000876728328256\n",
      "tp:  722\n",
      "fn:  600\n",
      "tn:  603\n",
      "fp:  719\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1325\n",
      "tp:  119\n",
      "fn:  445\n",
      "tn:  442\n",
      "fp:  122\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  561\n",
      "EPOCH 3\n",
      "   TRAIN | Label 1 loss: 29.5608 ; P: 0.6274 ; R: 0.1913 ; F1: 0.2932 ; Acc: 0.8301\n",
      "           Label 2 loss: 64.1358 ; P: 0.501 ; R: 0.5461 ; F1: 0.5226 ; Acc: 0.5011\n",
      "    TEST | Label 1 loss: 11.5761 ; P: 0.7104 ; R: 0.4143 ; F1: 0.5234 ; Acc: 0.8517\n",
      "           Label 2 loss: 27.14 ; P: 0.4938 ; R: 0.211 ; F1: 0.2957 ; Acc: 0.4973\n",
      "2023-01-29 12:23:23.261237\n",
      "2023-01-29 12:23:23.262237\n",
      "EPOCH 4\n",
      "TAG_LOSS_WEIGHT:  0.41927391891727267\n",
      "CLS_LOSS_WEIGHT:  0.5807260810827274\n",
      "tp:  748\n",
      "fn:  574\n",
      "tn:  601\n",
      "fp:  721\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1349\n",
      "tp:  139\n",
      "fn:  425\n",
      "tn:  431\n",
      "fp:  133\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  570\n",
      "EPOCH 4\n",
      "   TRAIN | Label 1 loss: 27.5247 ; P: 0.6788 ; R: 0.2803 ; F1: 0.3968 ; Acc: 0.843\n",
      "           Label 2 loss: 63.4167 ; P: 0.5092 ; R: 0.5658 ; F1: 0.536 ; Acc: 0.5102\n",
      "    TEST | Label 1 loss: 10.8362 ; P: 0.6859 ; R: 0.4972 ; F1: 0.5765 ; Acc: 0.8565\n",
      "           Label 2 loss: 27.1 ; P: 0.511 ; R: 0.2465 ; F1: 0.3325 ; Acc: 0.5053\n",
      "2023-01-29 12:23:54.550271\n",
      "2023-01-29 12:23:56.312516\n",
      "EPOCH 5\n",
      "TAG_LOSS_WEIGHT:  0.390327801050322\n",
      "CLS_LOSS_WEIGHT:  0.6096721989496781\n",
      "tp:  685\n",
      "fn:  637\n",
      "tn:  655\n",
      "fp:  667\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1340\n",
      "tp:  209\n",
      "fn:  355\n",
      "tn:  357\n",
      "fp:  207\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  566\n",
      "EPOCH 5\n",
      "   TRAIN | Label 1 loss: 25.9702 ; P: 0.697 ; R: 0.3644 ; F1: 0.4786 ; Acc: 0.8537\n",
      "           Label 2 loss: 62.857 ; P: 0.5067 ; R: 0.5182 ; F1: 0.5123 ; Acc: 0.5068\n",
      "    TEST | Label 1 loss: 10.5092 ; P: 0.6518 ; R: 0.5743 ; F1: 0.6106 ; Acc: 0.8561\n",
      "           Label 2 loss: 27.0694 ; P: 0.5024 ; R: 0.3706 ; F1: 0.4265 ; Acc: 0.5018\n",
      "2023-01-29 12:24:28.663654\n",
      "2023-01-29 12:24:28.664644\n",
      "EPOCH 6\n",
      "TAG_LOSS_WEIGHT:  0.367147712525142\n",
      "CLS_LOSS_WEIGHT:  0.632852287474858\n",
      "tp:  726\n",
      "fn:  596\n",
      "tn:  625\n",
      "fp:  697\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1351\n",
      "tp:  192\n",
      "fn:  372\n",
      "tn:  386\n",
      "fp:  178\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  578\n",
      "EPOCH 6\n",
      "   TRAIN | Label 1 loss: 24.6834 ; P: 0.6948 ; R: 0.4212 ; F1: 0.5245 ; Acc: 0.8593\n",
      "           Label 2 loss: 62.972 ; P: 0.5102 ; R: 0.5492 ; F1: 0.529 ; Acc: 0.511\n",
      "    TEST | Label 1 loss: 10.2521 ; P: 0.6354 ; R: 0.6262 ; F1: 0.6308 ; Acc: 0.856\n",
      "           Label 2 loss: 27.0558 ; P: 0.5189 ; R: 0.3404 ; F1: 0.4111 ; Acc: 0.5124\n",
      "2023-01-29 12:25:00.445632\n",
      "2023-01-29 12:25:02.323223\n",
      "EPOCH 7\n",
      "TAG_LOSS_WEIGHT:  0.3430422498598386\n",
      "CLS_LOSS_WEIGHT:  0.6569577501401613\n",
      "tp:  764\n",
      "fn:  558\n",
      "tn:  566\n",
      "fp:  756\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1330\n",
      "tp:  88\n",
      "fn:  476\n",
      "tn:  478\n",
      "fp:  86\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  566\n",
      "EPOCH 7\n",
      "   TRAIN | Label 1 loss: 23.6121 ; P: 0.6991 ; R: 0.4629 ; F1: 0.557 ; Acc: 0.8643\n",
      "           Label 2 loss: 63.0115 ; P: 0.5026 ; R: 0.5779 ; F1: 0.5376 ; Acc: 0.503\n",
      "    TEST | Label 1 loss: 9.8942 ; P: 0.6466 ; R: 0.611 ; F1: 0.6283 ; Acc: 0.8579\n",
      "           Label 2 loss: 27.0792 ; P: 0.5057 ; R: 0.156 ; F1: 0.2385 ; Acc: 0.5018\n",
      "2023-01-29 12:25:34.638627\n",
      "2023-01-29 12:25:34.639626\n",
      "EPOCH 8\n",
      "TAG_LOSS_WEIGHT:  0.32305585201064047\n",
      "CLS_LOSS_WEIGHT:  0.6769441479893596\n",
      "tp:  642\n",
      "fn:  680\n",
      "tn:  687\n",
      "fp:  635\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1329\n",
      "tp:  291\n",
      "fn:  273\n",
      "tn:  272\n",
      "fp:  292\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  563\n",
      "EPOCH 8\n",
      "   TRAIN | Label 1 loss: 23.0723 ; P: 0.6958 ; R: 0.485 ; F1: 0.5716 ; Acc: 0.8661\n",
      "           Label 2 loss: 62.6837 ; P: 0.5027 ; R: 0.4856 ; F1: 0.494 ; Acc: 0.5026\n",
      "    TEST | Label 1 loss: 9.6636 ; P: 0.6458 ; R: 0.6078 ; F1: 0.6263 ; Acc: 0.8574\n",
      "           Label 2 loss: 27.0439 ; P: 0.4991 ; R: 0.516 ; F1: 0.5074 ; Acc: 0.4991\n",
      "2023-01-29 12:26:06.857101\n",
      "2023-01-29 12:26:06.857101\n",
      "EPOCH 9\n",
      "TAG_LOSS_WEIGHT:  0.31527219973486476\n",
      "CLS_LOSS_WEIGHT:  0.6847278002651352\n",
      "tp:  741\n",
      "fn:  581\n",
      "tn:  635\n",
      "fp:  687\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1376\n",
      "tp:  169\n",
      "fn:  395\n",
      "tn:  385\n",
      "fp:  179\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  554\n",
      "EPOCH 9\n",
      "   TRAIN | Label 1 loss: 22.5708 ; P: 0.6991 ; R: 0.4973 ; F1: 0.5812 ; Acc: 0.8679\n",
      "           Label 2 loss: 62.4997 ; P: 0.5189 ; R: 0.5605 ; F1: 0.5389 ; Acc: 0.5204\n",
      "    TEST | Label 1 loss: 9.5926 ; P: 0.6353 ; R: 0.6414 ; F1: 0.6383 ; Acc: 0.8572\n",
      "           Label 2 loss: 27.0489 ; P: 0.4856 ; R: 0.2996 ; F1: 0.3706 ; Acc: 0.4911\n",
      "2023-01-29 12:26:37.951939\n",
      "2023-01-29 12:26:37.951939\n",
      "EPOCH 10\n",
      "TAG_LOSS_WEIGHT:  0.3071117433435565\n",
      "CLS_LOSS_WEIGHT:  0.6928882566564434\n",
      "tp:  665\n",
      "fn:  657\n",
      "tn:  648\n",
      "fp:  674\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1313\n",
      "tp:  174\n",
      "fn:  390\n",
      "tn:  384\n",
      "fp:  180\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  558\n",
      "EPOCH 10\n",
      "   TRAIN | Label 1 loss: 22.2377 ; P: 0.704 ; R: 0.5095 ; F1: 0.5912 ; Acc: 0.8702\n",
      "           Label 2 loss: 62.891 ; P: 0.4966 ; R: 0.503 ; F1: 0.4998 ; Acc: 0.4966\n",
      "    TEST | Label 1 loss: 9.5855 ; P: 0.6258 ; R: 0.6591 ; F1: 0.642 ; Acc: 0.8556\n",
      "           Label 2 loss: 27.0465 ; P: 0.4915 ; R: 0.3085 ; F1: 0.3791 ; Acc: 0.4947\n",
      "2023-01-29 12:27:09.196058\n",
      "2023-01-29 12:27:09.196058\n",
      "EPOCH 11\n",
      "TAG_LOSS_WEIGHT:  0.2982017546308012\n",
      "CLS_LOSS_WEIGHT:  0.7017982453691989\n",
      "tp:  673\n",
      "fn:  649\n",
      "tn:  607\n",
      "fp:  715\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1280\n",
      "tp:  235\n",
      "fn:  329\n",
      "tn:  329\n",
      "fp:  235\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  564\n",
      "EPOCH 11\n",
      "   TRAIN | Label 1 loss: 21.6789 ; P: 0.6927 ; R: 0.5283 ; F1: 0.5994 ; Acc: 0.8699\n",
      "           Label 2 loss: 62.6807 ; P: 0.4849 ; R: 0.5091 ; F1: 0.4967 ; Acc: 0.4841\n",
      "    TEST | Label 1 loss: 9.5488 ; P: 0.6253 ; R: 0.6755 ; F1: 0.6494 ; Acc: 0.8567\n",
      "           Label 2 loss: 27.0358 ; P: 0.5 ; R: 0.4167 ; F1: 0.4545 ; Acc: 0.5\n",
      "2023-01-29 12:27:40.566327\n",
      "2023-01-29 12:27:40.567327\n",
      "EPOCH 12\n",
      "TAG_LOSS_WEIGHT:  0.2890348944667824\n",
      "CLS_LOSS_WEIGHT:  0.7109651055332176\n",
      "tp:  635\n",
      "fn:  687\n",
      "tn:  700\n",
      "fp:  622\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1335\n",
      "tp:  262\n",
      "fn:  302\n",
      "tn:  305\n",
      "fp:  259\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  567\n",
      "EPOCH 12\n",
      "   TRAIN | Label 1 loss: 21.3808 ; P: 0.6967 ; R: 0.5339 ; F1: 0.6045 ; Acc: 0.8713\n",
      "           Label 2 loss: 62.705 ; P: 0.5052 ; R: 0.4803 ; F1: 0.4924 ; Acc: 0.5049\n",
      "    TEST | Label 1 loss: 9.5349 ; P: 0.6206 ; R: 0.6983 ; F1: 0.6571 ; Acc: 0.8568\n",
      "           Label 2 loss: 27.0324 ; P: 0.5029 ; R: 0.4645 ; F1: 0.4829 ; Acc: 0.5027\n",
      "2023-01-29 12:28:11.905404\n",
      "2023-01-29 12:28:11.905404\n",
      "EPOCH 13\n",
      "TAG_LOSS_WEIGHT:  0.28322032776117867\n",
      "CLS_LOSS_WEIGHT:  0.7167796722388214\n",
      "tp:  647\n",
      "fn:  675\n",
      "tn:  732\n",
      "fp:  590\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1379\n",
      "tp:  206\n",
      "fn:  358\n",
      "tn:  368\n",
      "fp:  196\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  574\n",
      "EPOCH 13\n",
      "   TRAIN | Label 1 loss: 21.3069 ; P: 0.6832 ; R: 0.5367 ; F1: 0.6011 ; Acc: 0.8688\n",
      "           Label 2 loss: 62.3225 ; P: 0.523 ; R: 0.4894 ; F1: 0.5057 ; Acc: 0.5216\n",
      "    TEST | Label 1 loss: 9.4087 ; P: 0.6297 ; R: 0.6743 ; F1: 0.6512 ; Acc: 0.8581\n",
      "           Label 2 loss: 27.0354 ; P: 0.5124 ; R: 0.3652 ; F1: 0.4265 ; Acc: 0.5089\n",
      "2023-01-29 12:28:42.915098\n",
      "2023-01-29 12:28:42.916108\n",
      "EPOCH 14\n",
      "TAG_LOSS_WEIGHT:  0.2843000670753453\n",
      "CLS_LOSS_WEIGHT:  0.7156999329246546\n",
      "tp:  689\n",
      "fn:  633\n",
      "tn:  552\n",
      "fp:  770\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1241\n",
      "tp:  245\n",
      "fn:  319\n",
      "tn:  318\n",
      "fp:  246\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  563\n",
      "EPOCH 14\n",
      "   TRAIN | Label 1 loss: 20.9335 ; P: 0.6968 ; R: 0.55 ; F1: 0.6147 ; Acc: 0.873\n",
      "           Label 2 loss: 62.9467 ; P: 0.4722 ; R: 0.5212 ; F1: 0.4955 ; Acc: 0.4694\n",
      "    TEST | Label 1 loss: 9.3351 ; P: 0.6293 ; R: 0.6755 ; F1: 0.6516 ; Acc: 0.8581\n",
      "           Label 2 loss: 27.0307 ; P: 0.499 ; R: 0.4344 ; F1: 0.4645 ; Acc: 0.4991\n",
      "2023-01-29 12:29:13.774453\n",
      "2023-01-29 12:29:13.774453\n",
      "EPOCH 15\n",
      "TAG_LOSS_WEIGHT:  0.27318498841865324\n",
      "CLS_LOSS_WEIGHT:  0.7268150115813468\n",
      "tp:  691\n",
      "fn:  631\n",
      "tn:  622\n",
      "fp:  700\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1313\n",
      "tp:  166\n",
      "fn:  398\n",
      "tn:  401\n",
      "fp:  163\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  567\n",
      "EPOCH 15\n",
      "   TRAIN | Label 1 loss: 20.8008 ; P: 0.6873 ; R: 0.5509 ; F1: 0.6116 ; Acc: 0.8711\n",
      "           Label 2 loss: 62.7866 ; P: 0.4968 ; R: 0.5227 ; F1: 0.5094 ; Acc: 0.4966\n",
      "    TEST | Label 1 loss: 9.4152 ; P: 0.6179 ; R: 0.716 ; F1: 0.6633 ; Acc: 0.8572\n",
      "           Label 2 loss: 27.0335 ; P: 0.5046 ; R: 0.2943 ; F1: 0.3718 ; Acc: 0.5027\n",
      "2023-01-29 12:29:44.457428\n",
      "2023-01-29 12:29:44.458432\n",
      "EPOCH 16\n",
      "TAG_LOSS_WEIGHT:  0.2716735737124147\n",
      "CLS_LOSS_WEIGHT:  0.7283264262875853\n",
      "tp:  574\n",
      "fn:  748\n",
      "tn:  751\n",
      "fp:  571\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1325\n",
      "tp:  268\n",
      "fn:  296\n",
      "tn:  297\n",
      "fp:  267\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  565\n",
      "EPOCH 16\n",
      "   TRAIN | Label 1 loss: 20.6845 ; P: 0.6842 ; R: 0.5546 ; F1: 0.6126 ; Acc: 0.8708\n",
      "           Label 2 loss: 62.5297 ; P: 0.5013 ; R: 0.4342 ; F1: 0.4653 ; Acc: 0.5011\n",
      "    TEST | Label 1 loss: 9.1774 ; P: 0.6356 ; R: 0.6762 ; F1: 0.6552 ; Acc: 0.8602\n",
      "           Label 2 loss: 27.0285 ; P: 0.5009 ; R: 0.4752 ; F1: 0.4877 ; Acc: 0.5009\n",
      "2023-01-29 12:30:15.766956\n",
      "2023-01-29 12:30:15.766956\n",
      "EPOCH 17\n",
      "TAG_LOSS_WEIGHT:  0.27107769642591123\n",
      "CLS_LOSS_WEIGHT:  0.7289223035740887\n",
      "tp:  648\n",
      "fn:  674\n",
      "tn:  680\n",
      "fp:  642\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1328\n",
      "tp:  265\n",
      "fn:  299\n",
      "tn:  299\n",
      "fp:  265\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  564\n",
      "EPOCH 17\n",
      "   TRAIN | Label 1 loss: 20.3621 ; P: 0.6951 ; R: 0.5656 ; F1: 0.6237 ; Acc: 0.8743\n",
      "           Label 2 loss: 62.5759 ; P: 0.5023 ; R: 0.4902 ; F1: 0.4962 ; Acc: 0.5023\n",
      "    TEST | Label 1 loss: 9.1854 ; P: 0.6322 ; R: 0.6837 ; F1: 0.6569 ; Acc: 0.8597\n",
      "           Label 2 loss: 27.0297 ; P: 0.5 ; R: 0.4699 ; F1: 0.4845 ; Acc: 0.5\n",
      "2023-01-29 12:30:46.912280\n",
      "2023-01-29 12:30:46.912280\n",
      "EPOCH 18\n",
      "TAG_LOSS_WEIGHT:  0.26462683539789966\n",
      "CLS_LOSS_WEIGHT:  0.7353731646021004\n",
      "tp:  693\n",
      "fn:  629\n",
      "tn:  593\n",
      "fp:  729\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1286\n",
      "tp:  213\n",
      "fn:  351\n",
      "tn:  348\n",
      "fp:  216\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  561\n",
      "EPOCH 18\n",
      "   TRAIN | Label 1 loss: 20.1328 ; P: 0.6945 ; R: 0.5721 ; F1: 0.6274 ; Acc: 0.8748\n",
      "           Label 2 loss: 62.5923 ; P: 0.4873 ; R: 0.5242 ; F1: 0.5051 ; Acc: 0.4864\n",
      "    TEST | Label 1 loss: 9.0896 ; P: 0.6354 ; R: 0.6901 ; F1: 0.6616 ; Acc: 0.8613\n",
      "           Label 2 loss: 27.0271 ; P: 0.4965 ; R: 0.3777 ; F1: 0.429 ; Acc: 0.4973\n",
      "2023-01-29 12:31:17.757011\n",
      "2023-01-29 12:31:17.758008\n",
      "EPOCH 19\n",
      "TAG_LOSS_WEIGHT:  0.2601418316762235\n",
      "CLS_LOSS_WEIGHT:  0.7398581683237765\n",
      "tp:  637\n",
      "fn:  685\n",
      "tn:  648\n",
      "fp:  674\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1285\n",
      "tp:  152\n",
      "fn:  412\n",
      "tn:  415\n",
      "fp:  149\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  567\n",
      "EPOCH 19\n",
      "   TRAIN | Label 1 loss: 19.9069 ; P: 0.6893 ; R: 0.5747 ; F1: 0.6268 ; Acc: 0.8739\n",
      "           Label 2 loss: 62.6455 ; P: 0.4859 ; R: 0.4818 ; F1: 0.4839 ; Acc: 0.486\n",
      "    TEST | Label 1 loss: 9.1285 ; P: 0.6241 ; R: 0.7078 ; F1: 0.6633 ; Acc: 0.8588\n",
      "           Label 2 loss: 27.0336 ; P: 0.505 ; R: 0.2695 ; F1: 0.3514 ; Acc: 0.5027\n",
      "2023-01-29 12:31:48.449164\n",
      "2023-01-29 12:31:48.449164\n",
      "EPOCH 20\n",
      "TAG_LOSS_WEIGHT:  0.2554984628546282\n",
      "CLS_LOSS_WEIGHT:  0.7445015371453718\n",
      "tp:  563\n",
      "fn:  759\n",
      "tn:  736\n",
      "fp:  586\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1299\n",
      "tp:  304\n",
      "fn:  260\n",
      "tn:  263\n",
      "fp:  301\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  567\n",
      "EPOCH 20\n",
      "   TRAIN | Label 1 loss: 20.0608 ; P: 0.6902 ; R: 0.5624 ; F1: 0.6198 ; Acc: 0.8729\n",
      "           Label 2 loss: 62.5337 ; P: 0.49 ; R: 0.4259 ; F1: 0.4557 ; Acc: 0.4913\n",
      "    TEST | Label 1 loss: 9.0271 ; P: 0.6335 ; R: 0.7052 ; F1: 0.6675 ; Acc: 0.8619\n",
      "           Label 2 loss: 27.0273 ; P: 0.5025 ; R: 0.539 ; F1: 0.5201 ; Acc: 0.5027\n",
      "2023-01-29 12:32:19.473049\n",
      "2023-01-29 12:32:19.474049\n",
      "EPOCH 21\n",
      "TAG_LOSS_WEIGHT:  0.2591245812938531\n",
      "CLS_LOSS_WEIGHT:  0.740875418706147\n",
      "tp:  731\n",
      "fn:  591\n",
      "tn:  620\n",
      "fp:  702\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1351\n",
      "tp:  313\n",
      "fn:  251\n",
      "tn:  253\n",
      "fp:  311\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  566\n",
      "EPOCH 21\n",
      "   TRAIN | Label 1 loss: 19.9104 ; P: 0.6893 ; R: 0.5635 ; F1: 0.6201 ; Acc: 0.8728\n",
      "           Label 2 loss: 62.4481 ; P: 0.5101 ; R: 0.553 ; F1: 0.5307 ; Acc: 0.511\n",
      "    TEST | Label 1 loss: 9.1285 ; P: 0.6249 ; R: 0.7375 ; F1: 0.6765 ; Acc: 0.8614\n",
      "           Label 2 loss: 27.0262 ; P: 0.5016 ; R: 0.555 ; F1: 0.5269 ; Acc: 0.5018\n",
      "2023-01-29 12:32:50.237428\n",
      "2023-01-29 12:32:50.237428\n",
      "EPOCH 22\n",
      "TAG_LOSS_WEIGHT:  0.2567680861624727\n",
      "CLS_LOSS_WEIGHT:  0.7432319138375273\n",
      "tp:  753\n",
      "fn:  569\n",
      "tn:  616\n",
      "fp:  706\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1369\n",
      "tp:  223\n",
      "fn:  341\n",
      "tn:  337\n",
      "fp:  227\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  560\n",
      "EPOCH 22\n",
      "   TRAIN | Label 1 loss: 19.7787 ; P: 0.6937 ; R: 0.5705 ; F1: 0.6261 ; Acc: 0.8745\n",
      "           Label 2 loss: 62.3439 ; P: 0.5161 ; R: 0.5696 ; F1: 0.5415 ; Acc: 0.5178\n",
      "    TEST | Label 1 loss: 9.0798 ; P: 0.6306 ; R: 0.7084 ; F1: 0.6673 ; Acc: 0.8612\n",
      "           Label 2 loss: 27.0295 ; P: 0.4956 ; R: 0.3954 ; F1: 0.4398 ; Acc: 0.4965\n",
      "2023-01-29 12:33:21.141555\n",
      "2023-01-29 12:33:21.141555\n",
      "EPOCH 23\n",
      "TAG_LOSS_WEIGHT:  0.254877025633626\n",
      "CLS_LOSS_WEIGHT:  0.7451229743663739\n",
      "tp:  619\n",
      "fn:  703\n",
      "tn:  705\n",
      "fp:  617\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1324\n",
      "tp:  166\n",
      "fn:  398\n",
      "tn:  402\n",
      "fp:  162\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  568\n",
      "EPOCH 23\n",
      "   TRAIN | Label 1 loss: 19.5541 ; P: 0.6881 ; R: 0.5701 ; F1: 0.6236 ; Acc: 0.8732\n",
      "           Label 2 loss: 62.5125 ; P: 0.5008 ; R: 0.4682 ; F1: 0.484 ; Acc: 0.5008\n",
      "    TEST | Label 1 loss: 9.0155 ; P: 0.6333 ; R: 0.7034 ; F1: 0.6665 ; Acc: 0.8617\n",
      "           Label 2 loss: 27.0282 ; P: 0.5061 ; R: 0.2943 ; F1: 0.3722 ; Acc: 0.5035\n",
      "2023-01-29 12:33:52.365332\n",
      "2023-01-29 12:33:52.365332\n",
      "EPOCH 24\n",
      "TAG_LOSS_WEIGHT:  0.24955056027624373\n",
      "CLS_LOSS_WEIGHT:  0.7504494397237563\n",
      "tp:  595\n",
      "fn:  727\n",
      "tn:  731\n",
      "fp:  591\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1326\n",
      "tp:  250\n",
      "fn:  314\n",
      "tn:  321\n",
      "fp:  243\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  571\n",
      "EPOCH 24\n",
      "   TRAIN | Label 1 loss: 19.4748 ; P: 0.6964 ; R: 0.5806 ; F1: 0.6332 ; Acc: 0.8761\n",
      "           Label 2 loss: 62.4585 ; P: 0.5017 ; R: 0.4501 ; F1: 0.4745 ; Acc: 0.5015\n",
      "    TEST | Label 1 loss: 8.9533 ; P: 0.6348 ; R: 0.7046 ; F1: 0.6679 ; Acc: 0.8623\n",
      "           Label 2 loss: 27.0231 ; P: 0.5071 ; R: 0.4433 ; F1: 0.473 ; Acc: 0.5062\n",
      "2023-01-29 12:34:23.593313\n",
      "2023-01-29 12:34:23.593313\n",
      "EPOCH 25\n",
      "TAG_LOSS_WEIGHT:  0.24835412336893006\n",
      "CLS_LOSS_WEIGHT:  0.75164587663107\n",
      "tp:  721\n",
      "fn:  601\n",
      "tn:  639\n",
      "fp:  683\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1360\n",
      "tp:  216\n",
      "fn:  348\n",
      "tn:  362\n",
      "fp:  202\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  578\n",
      "EPOCH 25\n",
      "   TRAIN | Label 1 loss: 19.3957 ; P: 0.6932 ; R: 0.5697 ; F1: 0.6254 ; Acc: 0.8743\n",
      "           Label 2 loss: 62.3409 ; P: 0.5135 ; R: 0.5454 ; F1: 0.529 ; Acc: 0.5144\n",
      "    TEST | Label 1 loss: 8.9233 ; P: 0.6371 ; R: 0.7084 ; F1: 0.6709 ; Acc: 0.8634\n",
      "           Label 2 loss: 27.0247 ; P: 0.5167 ; R: 0.383 ; F1: 0.4399 ; Acc: 0.5124\n",
      "2023-01-29 12:34:54.743003\n",
      "2023-01-29 12:34:54.743003\n",
      "EPOCH 26\n",
      "TAG_LOSS_WEIGHT:  0.2475391401890949\n",
      "CLS_LOSS_WEIGHT:  0.752460859810905\n",
      "tp:  654\n",
      "fn:  668\n",
      "tn:  656\n",
      "fp:  666\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1310\n",
      "tp:  204\n",
      "fn:  360\n",
      "tn:  365\n",
      "fp:  199\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  569\n",
      "EPOCH 26\n",
      "   TRAIN | Label 1 loss: 19.302 ; P: 0.6978 ; R: 0.5803 ; F1: 0.6337 ; Acc: 0.8764\n",
      "           Label 2 loss: 62.5058 ; P: 0.4955 ; R: 0.4947 ; F1: 0.4951 ; Acc: 0.4955\n",
      "    TEST | Label 1 loss: 8.955 ; P: 0.6309 ; R: 0.7179 ; F1: 0.6716 ; Acc: 0.862\n",
      "           Label 2 loss: 27.0237 ; P: 0.5062 ; R: 0.3617 ; F1: 0.4219 ; Acc: 0.5044\n",
      "2023-01-29 12:35:25.665014\n",
      "2023-01-29 12:35:25.665014\n",
      "EPOCH 27\n",
      "TAG_LOSS_WEIGHT:  0.24476157852209818\n",
      "CLS_LOSS_WEIGHT:  0.755238421477902\n",
      "tp:  657\n",
      "fn:  665\n",
      "tn:  695\n",
      "fp:  627\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1352\n",
      "tp:  285\n",
      "fn:  279\n",
      "tn:  283\n",
      "fp:  281\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  568\n",
      "EPOCH 27\n",
      "   TRAIN | Label 1 loss: 19.4195 ; P: 0.6839 ; R: 0.5725 ; F1: 0.6232 ; Acc: 0.8725\n",
      "           Label 2 loss: 62.381 ; P: 0.5117 ; R: 0.497 ; F1: 0.5042 ; Acc: 0.5113\n",
      "    TEST | Label 1 loss: 8.9472 ; P: 0.6315 ; R: 0.7261 ; F1: 0.6755 ; Acc: 0.8629\n",
      "           Label 2 loss: 27.0185 ; P: 0.5035 ; R: 0.5053 ; F1: 0.5044 ; Acc: 0.5035\n",
      "2023-01-29 12:35:56.659246\n",
      "2023-01-29 12:35:56.660246\n",
      "EPOCH 28\n",
      "TAG_LOSS_WEIGHT:  0.24775649667167904\n",
      "CLS_LOSS_WEIGHT:  0.7522435033283211\n",
      "tp:  673\n",
      "fn:  649\n",
      "tn:  660\n",
      "fp:  662\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1333\n",
      "tp:  248\n",
      "fn:  316\n",
      "tn:  334\n",
      "fp:  230\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  582\n",
      "EPOCH 28\n",
      "   TRAIN | Label 1 loss: 19.3134 ; P: 0.6913 ; R: 0.573 ; F1: 0.6266 ; Acc: 0.8742\n",
      "           Label 2 loss: 62.5072 ; P: 0.5041 ; R: 0.5091 ; F1: 0.5066 ; Acc: 0.5042\n",
      "    TEST | Label 1 loss: 9.0875 ; P: 0.6151 ; R: 0.754 ; F1: 0.6775 ; Acc: 0.8589\n",
      "           Label 2 loss: 27.0185 ; P: 0.5188 ; R: 0.4397 ; F1: 0.476 ; Acc: 0.516\n",
      "2023-01-29 12:36:27.687831\n",
      "2023-01-29 12:36:30.153643\n",
      "EPOCH 29\n",
      "TAG_LOSS_WEIGHT:  0.2449716477378647\n",
      "CLS_LOSS_WEIGHT:  0.7550283522621353\n",
      "tp:  645\n",
      "fn:  677\n",
      "tn:  693\n",
      "fp:  629\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1338\n",
      "tp:  262\n",
      "fn:  302\n",
      "tn:  320\n",
      "fp:  244\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  582\n",
      "EPOCH 29\n",
      "   TRAIN | Label 1 loss: 19.0929 ; P: 0.7018 ; R: 0.5782 ; F1: 0.634 ; Acc: 0.877\n",
      "           Label 2 loss: 62.343 ; P: 0.5063 ; R: 0.4879 ; F1: 0.4969 ; Acc: 0.5061\n",
      "    TEST | Label 1 loss: 8.8556 ; P: 0.6354 ; R: 0.7122 ; F1: 0.6716 ; Acc: 0.8632\n",
      "           Label 2 loss: 27.0177 ; P: 0.5178 ; R: 0.4645 ; F1: 0.4897 ; Acc: 0.516\n",
      "2023-01-29 12:37:02.661088\n",
      "2023-01-29 12:37:02.661088\n",
      "EPOCH 30\n",
      "TAG_LOSS_WEIGHT:  0.2417118126538001\n",
      "CLS_LOSS_WEIGHT:  0.7582881873462\n",
      "tp:  643\n",
      "fn:  679\n",
      "tn:  682\n",
      "fp:  640\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1325\n",
      "tp:  297\n",
      "fn:  267\n",
      "tn:  275\n",
      "fp:  289\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  572\n",
      "EPOCH 30\n",
      "   TRAIN | Label 1 loss: 19.1225 ; P: 0.6894 ; R: 0.5746 ; F1: 0.6268 ; Acc: 0.8739\n",
      "           Label 2 loss: 62.5205 ; P: 0.5012 ; R: 0.4864 ; F1: 0.4937 ; Acc: 0.5011\n",
      "    TEST | Label 1 loss: 8.9531 ; P: 0.6267 ; R: 0.74 ; F1: 0.6787 ; Acc: 0.8623\n",
      "           Label 2 loss: 27.0171 ; P: 0.5068 ; R: 0.5266 ; F1: 0.5165 ; Acc: 0.5071\n",
      "2023-01-29 12:37:34.221229\n",
      "2023-01-29 12:37:34.221229\n",
      "EPOCH 31\n",
      "TAG_LOSS_WEIGHT:  0.24123778519929592\n",
      "CLS_LOSS_WEIGHT:  0.758762214800704\n",
      "tp:  662\n",
      "fn:  660\n",
      "tn:  667\n",
      "fp:  655\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1329\n",
      "tp:  328\n",
      "fn:  236\n",
      "tn:  216\n",
      "fp:  348\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  544\n",
      "EPOCH 31\n",
      "   TRAIN | Label 1 loss: 18.9319 ; P: 0.697 ; R: 0.5785 ; F1: 0.6323 ; Acc: 0.876\n",
      "           Label 2 loss: 62.5215 ; P: 0.5027 ; R: 0.5008 ; F1: 0.5017 ; Acc: 0.5026\n",
      "    TEST | Label 1 loss: 8.9058 ; P: 0.6292 ; R: 0.7362 ; F1: 0.6785 ; Acc: 0.8629\n",
      "           Label 2 loss: 27.0171 ; P: 0.4852 ; R: 0.5816 ; F1: 0.529 ; Acc: 0.4823\n",
      "2023-01-29 12:38:05.388858\n",
      "2023-01-29 12:38:05.388858\n",
      "EPOCH 32\n",
      "TAG_LOSS_WEIGHT:  0.2375838417566061\n",
      "CLS_LOSS_WEIGHT:  0.762416158243394\n",
      "tp:  709\n",
      "fn:  613\n",
      "tn:  625\n",
      "fp:  697\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1334\n",
      "tp:  315\n",
      "fn:  249\n",
      "tn:  241\n",
      "fp:  323\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  556\n",
      "EPOCH 32\n",
      "   TRAIN | Label 1 loss: 19.1209 ; P: 0.6916 ; R: 0.5842 ; F1: 0.6334 ; Acc: 0.8754\n",
      "           Label 2 loss: 62.4739 ; P: 0.5043 ; R: 0.5363 ; F1: 0.5198 ; Acc: 0.5045\n",
      "    TEST | Label 1 loss: 8.8578 ; P: 0.632 ; R: 0.7312 ; F1: 0.678 ; Acc: 0.8635\n",
      "           Label 2 loss: 27.0167 ; P: 0.4937 ; R: 0.5585 ; F1: 0.5241 ; Acc: 0.4929\n",
      "2023-01-29 12:38:36.587980\n",
      "2023-01-29 12:38:36.587980\n",
      "EPOCH 33\n",
      "TAG_LOSS_WEIGHT:  0.24148020091549896\n",
      "CLS_LOSS_WEIGHT:  0.7585197990845011\n",
      "tp:  677\n",
      "fn:  645\n",
      "tn:  666\n",
      "fp:  656\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1343\n",
      "tp:  310\n",
      "fn:  254\n",
      "tn:  258\n",
      "fp:  306\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  568\n",
      "EPOCH 33\n",
      "   TRAIN | Label 1 loss: 19.0796 ; P: 0.6916 ; R: 0.5777 ; F1: 0.6295 ; Acc: 0.8747\n",
      "           Label 2 loss: 62.3638 ; P: 0.5079 ; R: 0.5121 ; F1: 0.51 ; Acc: 0.5079\n",
      "    TEST | Label 1 loss: 8.9148 ; P: 0.6232 ; R: 0.7438 ; F1: 0.6782 ; Acc: 0.8613\n",
      "           Label 2 loss: 27.0163 ; P: 0.5032 ; R: 0.5496 ; F1: 0.5254 ; Acc: 0.5035\n",
      "2023-01-29 12:39:07.477836\n",
      "2023-01-29 12:39:07.477836\n",
      "EPOCH 34\n",
      "TAG_LOSS_WEIGHT:  0.24133428841081073\n",
      "CLS_LOSS_WEIGHT:  0.7586657115891893\n",
      "tp:  666\n",
      "fn:  656\n",
      "tn:  675\n",
      "fp:  647\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1341\n",
      "tp:  299\n",
      "fn:  265\n",
      "tn:  269\n",
      "fp:  295\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  568\n",
      "EPOCH 34\n",
      "   TRAIN | Label 1 loss: 19.0266 ; P: 0.6885 ; R: 0.5866 ; F1: 0.6335 ; Acc: 0.8749\n",
      "           Label 2 loss: 62.4483 ; P: 0.5072 ; R: 0.5038 ; F1: 0.5055 ; Acc: 0.5072\n",
      "    TEST | Label 1 loss: 8.795 ; P: 0.6367 ; R: 0.7249 ; F1: 0.6779 ; Acc: 0.8647\n",
      "           Label 2 loss: 27.0154 ; P: 0.5034 ; R: 0.5301 ; F1: 0.5164 ; Acc: 0.5035\n",
      "2023-01-29 12:39:38.519789\n",
      "2023-01-29 12:39:38.519789\n",
      "EPOCH 35\n",
      "TAG_LOSS_WEIGHT:  0.23982308919719478\n",
      "CLS_LOSS_WEIGHT:  0.7601769108028053\n",
      "tp:  677\n",
      "fn:  645\n",
      "tn:  657\n",
      "fp:  665\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1334\n",
      "tp:  284\n",
      "fn:  280\n",
      "tn:  293\n",
      "fp:  271\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  577\n",
      "EPOCH 35\n",
      "   TRAIN | Label 1 loss: 18.9015 ; P: 0.6974 ; R: 0.5856 ; F1: 0.6366 ; Acc: 0.8768\n",
      "           Label 2 loss: 62.3985 ; P: 0.5045 ; R: 0.5121 ; F1: 0.5083 ; Acc: 0.5045\n",
      "    TEST | Label 1 loss: 8.8344 ; P: 0.6287 ; R: 0.7324 ; F1: 0.6766 ; Acc: 0.8624\n",
      "           Label 2 loss: 27.0148 ; P: 0.5117 ; R: 0.5035 ; F1: 0.5076 ; Acc: 0.5115\n",
      "2023-01-29 12:40:09.523179\n",
      "2023-01-29 12:40:09.524179\n",
      "EPOCH 36\n",
      "TAG_LOSS_WEIGHT:  0.23771508832518237\n",
      "CLS_LOSS_WEIGHT:  0.7622849116748176\n",
      "tp:  695\n",
      "fn:  627\n",
      "tn:  705\n",
      "fp:  617\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1400\n",
      "tp:  265\n",
      "fn:  299\n",
      "tn:  321\n",
      "fp:  243\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  586\n",
      "EPOCH 36\n",
      "   TRAIN | Label 1 loss: 18.9081 ; P: 0.6924 ; R: 0.5765 ; F1: 0.6292 ; Acc: 0.8748\n",
      "           Label 2 loss: 62.2407 ; P: 0.5297 ; R: 0.5257 ; F1: 0.5277 ; Acc: 0.5295\n",
      "    TEST | Label 1 loss: 8.818 ; P: 0.6298 ; R: 0.7318 ; F1: 0.677 ; Acc: 0.8628\n",
      "           Label 2 loss: 27.0147 ; P: 0.5217 ; R: 0.4699 ; F1: 0.4944 ; Acc: 0.5195\n",
      "2023-01-29 12:40:40.438913\n",
      "2023-01-29 12:40:42.264606\n",
      "EPOCH 37\n",
      "TAG_LOSS_WEIGHT:  0.2387608611200929\n",
      "CLS_LOSS_WEIGHT:  0.7612391388799071\n",
      "tp:  654\n",
      "fn:  668\n",
      "tn:  646\n",
      "fp:  676\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1300\n",
      "tp:  252\n",
      "fn:  312\n",
      "tn:  330\n",
      "fp:  234\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  582\n",
      "EPOCH 37\n",
      "   TRAIN | Label 1 loss: 18.9247 ; P: 0.6963 ; R: 0.5827 ; F1: 0.6345 ; Acc: 0.8763\n",
      "           Label 2 loss: 62.5012 ; P: 0.4917 ; R: 0.4947 ; F1: 0.4932 ; Acc: 0.4917\n",
      "    TEST | Label 1 loss: 8.8403 ; P: 0.6284 ; R: 0.7369 ; F1: 0.6783 ; Acc: 0.8627\n",
      "           Label 2 loss: 27.0146 ; P: 0.5185 ; R: 0.4468 ; F1: 0.48 ; Acc: 0.516\n",
      "2023-01-29 12:41:14.753148\n",
      "2023-01-29 12:41:14.754148\n",
      "EPOCH 38\n",
      "TAG_LOSS_WEIGHT:  0.23756368468769073\n",
      "CLS_LOSS_WEIGHT:  0.7624363153123093\n",
      "tp:  666\n",
      "fn:  656\n",
      "tn:  675\n",
      "fp:  647\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1341\n",
      "tp:  259\n",
      "fn:  305\n",
      "tn:  318\n",
      "fp:  246\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  577\n",
      "EPOCH 38\n",
      "   TRAIN | Label 1 loss: 18.592 ; P: 0.6988 ; R: 0.5942 ; F1: 0.6423 ; Acc: 0.878\n",
      "           Label 2 loss: 62.3676 ; P: 0.5072 ; R: 0.5038 ; F1: 0.5055 ; Acc: 0.5072\n",
      "    TEST | Label 1 loss: 8.7455 ; P: 0.6387 ; R: 0.7211 ; F1: 0.6774 ; Acc: 0.865\n",
      "           Label 2 loss: 27.0145 ; P: 0.5129 ; R: 0.4592 ; F1: 0.4846 ; Acc: 0.5115\n",
      "2023-01-29 12:41:46.542890\n",
      "2023-01-29 12:41:46.543878\n",
      "EPOCH 39\n",
      "TAG_LOSS_WEIGHT:  0.23196003246766686\n",
      "CLS_LOSS_WEIGHT:  0.768039967532333\n",
      "tp:  682\n",
      "fn:  640\n",
      "tn:  682\n",
      "fp:  640\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1364\n",
      "tp:  243\n",
      "fn:  321\n",
      "tn:  335\n",
      "fp:  229\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  578\n",
      "EPOCH 39\n",
      "   TRAIN | Label 1 loss: 18.9438 ; P: 0.693 ; R: 0.5775 ; F1: 0.63 ; Acc: 0.875\n",
      "           Label 2 loss: 62.2555 ; P: 0.5159 ; R: 0.5159 ; F1: 0.5159 ; Acc: 0.5159\n",
      "    TEST | Label 1 loss: 8.8092 ; P: 0.6285 ; R: 0.7287 ; F1: 0.6749 ; Acc: 0.862\n",
      "           Label 2 loss: 27.0155 ; P: 0.5148 ; R: 0.4309 ; F1: 0.4691 ; Acc: 0.5124\n",
      "2023-01-29 12:42:17.588857\n",
      "2023-01-29 12:42:17.588857\n",
      "EPOCH 40\n",
      "TAG_LOSS_WEIGHT:  0.2393606354880962\n",
      "CLS_LOSS_WEIGHT:  0.7606393645119038\n",
      "tp:  655\n",
      "fn:  667\n",
      "tn:  688\n",
      "fp:  634\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1343\n",
      "tp:  263\n",
      "fn:  301\n",
      "tn:  321\n",
      "fp:  243\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  584\n",
      "EPOCH 40\n",
      "   TRAIN | Label 1 loss: 18.7085 ; P: 0.6981 ; R: 0.5893 ; F1: 0.6391 ; Acc: 0.8774\n",
      "           Label 2 loss: 62.4167 ; P: 0.5081 ; R: 0.4955 ; F1: 0.5017 ; Acc: 0.5079\n",
      "    TEST | Label 1 loss: 8.8117 ; P: 0.6274 ; R: 0.7306 ; F1: 0.675 ; Acc: 0.8618\n",
      "           Label 2 loss: 27.0152 ; P: 0.5198 ; R: 0.4663 ; F1: 0.4916 ; Acc: 0.5177\n",
      "2023-01-29 12:42:49.006873\n",
      "2023-01-29 12:42:49.007865\n",
      "EPOCH 41\n",
      "TAG_LOSS_WEIGHT:  0.23391103847196246\n",
      "CLS_LOSS_WEIGHT:  0.7660889615280376\n",
      "tp:  637\n",
      "fn:  685\n",
      "tn:  682\n",
      "fp:  640\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1319\n",
      "tp:  264\n",
      "fn:  300\n",
      "tn:  320\n",
      "fp:  244\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  584\n",
      "EPOCH 41\n",
      "   TRAIN | Label 1 loss: 18.758 ; P: 0.6949 ; R: 0.5841 ; F1: 0.6347 ; Acc: 0.8761\n",
      "           Label 2 loss: 62.4942 ; P: 0.4988 ; R: 0.4818 ; F1: 0.4902 ; Acc: 0.4989\n",
      "    TEST | Label 1 loss: 8.7964 ; P: 0.6295 ; R: 0.7318 ; F1: 0.6768 ; Acc: 0.8627\n",
      "           Label 2 loss: 27.0148 ; P: 0.5197 ; R: 0.4681 ; F1: 0.4925 ; Acc: 0.5177\n",
      "2023-01-29 12:43:20.012015\n",
      "2023-01-29 12:43:20.012015\n",
      "EPOCH 42\n",
      "TAG_LOSS_WEIGHT:  0.23441369318598976\n",
      "CLS_LOSS_WEIGHT:  0.7655863068140102\n",
      "tp:  652\n",
      "fn:  670\n",
      "tn:  680\n",
      "fp:  642\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1332\n",
      "tp:  267\n",
      "fn:  297\n",
      "tn:  314\n",
      "fp:  250\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  581\n",
      "EPOCH 42\n",
      "   TRAIN | Label 1 loss: 18.7475 ; P: 0.695 ; R: 0.5854 ; F1: 0.6355 ; Acc: 0.8763\n",
      "           Label 2 loss: 62.3866 ; P: 0.5039 ; R: 0.4932 ; F1: 0.4985 ; Acc: 0.5038\n",
      "    TEST | Label 1 loss: 8.7532 ; P: 0.635 ; R: 0.723 ; F1: 0.6761 ; Acc: 0.8639\n",
      "           Label 2 loss: 27.0146 ; P: 0.5164 ; R: 0.4734 ; F1: 0.494 ; Acc: 0.5151\n",
      "2023-01-29 12:43:50.744006\n",
      "2023-01-29 12:43:50.745005\n",
      "EPOCH 43\n",
      "TAG_LOSS_WEIGHT:  0.2348315011804964\n",
      "CLS_LOSS_WEIGHT:  0.7651684988195036\n",
      "tp:  689\n",
      "fn:  633\n",
      "tn:  662\n",
      "fp:  660\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1351\n",
      "tp:  284\n",
      "fn:  280\n",
      "tn:  289\n",
      "fp:  275\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  573\n",
      "EPOCH 43\n",
      "   TRAIN | Label 1 loss: 18.7912 ; P: 0.6886 ; R: 0.5761 ; F1: 0.6274 ; Acc: 0.8739\n",
      "           Label 2 loss: 62.3399 ; P: 0.5107 ; R: 0.5212 ; F1: 0.5159 ; Acc: 0.511\n",
      "    TEST | Label 1 loss: 8.7737 ; P: 0.6305 ; R: 0.7274 ; F1: 0.6755 ; Acc: 0.8627\n",
      "           Label 2 loss: 27.0146 ; P: 0.5081 ; R: 0.5035 ; F1: 0.5058 ; Acc: 0.508\n",
      "2023-01-29 12:44:21.452248\n",
      "2023-01-29 12:44:21.453241\n",
      "EPOCH 44\n",
      "TAG_LOSS_WEIGHT:  0.2359391279936409\n",
      "CLS_LOSS_WEIGHT:  0.7640608720063592\n",
      "tp:  655\n",
      "fn:  667\n",
      "tn:  685\n",
      "fp:  637\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1340\n",
      "tp:  294\n",
      "fn:  270\n",
      "tn:  277\n",
      "fp:  287\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  571\n",
      "EPOCH 44\n",
      "   TRAIN | Label 1 loss: 18.7819 ; P: 0.6995 ; R: 0.5841 ; F1: 0.6366 ; Acc: 0.8771\n",
      "           Label 2 loss: 62.3736 ; P: 0.507 ; R: 0.4955 ; F1: 0.5011 ; Acc: 0.5068\n",
      "    TEST | Label 1 loss: 8.7874 ; P: 0.6298 ; R: 0.7306 ; F1: 0.6764 ; Acc: 0.8627\n",
      "           Label 2 loss: 27.0145 ; P: 0.506 ; R: 0.5213 ; F1: 0.5135 ; Acc: 0.5062\n",
      "2023-01-29 12:44:52.082555\n",
      "2023-01-29 12:44:52.083555\n",
      "EPOCH 45\n",
      "TAG_LOSS_WEIGHT:  0.2355659986364933\n",
      "CLS_LOSS_WEIGHT:  0.7644340013635067\n",
      "tp:  667\n",
      "fn:  655\n",
      "tn:  665\n",
      "fp:  657\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1332\n",
      "tp:  300\n",
      "fn:  264\n",
      "tn:  271\n",
      "fp:  293\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  571\n",
      "EPOCH 45\n",
      "   TRAIN | Label 1 loss: 18.7856 ; P: 0.6995 ; R: 0.5835 ; F1: 0.6363 ; Acc: 0.8771\n",
      "           Label 2 loss: 62.4248 ; P: 0.5038 ; R: 0.5045 ; F1: 0.5042 ; Acc: 0.5038\n",
      "    TEST | Label 1 loss: 8.7878 ; P: 0.6298 ; R: 0.7318 ; F1: 0.677 ; Acc: 0.8628\n",
      "           Label 2 loss: 27.0145 ; P: 0.5059 ; R: 0.5319 ; F1: 0.5186 ; Acc: 0.5062\n",
      "2023-01-29 12:45:22.636659\n",
      "2023-01-29 12:45:22.636659\n",
      "EPOCH 46\n",
      "TAG_LOSS_WEIGHT:  0.2353415035306256\n",
      "CLS_LOSS_WEIGHT:  0.7646584964693743\n",
      "tp:  669\n",
      "fn:  653\n",
      "tn:  664\n",
      "fp:  658\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1333\n",
      "tp:  300\n",
      "fn:  264\n",
      "tn:  273\n",
      "fp:  291\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  573\n",
      "EPOCH 46\n",
      "   TRAIN | Label 1 loss: 18.7333 ; P: 0.6907 ; R: 0.5837 ; F1: 0.6327 ; Acc: 0.8751\n",
      "           Label 2 loss: 62.5109 ; P: 0.5041 ; R: 0.5061 ; F1: 0.5051 ; Acc: 0.5042\n",
      "    TEST | Label 1 loss: 8.7854 ; P: 0.6294 ; R: 0.7306 ; F1: 0.6762 ; Acc: 0.8625\n",
      "           Label 2 loss: 27.0145 ; P: 0.5076 ; R: 0.5319 ; F1: 0.5195 ; Acc: 0.508\n",
      "2023-01-29 12:45:53.852207\n",
      "2023-01-29 12:45:53.852207\n",
      "EPOCH 47\n",
      "TAG_LOSS_WEIGHT:  0.23384533313298725\n",
      "CLS_LOSS_WEIGHT:  0.7661546668670128\n",
      "tp:  638\n",
      "fn:  684\n",
      "tn:  681\n",
      "fp:  641\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1319\n",
      "tp:  292\n",
      "fn:  272\n",
      "tn:  279\n",
      "fp:  285\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  571\n",
      "EPOCH 47\n",
      "   TRAIN | Label 1 loss: 18.7536 ; P: 0.6997 ; R: 0.5891 ; F1: 0.6397 ; Acc: 0.8777\n",
      "           Label 2 loss: 62.4832 ; P: 0.4988 ; R: 0.4826 ; F1: 0.4906 ; Acc: 0.4989\n",
      "    TEST | Label 1 loss: 8.7774 ; P: 0.6308 ; R: 0.7306 ; F1: 0.677 ; Acc: 0.863\n",
      "           Label 2 loss: 27.0144 ; P: 0.5061 ; R: 0.5177 ; F1: 0.5118 ; Acc: 0.5062\n",
      "2023-01-29 12:46:24.891110\n",
      "2023-01-29 12:46:24.891110\n",
      "EPOCH 48\n",
      "TAG_LOSS_WEIGHT:  0.23439267421045124\n",
      "CLS_LOSS_WEIGHT:  0.7656073257895489\n",
      "tp:  689\n",
      "fn:  633\n",
      "tn:  666\n",
      "fp:  656\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1355\n",
      "tp:  298\n",
      "fn:  266\n",
      "tn:  276\n",
      "fp:  288\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  574\n",
      "EPOCH 48\n",
      "   TRAIN | Label 1 loss: 18.8953 ; P: 0.6939 ; R: 0.5805 ; F1: 0.6321 ; Acc: 0.8755\n",
      "           Label 2 loss: 62.2924 ; P: 0.5123 ; R: 0.5212 ; F1: 0.5167 ; Acc: 0.5125\n",
      "    TEST | Label 1 loss: 8.7752 ; P: 0.6313 ; R: 0.7299 ; F1: 0.677 ; Acc: 0.8632\n",
      "           Label 2 loss: 27.0144 ; P: 0.5085 ; R: 0.5284 ; F1: 0.5183 ; Acc: 0.5089\n",
      "2023-01-29 12:46:55.835378\n",
      "2023-01-29 12:46:55.835378\n",
      "EPOCH 49\n",
      "TAG_LOSS_WEIGHT:  0.23821330808829405\n",
      "CLS_LOSS_WEIGHT:  0.7617866919117061\n",
      "tp:  692\n",
      "fn:  630\n",
      "tn:  688\n",
      "fp:  634\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1380\n",
      "tp:  297\n",
      "fn:  267\n",
      "tn:  276\n",
      "fp:  288\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  573\n",
      "EPOCH 49\n",
      "   TRAIN | Label 1 loss: 18.8951 ; P: 0.6934 ; R: 0.5859 ; F1: 0.6352 ; Acc: 0.876\n",
      "           Label 2 loss: 62.293 ; P: 0.5219 ; R: 0.5234 ; F1: 0.5227 ; Acc: 0.5219\n",
      "    TEST | Label 1 loss: 8.7754 ; P: 0.6316 ; R: 0.7299 ; F1: 0.6772 ; Acc: 0.8633\n",
      "           Label 2 loss: 27.0144 ; P: 0.5077 ; R: 0.5266 ; F1: 0.517 ; Acc: 0.508\n",
      "2023-01-29 12:47:26.803393\n",
      "2023-01-29 12:47:26.805384\n",
      "EPOCH 50\n",
      "TAG_LOSS_WEIGHT:  0.238205970828326\n",
      "CLS_LOSS_WEIGHT:  0.7617940291716739\n",
      "tp:  671\n",
      "fn:  651\n",
      "tn:  680\n",
      "fp:  642\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1351\n",
      "tp:  297\n",
      "fn:  267\n",
      "tn:  276\n",
      "fp:  288\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  573\n",
      "EPOCH 50\n",
      "   TRAIN | Label 1 loss: 18.8507 ; P: 0.6933 ; R: 0.5894 ; F1: 0.6372 ; Acc: 0.8763\n",
      "           Label 2 loss: 62.3296 ; P: 0.511 ; R: 0.5076 ; F1: 0.5093 ; Acc: 0.511\n",
      "    TEST | Label 1 loss: 8.7752 ; P: 0.6313 ; R: 0.7299 ; F1: 0.677 ; Acc: 0.8632\n",
      "           Label 2 loss: 27.0144 ; P: 0.5077 ; R: 0.5266 ; F1: 0.517 ; Acc: 0.508\n",
      "2023-01-29 12:47:57.868101\n",
      "2023-01-29 12:47:57.868101\n",
      "EPOCH 51\n",
      "TAG_LOSS_WEIGHT:  0.23714062281252926\n",
      "CLS_LOSS_WEIGHT:  0.7628593771874707\n",
      "tp:  669\n",
      "fn:  653\n",
      "tn:  656\n",
      "fp:  666\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1325\n",
      "tp:  298\n",
      "fn:  266\n",
      "tn:  276\n",
      "fp:  288\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  574\n",
      "EPOCH 51\n",
      "   TRAIN | Label 1 loss: 18.8968 ; P: 0.6904 ; R: 0.5894 ; F1: 0.6359 ; Acc: 0.8757\n",
      "           Label 2 loss: 62.382 ; P: 0.5011 ; R: 0.5061 ; F1: 0.5036 ; Acc: 0.5011\n",
      "    TEST | Label 1 loss: 8.7751 ; P: 0.6316 ; R: 0.7299 ; F1: 0.6772 ; Acc: 0.8633\n",
      "           Label 2 loss: 27.0144 ; P: 0.5085 ; R: 0.5284 ; F1: 0.5183 ; Acc: 0.5089\n",
      "2023-01-29 12:48:28.717775\n",
      "2023-01-29 12:48:28.718771\n",
      "EPOCH 52\n",
      "TAG_LOSS_WEIGHT:  0.23772080579185267\n",
      "CLS_LOSS_WEIGHT:  0.7622791942081474\n",
      "tp:  669\n",
      "fn:  653\n",
      "tn:  682\n",
      "fp:  640\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1351\n",
      "tp:  298\n",
      "fn:  266\n",
      "tn:  276\n",
      "fp:  288\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  574\n",
      "EPOCH 52\n",
      "   TRAIN | Label 1 loss: 18.7636 ; P: 0.6905 ; R: 0.5883 ; F1: 0.6353 ; Acc: 0.8756\n",
      "           Label 2 loss: 62.3707 ; P: 0.5111 ; R: 0.5061 ; F1: 0.5086 ; Acc: 0.511\n",
      "    TEST | Label 1 loss: 8.7745 ; P: 0.6316 ; R: 0.7299 ; F1: 0.6772 ; Acc: 0.8633\n",
      "           Label 2 loss: 27.0144 ; P: 0.5085 ; R: 0.5284 ; F1: 0.5183 ; Acc: 0.5089\n",
      "2023-01-29 12:48:59.914089\n",
      "2023-01-29 12:48:59.914089\n",
      "EPOCH 53\n",
      "TAG_LOSS_WEIGHT:  0.23523182819382424\n",
      "CLS_LOSS_WEIGHT:  0.7647681718061757\n",
      "tp:  613\n",
      "fn:  709\n",
      "tn:  668\n",
      "fp:  654\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1281\n",
      "tp:  295\n",
      "fn:  269\n",
      "tn:  279\n",
      "fp:  285\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  574\n",
      "EPOCH 53\n",
      "   TRAIN | Label 1 loss: 18.8288 ; P: 0.6948 ; R: 0.5884 ; F1: 0.6372 ; Acc: 0.8766\n",
      "           Label 2 loss: 62.4647 ; P: 0.4838 ; R: 0.4637 ; F1: 0.4735 ; Acc: 0.4845\n",
      "    TEST | Label 1 loss: 8.7734 ; P: 0.6309 ; R: 0.7287 ; F1: 0.6763 ; Acc: 0.8629\n",
      "           Label 2 loss: 27.0138 ; P: 0.5086 ; R: 0.523 ; F1: 0.5157 ; Acc: 0.5089\n",
      "2023-01-29 12:49:30.972923\n",
      "2023-01-29 12:49:30.972923\n",
      "EPOCH 54\n",
      "TAG_LOSS_WEIGHT:  0.23593877121780515\n",
      "CLS_LOSS_WEIGHT:  0.764061228782195\n",
      "tp:  653\n",
      "fn:  669\n",
      "tn:  660\n",
      "fp:  662\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1313\n",
      "tp:  288\n",
      "fn:  276\n",
      "tn:  285\n",
      "fp:  279\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  573\n",
      "EPOCH 54\n",
      "   TRAIN | Label 1 loss: 18.7406 ; P: 0.6982 ; R: 0.5875 ; F1: 0.638 ; Acc: 0.8772\n",
      "           Label 2 loss: 62.4343 ; P: 0.4966 ; R: 0.4939 ; F1: 0.4953 ; Acc: 0.4966\n",
      "    TEST | Label 1 loss: 8.7698 ; P: 0.6314 ; R: 0.728 ; F1: 0.6763 ; Acc: 0.863\n",
      "           Label 2 loss: 27.0136 ; P: 0.5079 ; R: 0.5106 ; F1: 0.5093 ; Acc: 0.508\n",
      "2023-01-29 12:50:01.808443\n",
      "2023-01-29 12:50:01.809443\n",
      "EPOCH 55\n",
      "TAG_LOSS_WEIGHT:  0.234424789219542\n",
      "CLS_LOSS_WEIGHT:  0.7655752107804579\n",
      "tp:  645\n",
      "fn:  677\n",
      "tn:  648\n",
      "fp:  674\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1293\n",
      "tp:  297\n",
      "fn:  267\n",
      "tn:  277\n",
      "fp:  287\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  574\n",
      "EPOCH 55\n",
      "   TRAIN | Label 1 loss: 18.7174 ; P: 0.699 ; R: 0.5821 ; F1: 0.6353 ; Acc: 0.8768\n",
      "           Label 2 loss: 62.429 ; P: 0.489 ; R: 0.4879 ; F1: 0.4885 ; Acc: 0.489\n",
      "    TEST | Label 1 loss: 8.784 ; P: 0.6296 ; R: 0.7312 ; F1: 0.6766 ; Acc: 0.8627\n",
      "           Label 2 loss: 27.0136 ; P: 0.5086 ; R: 0.5266 ; F1: 0.5174 ; Acc: 0.5089\n",
      "2023-01-29 12:50:33.284762\n",
      "2023-01-29 12:50:33.284762\n",
      "EPOCH 56\n",
      "TAG_LOSS_WEIGHT:  0.23401088847976406\n",
      "CLS_LOSS_WEIGHT:  0.765989111520236\n",
      "tp:  668\n",
      "fn:  654\n",
      "tn:  638\n",
      "fp:  684\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1306\n",
      "tp:  287\n",
      "fn:  277\n",
      "tn:  285\n",
      "fp:  279\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  572\n",
      "EPOCH 56\n",
      "   TRAIN | Label 1 loss: 18.7066 ; P: 0.6943 ; R: 0.5852 ; F1: 0.6351 ; Acc: 0.8761\n",
      "           Label 2 loss: 62.5052 ; P: 0.4941 ; R: 0.5053 ; F1: 0.4996 ; Acc: 0.4939\n",
      "    TEST | Label 1 loss: 8.7814 ; P: 0.6301 ; R: 0.7306 ; F1: 0.6766 ; Acc: 0.8628\n",
      "           Label 2 loss: 27.0135 ; P: 0.5071 ; R: 0.5089 ; F1: 0.508 ; Acc: 0.5071\n",
      "2023-01-29 12:51:04.146039\n",
      "2023-01-29 12:51:04.146039\n",
      "EPOCH 57\n",
      "TAG_LOSS_WEIGHT:  0.23336727638261337\n",
      "CLS_LOSS_WEIGHT:  0.7666327236173867\n",
      "tp:  646\n",
      "fn:  676\n",
      "tn:  687\n",
      "fp:  635\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1333\n",
      "tp:  297\n",
      "fn:  267\n",
      "tn:  272\n",
      "fp:  292\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  569\n",
      "EPOCH 57\n",
      "   TRAIN | Label 1 loss: 18.7126 ; P: 0.6933 ; R: 0.5842 ; F1: 0.6341 ; Acc: 0.8758\n",
      "           Label 2 loss: 62.4258 ; P: 0.5043 ; R: 0.4887 ; F1: 0.4964 ; Acc: 0.5042\n",
      "    TEST | Label 1 loss: 8.7768 ; P: 0.6315 ; R: 0.7306 ; F1: 0.6774 ; Acc: 0.8633\n",
      "           Label 2 loss: 27.0129 ; P: 0.5042 ; R: 0.5266 ; F1: 0.5152 ; Acc: 0.5044\n",
      "2023-01-29 12:51:34.760700\n",
      "2023-01-29 12:51:34.760700\n",
      "EPOCH 58\n",
      "TAG_LOSS_WEIGHT:  0.23393732550707894\n",
      "CLS_LOSS_WEIGHT:  0.7660626744929211\n",
      "tp:  689\n",
      "fn:  633\n",
      "tn:  669\n",
      "fp:  653\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1358\n",
      "tp:  293\n",
      "fn:  271\n",
      "tn:  276\n",
      "fp:  288\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  569\n",
      "EPOCH 58\n",
      "   TRAIN | Label 1 loss: 18.7638 ; P: 0.6922 ; R: 0.5852 ; F1: 0.6342 ; Acc: 0.8756\n",
      "           Label 2 loss: 62.3267 ; P: 0.5134 ; R: 0.5212 ; F1: 0.5173 ; Acc: 0.5136\n",
      "    TEST | Label 1 loss: 8.7598 ; P: 0.6306 ; R: 0.7299 ; F1: 0.6766 ; Acc: 0.8629\n",
      "           Label 2 loss: 27.0127 ; P: 0.5043 ; R: 0.5195 ; F1: 0.5118 ; Acc: 0.5044\n",
      "2023-01-29 12:52:05.842334\n",
      "2023-01-29 12:52:05.843334\n",
      "EPOCH 59\n",
      "TAG_LOSS_WEIGHT:  0.2354896717802695\n",
      "CLS_LOSS_WEIGHT:  0.7645103282197305\n",
      "tp:  652\n",
      "fn:  670\n",
      "tn:  653\n",
      "fp:  669\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1305\n",
      "tp:  278\n",
      "fn:  286\n",
      "tn:  301\n",
      "fp:  263\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  579\n",
      "EPOCH 59\n",
      "   TRAIN | Label 1 loss: 18.7287 ; P: 0.6914 ; R: 0.5897 ; F1: 0.6365 ; Acc: 0.8759\n",
      "           Label 2 loss: 62.4397 ; P: 0.4936 ; R: 0.4932 ; F1: 0.4934 ; Acc: 0.4936\n",
      "    TEST | Label 1 loss: 8.7516 ; P: 0.6317 ; R: 0.7312 ; F1: 0.6778 ; Acc: 0.8634\n",
      "           Label 2 loss: 27.0126 ; P: 0.5139 ; R: 0.4929 ; F1: 0.5032 ; Acc: 0.5133\n",
      "2023-01-29 12:52:36.927610\n",
      "2023-01-29 12:52:36.927610\n",
      "EPOCH 60\n",
      "TAG_LOSS_WEIGHT:  0.23416585117782285\n",
      "CLS_LOSS_WEIGHT:  0.7658341488221772\n",
      "tp:  629\n",
      "fn:  693\n",
      "tn:  691\n",
      "fp:  631\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1320\n",
      "tp:  309\n",
      "fn:  255\n",
      "tn:  265\n",
      "fp:  299\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  574\n",
      "EPOCH 60\n",
      "   TRAIN | Label 1 loss: 18.6908 ; P: 0.6931 ; R: 0.5817 ; F1: 0.6325 ; Acc: 0.8755\n",
      "           Label 2 loss: 62.3561 ; P: 0.4992 ; R: 0.4758 ; F1: 0.4872 ; Acc: 0.4992\n",
      "    TEST | Label 1 loss: 8.7748 ; P: 0.6304 ; R: 0.7324 ; F1: 0.6776 ; Acc: 0.863\n",
      "           Label 2 loss: 27.0125 ; P: 0.5082 ; R: 0.5479 ; F1: 0.5273 ; Acc: 0.5089\n",
      "2023-01-29 12:53:08.227644\n",
      "2023-01-29 12:53:08.227644\n",
      "EPOCH 61\n",
      "TAG_LOSS_WEIGHT:  0.23391993526648516\n",
      "CLS_LOSS_WEIGHT:  0.7660800647335149\n",
      "tp:  644\n",
      "fn:  678\n",
      "tn:  639\n",
      "fp:  683\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1283\n",
      "tp:  282\n",
      "fn:  282\n",
      "tn:  294\n",
      "fp:  270\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  576\n",
      "EPOCH 61\n",
      "   TRAIN | Label 1 loss: 18.6307 ; P: 0.6999 ; R: 0.5859 ; F1: 0.6379 ; Acc: 0.8774\n",
      "           Label 2 loss: 62.5479 ; P: 0.4853 ; R: 0.4871 ; F1: 0.4862 ; Acc: 0.4852\n",
      "    TEST | Label 1 loss: 8.7716 ; P: 0.6289 ; R: 0.7331 ; F1: 0.677 ; Acc: 0.8625\n",
      "           Label 2 loss: 27.0114 ; P: 0.5109 ; R: 0.5 ; F1: 0.5054 ; Acc: 0.5106\n",
      "2023-01-29 12:53:39.224921\n",
      "2023-01-29 12:53:39.225921\n",
      "EPOCH 62\n",
      "TAG_LOSS_WEIGHT:  0.23167248138566984\n",
      "CLS_LOSS_WEIGHT:  0.7683275186143301\n",
      "tp:  646\n",
      "fn:  676\n",
      "tn:  658\n",
      "fp:  664\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1304\n",
      "tp:  290\n",
      "fn:  274\n",
      "tn:  279\n",
      "fp:  285\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  569\n",
      "EPOCH 62\n",
      "   TRAIN | Label 1 loss: 18.7273 ; P: 0.6903 ; R: 0.5873 ; F1: 0.6347 ; Acc: 0.8754\n",
      "           Label 2 loss: 62.4609 ; P: 0.4931 ; R: 0.4887 ; F1: 0.4909 ; Acc: 0.4932\n",
      "    TEST | Label 1 loss: 8.7547 ; P: 0.6268 ; R: 0.735 ; F1: 0.6766 ; Acc: 0.8619\n",
      "           Label 2 loss: 27.0127 ; P: 0.5043 ; R: 0.5142 ; F1: 0.5092 ; Acc: 0.5044\n",
      "2023-01-29 12:54:10.190143\n",
      "2023-01-29 12:54:10.190143\n",
      "EPOCH 63\n",
      "TAG_LOSS_WEIGHT:  0.23401731637355908\n",
      "CLS_LOSS_WEIGHT:  0.7659826836264408\n",
      "tp:  681\n",
      "fn:  641\n",
      "tn:  696\n",
      "fp:  626\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1377\n",
      "tp:  310\n",
      "fn:  254\n",
      "tn:  257\n",
      "fp:  307\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  567\n",
      "EPOCH 63\n",
      "   TRAIN | Label 1 loss: 18.7198 ; P: 0.6928 ; R: 0.5868 ; F1: 0.6354 ; Acc: 0.8759\n",
      "           Label 2 loss: 62.1992 ; P: 0.521 ; R: 0.5151 ; F1: 0.5181 ; Acc: 0.5208\n",
      "    TEST | Label 1 loss: 8.7731 ; P: 0.6268 ; R: 0.7426 ; F1: 0.6798 ; Acc: 0.8625\n",
      "           Label 2 loss: 27.0102 ; P: 0.5024 ; R: 0.5496 ; F1: 0.525 ; Acc: 0.5027\n",
      "2023-01-29 12:54:41.467929\n",
      "2023-01-29 12:54:41.467929\n",
      "EPOCH 64\n",
      "TAG_LOSS_WEIGHT:  0.23538169463492742\n",
      "CLS_LOSS_WEIGHT:  0.7646183053650727\n",
      "tp:  685\n",
      "fn:  637\n",
      "tn:  653\n",
      "fp:  669\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1338\n",
      "tp:  303\n",
      "fn:  261\n",
      "tn:  270\n",
      "fp:  294\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  573\n",
      "EPOCH 64\n",
      "   TRAIN | Label 1 loss: 18.6675 ; P: 0.6962 ; R: 0.5859 ; F1: 0.6363 ; Acc: 0.8766\n",
      "           Label 2 loss: 62.3629 ; P: 0.5059 ; R: 0.5182 ; F1: 0.512 ; Acc: 0.5061\n",
      "    TEST | Label 1 loss: 8.7401 ; P: 0.6293 ; R: 0.7324 ; F1: 0.677 ; Acc: 0.8627\n",
      "           Label 2 loss: 27.0102 ; P: 0.5075 ; R: 0.5372 ; F1: 0.522 ; Acc: 0.508\n",
      "2023-01-29 12:55:12.261542\n",
      "2023-01-29 12:55:12.261542\n",
      "EPOCH 65\n",
      "TAG_LOSS_WEIGHT:  0.23343413957154246\n",
      "CLS_LOSS_WEIGHT:  0.7665658604284576\n",
      "tp:  627\n",
      "fn:  695\n",
      "tn:  714\n",
      "fp:  608\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1341\n",
      "tp:  276\n",
      "fn:  288\n",
      "tn:  290\n",
      "fp:  274\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  566\n",
      "EPOCH 65\n",
      "   TRAIN | Label 1 loss: 18.7153 ; P: 0.6884 ; R: 0.5862 ; F1: 0.6332 ; Acc: 0.8749\n",
      "           Label 2 loss: 62.3706 ; P: 0.5077 ; R: 0.4743 ; F1: 0.4904 ; Acc: 0.5072\n",
      "    TEST | Label 1 loss: 8.6859 ; P: 0.6351 ; R: 0.7211 ; F1: 0.6754 ; Acc: 0.8638\n",
      "           Label 2 loss: 27.0102 ; P: 0.5018 ; R: 0.4894 ; F1: 0.4955 ; Acc: 0.5018\n",
      "2023-01-29 12:55:43.358859\n",
      "2023-01-29 12:55:43.359848\n",
      "EPOCH 66\n",
      "TAG_LOSS_WEIGHT:  0.23430631366515753\n",
      "CLS_LOSS_WEIGHT:  0.7656936863348425\n",
      "tp:  676\n",
      "fn:  646\n",
      "tn:  666\n",
      "fp:  656\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1342\n",
      "tp:  308\n",
      "fn:  256\n",
      "tn:  265\n",
      "fp:  299\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  573\n",
      "EPOCH 66\n",
      "   TRAIN | Label 1 loss: 18.4865 ; P: 0.6979 ; R: 0.5904 ; F1: 0.6397 ; Acc: 0.8775\n",
      "           Label 2 loss: 62.403 ; P: 0.5075 ; R: 0.5113 ; F1: 0.5094 ; Acc: 0.5076\n",
      "    TEST | Label 1 loss: 8.6864 ; P: 0.6356 ; R: 0.7293 ; F1: 0.6792 ; Acc: 0.8647\n",
      "           Label 2 loss: 27.0087 ; P: 0.5074 ; R: 0.5461 ; F1: 0.526 ; Acc: 0.508\n",
      "2023-01-29 12:56:14.244185\n",
      "2023-01-29 12:56:14.244185\n",
      "EPOCH 67\n",
      "TAG_LOSS_WEIGHT:  0.22973770368190446\n",
      "CLS_LOSS_WEIGHT:  0.7702622963180955\n",
      "tp:  711\n",
      "fn:  611\n",
      "tn:  642\n",
      "fp:  680\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1353\n",
      "tp:  321\n",
      "fn:  243\n",
      "tn:  252\n",
      "fp:  312\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  573\n",
      "EPOCH 67\n",
      "   TRAIN | Label 1 loss: 18.3901 ; P: 0.7011 ; R: 0.5904 ; F1: 0.641 ; Acc: 0.8782\n",
      "           Label 2 loss: 62.4146 ; P: 0.5111 ; R: 0.5378 ; F1: 0.5241 ; Acc: 0.5117\n",
      "    TEST | Label 1 loss: 8.6793 ; P: 0.638 ; R: 0.7236 ; F1: 0.6781 ; Acc: 0.865\n",
      "           Label 2 loss: 27.0085 ; P: 0.5071 ; R: 0.5691 ; F1: 0.5363 ; Acc: 0.508\n",
      "2023-01-29 12:56:44.995533\n",
      "2023-01-29 12:56:44.995533\n",
      "EPOCH 68\n",
      "TAG_LOSS_WEIGHT:  0.22782716280253912\n",
      "CLS_LOSS_WEIGHT:  0.7721728371974609\n",
      "tp:  686\n",
      "fn:  636\n",
      "tn:  634\n",
      "fp:  688\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1320\n",
      "tp:  320\n",
      "fn:  244\n",
      "tn:  252\n",
      "fp:  312\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  572\n",
      "EPOCH 68\n",
      "   TRAIN | Label 1 loss: 18.5665 ; P: 0.6975 ; R: 0.5863 ; F1: 0.6371 ; Acc: 0.8769\n",
      "           Label 2 loss: 62.3987 ; P: 0.4993 ; R: 0.5189 ; F1: 0.5089 ; Acc: 0.4992\n",
      "    TEST | Label 1 loss: 8.7337 ; P: 0.6333 ; R: 0.7438 ; F1: 0.6841 ; Acc: 0.865\n",
      "           Label 2 loss: 27.0082 ; P: 0.5063 ; R: 0.5674 ; F1: 0.5351 ; Acc: 0.5071\n",
      "2023-01-29 12:57:15.323324\n",
      "2023-01-29 12:57:15.324324\n",
      "EPOCH 69\n",
      "TAG_LOSS_WEIGHT:  0.23129403572514742\n",
      "CLS_LOSS_WEIGHT:  0.7687059642748526\n",
      "tp:  641\n",
      "fn:  681\n",
      "tn:  642\n",
      "fp:  680\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1283\n",
      "tp:  235\n",
      "fn:  329\n",
      "tn:  335\n",
      "fp:  229\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  570\n",
      "EPOCH 69\n",
      "   TRAIN | Label 1 loss: 18.593 ; P: 0.6927 ; R: 0.5925 ; F1: 0.6387 ; Acc: 0.8765\n",
      "           Label 2 loss: 62.5108 ; P: 0.4852 ; R: 0.4849 ; F1: 0.4851 ; Acc: 0.4852\n",
      "    TEST | Label 1 loss: 8.625 ; P: 0.6426 ; R: 0.7211 ; F1: 0.6796 ; Acc: 0.8664\n",
      "           Label 2 loss: 27.0071 ; P: 0.5065 ; R: 0.4167 ; F1: 0.4572 ; Acc: 0.5053\n",
      "2023-01-29 12:57:46.040215\n",
      "2023-01-29 12:57:46.040215\n",
      "EPOCH 70\n",
      "TAG_LOSS_WEIGHT:  0.23116298406407693\n",
      "CLS_LOSS_WEIGHT:  0.7688370159359231\n",
      "tp:  561\n",
      "fn:  761\n",
      "tn:  749\n",
      "fp:  573\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1310\n",
      "tp:  267\n",
      "fn:  297\n",
      "tn:  298\n",
      "fp:  266\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  565\n",
      "EPOCH 70\n",
      "   TRAIN | Label 1 loss: 18.5679 ; P: 0.6883 ; R: 0.5856 ; F1: 0.6328 ; Acc: 0.8748\n",
      "           Label 2 loss: 62.4444 ; P: 0.4947 ; R: 0.4244 ; F1: 0.4568 ; Acc: 0.4955\n",
      "    TEST | Label 1 loss: 8.6594 ; P: 0.6371 ; R: 0.7306 ; F1: 0.6806 ; Acc: 0.8653\n",
      "           Label 2 loss: 27.0053 ; P: 0.5009 ; R: 0.4734 ; F1: 0.4868 ; Acc: 0.5009\n",
      "2023-01-29 12:58:16.655987\n",
      "2023-01-29 12:58:16.656988\n",
      "EPOCH 71\n",
      "TAG_LOSS_WEIGHT:  0.2310605933117437\n",
      "CLS_LOSS_WEIGHT:  0.7689394066882563\n",
      "tp:  630\n",
      "fn:  692\n",
      "tn:  717\n",
      "fp:  605\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1347\n",
      "tp:  343\n",
      "fn:  221\n",
      "tn:  232\n",
      "fp:  332\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  575\n",
      "EPOCH 71\n",
      "   TRAIN | Label 1 loss: 18.4277 ; P: 0.6998 ; R: 0.5921 ; F1: 0.6414 ; Acc: 0.878\n",
      "           Label 2 loss: 62.3754 ; P: 0.5101 ; R: 0.4766 ; F1: 0.4928 ; Acc: 0.5095\n",
      "    TEST | Label 1 loss: 8.6088 ; P: 0.6421 ; R: 0.7217 ; F1: 0.6796 ; Acc: 0.8663\n",
      "           Label 2 loss: 27.0042 ; P: 0.5081 ; R: 0.6082 ; F1: 0.5537 ; Acc: 0.5098\n",
      "2023-01-29 12:58:47.924736\n",
      "2023-01-29 12:58:47.925735\n",
      "EPOCH 72\n",
      "TAG_LOSS_WEIGHT:  0.22876821452764987\n",
      "CLS_LOSS_WEIGHT:  0.7712317854723502\n",
      "tp:  671\n",
      "fn:  651\n",
      "tn:  657\n",
      "fp:  665\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1328\n",
      "tp:  375\n",
      "fn:  189\n",
      "tn:  186\n",
      "fp:  378\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  561\n",
      "EPOCH 72\n",
      "   TRAIN | Label 1 loss: 18.2711 ; P: 0.6968 ; R: 0.5991 ; F1: 0.6442 ; Acc: 0.8781\n",
      "           Label 2 loss: 62.4293 ; P: 0.5022 ; R: 0.5076 ; F1: 0.5049 ; Acc: 0.5023\n",
      "    TEST | Label 1 loss: 8.6144 ; P: 0.6389 ; R: 0.7331 ; F1: 0.6828 ; Acc: 0.8661\n",
      "           Label 2 loss: 27.0033 ; P: 0.498 ; R: 0.6649 ; F1: 0.5695 ; Acc: 0.4973\n",
      "2023-01-29 12:59:18.104741\n",
      "2023-01-29 12:59:18.104741\n",
      "EPOCH 73\n",
      "TAG_LOSS_WEIGHT:  0.2254688421686428\n",
      "CLS_LOSS_WEIGHT:  0.7745311578313572\n",
      "tp:  703\n",
      "fn:  619\n",
      "tn:  629\n",
      "fp:  693\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1332\n",
      "tp:  331\n",
      "fn:  233\n",
      "tn:  249\n",
      "fp:  315\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  580\n",
      "EPOCH 73\n",
      "   TRAIN | Label 1 loss: 18.2639 ; P: 0.7009 ; R: 0.5917 ; F1: 0.6417 ; Acc: 0.8783\n",
      "           Label 2 loss: 62.4485 ; P: 0.5036 ; R: 0.5318 ; F1: 0.5173 ; Acc: 0.5038\n",
      "    TEST | Label 1 loss: 8.6553 ; P: 0.6296 ; R: 0.7495 ; F1: 0.6844 ; Acc: 0.8642\n",
      "           Label 2 loss: 27.0007 ; P: 0.5124 ; R: 0.5869 ; F1: 0.5471 ; Acc: 0.5142\n",
      "2023-01-29 12:59:48.973741\n",
      "2023-01-29 12:59:48.975740\n",
      "EPOCH 74\n",
      "TAG_LOSS_WEIGHT:  0.22522387695915125\n",
      "CLS_LOSS_WEIGHT:  0.7747761230408488\n",
      "tp:  571\n",
      "fn:  751\n",
      "tn:  711\n",
      "fp:  611\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1282\n",
      "tp:  398\n",
      "fn:  166\n",
      "tn:  172\n",
      "fp:  392\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  570\n",
      "EPOCH 74\n",
      "   TRAIN | Label 1 loss: 18.1473 ; P: 0.7012 ; R: 0.5961 ; F1: 0.6444 ; Acc: 0.8788\n",
      "           Label 2 loss: 62.6494 ; P: 0.4831 ; R: 0.4319 ; F1: 0.4561 ; Acc: 0.4849\n",
      "    TEST | Label 1 loss: 8.58 ; P: 0.6284 ; R: 0.7521 ; F1: 0.6847 ; Acc: 0.8639\n",
      "           Label 2 loss: 27.0025 ; P: 0.5038 ; R: 0.7057 ; F1: 0.5879 ; Acc: 0.5053\n",
      "2023-01-29 13:00:19.814910\n",
      "2023-01-29 13:00:19.814910\n",
      "EPOCH 75\n",
      "TAG_LOSS_WEIGHT:  0.22188548979735154\n",
      "CLS_LOSS_WEIGHT:  0.7781145102026484\n",
      "tp:  713\n",
      "fn:  609\n",
      "tn:  642\n",
      "fp:  680\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1355\n",
      "tp:  423\n",
      "fn:  141\n",
      "tn:  149\n",
      "fp:  415\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  572\n",
      "EPOCH 75\n",
      "   TRAIN | Label 1 loss: 18.0428 ; P: 0.7046 ; R: 0.6002 ; F1: 0.6482 ; Acc: 0.88\n",
      "           Label 2 loss: 62.2881 ; P: 0.5118 ; R: 0.5393 ; F1: 0.5252 ; Acc: 0.5125\n",
      "    TEST | Label 1 loss: 8.6371 ; P: 0.6249 ; R: 0.7704 ; F1: 0.6901 ; Acc: 0.864\n",
      "           Label 2 loss: 27.0016 ; P: 0.5048 ; R: 0.75 ; F1: 0.6034 ; Acc: 0.5071\n",
      "2023-01-29 13:00:50.415631\n",
      "2023-01-29 13:00:50.415631\n",
      "EPOCH 76\n",
      "TAG_LOSS_WEIGHT:  0.22188847044254875\n",
      "CLS_LOSS_WEIGHT:  0.7781115295574513\n",
      "tp:  646\n",
      "fn:  676\n",
      "tn:  694\n",
      "fp:  628\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1340\n",
      "tp:  271\n",
      "fn:  293\n",
      "tn:  304\n",
      "fp:  260\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  575\n",
      "EPOCH 76\n",
      "   TRAIN | Label 1 loss: 17.8908 ; P: 0.6997 ; R: 0.6013 ; F1: 0.6468 ; Acc: 0.879\n",
      "           Label 2 loss: 62.3114 ; P: 0.5071 ; R: 0.4887 ; F1: 0.4977 ; Acc: 0.5068\n",
      "    TEST | Label 1 loss: 8.5226 ; P: 0.627 ; R: 0.7432 ; F1: 0.6802 ; Acc: 0.8627\n",
      "           Label 2 loss: 26.9974 ; P: 0.5104 ; R: 0.4805 ; F1: 0.495 ; Acc: 0.5098\n",
      "2023-01-29 13:01:21.271997\n",
      "2023-01-29 13:01:21.271997\n",
      "EPOCH 77\n",
      "TAG_LOSS_WEIGHT:  0.21885298091610061\n",
      "CLS_LOSS_WEIGHT:  0.7811470190838993\n",
      "tp:  683\n",
      "fn:  639\n",
      "tn:  647\n",
      "fp:  675\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1330\n",
      "tp:  298\n",
      "fn:  266\n",
      "tn:  278\n",
      "fp:  286\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  576\n",
      "EPOCH 77\n",
      "   TRAIN | Label 1 loss: 17.9746 ; P: 0.6985 ; R: 0.6026 ; F1: 0.647 ; Acc: 0.8788\n",
      "           Label 2 loss: 62.4019 ; P: 0.5029 ; R: 0.5166 ; F1: 0.5097 ; Acc: 0.503\n",
      "    TEST | Label 1 loss: 8.5523 ; P: 0.6276 ; R: 0.759 ; F1: 0.6871 ; Acc: 0.8642\n",
      "           Label 2 loss: 26.9963 ; P: 0.5103 ; R: 0.5284 ; F1: 0.5192 ; Acc: 0.5106\n",
      "2023-01-29 13:01:52.237479\n",
      "2023-01-29 13:01:52.237479\n",
      "EPOCH 78\n",
      "TAG_LOSS_WEIGHT:  0.2199565187597975\n",
      "CLS_LOSS_WEIGHT:  0.7800434812402025\n",
      "tp:  610\n",
      "fn:  712\n",
      "tn:  749\n",
      "fp:  573\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1359\n",
      "tp:  269\n",
      "fn:  295\n",
      "tn:  306\n",
      "fp:  258\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  575\n",
      "EPOCH 78\n",
      "   TRAIN | Label 1 loss: 17.9056 ; P: 0.6972 ; R: 0.5999 ; F1: 0.6449 ; Acc: 0.8783\n",
      "           Label 2 loss: 62.257 ; P: 0.5156 ; R: 0.4614 ; F1: 0.487 ; Acc: 0.514\n",
      "    TEST | Label 1 loss: 8.5723 ; P: 0.6249 ; R: 0.7672 ; F1: 0.6888 ; Acc: 0.8638\n",
      "           Label 2 loss: 26.9947 ; P: 0.5104 ; R: 0.477 ; F1: 0.4931 ; Acc: 0.5098\n",
      "2023-01-29 13:02:22.974171\n",
      "2023-01-29 13:02:22.974171\n",
      "EPOCH 79\n",
      "TAG_LOSS_WEIGHT:  0.21943489588804024\n",
      "CLS_LOSS_WEIGHT:  0.7805651041119597\n",
      "tp:  742\n",
      "fn:  580\n",
      "tn:  582\n",
      "fp:  740\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1324\n",
      "tp:  489\n",
      "fn:  75\n",
      "tn:  89\n",
      "fp:  475\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  578\n",
      "EPOCH 79\n",
      "   TRAIN | Label 1 loss: 17.9281 ; P: 0.7027 ; R: 0.601 ; F1: 0.6479 ; Acc: 0.8796\n",
      "           Label 2 loss: 62.4158 ; P: 0.5007 ; R: 0.5613 ; F1: 0.5292 ; Acc: 0.5008\n",
      "    TEST | Label 1 loss: 8.4917 ; P: 0.6298 ; R: 0.7565 ; F1: 0.6874 ; Acc: 0.8648\n",
      "           Label 2 loss: 26.9967 ; P: 0.5073 ; R: 0.867 ; F1: 0.6401 ; Acc: 0.5124\n",
      "2023-01-29 13:02:53.400080\n",
      "2023-01-29 13:02:53.401082\n",
      "EPOCH 80\n",
      "TAG_LOSS_WEIGHT:  0.21899273437146807\n",
      "CLS_LOSS_WEIGHT:  0.781007265628532\n",
      "tp:  678\n",
      "fn:  644\n",
      "tn:  664\n",
      "fp:  658\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1342\n",
      "tp:  319\n",
      "fn:  245\n",
      "tn:  273\n",
      "fp:  291\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  592\n",
      "EPOCH 80\n",
      "   TRAIN | Label 1 loss: 17.875 ; P: 0.6967 ; R: 0.5988 ; F1: 0.644 ; Acc: 0.878\n",
      "           Label 2 loss: 62.3082 ; P: 0.5075 ; R: 0.5129 ; F1: 0.5102 ; Acc: 0.5076\n",
      "    TEST | Label 1 loss: 8.5402 ; P: 0.6274 ; R: 0.7679 ; F1: 0.6906 ; Acc: 0.8648\n",
      "           Label 2 loss: 26.9898 ; P: 0.523 ; R: 0.5656 ; F1: 0.5434 ; Acc: 0.5248\n",
      "2023-01-29 13:03:24.230823\n",
      "2023-01-29 13:03:26.067025\n",
      "EPOCH 81\n",
      "TAG_LOSS_WEIGHT:  0.21856858477433244\n",
      "CLS_LOSS_WEIGHT:  0.7814314152256677\n",
      "tp:  608\n",
      "fn:  714\n",
      "tn:  720\n",
      "fp:  602\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1328\n",
      "tp:  480\n",
      "fn:  84\n",
      "tn:  101\n",
      "fp:  463\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  581\n",
      "EPOCH 81\n",
      "   TRAIN | Label 1 loss: 17.8962 ; P: 0.6986 ; R: 0.5961 ; F1: 0.6433 ; Acc: 0.8782\n",
      "           Label 2 loss: 62.4553 ; P: 0.5025 ; R: 0.4599 ; F1: 0.4803 ; Acc: 0.5023\n",
      "    TEST | Label 1 loss: 8.4613 ; P: 0.6294 ; R: 0.7552 ; F1: 0.6866 ; Acc: 0.8645\n",
      "           Label 2 loss: 26.9916 ; P: 0.509 ; R: 0.8511 ; F1: 0.637 ; Acc: 0.5151\n",
      "2023-01-29 13:03:58.501893\n",
      "2023-01-29 13:03:58.502893\n",
      "EPOCH 82\n",
      "TAG_LOSS_WEIGHT:  0.21816824591169695\n",
      "CLS_LOSS_WEIGHT:  0.7818317540883031\n",
      "tp:  649\n",
      "fn:  673\n",
      "tn:  674\n",
      "fp:  648\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1323\n",
      "tp:  255\n",
      "fn:  309\n",
      "tn:  333\n",
      "fp:  231\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  588\n",
      "EPOCH 82\n",
      "   TRAIN | Label 1 loss: 17.6684 ; P: 0.6988 ; R: 0.6065 ; F1: 0.6494 ; Acc: 0.8793\n",
      "           Label 2 loss: 62.3995 ; P: 0.5004 ; R: 0.4909 ; F1: 0.4956 ; Acc: 0.5004\n",
      "    TEST | Label 1 loss: 8.4834 ; P: 0.6287 ; R: 0.7679 ; F1: 0.6913 ; Acc: 0.8653\n",
      "           Label 2 loss: 26.9872 ; P: 0.5247 ; R: 0.4521 ; F1: 0.4857 ; Acc: 0.5213\n",
      "2023-01-29 13:04:30.468411\n",
      "2023-01-29 13:04:30.469411\n",
      "EPOCH 83\n",
      "TAG_LOSS_WEIGHT:  0.21413023339359596\n",
      "CLS_LOSS_WEIGHT:  0.7858697666064041\n",
      "tp:  684\n",
      "fn:  638\n",
      "tn:  663\n",
      "fp:  659\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1347\n",
      "tp:  509\n",
      "fn:  55\n",
      "tn:  68\n",
      "fp:  496\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  577\n",
      "EPOCH 83\n",
      "   TRAIN | Label 1 loss: 17.6861 ; P: 0.7005 ; R: 0.6114 ; F1: 0.6529 ; Acc: 0.8802\n",
      "           Label 2 loss: 62.3008 ; P: 0.5093 ; R: 0.5174 ; F1: 0.5133 ; Acc: 0.5095\n",
      "    TEST | Label 1 loss: 8.2538 ; P: 0.6568 ; R: 0.6996 ; F1: 0.6775 ; Acc: 0.8691\n",
      "           Label 2 loss: 26.9901 ; P: 0.5065 ; R: 0.9025 ; F1: 0.6488 ; Acc: 0.5115\n",
      "2023-01-29 13:05:01.906699\n",
      "2023-01-29 13:05:01.907699\n",
      "EPOCH 84\n",
      "TAG_LOSS_WEIGHT:  0.21500127678760372\n",
      "CLS_LOSS_WEIGHT:  0.7849987232123963\n",
      "tp:  811\n",
      "fn:  511\n",
      "tn:  523\n",
      "fp:  799\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1334\n",
      "tp:  363\n",
      "fn:  201\n",
      "tn:  237\n",
      "fp:  327\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  600\n",
      "EPOCH 84\n",
      "   TRAIN | Label 1 loss: 17.7447 ; P: 0.7031 ; R: 0.6115 ; F1: 0.6541 ; Acc: 0.8809\n",
      "           Label 2 loss: 62.2858 ; P: 0.5037 ; R: 0.6135 ; F1: 0.5532 ; Acc: 0.5045\n",
      "    TEST | Label 1 loss: 8.3382 ; P: 0.646 ; R: 0.7261 ; F1: 0.6837 ; Acc: 0.868\n",
      "           Label 2 loss: 26.9801 ; P: 0.5261 ; R: 0.6436 ; F1: 0.5789 ; Acc: 0.5319\n",
      "2023-01-29 13:05:32.835755\n",
      "2023-01-29 13:05:34.568068\n",
      "EPOCH 85\n",
      "TAG_LOSS_WEIGHT:  0.2162015535160745\n",
      "CLS_LOSS_WEIGHT:  0.7837984464839256\n",
      "tp:  664\n",
      "fn:  658\n",
      "tn:  692\n",
      "fp:  630\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1356\n",
      "tp:  285\n",
      "fn:  279\n",
      "tn:  308\n",
      "fp:  256\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  593\n",
      "EPOCH 85\n",
      "   TRAIN | Label 1 loss: 17.6572 ; P: 0.7039 ; R: 0.6111 ; F1: 0.6542 ; Acc: 0.881\n",
      "           Label 2 loss: 62.3741 ; P: 0.5131 ; R: 0.5023 ; F1: 0.5076 ; Acc: 0.5129\n",
      "    TEST | Label 1 loss: 8.5043 ; P: 0.6283 ; R: 0.79 ; F1: 0.6999 ; Acc: 0.8669\n",
      "           Label 2 loss: 26.9769 ; P: 0.5268 ; R: 0.5053 ; F1: 0.5158 ; Acc: 0.5257\n",
      "2023-01-29 13:06:06.330044\n",
      "2023-01-29 13:06:06.331044\n",
      "EPOCH 86\n",
      "TAG_LOSS_WEIGHT:  0.21405385710898664\n",
      "CLS_LOSS_WEIGHT:  0.7859461428910134\n",
      "tp:  676\n",
      "fn:  646\n",
      "tn:  694\n",
      "fp:  628\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1370\n",
      "tp:  213\n",
      "fn:  351\n",
      "tn:  391\n",
      "fp:  173\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  604\n",
      "EPOCH 86\n",
      "   TRAIN | Label 1 loss: 17.5804 ; P: 0.7037 ; R: 0.6093 ; F1: 0.6531 ; Acc: 0.8808\n",
      "           Label 2 loss: 62.2555 ; P: 0.5184 ; R: 0.5113 ; F1: 0.5149 ; Acc: 0.5182\n",
      "    TEST | Label 1 loss: 8.4288 ; P: 0.6302 ; R: 0.79 ; F1: 0.7011 ; Acc: 0.8676\n",
      "           Label 2 loss: 26.9747 ; P: 0.5518 ; R: 0.3777 ; F1: 0.4484 ; Acc: 0.5355\n",
      "2023-01-29 13:06:38.022932\n",
      "2023-01-29 13:06:39.786449\n",
      "EPOCH 87\n",
      "TAG_LOSS_WEIGHT:  0.21322873342066143\n",
      "CLS_LOSS_WEIGHT:  0.7867712665793386\n",
      "tp:  614\n",
      "fn:  708\n",
      "tn:  746\n",
      "fp:  576\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1360\n",
      "tp:  400\n",
      "fn:  164\n",
      "tn:  200\n",
      "fp:  364\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  600\n",
      "EPOCH 87\n",
      "   TRAIN | Label 1 loss: 17.4067 ; P: 0.7023 ; R: 0.6171 ; F1: 0.657 ; Acc: 0.8813\n",
      "           Label 2 loss: 62.2704 ; P: 0.516 ; R: 0.4644 ; F1: 0.4889 ; Acc: 0.5144\n",
      "    TEST | Label 1 loss: 8.2502 ; P: 0.6458 ; R: 0.7508 ; F1: 0.6944 ; Acc: 0.8701\n",
      "           Label 2 loss: 26.9704 ; P: 0.5236 ; R: 0.7092 ; F1: 0.6024 ; Acc: 0.5319\n",
      "2023-01-29 13:07:11.847668\n",
      "2023-01-29 13:07:11.849662\n",
      "EPOCH 88\n",
      "TAG_LOSS_WEIGHT:  0.2098367640418343\n",
      "CLS_LOSS_WEIGHT:  0.7901632359581657\n",
      "tp:  729\n",
      "fn:  593\n",
      "tn:  636\n",
      "fp:  686\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1365\n",
      "tp:  361\n",
      "fn:  203\n",
      "tn:  240\n",
      "fp:  324\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  601\n",
      "EPOCH 88\n",
      "   TRAIN | Label 1 loss: 17.2837 ; P: 0.7048 ; R: 0.6251 ; F1: 0.6626 ; Acc: 0.8827\n",
      "           Label 2 loss: 62.2027 ; P: 0.5152 ; R: 0.5514 ; F1: 0.5327 ; Acc: 0.5163\n",
      "    TEST | Label 1 loss: 8.4088 ; P: 0.6292 ; R: 0.8027 ; F1: 0.7054 ; Acc: 0.8683\n",
      "           Label 2 loss: 26.9658 ; P: 0.527 ; R: 0.6401 ; F1: 0.5781 ; Acc: 0.5328\n",
      "2023-01-29 13:07:43.555184\n",
      "2023-01-29 13:07:43.555184\n",
      "EPOCH 89\n",
      "TAG_LOSS_WEIGHT:  0.20785286123367938\n",
      "CLS_LOSS_WEIGHT:  0.7921471387663207\n",
      "tp:  725\n",
      "fn:  597\n",
      "tn:  579\n",
      "fp:  743\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1304\n",
      "tp:  361\n",
      "fn:  203\n",
      "tn:  245\n",
      "fp:  319\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  606\n",
      "EPOCH 89\n",
      "   TRAIN | Label 1 loss: 17.1628 ; P: 0.6992 ; R: 0.6203 ; F1: 0.6574 ; Acc: 0.8809\n",
      "           Label 2 loss: 62.4385 ; P: 0.4939 ; R: 0.5484 ; F1: 0.5197 ; Acc: 0.4932\n",
      "    TEST | Label 1 loss: 8.4437 ; P: 0.6273 ; R: 0.8197 ; F1: 0.7107 ; Acc: 0.8689\n",
      "           Label 2 loss: 26.9622 ; P: 0.5309 ; R: 0.6401 ; F1: 0.5804 ; Acc: 0.5372\n",
      "2023-01-29 13:08:14.734994\n",
      "2023-01-29 13:08:16.990203\n",
      "EPOCH 90\n",
      "TAG_LOSS_WEIGHT:  0.20431779359940322\n",
      "CLS_LOSS_WEIGHT:  0.7956822064005968\n",
      "tp:  572\n",
      "fn:  750\n",
      "tn:  740\n",
      "fp:  582\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1312\n",
      "tp:  548\n",
      "fn:  16\n",
      "tn:  17\n",
      "fp:  547\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  565\n",
      "EPOCH 90\n",
      "   TRAIN | Label 1 loss: 17.1998 ; P: 0.7029 ; R: 0.6278 ; F1: 0.6632 ; Acc: 0.8825\n",
      "           Label 2 loss: 62.4077 ; P: 0.4957 ; R: 0.4327 ; F1: 0.462 ; Acc: 0.4962\n",
      "    TEST | Label 1 loss: 8.1737 ; P: 0.6427 ; R: 0.7793 ; F1: 0.7044 ; Acc: 0.8715\n",
      "           Label 2 loss: 26.9759 ; P: 0.5005 ; R: 0.9716 ; F1: 0.6606 ; Acc: 0.5009\n",
      "2023-01-29 13:08:49.267890\n",
      "2023-01-29 13:08:49.267890\n",
      "EPOCH 91\n",
      "TAG_LOSS_WEIGHT:  0.2051797685658503\n",
      "CLS_LOSS_WEIGHT:  0.7948202314341496\n",
      "tp:  732\n",
      "fn:  590\n",
      "tn:  568\n",
      "fp:  754\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1300\n",
      "tp:  395\n",
      "fn:  169\n",
      "tn:  229\n",
      "fp:  335\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  624\n",
      "EPOCH 91\n",
      "   TRAIN | Label 1 loss: 16.8514 ; P: 0.71 ; R: 0.6224 ; F1: 0.6633 ; Acc: 0.8836\n",
      "           Label 2 loss: 62.3663 ; P: 0.4926 ; R: 0.5537 ; F1: 0.5214 ; Acc: 0.4917\n",
      "    TEST | Label 1 loss: 8.3194 ; P: 0.6327 ; R: 0.814 ; F1: 0.712 ; Acc: 0.8706\n",
      "           Label 2 loss: 26.9607 ; P: 0.5411 ; R: 0.7004 ; F1: 0.6105 ; Acc: 0.5532\n",
      "2023-01-29 13:09:20.709574\n",
      "2023-01-29 13:09:22.474526\n",
      "EPOCH 92\n",
      "TAG_LOSS_WEIGHT:  0.19879697785086148\n",
      "CLS_LOSS_WEIGHT:  0.8012030221491385\n",
      "tp:  747\n",
      "fn:  575\n",
      "tn:  622\n",
      "fp:  700\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1369\n",
      "tp:  343\n",
      "fn:  221\n",
      "tn:  277\n",
      "fp:  287\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  620\n",
      "EPOCH 92\n",
      "   TRAIN | Label 1 loss: 17.0917 ; P: 0.7105 ; R: 0.6265 ; F1: 0.6659 ; Acc: 0.8842\n",
      "           Label 2 loss: 62.284 ; P: 0.5162 ; R: 0.5651 ; F1: 0.5395 ; Acc: 0.5178\n",
      "    TEST | Label 1 loss: 8.1613 ; P: 0.6415 ; R: 0.797 ; F1: 0.7109 ; Acc: 0.8726\n",
      "           Label 2 loss: 26.9541 ; P: 0.5444 ; R: 0.6082 ; F1: 0.5745 ; Acc: 0.5496\n",
      "2023-01-29 13:09:54.586080\n",
      "2023-01-29 13:09:54.586080\n",
      "EPOCH 93\n",
      "TAG_LOSS_WEIGHT:  0.20377411130553783\n",
      "CLS_LOSS_WEIGHT:  0.7962258886944622\n",
      "tp:  624\n",
      "fn:  698\n",
      "tn:  717\n",
      "fp:  605\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1341\n",
      "tp:  448\n",
      "fn:  116\n",
      "tn:  151\n",
      "fp:  413\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  599\n",
      "EPOCH 93\n",
      "   TRAIN | Label 1 loss: 16.7105 ; P: 0.7167 ; R: 0.6419 ; F1: 0.6772 ; Acc: 0.8873\n",
      "           Label 2 loss: 62.317 ; P: 0.5077 ; R: 0.472 ; F1: 0.4892 ; Acc: 0.5072\n",
      "    TEST | Label 1 loss: 8.0426 ; P: 0.6458 ; R: 0.79 ; F1: 0.7107 ; Acc: 0.8736\n",
      "           Label 2 loss: 26.9504 ; P: 0.5203 ; R: 0.7943 ; F1: 0.6288 ; Acc: 0.531\n",
      "2023-01-29 13:10:26.224424\n",
      "2023-01-29 13:10:26.225427\n",
      "EPOCH 94\n",
      "TAG_LOSS_WEIGHT:  0.19638526103309964\n",
      "CLS_LOSS_WEIGHT:  0.8036147389669003\n",
      "tp:  676\n",
      "fn:  646\n",
      "tn:  670\n",
      "fp:  652\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1346\n",
      "tp:  419\n",
      "fn:  145\n",
      "tn:  200\n",
      "fp:  364\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  619\n",
      "EPOCH 94\n",
      "   TRAIN | Label 1 loss: 16.7221 ; P: 0.7118 ; R: 0.6406 ; F1: 0.6743 ; Acc: 0.886\n",
      "           Label 2 loss: 62.2275 ; P: 0.509 ; R: 0.5113 ; F1: 0.5102 ; Acc: 0.5091\n",
      "    TEST | Label 1 loss: 7.9293 ; P: 0.6635 ; R: 0.7584 ; F1: 0.7078 ; Acc: 0.877\n",
      "           Label 2 loss: 26.9334 ; P: 0.5351 ; R: 0.7429 ; F1: 0.6221 ; Acc: 0.5488\n",
      "2023-01-29 13:10:57.376300\n",
      "2023-01-29 13:10:57.377294\n",
      "EPOCH 95\n",
      "TAG_LOSS_WEIGHT:  0.19705880634033643\n",
      "CLS_LOSS_WEIGHT:  0.8029411936596637\n",
      "tp:  726\n",
      "fn:  596\n",
      "tn:  628\n",
      "fp:  694\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1354\n",
      "tp:  518\n",
      "fn:  46\n",
      "tn:  66\n",
      "fp:  498\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  584\n",
      "EPOCH 95\n",
      "   TRAIN | Label 1 loss: 16.9289 ; P: 0.7059 ; R: 0.6324 ; F1: 0.6671 ; Acc: 0.8837\n",
      "           Label 2 loss: 62.2438 ; P: 0.5113 ; R: 0.5492 ; F1: 0.5295 ; Acc: 0.5121\n",
      "    TEST | Label 1 loss: 7.8569 ; P: 0.6786 ; R: 0.7223 ; F1: 0.6998 ; Acc: 0.8782\n",
      "           Label 2 loss: 26.942 ; P: 0.5098 ; R: 0.9184 ; F1: 0.6557 ; Acc: 0.5177\n",
      "2023-01-29 13:11:28.505071\n",
      "2023-01-29 13:11:28.507072\n",
      "EPOCH 96\n",
      "TAG_LOSS_WEIGHT:  0.2008932202127439\n",
      "CLS_LOSS_WEIGHT:  0.7991067797872561\n",
      "tp:  592\n",
      "fn:  730\n",
      "tn:  757\n",
      "fp:  565\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1349\n",
      "tp:  495\n",
      "fn:  69\n",
      "tn:  85\n",
      "fp:  479\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  580\n",
      "EPOCH 96\n",
      "   TRAIN | Label 1 loss: 16.5723 ; P: 0.7176 ; R: 0.6425 ; F1: 0.6779 ; Acc: 0.8875\n",
      "           Label 2 loss: 62.2369 ; P: 0.5117 ; R: 0.4478 ; F1: 0.4776 ; Acc: 0.5102\n",
      "    TEST | Label 1 loss: 8.0267 ; P: 0.6496 ; R: 0.809 ; F1: 0.7206 ; Acc: 0.8767\n",
      "           Label 2 loss: 26.9318 ; P: 0.5082 ; R: 0.8777 ; F1: 0.6437 ; Acc: 0.5142\n",
      "2023-01-29 13:11:59.456565\n",
      "2023-01-29 13:11:59.456565\n",
      "EPOCH 97\n",
      "TAG_LOSS_WEIGHT:  0.19417942226002827\n",
      "CLS_LOSS_WEIGHT:  0.8058205777399718\n",
      "tp:  713\n",
      "fn:  609\n",
      "tn:  646\n",
      "fp:  676\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1359\n",
      "tp:  362\n",
      "fn:  202\n",
      "tn:  275\n",
      "fp:  289\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  637\n",
      "EPOCH 97\n",
      "   TRAIN | Label 1 loss: 16.4663 ; P: 0.7137 ; R: 0.6436 ; F1: 0.6768 ; Acc: 0.8868\n",
      "           Label 2 loss: 62.1184 ; P: 0.5133 ; R: 0.5393 ; F1: 0.526 ; Acc: 0.514\n",
      "    TEST | Label 1 loss: 7.8881 ; P: 0.662 ; R: 0.7729 ; F1: 0.7132 ; Acc: 0.8778\n",
      "           Label 2 loss: 26.9157 ; P: 0.5561 ; R: 0.6418 ; F1: 0.5959 ; Acc: 0.5647\n",
      "2023-01-29 13:12:30.222212\n",
      "2023-01-29 13:12:31.882170\n",
      "EPOCH 98\n",
      "TAG_LOSS_WEIGHT:  0.192771631915957\n",
      "CLS_LOSS_WEIGHT:  0.807228368084043\n",
      "tp:  842\n",
      "fn:  480\n",
      "tn:  503\n",
      "fp:  819\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1345\n",
      "tp:  266\n",
      "fn:  298\n",
      "tn:  376\n",
      "fp:  188\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  642\n",
      "EPOCH 98\n",
      "   TRAIN | Label 1 loss: 16.3642 ; P: 0.721 ; R: 0.6392 ; F1: 0.6776 ; Acc: 0.8879\n",
      "           Label 2 loss: 62.2551 ; P: 0.5069 ; R: 0.6369 ; F1: 0.5645 ; Acc: 0.5087\n",
      "    TEST | Label 1 loss: 7.9874 ; P: 0.6483 ; R: 0.7906 ; F1: 0.7125 ; Acc: 0.8746\n",
      "           Label 2 loss: 26.913 ; P: 0.5859 ; R: 0.4716 ; F1: 0.5226 ; Acc: 0.5691\n",
      "2023-01-29 13:13:03.742036\n",
      "2023-01-29 13:13:05.413492\n",
      "EPOCH 99\n",
      "TAG_LOSS_WEIGHT:  0.19016529255097847\n",
      "CLS_LOSS_WEIGHT:  0.8098347074490214\n",
      "tp:  459\n",
      "fn:  863\n",
      "tn:  942\n",
      "fp:  380\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1401\n",
      "tp:  491\n",
      "fn:  73\n",
      "tn:  118\n",
      "fp:  446\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  609\n",
      "EPOCH 99\n",
      "   TRAIN | Label 1 loss: 16.3742 ; P: 0.709 ; R: 0.6384 ; F1: 0.6719 ; Acc: 0.8851\n",
      "           Label 2 loss: 62.1868 ; P: 0.5471 ; R: 0.3472 ; F1: 0.4248 ; Acc: 0.5299\n",
      "    TEST | Label 1 loss: 8.0322 ; P: 0.6448 ; R: 0.8128 ; F1: 0.7191 ; Acc: 0.8752\n",
      "           Label 2 loss: 26.907 ; P: 0.524 ; R: 0.8706 ; F1: 0.6542 ; Acc: 0.5399\n",
      "2023-01-29 13:13:37.686216\n",
      "2023-01-29 13:13:37.687206\n",
      "EPOCH 100\n",
      "TAG_LOSS_WEIGHT:  0.19069210840216397\n",
      "CLS_LOSS_WEIGHT:  0.8093078915978361\n",
      "tp:  812\n",
      "fn:  510\n",
      "tn:  613\n",
      "fp:  709\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1425\n",
      "tp:  443\n",
      "fn:  121\n",
      "tn:  190\n",
      "fp:  374\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  633\n",
      "EPOCH 100\n",
      "   TRAIN | Label 1 loss: 16.2324 ; P: 0.7193 ; R: 0.6542 ; F1: 0.6852 ; Acc: 0.8893\n",
      "           Label 2 loss: 61.9827 ; P: 0.5339 ; R: 0.6142 ; F1: 0.5712 ; Acc: 0.539\n",
      "    TEST | Label 1 loss: 7.8854 ; P: 0.6572 ; R: 0.7881 ; F1: 0.7167 ; Acc: 0.8776\n",
      "           Label 2 loss: 26.8742 ; P: 0.5422 ; R: 0.7855 ; F1: 0.6416 ; Acc: 0.5612\n",
      "2023-01-29 13:14:09.322504\n",
      "2023-01-29 13:14:09.322504\n",
      "EPOCH 101\n",
      "TAG_LOSS_WEIGHT:  0.18902778636861958\n",
      "CLS_LOSS_WEIGHT:  0.8109722136313803\n",
      "tp:  654\n",
      "fn:  668\n",
      "tn:  765\n",
      "fp:  557\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1419\n",
      "tp:  445\n",
      "fn:  119\n",
      "tn:  179\n",
      "fp:  385\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  624\n",
      "EPOCH 101\n",
      "   TRAIN | Label 1 loss: 16.1507 ; P: 0.7204 ; R: 0.6584 ; F1: 0.688 ; Acc: 0.89\n",
      "           Label 2 loss: 62.0762 ; P: 0.54 ; R: 0.4947 ; F1: 0.5164 ; Acc: 0.5367\n",
      "    TEST | Label 1 loss: 7.8641 ; P: 0.6679 ; R: 0.7761 ; F1: 0.718 ; Acc: 0.8802\n",
      "           Label 2 loss: 26.8665 ; P: 0.5361 ; R: 0.789 ; F1: 0.6385 ; Acc: 0.5532\n",
      "2023-01-29 13:14:40.144961\n",
      "2023-01-29 13:14:40.144961\n",
      "EPOCH 102\n",
      "TAG_LOSS_WEIGHT:  0.18702680765269183\n",
      "CLS_LOSS_WEIGHT:  0.8129731923473081\n",
      "tp:  691\n",
      "fn:  631\n",
      "tn:  722\n",
      "fp:  600\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1413\n",
      "tp:  401\n",
      "fn:  163\n",
      "tn:  262\n",
      "fp:  302\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  663\n",
      "EPOCH 102\n",
      "   TRAIN | Label 1 loss: 16.0257 ; P: 0.7222 ; R: 0.6623 ; F1: 0.6909 ; Acc: 0.8908\n",
      "           Label 2 loss: 61.946 ; P: 0.5352 ; R: 0.5227 ; F1: 0.5289 ; Acc: 0.5344\n",
      "    TEST | Label 1 loss: 7.8825 ; P: 0.6616 ; R: 0.7925 ; F1: 0.7212 ; Acc: 0.8796\n",
      "           Label 2 loss: 26.8241 ; P: 0.5704 ; R: 0.711 ; F1: 0.633 ; Acc: 0.5878\n",
      "2023-01-29 13:15:11.174120\n",
      "2023-01-29 13:15:12.883549\n",
      "EPOCH 103\n",
      "TAG_LOSS_WEIGHT:  0.1853086766494114\n",
      "CLS_LOSS_WEIGHT:  0.8146913233505887\n",
      "tp:  731\n",
      "fn:  591\n",
      "tn:  699\n",
      "fp:  623\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1430\n",
      "tp:  487\n",
      "fn:  77\n",
      "tn:  147\n",
      "fp:  417\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  634\n",
      "EPOCH 103\n",
      "   TRAIN | Label 1 loss: 15.8934 ; P: 0.724 ; R: 0.6714 ; F1: 0.6967 ; Acc: 0.8923\n",
      "           Label 2 loss: 61.8705 ; P: 0.5399 ; R: 0.553 ; F1: 0.5463 ; Acc: 0.5408\n",
      "    TEST | Label 1 loss: 7.8536 ; P: 0.6602 ; R: 0.8159 ; F1: 0.7298 ; Acc: 0.8813\n",
      "           Label 2 loss: 26.7833 ; P: 0.5387 ; R: 0.8635 ; F1: 0.6635 ; Acc: 0.5621\n",
      "2023-01-29 13:15:44.733509\n",
      "2023-01-29 13:15:44.733509\n",
      "EPOCH 104\n",
      "TAG_LOSS_WEIGHT:  0.18318339953050558\n",
      "CLS_LOSS_WEIGHT:  0.8168166004694943\n",
      "tp:  715\n",
      "fn:  607\n",
      "tn:  757\n",
      "fp:  565\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1472\n",
      "tp:  524\n",
      "fn:  40\n",
      "tn:  91\n",
      "fp:  473\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  615\n",
      "EPOCH 104\n",
      "   TRAIN | Label 1 loss: 15.8448 ; P: 0.7286 ; R: 0.6776 ; F1: 0.7021 ; Acc: 0.8941\n",
      "           Label 2 loss: 61.8384 ; P: 0.5586 ; R: 0.5408 ; F1: 0.5496 ; Acc: 0.5567\n",
      "    TEST | Label 1 loss: 7.7446 ; P: 0.6788 ; R: 0.778 ; F1: 0.725 ; Acc: 0.884\n",
      "           Label 2 loss: 26.7531 ; P: 0.5256 ; R: 0.9291 ; F1: 0.6714 ; Acc: 0.5452\n",
      "2023-01-29 13:16:16.271980\n",
      "2023-01-29 13:16:16.271980\n",
      "EPOCH 105\n",
      "TAG_LOSS_WEIGHT:  0.18242344298849608\n",
      "CLS_LOSS_WEIGHT:  0.8175765570115038\n",
      "tp:  832\n",
      "fn:  490\n",
      "tn:  624\n",
      "fp:  698\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1456\n",
      "tp:  416\n",
      "fn:  148\n",
      "tn:  277\n",
      "fp:  287\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  693\n",
      "EPOCH 105\n",
      "   TRAIN | Label 1 loss: 15.7608 ; P: 0.731 ; R: 0.6909 ; F1: 0.7104 ; Acc: 0.8962\n",
      "           Label 2 loss: 61.6395 ; P: 0.5438 ; R: 0.6293 ; F1: 0.5835 ; Acc: 0.5507\n",
      "    TEST | Label 1 loss: 7.6168 ; P: 0.6859 ; R: 0.7761 ; F1: 0.7282 ; Acc: 0.8862\n",
      "           Label 2 loss: 26.5997 ; P: 0.5917 ; R: 0.7376 ; F1: 0.6567 ; Acc: 0.6144\n",
      "2023-01-29 13:16:47.620254\n",
      "2023-01-29 13:16:49.445435\n",
      "EPOCH 106\n",
      "TAG_LOSS_WEIGHT:  0.18179968518510428\n",
      "CLS_LOSS_WEIGHT:  0.8182003148148956\n",
      "tp:  642\n",
      "fn:  680\n",
      "tn:  847\n",
      "fp:  475\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1489\n",
      "tp:  493\n",
      "fn:  71\n",
      "tn:  162\n",
      "fp:  402\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  655\n",
      "EPOCH 106\n",
      "   TRAIN | Label 1 loss: 15.6027 ; P: 0.7366 ; R: 0.6976 ; F1: 0.7165 ; Acc: 0.8983\n",
      "           Label 2 loss: 61.2452 ; P: 0.5748 ; R: 0.4856 ; F1: 0.5264 ; Acc: 0.5632\n",
      "    TEST | Label 1 loss: 7.6644 ; P: 0.6799 ; R: 0.814 ; F1: 0.7409 ; Acc: 0.8881\n",
      "           Label 2 loss: 26.4974 ; P: 0.5508 ; R: 0.8741 ; F1: 0.6758 ; Acc: 0.5807\n",
      "2023-01-29 13:17:21.117282\n",
      "2023-01-29 13:17:21.117282\n",
      "EPOCH 107\n",
      "TAG_LOSS_WEIGHT:  0.18071206355774566\n",
      "CLS_LOSS_WEIGHT:  0.8192879364422543\n",
      "tp:  833\n",
      "fn:  489\n",
      "tn:  659\n",
      "fp:  663\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1492\n",
      "tp:  365\n",
      "fn:  199\n",
      "tn:  341\n",
      "fp:  223\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  706\n",
      "EPOCH 107\n",
      "   TRAIN | Label 1 loss: 15.9543 ; P: 0.7402 ; R: 0.673 ; F1: 0.705 ; Acc: 0.8962\n",
      "           Label 2 loss: 61.4471 ; P: 0.5568 ; R: 0.6301 ; F1: 0.5912 ; Acc: 0.5643\n",
      "    TEST | Label 1 loss: 7.8067 ; P: 0.6854 ; R: 0.809 ; F1: 0.7421 ; Acc: 0.8895\n",
      "           Label 2 loss: 26.3063 ; P: 0.6207 ; R: 0.6472 ; F1: 0.6337 ; Acc: 0.6259\n",
      "2023-01-29 13:17:53.021707\n",
      "2023-01-29 13:17:54.789511\n",
      "EPOCH 108\n",
      "TAG_LOSS_WEIGHT:  0.18640451897119548\n",
      "CLS_LOSS_WEIGHT:  0.8135954810288044\n",
      "tp:  750\n",
      "fn:  572\n",
      "tn:  787\n",
      "fp:  535\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1537\n",
      "tp:  397\n",
      "fn:  167\n",
      "tn:  330\n",
      "fp:  234\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  727\n",
      "EPOCH 108\n",
      "   TRAIN | Label 1 loss: 16.0982 ; P: 0.7388 ; R: 0.6847 ; F1: 0.7107 ; Acc: 0.8973\n",
      "           Label 2 loss: 60.9745 ; P: 0.5837 ; R: 0.5673 ; F1: 0.5754 ; Acc: 0.5813\n",
      "    TEST | Label 1 loss: 7.6925 ; P: 0.7001 ; R: 0.7989 ; F1: 0.7462 ; Acc: 0.8932\n",
      "           Label 2 loss: 25.9856 ; P: 0.6292 ; R: 0.7039 ; F1: 0.6644 ; Acc: 0.6445\n",
      "2023-01-29 13:18:26.906432\n",
      "2023-01-29 13:18:28.539299\n",
      "EPOCH 109\n",
      "TAG_LOSS_WEIGHT:  0.19152302080345435\n",
      "CLS_LOSS_WEIGHT:  0.8084769791965457\n",
      "tp:  785\n",
      "fn:  537\n",
      "tn:  770\n",
      "fp:  552\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1555\n",
      "tp:  345\n",
      "fn:  219\n",
      "tn:  378\n",
      "fp:  186\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  723\n",
      "EPOCH 109\n",
      "   TRAIN | Label 1 loss: 15.9964 ; P: 0.743 ; R: 0.6963 ; F1: 0.7189 ; Acc: 0.8997\n",
      "           Label 2 loss: 60.6404 ; P: 0.5871 ; R: 0.5938 ; F1: 0.5904 ; Acc: 0.5881\n",
      "    TEST | Label 1 loss: 7.7374 ; P: 0.6922 ; R: 0.8223 ; F1: 0.7517 ; Acc: 0.8932\n",
      "           Label 2 loss: 25.5597 ; P: 0.6497 ; R: 0.6117 ; F1: 0.6301 ; Acc: 0.641\n",
      "2023-01-29 13:19:00.445354\n",
      "2023-01-29 13:19:00.445354\n",
      "EPOCH 110\n",
      "TAG_LOSS_WEIGHT:  0.1912601251318454\n",
      "CLS_LOSS_WEIGHT:  0.8087398748681547\n",
      "tp:  778\n",
      "fn:  544\n",
      "tn:  839\n",
      "fp:  483\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1617\n",
      "tp:  446\n",
      "fn:  118\n",
      "tn:  306\n",
      "fp:  258\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  752\n",
      "EPOCH 110\n",
      "   TRAIN | Label 1 loss: 15.9004 ; P: 0.7515 ; R: 0.7068 ; F1: 0.7285 ; Acc: 0.9029\n",
      "           Label 2 loss: 59.7185 ; P: 0.617 ; R: 0.5885 ; F1: 0.6024 ; Acc: 0.6116\n",
      "    TEST | Label 1 loss: 7.643 ; P: 0.7052 ; R: 0.8368 ; F1: 0.7654 ; Acc: 0.8992\n",
      "           Label 2 loss: 25.0121 ; P: 0.6335 ; R: 0.7908 ; F1: 0.7035 ; Acc: 0.6667\n",
      "2023-01-29 13:19:32.199354\n",
      "2023-01-29 13:19:33.930721\n",
      "EPOCH 111\n",
      "TAG_LOSS_WEIGHT:  0.1941537166495545\n",
      "CLS_LOSS_WEIGHT:  0.8058462833504455\n",
      "tp:  860\n",
      "fn:  462\n",
      "tn:  799\n",
      "fp:  523\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1659\n",
      "tp:  434\n",
      "fn:  130\n",
      "tn:  327\n",
      "fp:  237\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  761\n",
      "EPOCH 111\n",
      "   TRAIN | Label 1 loss: 15.3123 ; P: 0.7568 ; R: 0.7338 ; F1: 0.7452 ; Acc: 0.9075\n",
      "           Label 2 loss: 58.5711 ; P: 0.6218 ; R: 0.6505 ; F1: 0.6359 ; Acc: 0.6275\n",
      "    TEST | Label 1 loss: 7.4051 ; P: 0.7212 ; R: 0.8115 ; F1: 0.7637 ; Acc: 0.9013\n",
      "           Label 2 loss: 24.449 ; P: 0.6468 ; R: 0.7695 ; F1: 0.7028 ; Acc: 0.6746\n",
      "2023-01-29 13:20:06.308472\n",
      "2023-01-29 13:20:07.946138\n",
      "EPOCH 112\n",
      "TAG_LOSS_WEIGHT:  0.1884952275476856\n",
      "CLS_LOSS_WEIGHT:  0.8115047724523143\n",
      "tp:  875\n",
      "fn:  447\n",
      "tn:  861\n",
      "fp:  461\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1736\n",
      "tp:  449\n",
      "fn:  115\n",
      "tn:  335\n",
      "fp:  229\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  784\n",
      "EPOCH 112\n",
      "   TRAIN | Label 1 loss: 15.329 ; P: 0.77 ; R: 0.7463 ; F1: 0.758 ; Acc: 0.9122\n",
      "           Label 2 loss: 56.7698 ; P: 0.6549 ; R: 0.6619 ; F1: 0.6584 ; Acc: 0.6566\n",
      "    TEST | Label 1 loss: 7.6934 ; P: 0.7028 ; R: 0.845 ; F1: 0.7674 ; Acc: 0.8993\n",
      "           Label 2 loss: 23.7087 ; P: 0.6622 ; R: 0.7961 ; F1: 0.723 ; Acc: 0.695\n",
      "2023-01-29 13:20:40.518352\n",
      "2023-01-29 13:20:41.979122\n",
      "EPOCH 113\n",
      "TAG_LOSS_WEIGHT:  0.19858468066952498\n",
      "CLS_LOSS_WEIGHT:  0.8014153193304749\n",
      "tp:  918\n",
      "fn:  404\n",
      "tn:  875\n",
      "fp:  447\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1793\n",
      "tp:  440\n",
      "fn:  124\n",
      "tn:  349\n",
      "fp:  215\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  789\n",
      "EPOCH 113\n",
      "   TRAIN | Label 1 loss: 14.8913 ; P: 0.7808 ; R: 0.7541 ; F1: 0.7672 ; Acc: 0.9157\n",
      "           Label 2 loss: 54.2075 ; P: 0.6725 ; R: 0.6944 ; F1: 0.6833 ; Acc: 0.6781\n",
      "    TEST | Label 1 loss: 7.4579 ; P: 0.7229 ; R: 0.8235 ; F1: 0.77 ; Acc: 0.9033\n",
      "           Label 2 loss: 23.3876 ; P: 0.6718 ; R: 0.7801 ; F1: 0.7219 ; Acc: 0.6995\n",
      "2023-01-29 13:21:14.098311\n",
      "2023-01-29 13:21:15.712156\n",
      "EPOCH 114\n",
      "TAG_LOSS_WEIGHT:  0.20412137793311466\n",
      "CLS_LOSS_WEIGHT:  0.7958786220668854\n",
      "tp:  918\n",
      "fn:  404\n",
      "tn:  885\n",
      "fp:  437\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1803\n",
      "tp:  422\n",
      "fn:  142\n",
      "tn:  373\n",
      "fp:  191\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  795\n",
      "EPOCH 114\n",
      "   TRAIN | Label 1 loss: 14.7282 ; P: 0.7839 ; R: 0.7571 ; F1: 0.7703 ; Acc: 0.9168\n",
      "           Label 2 loss: 54.0789 ; P: 0.6775 ; R: 0.6944 ; F1: 0.6858 ; Acc: 0.6819\n",
      "    TEST | Label 1 loss: 7.4329 ; P: 0.7166 ; R: 0.8476 ; F1: 0.7766 ; Acc: 0.9042\n",
      "           Label 2 loss: 22.871 ; P: 0.6884 ; R: 0.7482 ; F1: 0.7171 ; Acc: 0.7048\n",
      "2023-01-29 13:21:48.163941\n",
      "2023-01-29 13:21:49.790064\n",
      "EPOCH 115\n",
      "TAG_LOSS_WEIGHT:  0.2013291516239694\n",
      "CLS_LOSS_WEIGHT:  0.7986708483760305\n",
      "tp:  952\n",
      "fn:  370\n",
      "tn:  900\n",
      "fp:  422\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1852\n",
      "tp:  445\n",
      "fn:  119\n",
      "tn:  356\n",
      "fp:  208\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  801\n",
      "EPOCH 115\n",
      "   TRAIN | Label 1 loss: 14.1249 ; P: 0.7919 ; R: 0.7781 ; F1: 0.7849 ; Acc: 0.9214\n",
      "           Label 2 loss: 51.5401 ; P: 0.6929 ; R: 0.7201 ; F1: 0.7062 ; Acc: 0.7005\n",
      "    TEST | Label 1 loss: 7.2698 ; P: 0.7323 ; R: 0.8305 ; F1: 0.7783 ; Acc: 0.907\n",
      "           Label 2 loss: 22.7439 ; P: 0.6815 ; R: 0.789 ; F1: 0.7313 ; Acc: 0.7101\n",
      "2023-01-29 13:22:22.316141\n",
      "2023-01-29 13:22:23.928933\n",
      "EPOCH 116\n",
      "TAG_LOSS_WEIGHT:  0.2033495586002672\n",
      "CLS_LOSS_WEIGHT:  0.7966504413997328\n",
      "tp:  983\n",
      "fn:  339\n",
      "tn:  928\n",
      "fp:  394\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1911\n",
      "tp:  439\n",
      "fn:  125\n",
      "tn:  368\n",
      "fp:  196\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  807\n",
      "EPOCH 116\n",
      "   TRAIN | Label 1 loss: 13.9225 ; P: 0.8008 ; R: 0.7855 ; F1: 0.7931 ; Acc: 0.9245\n",
      "           Label 2 loss: 51.2962 ; P: 0.7139 ; R: 0.7436 ; F1: 0.7284 ; Acc: 0.7228\n",
      "    TEST | Label 1 loss: 7.1483 ; P: 0.7487 ; R: 0.8197 ; F1: 0.7826 ; Acc: 0.9105\n",
      "           Label 2 loss: 22.4815 ; P: 0.6913 ; R: 0.7784 ; F1: 0.7323 ; Acc: 0.7154\n",
      "2023-01-29 13:22:56.152050\n",
      "2023-01-29 13:22:57.774858\n",
      "EPOCH 117\n",
      "TAG_LOSS_WEIGHT:  0.2002282338572122\n",
      "CLS_LOSS_WEIGHT:  0.7997717661427877\n",
      "tp:  1035\n",
      "fn:  287\n",
      "tn:  944\n",
      "fp:  378\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  1979\n",
      "tp:  434\n",
      "fn:  130\n",
      "tn:  382\n",
      "fp:  182\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  816\n",
      "EPOCH 117\n",
      "   TRAIN | Label 1 loss: 13.5642 ; P: 0.815 ; R: 0.7921 ; F1: 0.8033 ; Acc: 0.9286\n",
      "           Label 2 loss: 49.0613 ; P: 0.7325 ; R: 0.7829 ; F1: 0.7569 ; Acc: 0.7485\n",
      "    TEST | Label 1 loss: 7.109 ; P: 0.7531 ; R: 0.814 ; F1: 0.7824 ; Acc: 0.911\n",
      "           Label 2 loss: 22.4785 ; P: 0.7045 ; R: 0.7695 ; F1: 0.7356 ; Acc: 0.7234\n",
      "2023-01-29 13:23:30.487021\n",
      "2023-01-29 13:23:32.102981\n",
      "EPOCH 118\n",
      "TAG_LOSS_WEIGHT:  0.20621050886850398\n",
      "CLS_LOSS_WEIGHT:  0.793789491131496\n",
      "tp:  1039\n",
      "fn:  283\n",
      "tn:  983\n",
      "fp:  339\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2022\n",
      "tp:  442\n",
      "fn:  122\n",
      "tn:  371\n",
      "fp:  193\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  813\n",
      "EPOCH 118\n",
      "   TRAIN | Label 1 loss: 13.415 ; P: 0.8126 ; R: 0.7981 ; F1: 0.8053 ; Acc: 0.9289\n",
      "           Label 2 loss: 47.2516 ; P: 0.754 ; R: 0.7859 ; F1: 0.7696 ; Acc: 0.7648\n",
      "    TEST | Label 1 loss: 7.0922 ; P: 0.7395 ; R: 0.8387 ; F1: 0.786 ; Acc: 0.9103\n",
      "           Label 2 loss: 22.3471 ; P: 0.6961 ; R: 0.7837 ; F1: 0.7373 ; Acc: 0.7207\n",
      "2023-01-29 13:24:04.731228\n",
      "2023-01-29 13:24:04.731228\n",
      "EPOCH 119\n",
      "TAG_LOSS_WEIGHT:  0.21502902972994206\n",
      "CLS_LOSS_WEIGHT:  0.784970970270058\n",
      "tp:  1040\n",
      "fn:  282\n",
      "tn:  985\n",
      "fp:  337\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2025\n",
      "tp:  418\n",
      "fn:  146\n",
      "tn:  409\n",
      "fp:  155\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  827\n",
      "EPOCH 119\n",
      "   TRAIN | Label 1 loss: 12.9278 ; P: 0.8262 ; R: 0.8041 ; F1: 0.815 ; Acc: 0.9327\n",
      "           Label 2 loss: 46.754 ; P: 0.7553 ; R: 0.7867 ; F1: 0.7707 ; Acc: 0.7659\n",
      "    TEST | Label 1 loss: 6.9644 ; P: 0.758 ; R: 0.828 ; F1: 0.7914 ; Acc: 0.9142\n",
      "           Label 2 loss: 22.0699 ; P: 0.7295 ; R: 0.7411 ; F1: 0.7353 ; Acc: 0.7332\n",
      "2023-01-29 13:24:36.776711\n",
      "2023-01-29 13:24:38.382057\n",
      "EPOCH 120\n",
      "TAG_LOSS_WEIGHT:  0.20624874415654218\n",
      "CLS_LOSS_WEIGHT:  0.7937512558434577\n",
      "tp:  1020\n",
      "fn:  302\n",
      "tn:  1001\n",
      "fp:  321\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2021\n",
      "tp:  447\n",
      "fn:  117\n",
      "tn:  372\n",
      "fp:  192\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  819\n",
      "EPOCH 120\n",
      "   TRAIN | Label 1 loss: 12.931 ; P: 0.8237 ; R: 0.8129 ; F1: 0.8183 ; Acc: 0.9335\n",
      "           Label 2 loss: 46.6994 ; P: 0.7606 ; R: 0.7716 ; F1: 0.7661 ; Acc: 0.7644\n",
      "    TEST | Label 1 loss: 6.9687 ; P: 0.7611 ; R: 0.8261 ; F1: 0.7922 ; Acc: 0.9149\n",
      "           Label 2 loss: 22.1487 ; P: 0.6995 ; R: 0.7926 ; F1: 0.7431 ; Acc: 0.7261\n",
      "2023-01-29 13:25:10.186609\n",
      "2023-01-29 13:25:10.186609\n",
      "EPOCH 121\n",
      "TAG_LOSS_WEIGHT:  0.20671275547237156\n",
      "CLS_LOSS_WEIGHT:  0.7932872445276284\n",
      "tp:  1037\n",
      "fn:  285\n",
      "tn:  1013\n",
      "fp:  309\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2050\n",
      "tp:  434\n",
      "fn:  130\n",
      "tn:  396\n",
      "fp:  168\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  830\n",
      "EPOCH 121\n",
      "   TRAIN | Label 1 loss: 12.6814 ; P: 0.8346 ; R: 0.8186 ; F1: 0.8266 ; Acc: 0.9367\n",
      "           Label 2 loss: 45.3307 ; P: 0.7704 ; R: 0.7844 ; F1: 0.7774 ; Acc: 0.7753\n",
      "    TEST | Label 1 loss: 6.9873 ; P: 0.7679 ; R: 0.8204 ; F1: 0.7933 ; Acc: 0.916\n",
      "           Label 2 loss: 22.0588 ; P: 0.7209 ; R: 0.7695 ; F1: 0.7444 ; Acc: 0.7358\n",
      "2023-01-29 13:25:42.223583\n",
      "2023-01-29 13:25:44.558609\n",
      "EPOCH 122\n",
      "TAG_LOSS_WEIGHT:  0.2100964829326225\n",
      "CLS_LOSS_WEIGHT:  0.7899035170673775\n",
      "tp:  1041\n",
      "fn:  281\n",
      "tn:  1024\n",
      "fp:  298\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2065\n",
      "tp:  444\n",
      "fn:  120\n",
      "tn:  390\n",
      "fp:  174\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  834\n",
      "EPOCH 122\n",
      "   TRAIN | Label 1 loss: 12.5824 ; P: 0.8309 ; R: 0.8178 ; F1: 0.8243 ; Acc: 0.9358\n",
      "           Label 2 loss: 44.684 ; P: 0.7774 ; R: 0.7874 ; F1: 0.7824 ; Acc: 0.781\n",
      "    TEST | Label 1 loss: 6.9677 ; P: 0.7659 ; R: 0.8299 ; F1: 0.7966 ; Acc: 0.9167\n",
      "           Label 2 loss: 21.9459 ; P: 0.7184 ; R: 0.7872 ; F1: 0.7513 ; Acc: 0.7394\n",
      "2023-01-29 13:26:16.740424\n",
      "2023-01-29 13:26:18.573536\n",
      "EPOCH 123\n",
      "TAG_LOSS_WEIGHT:  0.21227263248268533\n",
      "CLS_LOSS_WEIGHT:  0.7877273675173145\n",
      "tp:  1082\n",
      "fn:  240\n",
      "tn:  1043\n",
      "fp:  279\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2125\n",
      "tp:  440\n",
      "fn:  124\n",
      "tn:  402\n",
      "fp:  162\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  842\n",
      "EPOCH 123\n",
      "   TRAIN | Label 1 loss: 12.2998 ; P: 0.8411 ; R: 0.8291 ; F1: 0.8351 ; Acc: 0.9397\n",
      "           Label 2 loss: 43.4987 ; P: 0.795 ; R: 0.8185 ; F1: 0.8066 ; Acc: 0.8037\n",
      "    TEST | Label 1 loss: 6.9773 ; P: 0.7702 ; R: 0.8248 ; F1: 0.7966 ; Acc: 0.9172\n",
      "           Label 2 loss: 21.8846 ; P: 0.7309 ; R: 0.7801 ; F1: 0.7547 ; Acc: 0.7465\n",
      "2023-01-29 13:26:51.091661\n",
      "2023-01-29 13:26:52.682738\n",
      "EPOCH 124\n",
      "TAG_LOSS_WEIGHT:  0.2136700084317579\n",
      "CLS_LOSS_WEIGHT:  0.786329991568242\n",
      "tp:  1059\n",
      "fn:  263\n",
      "tn:  1062\n",
      "fp:  260\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2121\n",
      "tp:  444\n",
      "fn:  120\n",
      "tn:  399\n",
      "fp:  165\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  843\n",
      "EPOCH 124\n",
      "   TRAIN | Label 1 loss: 12.0132 ; P: 0.8479 ; R: 0.8308 ; F1: 0.8393 ; Acc: 0.9414\n",
      "           Label 2 loss: 42.5034 ; P: 0.8029 ; R: 0.8011 ; F1: 0.802 ; Acc: 0.8022\n",
      "    TEST | Label 1 loss: 7.0401 ; P: 0.7671 ; R: 0.8355 ; F1: 0.7999 ; Acc: 0.9178\n",
      "           Label 2 loss: 21.9609 ; P: 0.7291 ; R: 0.7872 ; F1: 0.757 ; Acc: 0.7473\n",
      "2023-01-29 13:27:24.975101\n",
      "2023-01-29 13:27:26.729952\n",
      "EPOCH 125\n",
      "TAG_LOSS_WEIGHT:  0.21352555872301526\n",
      "CLS_LOSS_WEIGHT:  0.7864744412769847\n",
      "tp:  1057\n",
      "fn:  265\n",
      "tn:  1045\n",
      "fp:  277\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2102\n",
      "tp:  439\n",
      "fn:  125\n",
      "tn:  406\n",
      "fp:  158\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  845\n",
      "EPOCH 125\n",
      "   TRAIN | Label 1 loss: 12.0579 ; P: 0.8485 ; R: 0.8342 ; F1: 0.8413 ; Acc: 0.942\n",
      "           Label 2 loss: 42.8088 ; P: 0.7924 ; R: 0.7995 ; F1: 0.7959 ; Acc: 0.795\n",
      "    TEST | Label 1 loss: 7.0199 ; P: 0.7681 ; R: 0.8381 ; F1: 0.8016 ; Acc: 0.9185\n",
      "           Label 2 loss: 21.789 ; P: 0.7353 ; R: 0.7784 ; F1: 0.7562 ; Acc: 0.7491\n",
      "2023-01-29 13:27:59.137905\n",
      "2023-01-29 13:28:00.776509\n",
      "EPOCH 126\n",
      "TAG_LOSS_WEIGHT:  0.2123705827658435\n",
      "CLS_LOSS_WEIGHT:  0.7876294172341564\n",
      "tp:  1093\n",
      "fn:  229\n",
      "tn:  1037\n",
      "fp:  285\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2130\n",
      "tp:  439\n",
      "fn:  125\n",
      "tn:  409\n",
      "fp:  155\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  848\n",
      "EPOCH 126\n",
      "   TRAIN | Label 1 loss: 11.5912 ; P: 0.8521 ; R: 0.8388 ; F1: 0.8454 ; Acc: 0.9435\n",
      "           Label 2 loss: 42.0026 ; P: 0.7932 ; R: 0.8268 ; F1: 0.8096 ; Acc: 0.8056\n",
      "    TEST | Label 1 loss: 7.0565 ; P: 0.7744 ; R: 0.8381 ; F1: 0.805 ; Acc: 0.9202\n",
      "           Label 2 loss: 21.8121 ; P: 0.7391 ; R: 0.7784 ; F1: 0.7582 ; Acc: 0.7518\n",
      "2023-01-29 13:28:33.040121\n",
      "counter:  0\n",
      "2023-01-29 13:28:35.510738\n",
      "EPOCH 127\n",
      "TAG_LOSS_WEIGHT:  0.20560592632009314\n",
      "CLS_LOSS_WEIGHT:  0.7943940736799068\n",
      "tp:  1098\n",
      "fn:  224\n",
      "tn:  1051\n",
      "fp:  271\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2149\n",
      "tp:  439\n",
      "fn:  125\n",
      "tn:  411\n",
      "fp:  153\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  850\n",
      "EPOCH 127\n",
      "   TRAIN | Label 1 loss: 11.5737 ; P: 0.8535 ; R: 0.847 ; F1: 0.8503 ; Acc: 0.945\n",
      "           Label 2 loss: 41.5887 ; P: 0.802 ; R: 0.8306 ; F1: 0.8161 ; Acc: 0.8128\n",
      "    TEST | Label 1 loss: 7.0595 ; P: 0.7801 ; R: 0.8349 ; F1: 0.8066 ; Acc: 0.9213\n",
      "           Label 2 loss: 21.858 ; P: 0.7416 ; R: 0.7784 ; F1: 0.7595 ; Acc: 0.7535\n",
      "2023-01-29 13:29:07.593540\n",
      "counter:  0\n",
      "2023-01-29 13:29:09.079274\n",
      "EPOCH 128\n",
      "TAG_LOSS_WEIGHT:  0.20836087953489307\n",
      "CLS_LOSS_WEIGHT:  0.791639120465107\n",
      "tp:  1099\n",
      "fn:  223\n",
      "tn:  1062\n",
      "fp:  260\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2161\n",
      "tp:  433\n",
      "fn:  131\n",
      "tn:  421\n",
      "fp:  143\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  854\n",
      "EPOCH 128\n",
      "   TRAIN | Label 1 loss: 11.4133 ; P: 0.858 ; R: 0.8505 ; F1: 0.8543 ; Acc: 0.9465\n",
      "           Label 2 loss: 40.8434 ; P: 0.8087 ; R: 0.8313 ; F1: 0.8198 ; Acc: 0.8173\n",
      "    TEST | Label 1 loss: 7.1157 ; P: 0.78 ; R: 0.8318 ; F1: 0.805 ; Acc: 0.9208\n",
      "           Label 2 loss: 21.8578 ; P: 0.7517 ; R: 0.7677 ; F1: 0.7596 ; Acc: 0.7571\n",
      "2023-01-29 13:29:40.854379\n",
      "counter:  0\n",
      "2023-01-29 13:29:42.620374\n",
      "EPOCH 129\n",
      "TAG_LOSS_WEIGHT:  0.2097257303724026\n",
      "CLS_LOSS_WEIGHT:  0.7902742696275973\n",
      "tp:  1072\n",
      "fn:  250\n",
      "tn:  1082\n",
      "fp:  240\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2154\n",
      "tp:  433\n",
      "fn:  131\n",
      "tn:  418\n",
      "fp:  146\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  851\n",
      "EPOCH 129\n",
      "   TRAIN | Label 1 loss: 11.4868 ; P: 0.8582 ; R: 0.8458 ; F1: 0.8519 ; Acc: 0.9458\n",
      "           Label 2 loss: 41.2895 ; P: 0.8171 ; R: 0.8109 ; F1: 0.814 ; Acc: 0.8147\n",
      "    TEST | Label 1 loss: 7.1652 ; P: 0.7817 ; R: 0.8311 ; F1: 0.8056 ; Acc: 0.9212\n",
      "           Label 2 loss: 21.9102 ; P: 0.7478 ; R: 0.7677 ; F1: 0.7577 ; Acc: 0.7544\n",
      "2023-01-29 13:30:15.225867\n",
      "counter:  1\n",
      "2023-01-29 13:30:15.227868\n",
      "EPOCH 130\n",
      "TAG_LOSS_WEIGHT:  0.20825649840487623\n",
      "CLS_LOSS_WEIGHT:  0.7917435015951237\n",
      "tp:  1109\n",
      "fn:  213\n",
      "tn:  1088\n",
      "fp:  234\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2197\n",
      "tp:  433\n",
      "fn:  131\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  852\n",
      "EPOCH 130\n",
      "   TRAIN | Label 1 loss: 11.2135 ; P: 0.8628 ; R: 0.8441 ; F1: 0.8534 ; Acc: 0.9466\n",
      "           Label 2 loss: 39.4896 ; P: 0.8258 ; R: 0.8389 ; F1: 0.8323 ; Acc: 0.8309\n",
      "    TEST | Label 1 loss: 7.1738 ; P: 0.787 ; R: 0.8299 ; F1: 0.8079 ; Acc: 0.9224\n",
      "           Label 2 loss: 22.0771 ; P: 0.7491 ; R: 0.7677 ; F1: 0.7583 ; Acc: 0.7553\n",
      "2023-01-29 13:30:47.676364\n",
      "counter:  2\n",
      "2023-01-29 13:30:47.678365\n",
      "EPOCH 131\n",
      "TAG_LOSS_WEIGHT:  0.21509456030574906\n",
      "CLS_LOSS_WEIGHT:  0.784905439694251\n",
      "tp:  1094\n",
      "fn:  228\n",
      "tn:  1091\n",
      "fp:  231\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2185\n",
      "tp:  440\n",
      "fn:  124\n",
      "tn:  416\n",
      "fp:  148\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  856\n",
      "EPOCH 131\n",
      "   TRAIN | Label 1 loss: 11.2646 ; P: 0.8624 ; R: 0.8517 ; F1: 0.857 ; Acc: 0.9476\n",
      "           Label 2 loss: 39.5709 ; P: 0.8257 ; R: 0.8275 ; F1: 0.8266 ; Acc: 0.8264\n",
      "    TEST | Label 1 loss: 7.1164 ; P: 0.7873 ; R: 0.8336 ; F1: 0.8098 ; Acc: 0.9231\n",
      "           Label 2 loss: 21.8913 ; P: 0.7483 ; R: 0.7801 ; F1: 0.7639 ; Acc: 0.7589\n",
      "2023-01-29 13:31:19.787516\n",
      "counter:  0\n",
      "2023-01-29 13:31:21.438766\n",
      "EPOCH 132\n",
      "TAG_LOSS_WEIGHT:  0.21593652168747693\n",
      "CLS_LOSS_WEIGHT:  0.7840634783125231\n",
      "tp:  1105\n",
      "fn:  217\n",
      "tn:  1068\n",
      "fp:  254\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2173\n",
      "tp:  440\n",
      "fn:  124\n",
      "tn:  414\n",
      "fp:  150\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  854\n",
      "EPOCH 132\n",
      "   TRAIN | Label 1 loss: 10.9235 ; P: 0.8635 ; R: 0.8543 ; F1: 0.8589 ; Acc: 0.9483\n",
      "           Label 2 loss: 39.7167 ; P: 0.8131 ; R: 0.8359 ; F1: 0.8243 ; Acc: 0.8219\n",
      "    TEST | Label 1 loss: 7.1383 ; P: 0.7878 ; R: 0.8336 ; F1: 0.8101 ; Acc: 0.9232\n",
      "           Label 2 loss: 21.8599 ; P: 0.7458 ; R: 0.7801 ; F1: 0.7626 ; Acc: 0.7571\n",
      "2023-01-29 13:31:53.142370\n",
      "counter:  1\n",
      "2023-01-29 13:31:53.142370\n",
      "EPOCH 133\n",
      "TAG_LOSS_WEIGHT:  0.2045072549391609\n",
      "CLS_LOSS_WEIGHT:  0.795492745060839\n",
      "tp:  1118\n",
      "fn:  204\n",
      "tn:  1102\n",
      "fp:  220\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2220\n",
      "tp:  435\n",
      "fn:  129\n",
      "tn:  418\n",
      "fp:  146\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  853\n",
      "EPOCH 133\n",
      "   TRAIN | Label 1 loss: 11.0856 ; P: 0.8641 ; R: 0.8536 ; F1: 0.8589 ; Acc: 0.9483\n",
      "           Label 2 loss: 38.5986 ; P: 0.8356 ; R: 0.8457 ; F1: 0.8406 ; Acc: 0.8396\n",
      "    TEST | Label 1 loss: 7.1795 ; P: 0.7862 ; R: 0.8349 ; F1: 0.8098 ; Acc: 0.9229\n",
      "           Label 2 loss: 21.9773 ; P: 0.7487 ; R: 0.7713 ; F1: 0.7598 ; Acc: 0.7562\n",
      "2023-01-29 13:32:25.315405\n",
      "counter:  2\n",
      "2023-01-29 13:32:25.316405\n",
      "EPOCH 134\n",
      "TAG_LOSS_WEIGHT:  0.21895172177262237\n",
      "CLS_LOSS_WEIGHT:  0.7810482782273778\n",
      "tp:  1120\n",
      "fn:  202\n",
      "tn:  1088\n",
      "fp:  234\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2208\n",
      "tp:  435\n",
      "fn:  129\n",
      "tn:  418\n",
      "fp:  146\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  853\n",
      "EPOCH 134\n",
      "   TRAIN | Label 1 loss: 10.9618 ; P: 0.8635 ; R: 0.8589 ; F1: 0.8612 ; Acc: 0.949\n",
      "           Label 2 loss: 38.7909 ; P: 0.8272 ; R: 0.8472 ; F1: 0.8371 ; Acc: 0.8351\n",
      "    TEST | Label 1 loss: 7.1218 ; P: 0.7878 ; R: 0.8336 ; F1: 0.8101 ; Acc: 0.9232\n",
      "           Label 2 loss: 21.9471 ; P: 0.7487 ; R: 0.7713 ; F1: 0.7598 ; Acc: 0.7562\n",
      "2023-01-29 13:32:56.451471\n",
      "counter:  3\n",
      "2023-01-29 13:32:56.452471\n",
      "EPOCH 135\n",
      "TAG_LOSS_WEIGHT:  0.21346136388082557\n",
      "CLS_LOSS_WEIGHT:  0.7865386361191744\n",
      "tp:  1123\n",
      "fn:  199\n",
      "tn:  1108\n",
      "fp:  214\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2231\n",
      "tp:  434\n",
      "fn:  130\n",
      "tn:  420\n",
      "fp:  144\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  854\n",
      "EPOCH 135\n",
      "   TRAIN | Label 1 loss: 11.0184 ; P: 0.8662 ; R: 0.8591 ; F1: 0.8626 ; Acc: 0.9496\n",
      "           Label 2 loss: 38.36 ; P: 0.8399 ; R: 0.8495 ; F1: 0.8447 ; Acc: 0.8438\n",
      "    TEST | Label 1 loss: 7.1202 ; P: 0.7883 ; R: 0.8336 ; F1: 0.8103 ; Acc: 0.9233\n",
      "           Label 2 loss: 21.9438 ; P: 0.7509 ; R: 0.7695 ; F1: 0.7601 ; Acc: 0.7571\n",
      "2023-01-29 13:33:27.110651\n",
      "counter:  4\n",
      "2023-01-29 13:33:27.110651\n",
      "EPOCH 136\n",
      "TAG_LOSS_WEIGHT:  0.21899290085971773\n",
      "CLS_LOSS_WEIGHT:  0.7810070991402822\n",
      "tp:  1129\n",
      "fn:  193\n",
      "tn:  1093\n",
      "fp:  229\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2222\n",
      "tp:  434\n",
      "fn:  130\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  853\n",
      "EPOCH 136\n",
      "   TRAIN | Label 1 loss: 10.755 ; P: 0.87 ; R: 0.8627 ; F1: 0.8664 ; Acc: 0.951\n",
      "           Label 2 loss: 38.1892 ; P: 0.8314 ; R: 0.854 ; F1: 0.8425 ; Acc: 0.8404\n",
      "    TEST | Label 1 loss: 7.1166 ; P: 0.7892 ; R: 0.8336 ; F1: 0.8108 ; Acc: 0.9236\n",
      "           Label 2 loss: 21.9123 ; P: 0.7496 ; R: 0.7695 ; F1: 0.7594 ; Acc: 0.7562\n",
      "2023-01-29 13:33:58.244543\n",
      "counter:  5\n",
      "2023-01-29 13:33:58.244543\n",
      "EPOCH 137\n",
      "TAG_LOSS_WEIGHT:  0.21231761398036844\n",
      "CLS_LOSS_WEIGHT:  0.7876823860196315\n",
      "tp:  1113\n",
      "fn:  209\n",
      "tn:  1110\n",
      "fp:  212\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2223\n",
      "tp:  430\n",
      "fn:  134\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  849\n",
      "EPOCH 137\n",
      "   TRAIN | Label 1 loss: 10.9507 ; P: 0.8704 ; R: 0.8592 ; F1: 0.8648 ; Acc: 0.9505\n",
      "           Label 2 loss: 38.2297 ; P: 0.84 ; R: 0.8419 ; F1: 0.841 ; Acc: 0.8408\n",
      "    TEST | Label 1 loss: 7.2016 ; P: 0.7855 ; R: 0.8318 ; F1: 0.808 ; Acc: 0.9223\n",
      "           Label 2 loss: 22.0265 ; P: 0.7478 ; R: 0.7624 ; F1: 0.755 ; Acc: 0.7527\n",
      "2023-01-29 13:34:29.855432\n",
      "counter:  6\n",
      "2023-01-29 13:34:29.856432\n",
      "EPOCH 138\n",
      "TAG_LOSS_WEIGHT:  0.21805002307709995\n",
      "CLS_LOSS_WEIGHT:  0.7819499769228999\n",
      "tp:  1123\n",
      "fn:  199\n",
      "tn:  1119\n",
      "fp:  203\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2242\n",
      "tp:  433\n",
      "fn:  131\n",
      "tn:  418\n",
      "fp:  146\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  851\n",
      "EPOCH 138\n",
      "   TRAIN | Label 1 loss: 10.9243 ; P: 0.8667 ; R: 0.8626 ; F1: 0.8646 ; Acc: 0.9502\n",
      "           Label 2 loss: 37.8653 ; P: 0.8469 ; R: 0.8495 ; F1: 0.8482 ; Acc: 0.848\n",
      "    TEST | Label 1 loss: 7.1593 ; P: 0.79 ; R: 0.828 ; F1: 0.8085 ; Acc: 0.9229\n",
      "           Label 2 loss: 22.0306 ; P: 0.7478 ; R: 0.7677 ; F1: 0.7577 ; Acc: 0.7544\n",
      "2023-01-29 13:35:01.064087\n",
      "counter:  7\n",
      "2023-01-29 13:35:01.065079\n",
      "EPOCH 139\n",
      "TAG_LOSS_WEIGHT:  0.220502826143402\n",
      "CLS_LOSS_WEIGHT:  0.7794971738565981\n",
      "tp:  1121\n",
      "fn:  201\n",
      "tn:  1125\n",
      "fp:  197\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2246\n",
      "tp:  434\n",
      "fn:  130\n",
      "tn:  417\n",
      "fp:  147\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  851\n",
      "EPOCH 139\n",
      "   TRAIN | Label 1 loss: 10.63 ; P: 0.8721 ; R: 0.8644 ; F1: 0.8682 ; Acc: 0.9517\n",
      "           Label 2 loss: 37.2349 ; P: 0.8505 ; R: 0.848 ; F1: 0.8492 ; Acc: 0.8495\n",
      "    TEST | Label 1 loss: 7.1866 ; P: 0.7869 ; R: 0.8292 ; F1: 0.8075 ; Acc: 0.9223\n",
      "           Label 2 loss: 22.0639 ; P: 0.747 ; R: 0.7695 ; F1: 0.7581 ; Acc: 0.7544\n",
      "2023-01-29 13:35:31.962875\n",
      "counter:  8\n",
      "2023-01-29 13:35:31.962875\n",
      "EPOCH 140\n",
      "TAG_LOSS_WEIGHT:  0.21690743120656375\n",
      "CLS_LOSS_WEIGHT:  0.7830925687934363\n",
      "tp:  1142\n",
      "fn:  180\n",
      "tn:  1100\n",
      "fp:  222\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2242\n",
      "tp:  433\n",
      "fn:  131\n",
      "tn:  421\n",
      "fp:  143\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  854\n",
      "EPOCH 140\n",
      "   TRAIN | Label 1 loss: 10.5403 ; P: 0.8722 ; R: 0.8682 ; F1: 0.8702 ; Acc: 0.9523\n",
      "           Label 2 loss: 37.0385 ; P: 0.8372 ; R: 0.8638 ; F1: 0.8503 ; Acc: 0.848\n",
      "    TEST | Label 1 loss: 7.2081 ; P: 0.7887 ; R: 0.8286 ; F1: 0.8081 ; Acc: 0.9227\n",
      "           Label 2 loss: 22.1014 ; P: 0.7517 ; R: 0.7677 ; F1: 0.7596 ; Acc: 0.7571\n",
      "2023-01-29 13:36:02.991828\n",
      "counter:  9\n",
      "2023-01-29 13:36:02.992820\n",
      "EPOCH 141\n",
      "TAG_LOSS_WEIGHT:  0.2158271783430204\n",
      "CLS_LOSS_WEIGHT:  0.7841728216569795\n",
      "tp:  1111\n",
      "fn:  211\n",
      "tn:  1125\n",
      "fp:  197\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2236\n",
      "tp:  433\n",
      "fn:  131\n",
      "tn:  420\n",
      "fp:  144\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  853\n",
      "EPOCH 141\n",
      "   TRAIN | Label 1 loss: 10.5902 ; P: 0.8746 ; R: 0.8647 ; F1: 0.8696 ; Acc: 0.9522\n",
      "           Label 2 loss: 37.4546 ; P: 0.8494 ; R: 0.8404 ; F1: 0.8449 ; Acc: 0.8457\n",
      "    TEST | Label 1 loss: 7.2323 ; P: 0.7879 ; R: 0.8292 ; F1: 0.808 ; Acc: 0.9226\n",
      "           Label 2 loss: 22.1256 ; P: 0.7504 ; R: 0.7677 ; F1: 0.759 ; Acc: 0.7562\n",
      "2023-01-29 13:36:33.626467\n",
      "counter:  10\n",
      "2023-01-29 13:36:33.627467\n",
      "EPOCH 142\n",
      "TAG_LOSS_WEIGHT:  0.21365238848186693\n",
      "CLS_LOSS_WEIGHT:  0.786347611518133\n",
      "tp:  1121\n",
      "fn:  201\n",
      "tn:  1120\n",
      "fp:  202\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2241\n",
      "tp:  432\n",
      "fn:  132\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  851\n",
      "EPOCH 142\n",
      "   TRAIN | Label 1 loss: 10.5599 ; P: 0.8722 ; R: 0.8634 ; F1: 0.8678 ; Acc: 0.9515\n",
      "           Label 2 loss: 37.7394 ; P: 0.8473 ; R: 0.848 ; F1: 0.8476 ; Acc: 0.8476\n",
      "    TEST | Label 1 loss: 7.2225 ; P: 0.7872 ; R: 0.8305 ; F1: 0.8082 ; Acc: 0.9226\n",
      "           Label 2 loss: 22.0743 ; P: 0.7487 ; R: 0.766 ; F1: 0.7572 ; Acc: 0.7544\n",
      "2023-01-29 13:37:04.411563\n",
      "counter:  11\n",
      "2023-01-29 13:37:04.411563\n",
      "EPOCH 143\n",
      "TAG_LOSS_WEIGHT:  0.21016530354815066\n",
      "CLS_LOSS_WEIGHT:  0.7898346964518494\n",
      "tp:  1121\n",
      "fn:  201\n",
      "tn:  1112\n",
      "fp:  210\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2233\n",
      "tp:  432\n",
      "fn:  132\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  851\n",
      "EPOCH 143\n",
      "   TRAIN | Label 1 loss: 10.554 ; P: 0.8725 ; R: 0.8658 ; F1: 0.8691 ; Acc: 0.952\n",
      "           Label 2 loss: 37.774 ; P: 0.8422 ; R: 0.848 ; F1: 0.8451 ; Acc: 0.8446\n",
      "    TEST | Label 1 loss: 7.2142 ; P: 0.7885 ; R: 0.8299 ; F1: 0.8086 ; Acc: 0.9228\n",
      "           Label 2 loss: 22.0675 ; P: 0.7487 ; R: 0.766 ; F1: 0.7572 ; Acc: 0.7544\n",
      "2023-01-29 13:37:35.610503\n",
      "counter:  12\n",
      "2023-01-29 13:37:35.611504\n",
      "EPOCH 144\n",
      "TAG_LOSS_WEIGHT:  0.2096759459027365\n",
      "CLS_LOSS_WEIGHT:  0.7903240540972635\n",
      "tp:  1129\n",
      "fn:  193\n",
      "tn:  1100\n",
      "fp:  222\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2229\n",
      "tp:  432\n",
      "fn:  132\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  851\n",
      "EPOCH 144\n",
      "   TRAIN | Label 1 loss: 10.8314 ; P: 0.8679 ; R: 0.8645 ; F1: 0.8662 ; Acc: 0.9508\n",
      "           Label 2 loss: 37.6249 ; P: 0.8357 ; R: 0.854 ; F1: 0.8447 ; Acc: 0.843\n",
      "    TEST | Label 1 loss: 7.2061 ; P: 0.7884 ; R: 0.8318 ; F1: 0.8095 ; Acc: 0.9231\n",
      "           Label 2 loss: 22.0505 ; P: 0.7487 ; R: 0.766 ; F1: 0.7572 ; Acc: 0.7544\n",
      "2023-01-29 13:38:06.734858\n",
      "counter:  13\n",
      "2023-01-29 13:38:06.734858\n",
      "EPOCH 145\n",
      "TAG_LOSS_WEIGHT:  0.21975732636208653\n",
      "CLS_LOSS_WEIGHT:  0.7802426736379136\n",
      "tp:  1123\n",
      "fn:  199\n",
      "tn:  1125\n",
      "fp:  197\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2248\n",
      "tp:  432\n",
      "fn:  132\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  851\n",
      "EPOCH 145\n",
      "   TRAIN | Label 1 loss: 10.5014 ; P: 0.8749 ; R: 0.8693 ; F1: 0.8721 ; Acc: 0.953\n",
      "           Label 2 loss: 37.3567 ; P: 0.8508 ; R: 0.8495 ; F1: 0.8501 ; Acc: 0.8502\n",
      "    TEST | Label 1 loss: 7.21 ; P: 0.7891 ; R: 0.8305 ; F1: 0.8092 ; Acc: 0.9231\n",
      "           Label 2 loss: 22.0658 ; P: 0.7487 ; R: 0.766 ; F1: 0.7572 ; Acc: 0.7544\n",
      "2023-01-29 13:38:37.819596\n",
      "counter:  14\n",
      "2023-01-29 13:38:37.820595\n",
      "EPOCH 146\n",
      "TAG_LOSS_WEIGHT:  0.2117089320656402\n",
      "CLS_LOSS_WEIGHT:  0.7882910679343598\n",
      "tp:  1130\n",
      "fn:  192\n",
      "tn:  1115\n",
      "fp:  207\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2245\n",
      "tp:  433\n",
      "fn:  131\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  852\n",
      "EPOCH 146\n",
      "   TRAIN | Label 1 loss: 10.4324 ; P: 0.8715 ; R: 0.8659 ; F1: 0.8687 ; Acc: 0.9518\n",
      "           Label 2 loss: 37.2812 ; P: 0.8452 ; R: 0.8548 ; F1: 0.8499 ; Acc: 0.8491\n",
      "    TEST | Label 1 loss: 7.2091 ; P: 0.7887 ; R: 0.8311 ; F1: 0.8094 ; Acc: 0.9231\n",
      "           Label 2 loss: 22.0655 ; P: 0.7491 ; R: 0.7677 ; F1: 0.7583 ; Acc: 0.7553\n",
      "2023-01-29 13:39:09.124483\n",
      "counter:  15\n",
      "2023-01-29 13:39:09.125483\n",
      "EPOCH 147\n",
      "TAG_LOSS_WEIGHT:  0.2101878808341289\n",
      "CLS_LOSS_WEIGHT:  0.789812119165871\n",
      "tp:  1114\n",
      "fn:  208\n",
      "tn:  1113\n",
      "fp:  209\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2227\n",
      "tp:  433\n",
      "fn:  131\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  852\n",
      "EPOCH 147\n",
      "   TRAIN | Label 1 loss: 10.4822 ; P: 0.8712 ; R: 0.8697 ; F1: 0.8704 ; Acc: 0.9523\n",
      "           Label 2 loss: 37.5589 ; P: 0.842 ; R: 0.8427 ; F1: 0.8423 ; Acc: 0.8423\n",
      "    TEST | Label 1 loss: 7.2092 ; P: 0.7887 ; R: 0.8311 ; F1: 0.8094 ; Acc: 0.9231\n",
      "           Label 2 loss: 22.0663 ; P: 0.7491 ; R: 0.7677 ; F1: 0.7583 ; Acc: 0.7553\n",
      "2023-01-29 13:39:39.755999\n",
      "counter:  16\n",
      "2023-01-29 13:39:39.757010\n",
      "EPOCH 148\n",
      "TAG_LOSS_WEIGHT:  0.20930642024615984\n",
      "CLS_LOSS_WEIGHT:  0.7906935797538402\n",
      "tp:  1129\n",
      "fn:  193\n",
      "tn:  1116\n",
      "fp:  206\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2245\n",
      "tp:  433\n",
      "fn:  131\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  852\n",
      "EPOCH 148\n",
      "   TRAIN | Label 1 loss: 10.4815 ; P: 0.8755 ; R: 0.8676 ; F1: 0.8715 ; Acc: 0.9529\n",
      "           Label 2 loss: 37.3198 ; P: 0.8457 ; R: 0.854 ; F1: 0.8498 ; Acc: 0.8491\n",
      "    TEST | Label 1 loss: 7.2122 ; P: 0.7887 ; R: 0.8311 ; F1: 0.8094 ; Acc: 0.9231\n",
      "           Label 2 loss: 22.066 ; P: 0.7491 ; R: 0.7677 ; F1: 0.7583 ; Acc: 0.7553\n",
      "2023-01-29 13:40:10.698654\n",
      "counter:  17\n",
      "2023-01-29 13:40:10.698654\n",
      "EPOCH 149\n",
      "TAG_LOSS_WEIGHT:  0.21140584813775995\n",
      "CLS_LOSS_WEIGHT:  0.7885941518622401\n",
      "tp:  1137\n",
      "fn:  185\n",
      "tn:  1129\n",
      "fp:  193\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2266\n",
      "tp:  433\n",
      "fn:  131\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  852\n",
      "EPOCH 149\n",
      "   TRAIN | Label 1 loss: 10.6354 ; P: 0.8699 ; R: 0.8636 ; F1: 0.8667 ; Acc: 0.9511\n",
      "           Label 2 loss: 36.5088 ; P: 0.8549 ; R: 0.8601 ; F1: 0.8575 ; Acc: 0.857\n",
      "    TEST | Label 1 loss: 7.2169 ; P: 0.7887 ; R: 0.8311 ; F1: 0.8094 ; Acc: 0.9231\n",
      "           Label 2 loss: 22.0714 ; P: 0.7491 ; R: 0.7677 ; F1: 0.7583 ; Acc: 0.7553\n",
      "2023-01-29 13:40:41.393350\n",
      "counter:  18\n",
      "2023-01-29 13:40:41.394350\n",
      "EPOCH 150\n",
      "TAG_LOSS_WEIGHT:  0.2238485142492139\n",
      "CLS_LOSS_WEIGHT:  0.7761514857507861\n",
      "tp:  1134\n",
      "fn:  188\n",
      "tn:  1117\n",
      "fp:  205\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2251\n",
      "tp:  433\n",
      "fn:  131\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  852\n",
      "EPOCH 150\n",
      "   TRAIN | Label 1 loss: 10.5745 ; P: 0.8734 ; R: 0.8652 ; F1: 0.8693 ; Acc: 0.9521\n",
      "           Label 2 loss: 37.3176 ; P: 0.8469 ; R: 0.8578 ; F1: 0.8523 ; Acc: 0.8514\n",
      "    TEST | Label 1 loss: 7.2152 ; P: 0.7887 ; R: 0.8311 ; F1: 0.8094 ; Acc: 0.9231\n",
      "           Label 2 loss: 22.0678 ; P: 0.7491 ; R: 0.7677 ; F1: 0.7583 ; Acc: 0.7553\n",
      "2023-01-29 13:41:12.431755\n",
      "counter:  19\n",
      "2023-01-29 13:41:12.431755\n",
      "EPOCH 151\n",
      "TAG_LOSS_WEIGHT:  0.21438609632673042\n",
      "CLS_LOSS_WEIGHT:  0.7856139036732696\n",
      "tp:  1133\n",
      "fn:  189\n",
      "tn:  1115\n",
      "fp:  207\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2248\n",
      "tp:  433\n",
      "fn:  131\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  852\n",
      "EPOCH 151\n",
      "   TRAIN | Label 1 loss: 10.619 ; P: 0.8714 ; R: 0.8637 ; F1: 0.8675 ; Acc: 0.9514\n",
      "           Label 2 loss: 37.1069 ; P: 0.8455 ; R: 0.857 ; F1: 0.8512 ; Acc: 0.8502\n",
      "    TEST | Label 1 loss: 7.2127 ; P: 0.7887 ; R: 0.8311 ; F1: 0.8094 ; Acc: 0.9231\n",
      "           Label 2 loss: 22.0683 ; P: 0.7491 ; R: 0.7677 ; F1: 0.7583 ; Acc: 0.7553\n",
      "2023-01-29 13:41:43.062385\n",
      "counter:  20\n",
      "2023-01-29 13:41:43.062385\n",
      "EPOCH 152\n",
      "TAG_LOSS_WEIGHT:  0.2177266584876542\n",
      "CLS_LOSS_WEIGHT:  0.7822733415123458\n",
      "tp:  1114\n",
      "fn:  208\n",
      "tn:  1106\n",
      "fp:  216\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2220\n",
      "tp:  433\n",
      "fn:  131\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  852\n",
      "EPOCH 152\n",
      "   TRAIN | Label 1 loss: 10.6861 ; P: 0.8752 ; R: 0.862 ; F1: 0.8686 ; Acc: 0.9519\n",
      "           Label 2 loss: 38.0641 ; P: 0.8376 ; R: 0.8427 ; F1: 0.8401 ; Acc: 0.8396\n",
      "    TEST | Label 1 loss: 7.2166 ; P: 0.7887 ; R: 0.8311 ; F1: 0.8094 ; Acc: 0.9231\n",
      "           Label 2 loss: 22.0698 ; P: 0.7491 ; R: 0.7677 ; F1: 0.7583 ; Acc: 0.7553\n",
      "2023-01-29 13:42:14.087518\n",
      "counter:  21\n",
      "2023-01-29 13:42:14.087518\n",
      "EPOCH 153\n",
      "TAG_LOSS_WEIGHT:  0.21126733228450922\n",
      "CLS_LOSS_WEIGHT:  0.7887326677154908\n",
      "tp:  1136\n",
      "fn:  186\n",
      "tn:  1114\n",
      "fp:  208\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2250\n",
      "tp:  433\n",
      "fn:  131\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  852\n",
      "EPOCH 153\n",
      "   TRAIN | Label 1 loss: 10.8057 ; P: 0.8718 ; R: 0.8609 ; F1: 0.8663 ; Acc: 0.951\n",
      "           Label 2 loss: 37.3194 ; P: 0.8452 ; R: 0.8593 ; F1: 0.8522 ; Acc: 0.851\n",
      "    TEST | Label 1 loss: 7.2102 ; P: 0.7887 ; R: 0.8311 ; F1: 0.8094 ; Acc: 0.9231\n",
      "           Label 2 loss: 22.0658 ; P: 0.7491 ; R: 0.7677 ; F1: 0.7583 ; Acc: 0.7553\n",
      "2023-01-29 13:42:45.271467\n",
      "counter:  22\n",
      "2023-01-29 13:42:45.272466\n",
      "EPOCH 154\n",
      "TAG_LOSS_WEIGHT:  0.22174490978918865\n",
      "CLS_LOSS_WEIGHT:  0.7782550902108113\n",
      "tp:  1115\n",
      "fn:  207\n",
      "tn:  1121\n",
      "fp:  201\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2236\n",
      "tp:  432\n",
      "fn:  132\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  851\n",
      "EPOCH 154\n",
      "   TRAIN | Label 1 loss: 10.3267 ; P: 0.8769 ; R: 0.8731 ; F1: 0.875 ; Acc: 0.954\n",
      "           Label 2 loss: 37.5203 ; P: 0.8473 ; R: 0.8434 ; F1: 0.8453 ; Acc: 0.8457\n",
      "    TEST | Label 1 loss: 7.2106 ; P: 0.7887 ; R: 0.8311 ; F1: 0.8094 ; Acc: 0.9231\n",
      "           Label 2 loss: 22.0639 ; P: 0.7487 ; R: 0.766 ; F1: 0.7572 ; Acc: 0.7544\n",
      "2023-01-29 13:43:15.838296\n",
      "counter:  23\n",
      "2023-01-29 13:43:15.840317\n",
      "EPOCH 155\n",
      "TAG_LOSS_WEIGHT:  0.20473705306865972\n",
      "CLS_LOSS_WEIGHT:  0.7952629469313404\n",
      "tp:  1129\n",
      "fn:  193\n",
      "tn:  1112\n",
      "fp:  210\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2241\n",
      "tp:  432\n",
      "fn:  132\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  851\n",
      "EPOCH 155\n",
      "   TRAIN | Label 1 loss: 10.4217 ; P: 0.8782 ; R: 0.8651 ; F1: 0.8716 ; Acc: 0.9531\n",
      "           Label 2 loss: 36.9884 ; P: 0.8432 ; R: 0.854 ; F1: 0.8486 ; Acc: 0.8476\n",
      "    TEST | Label 1 loss: 7.2194 ; P: 0.7887 ; R: 0.8311 ; F1: 0.8094 ; Acc: 0.9231\n",
      "           Label 2 loss: 22.0658 ; P: 0.7487 ; R: 0.766 ; F1: 0.7572 ; Acc: 0.7544\n",
      "2023-01-29 13:43:46.406626\n",
      "counter:  24\n",
      "2023-01-29 13:43:46.406626\n",
      "EPOCH 156\n",
      "TAG_LOSS_WEIGHT:  0.2124741285200701\n",
      "CLS_LOSS_WEIGHT:  0.7875258714799298\n",
      "tp:  1136\n",
      "fn:  186\n",
      "tn:  1118\n",
      "fp:  204\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2254\n",
      "tp:  432\n",
      "fn:  132\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  851\n",
      "EPOCH 156\n",
      "   TRAIN | Label 1 loss: 10.619 ; P: 0.8716 ; R: 0.8636 ; F1: 0.8676 ; Acc: 0.9514\n",
      "           Label 2 loss: 37.3436 ; P: 0.8478 ; R: 0.8593 ; F1: 0.8535 ; Acc: 0.8525\n",
      "    TEST | Label 1 loss: 7.2182 ; P: 0.7901 ; R: 0.8311 ; F1: 0.8101 ; Acc: 0.9234\n",
      "           Label 2 loss: 22.067 ; P: 0.7487 ; R: 0.766 ; F1: 0.7572 ; Acc: 0.7544\n",
      "2023-01-29 13:44:17.647523\n",
      "counter:  25\n",
      "2023-01-29 13:44:17.648518\n",
      "EPOCH 157\n",
      "TAG_LOSS_WEIGHT:  0.2155684162355722\n",
      "CLS_LOSS_WEIGHT:  0.7844315837644277\n",
      "tp:  1117\n",
      "fn:  205\n",
      "tn:  1126\n",
      "fp:  196\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2243\n",
      "tp:  432\n",
      "fn:  132\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  851\n",
      "EPOCH 157\n",
      "   TRAIN | Label 1 loss: 10.5155 ; P: 0.874 ; R: 0.8706 ; F1: 0.8723 ; Acc: 0.953\n",
      "           Label 2 loss: 37.5505 ; P: 0.8507 ; R: 0.8449 ; F1: 0.8478 ; Acc: 0.8483\n",
      "    TEST | Label 1 loss: 7.2299 ; P: 0.7882 ; R: 0.8311 ; F1: 0.8091 ; Acc: 0.9229\n",
      "           Label 2 loss: 22.0713 ; P: 0.7487 ; R: 0.766 ; F1: 0.7572 ; Acc: 0.7544\n",
      "2023-01-29 13:44:48.594876\n",
      "counter:  26\n",
      "2023-01-29 13:44:48.594876\n",
      "EPOCH 158\n",
      "TAG_LOSS_WEIGHT:  0.2104325149144906\n",
      "CLS_LOSS_WEIGHT:  0.7895674850855093\n",
      "tp:  1123\n",
      "fn:  199\n",
      "tn:  1119\n",
      "fp:  203\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2242\n",
      "tp:  432\n",
      "fn:  132\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  851\n",
      "EPOCH 158\n",
      "   TRAIN | Label 1 loss: 10.2631 ; P: 0.8764 ; R: 0.8671 ; F1: 0.8717 ; Acc: 0.953\n",
      "           Label 2 loss: 37.0425 ; P: 0.8469 ; R: 0.8495 ; F1: 0.8482 ; Acc: 0.848\n",
      "    TEST | Label 1 loss: 7.2349 ; P: 0.7881 ; R: 0.8305 ; F1: 0.8087 ; Acc: 0.9228\n",
      "           Label 2 loss: 22.0693 ; P: 0.7487 ; R: 0.766 ; F1: 0.7572 ; Acc: 0.7544\n",
      "2023-01-29 13:45:19.092084\n",
      "counter:  27\n",
      "2023-01-29 13:45:19.092084\n",
      "EPOCH 159\n",
      "TAG_LOSS_WEIGHT:  0.2069072485724291\n",
      "CLS_LOSS_WEIGHT:  0.7930927514275707\n",
      "tp:  1138\n",
      "fn:  184\n",
      "tn:  1104\n",
      "fp:  218\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2242\n",
      "tp:  432\n",
      "fn:  132\n",
      "tn:  420\n",
      "fp:  144\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  852\n",
      "EPOCH 159\n",
      "   TRAIN | Label 1 loss: 10.6464 ; P: 0.8729 ; R: 0.8647 ; F1: 0.8688 ; Acc: 0.9519\n",
      "           Label 2 loss: 37.5959 ; P: 0.8392 ; R: 0.8608 ; F1: 0.8499 ; Acc: 0.848\n",
      "    TEST | Label 1 loss: 7.2243 ; P: 0.788 ; R: 0.8299 ; F1: 0.8084 ; Acc: 0.9227\n",
      "           Label 2 loss: 22.0548 ; P: 0.75 ; R: 0.766 ; F1: 0.7579 ; Acc: 0.7553\n",
      "2023-01-29 13:45:49.849688\n",
      "counter:  28\n",
      "2023-01-29 13:45:49.850689\n",
      "EPOCH 160\n",
      "TAG_LOSS_WEIGHT:  0.21416602307994528\n",
      "CLS_LOSS_WEIGHT:  0.7858339769200547\n",
      "tp:  1139\n",
      "fn:  183\n",
      "tn:  1110\n",
      "fp:  212\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2249\n",
      "tp:  432\n",
      "fn:  132\n",
      "tn:  420\n",
      "fp:  144\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  852\n",
      "EPOCH 160\n",
      "   TRAIN | Label 1 loss: 10.6492 ; P: 0.8722 ; R: 0.8679 ; F1: 0.87 ; Acc: 0.9522\n",
      "           Label 2 loss: 37.4745 ; P: 0.8431 ; R: 0.8616 ; F1: 0.8522 ; Acc: 0.8506\n",
      "    TEST | Label 1 loss: 7.2047 ; P: 0.7893 ; R: 0.8292 ; F1: 0.8088 ; Acc: 0.9229\n",
      "           Label 2 loss: 22.0159 ; P: 0.75 ; R: 0.766 ; F1: 0.7579 ; Acc: 0.7553\n",
      "2023-01-29 13:46:21.198705\n",
      "counter:  29\n",
      "2023-01-29 13:46:21.198705\n",
      "EPOCH 161\n",
      "TAG_LOSS_WEIGHT:  0.21534554855126423\n",
      "CLS_LOSS_WEIGHT:  0.7846544514487357\n",
      "tp:  1122\n",
      "fn:  200\n",
      "tn:  1126\n",
      "fp:  196\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2248\n",
      "tp:  432\n",
      "fn:  132\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  851\n",
      "EPOCH 161\n",
      "   TRAIN | Label 1 loss: 10.3896 ; P: 0.8723 ; R: 0.8682 ; F1: 0.8702 ; Acc: 0.9523\n",
      "           Label 2 loss: 37.2843 ; P: 0.8513 ; R: 0.8487 ; F1: 0.85 ; Acc: 0.8502\n",
      "    TEST | Label 1 loss: 7.2316 ; P: 0.7898 ; R: 0.8292 ; F1: 0.809 ; Acc: 0.9231\n",
      "           Label 2 loss: 22.0555 ; P: 0.7487 ; R: 0.766 ; F1: 0.7572 ; Acc: 0.7544\n",
      "2023-01-29 13:46:52.330186\n",
      "counter:  30\n",
      "2023-01-29 13:46:52.331187\n",
      "EPOCH 162\n",
      "TAG_LOSS_WEIGHT:  0.20879871988257273\n",
      "CLS_LOSS_WEIGHT:  0.7912012801174273\n",
      "tp:  1137\n",
      "fn:  185\n",
      "tn:  1127\n",
      "fp:  195\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2264\n",
      "tp:  432\n",
      "fn:  132\n",
      "tn:  420\n",
      "fp:  144\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  852\n",
      "EPOCH 162\n",
      "   TRAIN | Label 1 loss: 10.5091 ; P: 0.8727 ; R: 0.8676 ; F1: 0.8702 ; Acc: 0.9523\n",
      "           Label 2 loss: 37.1067 ; P: 0.8536 ; R: 0.8601 ; F1: 0.8568 ; Acc: 0.8563\n",
      "    TEST | Label 1 loss: 7.2139 ; P: 0.7908 ; R: 0.8299 ; F1: 0.8099 ; Acc: 0.9234\n",
      "           Label 2 loss: 22.0289 ; P: 0.75 ; R: 0.766 ; F1: 0.7579 ; Acc: 0.7553\n",
      "2023-01-29 13:47:22.435432\n",
      "counter:  31\n",
      "2023-01-29 13:47:22.435432\n",
      "EPOCH 163\n",
      "TAG_LOSS_WEIGHT:  0.21420547406694043\n",
      "CLS_LOSS_WEIGHT:  0.7857945259330595\n",
      "tp:  1133\n",
      "fn:  189\n",
      "tn:  1115\n",
      "fp:  207\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2248\n",
      "tp:  432\n",
      "fn:  132\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  851\n",
      "EPOCH 163\n",
      "   TRAIN | Label 1 loss: 10.5292 ; P: 0.8703 ; R: 0.8694 ; F1: 0.8699 ; Acc: 0.9521\n",
      "           Label 2 loss: 37.2394 ; P: 0.8455 ; R: 0.857 ; F1: 0.8512 ; Acc: 0.8502\n",
      "    TEST | Label 1 loss: 7.1994 ; P: 0.7917 ; R: 0.8318 ; F1: 0.8112 ; Acc: 0.9239\n",
      "           Label 2 loss: 21.9932 ; P: 0.7487 ; R: 0.766 ; F1: 0.7572 ; Acc: 0.7544\n",
      "2023-01-29 13:47:53.358182\n",
      "counter:  32\n",
      "2023-01-29 13:47:53.359179\n",
      "EPOCH 164\n",
      "TAG_LOSS_WEIGHT:  0.2136475153558158\n",
      "CLS_LOSS_WEIGHT:  0.7863524846441843\n",
      "tp:  1134\n",
      "fn:  188\n",
      "tn:  1115\n",
      "fp:  207\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2249\n",
      "tp:  432\n",
      "fn:  132\n",
      "tn:  420\n",
      "fp:  144\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  852\n",
      "EPOCH 164\n",
      "   TRAIN | Label 1 loss: 10.3974 ; P: 0.8757 ; R: 0.8713 ; F1: 0.8735 ; Acc: 0.9535\n",
      "           Label 2 loss: 36.9682 ; P: 0.8456 ; R: 0.8578 ; F1: 0.8517 ; Acc: 0.8506\n",
      "    TEST | Label 1 loss: 7.2039 ; P: 0.7904 ; R: 0.8349 ; F1: 0.8121 ; Acc: 0.9241\n",
      "           Label 2 loss: 22.0328 ; P: 0.75 ; R: 0.766 ; F1: 0.7579 ; Acc: 0.7553\n",
      "2023-01-29 13:48:24.256306\n",
      "counter:  33\n",
      "2023-01-29 13:48:24.256306\n",
      "EPOCH 165\n",
      "TAG_LOSS_WEIGHT:  0.21187633243515042\n",
      "CLS_LOSS_WEIGHT:  0.7881236675648495\n",
      "tp:  1131\n",
      "fn:  191\n",
      "tn:  1103\n",
      "fp:  219\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2234\n",
      "tp:  432\n",
      "fn:  132\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  851\n",
      "EPOCH 165\n",
      "   TRAIN | Label 1 loss: 10.4787 ; P: 0.8718 ; R: 0.868 ; F1: 0.8699 ; Acc: 0.9522\n",
      "           Label 2 loss: 37.7646 ; P: 0.8378 ; R: 0.8555 ; F1: 0.8466 ; Acc: 0.8449\n",
      "    TEST | Label 1 loss: 7.2052 ; P: 0.7899 ; R: 0.8324 ; F1: 0.8106 ; Acc: 0.9236\n",
      "           Label 2 loss: 21.9561 ; P: 0.7487 ; R: 0.766 ; F1: 0.7572 ; Acc: 0.7544\n",
      "2023-01-29 13:48:55.101835\n",
      "counter:  34\n",
      "2023-01-29 13:48:55.102830\n",
      "EPOCH 166\n",
      "TAG_LOSS_WEIGHT:  0.2073945247556942\n",
      "CLS_LOSS_WEIGHT:  0.7926054752443058\n",
      "tp:  1142\n",
      "fn:  180\n",
      "tn:  1137\n",
      "fp:  185\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2279\n",
      "tp:  433\n",
      "fn:  131\n",
      "tn:  418\n",
      "fp:  146\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  851\n",
      "EPOCH 166\n",
      "   TRAIN | Label 1 loss: 10.2849 ; P: 0.8797 ; R: 0.8696 ; F1: 0.8746 ; Acc: 0.9541\n",
      "           Label 2 loss: 36.2374 ; P: 0.8606 ; R: 0.8638 ; F1: 0.8622 ; Acc: 0.862\n",
      "    TEST | Label 1 loss: 7.2516 ; P: 0.7919 ; R: 0.8305 ; F1: 0.8107 ; Acc: 0.9238\n",
      "           Label 2 loss: 22.1296 ; P: 0.7478 ; R: 0.7677 ; F1: 0.7577 ; Acc: 0.7544\n",
      "2023-01-29 13:49:26.343325\n",
      "counter:  35\n",
      "2023-01-29 13:49:26.344325\n",
      "EPOCH 167\n",
      "TAG_LOSS_WEIGHT:  0.21492713005714376\n",
      "CLS_LOSS_WEIGHT:  0.7850728699428563\n",
      "tp:  1145\n",
      "fn:  177\n",
      "tn:  1118\n",
      "fp:  204\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2263\n",
      "tp:  432\n",
      "fn:  132\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  851\n",
      "EPOCH 167\n",
      "   TRAIN | Label 1 loss: 10.2594 ; P: 0.879 ; R: 0.8699 ; F1: 0.8744 ; Acc: 0.954\n",
      "           Label 2 loss: 36.4711 ; P: 0.8488 ; R: 0.8661 ; F1: 0.8574 ; Acc: 0.8559\n",
      "    TEST | Label 1 loss: 7.2302 ; P: 0.7961 ; R: 0.8273 ; F1: 0.8114 ; Acc: 0.9244\n",
      "           Label 2 loss: 22.0615 ; P: 0.7487 ; R: 0.766 ; F1: 0.7572 ; Acc: 0.7544\n",
      "2023-01-29 13:49:56.825520\n",
      "counter:  36\n",
      "2023-01-29 13:49:56.825520\n",
      "EPOCH 168\n",
      "TAG_LOSS_WEIGHT:  0.2119352844165154\n",
      "CLS_LOSS_WEIGHT:  0.7880647155834846\n",
      "tp:  1148\n",
      "fn:  174\n",
      "tn:  1132\n",
      "fp:  190\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2280\n",
      "tp:  430\n",
      "fn:  134\n",
      "tn:  416\n",
      "fp:  148\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  846\n",
      "EPOCH 168\n",
      "   TRAIN | Label 1 loss: 10.2049 ; P: 0.8843 ; R: 0.8715 ; F1: 0.8779 ; Acc: 0.9553\n",
      "           Label 2 loss: 36.1728 ; P: 0.858 ; R: 0.8684 ; F1: 0.8632 ; Acc: 0.8623\n",
      "    TEST | Label 1 loss: 7.2682 ; P: 0.7936 ; R: 0.8292 ; F1: 0.811 ; Acc: 0.9241\n",
      "           Label 2 loss: 22.1143 ; P: 0.7439 ; R: 0.7624 ; F1: 0.7531 ; Acc: 0.75\n",
      "2023-01-29 13:50:28.070763\n",
      "counter:  37\n",
      "2023-01-29 13:50:28.070763\n",
      "EPOCH 169\n",
      "TAG_LOSS_WEIGHT:  0.2129010365068045\n",
      "CLS_LOSS_WEIGHT:  0.7870989634931955\n",
      "tp:  1141\n",
      "fn:  181\n",
      "tn:  1139\n",
      "fp:  183\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2280\n",
      "tp:  428\n",
      "fn:  136\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  847\n",
      "EPOCH 169\n",
      "   TRAIN | Label 1 loss: 10.0474 ; P: 0.8836 ; R: 0.8731 ; F1: 0.8783 ; Acc: 0.9554\n",
      "           Label 2 loss: 35.6387 ; P: 0.8618 ; R: 0.8631 ; F1: 0.8624 ; Acc: 0.8623\n",
      "    TEST | Label 1 loss: 7.3175 ; P: 0.7875 ; R: 0.8393 ; F1: 0.8126 ; Acc: 0.9239\n",
      "           Label 2 loss: 22.0297 ; P: 0.7469 ; R: 0.7589 ; F1: 0.7529 ; Acc: 0.7509\n",
      "2023-01-29 13:50:59.461205\n",
      "counter:  38\n",
      "2023-01-29 13:50:59.461205\n",
      "EPOCH 170\n",
      "TAG_LOSS_WEIGHT:  0.2126736353698041\n",
      "CLS_LOSS_WEIGHT:  0.7873263646301959\n",
      "tp:  1152\n",
      "fn:  170\n",
      "tn:  1141\n",
      "fp:  181\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2293\n",
      "tp:  428\n",
      "fn:  136\n",
      "tn:  419\n",
      "fp:  145\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  847\n",
      "EPOCH 170\n",
      "   TRAIN | Label 1 loss: 10.0181 ; P: 0.8802 ; R: 0.8728 ; F1: 0.8765 ; Acc: 0.9547\n",
      "           Label 2 loss: 35.3044 ; P: 0.8642 ; R: 0.8714 ; F1: 0.8678 ; Acc: 0.8672\n",
      "    TEST | Label 1 loss: 7.3218 ; P: 0.7892 ; R: 0.8311 ; F1: 0.8096 ; Acc: 0.9232\n",
      "           Label 2 loss: 22.0511 ; P: 0.7469 ; R: 0.7589 ; F1: 0.7529 ; Acc: 0.7509\n",
      "2023-01-29 13:51:30.211085\n",
      "counter:  39\n",
      "2023-01-29 13:51:30.212094\n",
      "EPOCH 171\n",
      "TAG_LOSS_WEIGHT:  0.2148599106939499\n",
      "CLS_LOSS_WEIGHT:  0.7851400893060501\n",
      "tp:  1138\n",
      "fn:  184\n",
      "tn:  1137\n",
      "fp:  185\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2275\n",
      "tp:  433\n",
      "fn:  131\n",
      "tn:  420\n",
      "fp:  144\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  853\n",
      "EPOCH 171\n",
      "   TRAIN | Label 1 loss: 9.839 ; P: 0.8848 ; R: 0.8757 ; F1: 0.8802 ; Acc: 0.9561\n",
      "           Label 2 loss: 35.3889 ; P: 0.8602 ; R: 0.8608 ; F1: 0.8605 ; Acc: 0.8604\n",
      "    TEST | Label 1 loss: 7.2858 ; P: 0.7952 ; R: 0.8374 ; F1: 0.8158 ; Acc: 0.9257\n",
      "           Label 2 loss: 22.0564 ; P: 0.7504 ; R: 0.7677 ; F1: 0.759 ; Acc: 0.7562\n",
      "2023-01-29 13:52:01.198001\n",
      "counter:  40\n",
      "2023-01-29 13:52:01.198001\n",
      "EPOCH 172\n",
      "TAG_LOSS_WEIGHT:  0.2080473518828731\n",
      "CLS_LOSS_WEIGHT:  0.791952648117127\n",
      "tp:  1147\n",
      "fn:  175\n",
      "tn:  1141\n",
      "fp:  181\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2288\n",
      "tp:  436\n",
      "fn:  128\n",
      "tn:  416\n",
      "fp:  148\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  852\n",
      "EPOCH 172\n",
      "   TRAIN | Label 1 loss: 9.933 ; P: 0.8841 ; R: 0.8792 ; F1: 0.8816 ; Acc: 0.9565\n",
      "           Label 2 loss: 35.3914 ; P: 0.8637 ; R: 0.8676 ; F1: 0.8657 ; Acc: 0.8654\n",
      "    TEST | Label 1 loss: 7.3221 ; P: 0.7879 ; R: 0.8412 ; F1: 0.8137 ; Acc: 0.9243\n",
      "           Label 2 loss: 21.9797 ; P: 0.7466 ; R: 0.773 ; F1: 0.7596 ; Acc: 0.7553\n",
      "2023-01-29 13:52:32.268283\n",
      "counter:  41\n",
      "2023-01-29 13:52:32.269274\n",
      "EPOCH 173\n",
      "TAG_LOSS_WEIGHT:  0.21117451360535144\n",
      "CLS_LOSS_WEIGHT:  0.7888254863946484\n",
      "tp:  1154\n",
      "fn:  168\n",
      "tn:  1124\n",
      "fp:  198\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2278\n",
      "tp:  431\n",
      "fn:  133\n",
      "tn:  427\n",
      "fp:  137\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  858\n",
      "EPOCH 173\n",
      "   TRAIN | Label 1 loss: 9.8449 ; P: 0.8865 ; R: 0.8764 ; F1: 0.8814 ; Acc: 0.9566\n",
      "           Label 2 loss: 35.5839 ; P: 0.8536 ; R: 0.8729 ; F1: 0.8631 ; Acc: 0.8616\n",
      "    TEST | Label 1 loss: 7.2848 ; P: 0.8 ; R: 0.8349 ; F1: 0.8171 ; Acc: 0.9265\n",
      "           Label 2 loss: 21.9521 ; P: 0.7588 ; R: 0.7642 ; F1: 0.7615 ; Acc: 0.7606\n",
      "2023-01-29 13:53:02.990466\n",
      "counter:  0\n",
      "2023-01-29 13:53:04.829670\n",
      "EPOCH 174\n",
      "TAG_LOSS_WEIGHT:  0.20643872856888149\n",
      "CLS_LOSS_WEIGHT:  0.7935612714311187\n",
      "tp:  1154\n",
      "fn:  168\n",
      "tn:  1150\n",
      "fp:  172\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2304\n",
      "tp:  430\n",
      "fn:  134\n",
      "tn:  427\n",
      "fp:  137\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  857\n",
      "EPOCH 174\n",
      "   TRAIN | Label 1 loss: 9.6263 ; P: 0.8867 ; R: 0.8826 ; F1: 0.8846 ; Acc: 0.9576\n",
      "           Label 2 loss: 34.5188 ; P: 0.8703 ; R: 0.8729 ; F1: 0.8716 ; Acc: 0.8714\n",
      "    TEST | Label 1 loss: 7.321 ; P: 0.8037 ; R: 0.8311 ; F1: 0.8172 ; Acc: 0.9269\n",
      "           Label 2 loss: 22.0728 ; P: 0.7584 ; R: 0.7624 ; F1: 0.7604 ; Acc: 0.7598\n",
      "2023-01-29 13:53:36.953696\n",
      "counter:  1\n",
      "2023-01-29 13:53:36.954712\n",
      "EPOCH 175\n",
      "TAG_LOSS_WEIGHT:  0.20905055074483514\n",
      "CLS_LOSS_WEIGHT:  0.7909494492551649\n",
      "tp:  1147\n",
      "fn:  175\n",
      "tn:  1136\n",
      "fp:  186\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2283\n",
      "tp:  435\n",
      "fn:  129\n",
      "tn:  424\n",
      "fp:  140\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  859\n",
      "EPOCH 175\n",
      "   TRAIN | Label 1 loss: 9.8376 ; P: 0.8801 ; R: 0.8785 ; F1: 0.8793 ; Acc: 0.9556\n",
      "           Label 2 loss: 35.2163 ; P: 0.8605 ; R: 0.8676 ; F1: 0.864 ; Acc: 0.8635\n",
      "    TEST | Label 1 loss: 7.267 ; P: 0.8015 ; R: 0.8374 ; F1: 0.8191 ; Acc: 0.9273\n",
      "           Label 2 loss: 21.8997 ; P: 0.7565 ; R: 0.7713 ; F1: 0.7638 ; Acc: 0.7615\n",
      "2023-01-29 13:54:09.140075\n",
      "counter:  0\n",
      "2023-01-29 13:54:10.860988\n",
      "EPOCH 176\n",
      "TAG_LOSS_WEIGHT:  0.20961590999693008\n",
      "CLS_LOSS_WEIGHT:  0.79038409000307\n",
      "tp:  1162\n",
      "fn:  160\n",
      "tn:  1150\n",
      "fp:  172\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2312\n",
      "tp:  432\n",
      "fn:  132\n",
      "tn:  424\n",
      "fp:  140\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  856\n",
      "EPOCH 176\n",
      "   TRAIN | Label 1 loss: 9.4818 ; P: 0.8928 ; R: 0.8865 ; F1: 0.8896 ; Acc: 0.9595\n",
      "           Label 2 loss: 34.0964 ; P: 0.8711 ; R: 0.879 ; F1: 0.875 ; Acc: 0.8744\n",
      "    TEST | Label 1 loss: 7.3534 ; P: 0.8027 ; R: 0.8336 ; F1: 0.8179 ; Acc: 0.927\n",
      "           Label 2 loss: 22.0669 ; P: 0.7552 ; R: 0.766 ; F1: 0.7606 ; Acc: 0.7589\n",
      "2023-01-29 13:54:42.720977\n",
      "counter:  1\n",
      "2023-01-29 13:54:42.722976\n",
      "EPOCH 177\n",
      "TAG_LOSS_WEIGHT:  0.20812199855299357\n",
      "CLS_LOSS_WEIGHT:  0.7918780014470063\n",
      "tp:  1172\n",
      "fn:  150\n",
      "tn:  1149\n",
      "fp:  173\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2321\n",
      "tp:  432\n",
      "fn:  132\n",
      "tn:  423\n",
      "fp:  141\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  855\n",
      "EPOCH 177\n",
      "   TRAIN | Label 1 loss: 9.5823 ; P: 0.886 ; R: 0.8834 ; F1: 0.8847 ; Acc: 0.9576\n",
      "           Label 2 loss: 34.0915 ; P: 0.8714 ; R: 0.8865 ; F1: 0.8789 ; Acc: 0.8778\n",
      "    TEST | Label 1 loss: 7.3849 ; P: 0.8016 ; R: 0.8305 ; F1: 0.8158 ; Acc: 0.9263\n",
      "           Label 2 loss: 22.0362 ; P: 0.7539 ; R: 0.766 ; F1: 0.7599 ; Acc: 0.758\n",
      "2023-01-29 13:55:14.354283\n",
      "counter:  2\n",
      "2023-01-29 13:55:14.355283\n",
      "EPOCH 178\n",
      "TAG_LOSS_WEIGHT:  0.21166663178870615\n",
      "CLS_LOSS_WEIGHT:  0.7883333682112939\n",
      "tp:  1167\n",
      "fn:  155\n",
      "tn:  1151\n",
      "fp:  171\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2318\n",
      "tp:  439\n",
      "fn:  125\n",
      "tn:  422\n",
      "fp:  142\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  861\n",
      "EPOCH 178\n",
      "   TRAIN | Label 1 loss: 9.3566 ; P: 0.8885 ; R: 0.8841 ; F1: 0.8863 ; Acc: 0.9582\n",
      "           Label 2 loss: 33.8054 ; P: 0.8722 ; R: 0.8828 ; F1: 0.8774 ; Acc: 0.8767\n",
      "    TEST | Label 1 loss: 7.3133 ; P: 0.8084 ; R: 0.8355 ; F1: 0.8218 ; Acc: 0.9288\n",
      "           Label 2 loss: 21.9144 ; P: 0.7556 ; R: 0.7784 ; F1: 0.7668 ; Acc: 0.7633\n",
      "2023-01-29 13:55:45.287700\n",
      "counter:  0\n",
      "2023-01-29 13:55:46.924169\n",
      "EPOCH 179\n",
      "TAG_LOSS_WEIGHT:  0.20657019615403102\n",
      "CLS_LOSS_WEIGHT:  0.7934298038459691\n",
      "tp:  1166\n",
      "fn:  156\n",
      "tn:  1161\n",
      "fp:  161\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2327\n",
      "tp:  438\n",
      "fn:  126\n",
      "tn:  423\n",
      "fp:  141\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  861\n",
      "EPOCH 179\n",
      "   TRAIN | Label 1 loss: 9.1702 ; P: 0.8962 ; R: 0.8917 ; F1: 0.8939 ; Acc: 0.961\n",
      "           Label 2 loss: 33.4233 ; P: 0.8787 ; R: 0.882 ; F1: 0.8803 ; Acc: 0.8801\n",
      "    TEST | Label 1 loss: 7.3309 ; P: 0.8027 ; R: 0.8412 ; F1: 0.8215 ; Acc: 0.9282\n",
      "           Label 2 loss: 21.7919 ; P: 0.7565 ; R: 0.7766 ; F1: 0.7664 ; Acc: 0.7633\n",
      "2023-01-29 13:56:18.879295\n",
      "counter:  1\n",
      "2023-01-29 13:56:18.879295\n",
      "EPOCH 180\n",
      "TAG_LOSS_WEIGHT:  0.20371487695820692\n",
      "CLS_LOSS_WEIGHT:  0.796285123041793\n",
      "tp:  1179\n",
      "fn:  143\n",
      "tn:  1175\n",
      "fp:  147\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2354\n",
      "tp:  435\n",
      "fn:  129\n",
      "tn:  422\n",
      "fp:  142\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  857\n",
      "EPOCH 180\n",
      "   TRAIN | Label 1 loss: 9.1448 ; P: 0.8936 ; R: 0.8896 ; F1: 0.8916 ; Acc: 0.9601\n",
      "           Label 2 loss: 32.6898 ; P: 0.8891 ; R: 0.8918 ; F1: 0.8905 ; Acc: 0.8903\n",
      "    TEST | Label 1 loss: 7.373 ; P: 0.8077 ; R: 0.8343 ; F1: 0.8208 ; Acc: 0.9284\n",
      "           Label 2 loss: 21.968 ; P: 0.7539 ; R: 0.7713 ; F1: 0.7625 ; Acc: 0.7598\n",
      "2023-01-29 13:56:50.572009\n",
      "counter:  2\n",
      "2023-01-29 13:56:50.572009\n",
      "EPOCH 181\n",
      "TAG_LOSS_WEIGHT:  0.21008667949416882\n",
      "CLS_LOSS_WEIGHT:  0.7899133205058313\n",
      "tp:  1168\n",
      "fn:  154\n",
      "tn:  1175\n",
      "fp:  147\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2343\n",
      "tp:  434\n",
      "fn:  130\n",
      "tn:  427\n",
      "fp:  137\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  861\n",
      "EPOCH 181\n",
      "   TRAIN | Label 1 loss: 8.8326 ; P: 0.9036 ; R: 0.896 ; F1: 0.8998 ; Acc: 0.9632\n",
      "           Label 2 loss: 32.2254 ; P: 0.8882 ; R: 0.8835 ; F1: 0.8859 ; Acc: 0.8862\n",
      "    TEST | Label 1 loss: 7.4011 ; P: 0.8048 ; R: 0.8425 ; F1: 0.8232 ; Acc: 0.9289\n",
      "           Label 2 loss: 21.8645 ; P: 0.7601 ; R: 0.7695 ; F1: 0.7648 ; Acc: 0.7633\n",
      "2023-01-29 13:57:21.481969\n",
      "counter:  3\n",
      "2023-01-29 13:57:21.482969\n",
      "EPOCH 182\n",
      "TAG_LOSS_WEIGHT:  0.2033869532173684\n",
      "CLS_LOSS_WEIGHT:  0.7966130467826316\n",
      "tp:  1190\n",
      "fn:  132\n",
      "tn:  1174\n",
      "fp:  148\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2364\n",
      "tp:  437\n",
      "fn:  127\n",
      "tn:  429\n",
      "fp:  135\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  866\n",
      "EPOCH 182\n",
      "   TRAIN | Label 1 loss: 8.7885 ; P: 0.9023 ; R: 0.8981 ; F1: 0.9002 ; Acc: 0.9633\n",
      "           Label 2 loss: 31.829 ; P: 0.8894 ; R: 0.9002 ; F1: 0.8947 ; Acc: 0.8941\n",
      "    TEST | Label 1 loss: 7.4579 ; P: 0.8124 ; R: 0.8438 ; F1: 0.8278 ; Acc: 0.931\n",
      "           Label 2 loss: 21.9067 ; P: 0.764 ; R: 0.7748 ; F1: 0.7694 ; Acc: 0.7677\n",
      "2023-01-29 13:57:52.729444\n",
      "counter:  0\n",
      "2023-01-29 13:57:54.971252\n",
      "EPOCH 183\n",
      "TAG_LOSS_WEIGHT:  0.2057861585874446\n",
      "CLS_LOSS_WEIGHT:  0.7942138414125555\n",
      "tp:  1185\n",
      "fn:  137\n",
      "tn:  1181\n",
      "fp:  141\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2366\n",
      "tp:  437\n",
      "fn:  127\n",
      "tn:  433\n",
      "fp:  131\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  870\n",
      "EPOCH 183\n",
      "   TRAIN | Label 1 loss: 8.9653 ; P: 0.9028 ; R: 0.895 ; F1: 0.8989 ; Acc: 0.9629\n",
      "           Label 2 loss: 31.741 ; P: 0.8937 ; R: 0.8964 ; F1: 0.895 ; Acc: 0.8949\n",
      "    TEST | Label 1 loss: 7.5624 ; P: 0.8045 ; R: 0.8457 ; F1: 0.8245 ; Acc: 0.9293\n",
      "           Label 2 loss: 21.9432 ; P: 0.7694 ; R: 0.7748 ; F1: 0.7721 ; Acc: 0.7713\n",
      "2023-01-29 13:58:26.745575\n",
      "counter:  0\n",
      "2023-01-29 13:58:28.346237\n",
      "EPOCH 184\n",
      "TAG_LOSS_WEIGHT:  0.21330074218091533\n",
      "CLS_LOSS_WEIGHT:  0.7866992578190847\n",
      "tp:  1197\n",
      "fn:  125\n",
      "tn:  1183\n",
      "fp:  139\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2380\n",
      "tp:  433\n",
      "fn:  131\n",
      "tn:  436\n",
      "fp:  128\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  869\n",
      "EPOCH 184\n",
      "   TRAIN | Label 1 loss: 8.8021 ; P: 0.8974 ; R: 0.8983 ; F1: 0.8978 ; Acc: 0.9623\n",
      "           Label 2 loss: 31.583 ; P: 0.896 ; R: 0.9054 ; F1: 0.9007 ; Acc: 0.9002\n",
      "    TEST | Label 1 loss: 7.5531 ; P: 0.8116 ; R: 0.8419 ; F1: 0.8265 ; Acc: 0.9305\n",
      "           Label 2 loss: 22.0307 ; P: 0.7718 ; R: 0.7677 ; F1: 0.7698 ; Acc: 0.7704\n",
      "2023-01-29 13:59:00.304916\n",
      "counter:  1\n",
      "2023-01-29 13:59:00.304916\n",
      "EPOCH 185\n",
      "TAG_LOSS_WEIGHT:  0.2088444345540612\n",
      "CLS_LOSS_WEIGHT:  0.7911555654459389\n",
      "tp:  1185\n",
      "fn:  137\n",
      "tn:  1200\n",
      "fp:  122\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2385\n",
      "tp:  443\n",
      "fn:  121\n",
      "tn:  433\n",
      "fp:  131\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  876\n",
      "EPOCH 185\n",
      "   TRAIN | Label 1 loss: 8.7659 ; P: 0.8968 ; R: 0.9008 ; F1: 0.8988 ; Acc: 0.9626\n",
      "           Label 2 loss: 31.4947 ; P: 0.9067 ; R: 0.8964 ; F1: 0.9015 ; Acc: 0.902\n",
      "    TEST | Label 1 loss: 7.4131 ; P: 0.812 ; R: 0.8495 ; F1: 0.8303 ; Acc: 0.9318\n",
      "           Label 2 loss: 21.8007 ; P: 0.7718 ; R: 0.7855 ; F1: 0.7786 ; Acc: 0.7766\n",
      "2023-01-29 13:59:32.061618\n",
      "counter:  0\n",
      "2023-01-29 13:59:33.768648\n",
      "EPOCH 186\n",
      "TAG_LOSS_WEIGHT:  0.20840810097040896\n",
      "CLS_LOSS_WEIGHT:  0.791591899029591\n",
      "tp:  1214\n",
      "fn:  108\n",
      "tn:  1172\n",
      "fp:  150\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2386\n",
      "tp:  430\n",
      "fn:  134\n",
      "tn:  448\n",
      "fp:  116\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  878\n",
      "EPOCH 186\n",
      "   TRAIN | Label 1 loss: 8.3671 ; P: 0.9093 ; R: 0.906 ; F1: 0.9076 ; Acc: 0.966\n",
      "           Label 2 loss: 30.9512 ; P: 0.89 ; R: 0.9183 ; F1: 0.9039 ; Acc: 0.9024\n",
      "    TEST | Label 1 loss: 7.5968 ; P: 0.8184 ; R: 0.8381 ; F1: 0.8281 ; Acc: 0.9316\n",
      "           Label 2 loss: 22.004 ; P: 0.7875 ; R: 0.7624 ; F1: 0.7748 ; Acc: 0.7784\n",
      "2023-01-29 14:00:06.087166\n",
      "counter:  0\n",
      "2023-01-29 14:00:07.799777\n",
      "EPOCH 187\n",
      "TAG_LOSS_WEIGHT:  0.19895212842110868\n",
      "CLS_LOSS_WEIGHT:  0.8010478715788913\n",
      "tp:  1186\n",
      "fn:  136\n",
      "tn:  1211\n",
      "fp:  111\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2397\n",
      "tp:  437\n",
      "fn:  127\n",
      "tn:  439\n",
      "fp:  125\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  876\n",
      "EPOCH 187\n",
      "   TRAIN | Label 1 loss: 8.2633 ; P: 0.9063 ; R: 0.911 ; F1: 0.9086 ; Acc: 0.9663\n",
      "           Label 2 loss: 30.1761 ; P: 0.9144 ; R: 0.8971 ; F1: 0.9057 ; Acc: 0.9066\n",
      "    TEST | Label 1 loss: 7.5289 ; P: 0.8139 ; R: 0.8438 ; F1: 0.8286 ; Acc: 0.9314\n",
      "           Label 2 loss: 21.7618 ; P: 0.7776 ; R: 0.7748 ; F1: 0.7762 ; Acc: 0.7766\n",
      "2023-01-29 14:00:40.675586\n",
      "counter:  1\n",
      "2023-01-29 14:00:40.676587\n",
      "EPOCH 188\n",
      "TAG_LOSS_WEIGHT:  0.20308878503815295\n",
      "CLS_LOSS_WEIGHT:  0.796911214961847\n",
      "tp:  1218\n",
      "fn:  104\n",
      "tn:  1195\n",
      "fp:  127\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2413\n",
      "tp:  442\n",
      "fn:  122\n",
      "tn:  439\n",
      "fp:  125\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  881\n",
      "EPOCH 188\n",
      "   TRAIN | Label 1 loss: 7.9777 ; P: 0.9087 ; R: 0.9128 ; F1: 0.9108 ; Acc: 0.967\n",
      "           Label 2 loss: 29.351 ; P: 0.9056 ; R: 0.9213 ; F1: 0.9134 ; Acc: 0.9126\n",
      "    TEST | Label 1 loss: 7.6227 ; P: 0.8176 ; R: 0.8476 ; F1: 0.8323 ; Acc: 0.9329\n",
      "           Label 2 loss: 21.8822 ; P: 0.7795 ; R: 0.7837 ; F1: 0.7816 ; Acc: 0.781\n",
      "2023-01-29 14:01:11.983590\n",
      "counter:  0\n",
      "2023-01-29 14:01:13.800205\n",
      "EPOCH 189\n",
      "TAG_LOSS_WEIGHT:  0.20068789203072687\n",
      "CLS_LOSS_WEIGHT:  0.7993121079692731\n",
      "tp:  1206\n",
      "fn:  116\n",
      "tn:  1200\n",
      "fp:  122\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2406\n",
      "tp:  438\n",
      "fn:  126\n",
      "tn:  440\n",
      "fp:  124\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  878\n",
      "EPOCH 189\n",
      "   TRAIN | Label 1 loss: 7.9767 ; P: 0.9133 ; R: 0.9145 ; F1: 0.9139 ; Acc: 0.9683\n",
      "           Label 2 loss: 30.0742 ; P: 0.9081 ; R: 0.9123 ; F1: 0.9102 ; Acc: 0.91\n",
      "    TEST | Label 1 loss: 7.6992 ; P: 0.8135 ; R: 0.8469 ; F1: 0.8299 ; Acc: 0.9318\n",
      "           Label 2 loss: 21.7854 ; P: 0.7794 ; R: 0.7766 ; F1: 0.778 ; Acc: 0.7784\n",
      "2023-01-29 14:01:45.854603\n",
      "counter:  1\n",
      "2023-01-29 14:01:45.855597\n",
      "EPOCH 190\n",
      "TAG_LOSS_WEIGHT:  0.19295329600632743\n",
      "CLS_LOSS_WEIGHT:  0.8070467039936725\n",
      "tp:  1211\n",
      "fn:  111\n",
      "tn:  1199\n",
      "fp:  123\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2410\n",
      "tp:  439\n",
      "fn:  125\n",
      "tn:  441\n",
      "fp:  123\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  880\n",
      "EPOCH 190\n",
      "   TRAIN | Label 1 loss: 7.9034 ; P: 0.9134 ; R: 0.9148 ; F1: 0.9141 ; Acc: 0.9683\n",
      "           Label 2 loss: 29.5836 ; P: 0.9078 ; R: 0.916 ; F1: 0.9119 ; Acc: 0.9115\n",
      "    TEST | Label 1 loss: 7.6407 ; P: 0.8224 ; R: 0.8438 ; F1: 0.833 ; Acc: 0.9335\n",
      "           Label 2 loss: 21.5874 ; P: 0.7811 ; R: 0.7784 ; F1: 0.7798 ; Acc: 0.7801\n",
      "2023-01-29 14:02:17.505279\n",
      "counter:  2\n",
      "2023-01-29 14:02:17.505279\n",
      "EPOCH 191\n",
      "TAG_LOSS_WEIGHT:  0.195210569618077\n",
      "CLS_LOSS_WEIGHT:  0.8047894303819231\n",
      "tp:  1218\n",
      "fn:  104\n",
      "tn:  1213\n",
      "fp:  109\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2431\n",
      "tp:  435\n",
      "fn:  129\n",
      "tn:  446\n",
      "fp:  118\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  881\n",
      "EPOCH 191\n",
      "   TRAIN | Label 1 loss: 7.5788 ; P: 0.9156 ; R: 0.9211 ; F1: 0.9183 ; Acc: 0.9698\n",
      "           Label 2 loss: 28.6298 ; P: 0.9179 ; R: 0.9213 ; F1: 0.9196 ; Acc: 0.9194\n",
      "    TEST | Label 1 loss: 7.7116 ; P: 0.828 ; R: 0.8374 ; F1: 0.8327 ; Acc: 0.9339\n",
      "           Label 2 loss: 21.582 ; P: 0.7866 ; R: 0.7713 ; F1: 0.7789 ; Acc: 0.781\n",
      "2023-01-29 14:02:48.526692\n",
      "counter:  3\n",
      "2023-01-29 14:02:48.528688\n",
      "EPOCH 192\n",
      "TAG_LOSS_WEIGHT:  0.19234658542997626\n",
      "CLS_LOSS_WEIGHT:  0.8076534145700237\n",
      "tp:  1215\n",
      "fn:  107\n",
      "tn:  1220\n",
      "fp:  102\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2435\n",
      "tp:  441\n",
      "fn:  123\n",
      "tn:  433\n",
      "fp:  131\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  874\n",
      "EPOCH 192\n",
      "   TRAIN | Label 1 loss: 7.7983 ; P: 0.9112 ; R: 0.9146 ; F1: 0.9129 ; Acc: 0.9678\n",
      "           Label 2 loss: 28.3374 ; P: 0.9226 ; R: 0.9191 ; F1: 0.9208 ; Acc: 0.921\n",
      "    TEST | Label 1 loss: 7.6423 ; P: 0.8075 ; R: 0.8545 ; F1: 0.8304 ; Acc: 0.9314\n",
      "           Label 2 loss: 21.7772 ; P: 0.771 ; R: 0.7819 ; F1: 0.7764 ; Acc: 0.7748\n",
      "2023-01-29 14:03:19.675540\n",
      "counter:  4\n",
      "2023-01-29 14:03:19.676540\n",
      "EPOCH 193\n",
      "TAG_LOSS_WEIGHT:  0.20469557619448006\n",
      "CLS_LOSS_WEIGHT:  0.7953044238055199\n",
      "tp:  1225\n",
      "fn:  97\n",
      "tn:  1211\n",
      "fp:  111\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2436\n",
      "tp:  440\n",
      "fn:  124\n",
      "tn:  428\n",
      "fp:  136\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  868\n",
      "EPOCH 193\n",
      "   TRAIN | Label 1 loss: 7.4722 ; P: 0.9194 ; R: 0.9176 ; F1: 0.9185 ; Acc: 0.97\n",
      "           Label 2 loss: 28.2559 ; P: 0.9169 ; R: 0.9266 ; F1: 0.9217 ; Acc: 0.9213\n",
      "    TEST | Label 1 loss: 7.9054 ; P: 0.8096 ; R: 0.8552 ; F1: 0.8317 ; Acc: 0.932\n",
      "           Label 2 loss: 22.1113 ; P: 0.7639 ; R: 0.7801 ; F1: 0.7719 ; Acc: 0.7695\n",
      "2023-01-29 14:03:50.823277\n",
      "counter:  5\n",
      "2023-01-29 14:03:50.823277\n",
      "EPOCH 194\n",
      "TAG_LOSS_WEIGHT:  0.1920300079506592\n",
      "CLS_LOSS_WEIGHT:  0.8079699920493407\n",
      "tp:  1222\n",
      "fn:  100\n",
      "tn:  1218\n",
      "fp:  104\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2440\n",
      "tp:  443\n",
      "fn:  121\n",
      "tn:  424\n",
      "fp:  140\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  867\n",
      "EPOCH 194\n",
      "   TRAIN | Label 1 loss: 7.3579 ; P: 0.9174 ; R: 0.92 ; F1: 0.9187 ; Acc: 0.97\n",
      "           Label 2 loss: 27.709 ; P: 0.9216 ; R: 0.9244 ; F1: 0.923 ; Acc: 0.9228\n",
      "    TEST | Label 1 loss: 7.8515 ; P: 0.8117 ; R: 0.8533 ; F1: 0.8319 ; Acc: 0.9323\n",
      "           Label 2 loss: 22.0629 ; P: 0.7599 ; R: 0.7855 ; F1: 0.7724 ; Acc: 0.7686\n",
      "2023-01-29 14:04:22.110044\n",
      "counter:  6\n",
      "2023-01-29 14:04:22.110044\n",
      "EPOCH 195\n",
      "TAG_LOSS_WEIGHT:  0.19331488063371988\n",
      "CLS_LOSS_WEIGHT:  0.8066851193662802\n",
      "tp:  1226\n",
      "fn:  96\n",
      "tn:  1211\n",
      "fp:  111\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2437\n",
      "tp:  430\n",
      "fn:  134\n",
      "tn:  449\n",
      "fp:  115\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  879\n",
      "EPOCH 195\n",
      "   TRAIN | Label 1 loss: 7.2232 ; P: 0.9186 ; R: 0.9222 ; F1: 0.9204 ; Acc: 0.9706\n",
      "           Label 2 loss: 27.9427 ; P: 0.917 ; R: 0.9274 ; F1: 0.9222 ; Acc: 0.9217\n",
      "    TEST | Label 1 loss: 7.9232 ; P: 0.8246 ; R: 0.8412 ; F1: 0.8328 ; Acc: 0.9336\n",
      "           Label 2 loss: 21.9824 ; P: 0.789 ; R: 0.7624 ; F1: 0.7755 ; Acc: 0.7793\n",
      "2023-01-29 14:04:53.251076\n",
      "counter:  7\n",
      "2023-01-29 14:04:53.251076\n",
      "EPOCH 196\n",
      "TAG_LOSS_WEIGHT:  0.18507069720843647\n",
      "CLS_LOSS_WEIGHT:  0.8149293027915636\n",
      "tp:  1220\n",
      "fn:  102\n",
      "tn:  1237\n",
      "fp:  85\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2457\n",
      "tp:  440\n",
      "fn:  124\n",
      "tn:  430\n",
      "fp:  134\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  870\n",
      "EPOCH 196\n",
      "   TRAIN | Label 1 loss: 6.9372 ; P: 0.9253 ; R: 0.927 ; F1: 0.9261 ; Acc: 0.9727\n",
      "           Label 2 loss: 27.2938 ; P: 0.9349 ; R: 0.9228 ; F1: 0.9288 ; Acc: 0.9293\n",
      "    TEST | Label 1 loss: 7.9994 ; P: 0.8151 ; R: 0.8533 ; F1: 0.8337 ; Acc: 0.9331\n",
      "           Label 2 loss: 22.1788 ; P: 0.7666 ; R: 0.7801 ; F1: 0.7733 ; Acc: 0.7713\n",
      "2023-01-29 14:05:24.209724\n",
      "counter:  8\n",
      "2023-01-29 14:05:24.209724\n",
      "EPOCH 197\n",
      "TAG_LOSS_WEIGHT:  0.18002615430198904\n",
      "CLS_LOSS_WEIGHT:  0.8199738456980109\n",
      "tp:  1231\n",
      "fn:  91\n",
      "tn:  1212\n",
      "fp:  110\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2443\n",
      "tp:  442\n",
      "fn:  122\n",
      "tn:  434\n",
      "fp:  130\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  876\n",
      "EPOCH 197\n",
      "   TRAIN | Label 1 loss: 6.9759 ; P: 0.9222 ; R: 0.924 ; F1: 0.9231 ; Acc: 0.9716\n",
      "           Label 2 loss: 27.4461 ; P: 0.918 ; R: 0.9312 ; F1: 0.9245 ; Acc: 0.924\n",
      "    TEST | Label 1 loss: 7.9682 ; P: 0.8222 ; R: 0.8425 ; F1: 0.8322 ; Acc: 0.9333\n",
      "           Label 2 loss: 21.9783 ; P: 0.7727 ; R: 0.7837 ; F1: 0.7782 ; Acc: 0.7766\n",
      "2023-01-29 14:05:54.832668\n",
      "counter:  9\n",
      "2023-01-29 14:05:54.834666\n",
      "EPOCH 198\n",
      "TAG_LOSS_WEIGHT:  0.18002574261685597\n",
      "CLS_LOSS_WEIGHT:  0.819974257383144\n",
      "tp:  1231\n",
      "fn:  91\n",
      "tn:  1229\n",
      "fp:  93\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2460\n",
      "tp:  440\n",
      "fn:  124\n",
      "tn:  436\n",
      "fp:  128\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  876\n",
      "EPOCH 198\n",
      "   TRAIN | Label 1 loss: 6.8759 ; P: 0.9235 ; R: 0.9253 ; F1: 0.9244 ; Acc: 0.9721\n",
      "           Label 2 loss: 26.9007 ; P: 0.9298 ; R: 0.9312 ; F1: 0.9305 ; Acc: 0.9304\n",
      "    TEST | Label 1 loss: 8.0103 ; P: 0.8235 ; R: 0.8438 ; F1: 0.8335 ; Acc: 0.9338\n",
      "           Label 2 loss: 21.9591 ; P: 0.7746 ; R: 0.7801 ; F1: 0.7774 ; Acc: 0.7766\n",
      "2023-01-29 14:06:25.601853\n",
      "counter:  10\n",
      "2023-01-29 14:06:25.601853\n",
      "EPOCH 199\n",
      "TAG_LOSS_WEIGHT:  0.18169477845167098\n",
      "CLS_LOSS_WEIGHT:  0.818305221548329\n",
      "tp:  1249\n",
      "fn:  73\n",
      "tn:  1236\n",
      "fp:  86\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2485\n",
      "tp:  441\n",
      "fn:  123\n",
      "tn:  442\n",
      "fp:  122\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  883\n",
      "EPOCH 199\n",
      "   TRAIN | Label 1 loss: 6.5239 ; P: 0.9337 ; R: 0.9337 ; F1: 0.9337 ; Acc: 0.9756\n",
      "           Label 2 loss: 26.1537 ; P: 0.9356 ; R: 0.9448 ; F1: 0.9402 ; Acc: 0.9399\n",
      "    TEST | Label 1 loss: 8.1395 ; P: 0.8263 ; R: 0.8457 ; F1: 0.8359 ; Acc: 0.9348\n",
      "           Label 2 loss: 21.9661 ; P: 0.7833 ; R: 0.7819 ; F1: 0.7826 ; Acc: 0.7828\n",
      "2023-01-29 14:06:56.953102\n",
      "counter:  0\n",
      "2023-01-29 14:06:58.771650\n",
      "EPOCH 200\n",
      "TAG_LOSS_WEIGHT:  0.17455478306207076\n",
      "CLS_LOSS_WEIGHT:  0.8254452169379292\n",
      "tp:  1248\n",
      "fn:  74\n",
      "tn:  1237\n",
      "fp:  85\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2485\n",
      "tp:  437\n",
      "fn:  127\n",
      "tn:  452\n",
      "fp:  112\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  889\n",
      "EPOCH 200\n",
      "   TRAIN | Label 1 loss: 6.4388 ; P: 0.93 ; R: 0.931 ; F1: 0.9305 ; Acc: 0.9744\n",
      "           Label 2 loss: 26.0902 ; P: 0.9362 ; R: 0.944 ; F1: 0.9401 ; Acc: 0.9399\n",
      "    TEST | Label 1 loss: 8.2956 ; P: 0.8327 ; R: 0.8438 ; F1: 0.8382 ; Acc: 0.936\n",
      "           Label 2 loss: 22.1689 ; P: 0.796 ; R: 0.7748 ; F1: 0.7853 ; Acc: 0.7881\n",
      "2023-01-29 14:07:30.741669\n",
      "counter:  0\n",
      "2023-01-29 14:07:32.333130\n",
      "EPOCH 201\n",
      "TAG_LOSS_WEIGHT:  0.1714930070491217\n",
      "CLS_LOSS_WEIGHT:  0.8285069929508783\n",
      "tp:  1244\n",
      "fn:  78\n",
      "tn:  1239\n",
      "fp:  83\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2483\n",
      "tp:  439\n",
      "fn:  125\n",
      "tn:  446\n",
      "fp:  118\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  885\n",
      "EPOCH 201\n",
      "   TRAIN | Label 1 loss: 6.3773 ; P: 0.9331 ; R: 0.9353 ; F1: 0.9342 ; Acc: 0.9757\n",
      "           Label 2 loss: 25.9665 ; P: 0.9375 ; R: 0.941 ; F1: 0.9392 ; Acc: 0.9391\n",
      "    TEST | Label 1 loss: 8.1985 ; P: 0.8228 ; R: 0.8488 ; F1: 0.8356 ; Acc: 0.9344\n",
      "           Label 2 loss: 22.1035 ; P: 0.7882 ; R: 0.7784 ; F1: 0.7832 ; Acc: 0.7846\n",
      "2023-01-29 14:08:04.756500\n",
      "counter:  1\n",
      "2023-01-29 14:08:04.756500\n",
      "EPOCH 202\n",
      "TAG_LOSS_WEIGHT:  0.17012064083073913\n",
      "CLS_LOSS_WEIGHT:  0.8298793591692608\n",
      "tp:  1256\n",
      "fn:  66\n",
      "tn:  1241\n",
      "fp:  81\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2497\n",
      "tp:  447\n",
      "fn:  117\n",
      "tn:  430\n",
      "fp:  134\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  877\n",
      "EPOCH 202\n",
      "   TRAIN | Label 1 loss: 6.3429 ; P: 0.9303 ; R: 0.9339 ; F1: 0.9321 ; Acc: 0.9749\n",
      "           Label 2 loss: 25.1231 ; P: 0.9394 ; R: 0.9501 ; F1: 0.9447 ; Acc: 0.9444\n",
      "    TEST | Label 1 loss: 8.1412 ; P: 0.8239 ; R: 0.852 ; F1: 0.8377 ; Acc: 0.9351\n",
      "           Label 2 loss: 22.1214 ; P: 0.7694 ; R: 0.7926 ; F1: 0.7808 ; Acc: 0.7775\n",
      "2023-01-29 14:08:36.877133\n",
      "counter:  2\n",
      "2023-01-29 14:08:36.878133\n",
      "EPOCH 203\n",
      "TAG_LOSS_WEIGHT:  0.17805939509195445\n",
      "CLS_LOSS_WEIGHT:  0.8219406049080457\n",
      "tp:  1252\n",
      "fn:  70\n",
      "tn:  1255\n",
      "fp:  67\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2507\n",
      "tp:  446\n",
      "fn:  118\n",
      "tn:  434\n",
      "fp:  130\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  880\n",
      "EPOCH 203\n",
      "   TRAIN | Label 1 loss: 6.1153 ; P: 0.9353 ; R: 0.9386 ; F1: 0.9369 ; Acc: 0.9767\n",
      "           Label 2 loss: 24.9166 ; P: 0.9492 ; R: 0.947 ; F1: 0.9481 ; Acc: 0.9482\n",
      "    TEST | Label 1 loss: 8.0165 ; P: 0.8259 ; R: 0.852 ; F1: 0.8387 ; Acc: 0.9356\n",
      "           Label 2 loss: 21.8176 ; P: 0.7743 ; R: 0.7908 ; F1: 0.7825 ; Acc: 0.7801\n",
      "2023-01-29 14:09:08.287505\n",
      "counter:  3\n",
      "2023-01-29 14:09:08.287505\n",
      "EPOCH 204\n",
      "TAG_LOSS_WEIGHT:  0.1699292911448506\n",
      "CLS_LOSS_WEIGHT:  0.8300707088551494\n",
      "tp:  1252\n",
      "fn:  70\n",
      "tn:  1249\n",
      "fp:  73\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2501\n",
      "tp:  444\n",
      "fn:  120\n",
      "tn:  443\n",
      "fp:  121\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  887\n",
      "EPOCH 204\n",
      "   TRAIN | Label 1 loss: 6.2966 ; P: 0.9388 ; R: 0.936 ; F1: 0.9374 ; Acc: 0.977\n",
      "           Label 2 loss: 24.9994 ; P: 0.9449 ; R: 0.947 ; F1: 0.946 ; Acc: 0.9459\n",
      "    TEST | Label 1 loss: 8.2668 ; P: 0.8241 ; R: 0.8476 ; F1: 0.8357 ; Acc: 0.9345\n",
      "           Label 2 loss: 21.8439 ; P: 0.7858 ; R: 0.7872 ; F1: 0.7865 ; Acc: 0.7863\n",
      "2023-01-29 14:09:39.170803\n",
      "counter:  4\n",
      "2023-01-29 14:09:39.171803\n",
      "EPOCH 205\n",
      "TAG_LOSS_WEIGHT:  0.17736079446209968\n",
      "CLS_LOSS_WEIGHT:  0.8226392055379003\n",
      "tp:  1265\n",
      "fn:  57\n",
      "tn:  1255\n",
      "fp:  67\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2520\n",
      "tp:  443\n",
      "fn:  121\n",
      "tn:  443\n",
      "fp:  121\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  886\n",
      "EPOCH 205\n",
      "   TRAIN | Label 1 loss: 6.0434 ; P: 0.9336 ; R: 0.9386 ; F1: 0.9361 ; Acc: 0.9764\n",
      "           Label 2 loss: 24.4371 ; P: 0.9497 ; R: 0.9569 ; F1: 0.9533 ; Acc: 0.9531\n",
      "    TEST | Label 1 loss: 8.2207 ; P: 0.8324 ; R: 0.8482 ; F1: 0.8402 ; Acc: 0.9366\n",
      "           Label 2 loss: 21.9019 ; P: 0.7855 ; R: 0.7855 ; F1: 0.7855 ; Acc: 0.7855\n",
      "2023-01-29 14:10:10.241039\n",
      "counter:  5\n",
      "2023-01-29 14:10:10.241039\n",
      "EPOCH 206\n",
      "TAG_LOSS_WEIGHT:  0.17208541543838088\n",
      "CLS_LOSS_WEIGHT:  0.8279145845616191\n",
      "tp:  1266\n",
      "fn:  56\n",
      "tn:  1252\n",
      "fp:  70\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2518\n",
      "tp:  449\n",
      "fn:  115\n",
      "tn:  438\n",
      "fp:  126\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  887\n",
      "EPOCH 206\n",
      "   TRAIN | Label 1 loss: 6.1361 ; P: 0.9344 ; R: 0.9402 ; F1: 0.9373 ; Acc: 0.9768\n",
      "           Label 2 loss: 24.7329 ; P: 0.9476 ; R: 0.9576 ; F1: 0.9526 ; Acc: 0.9523\n",
      "    TEST | Label 1 loss: 8.1246 ; P: 0.8344 ; R: 0.8539 ; F1: 0.844 ; Acc: 0.938\n",
      "           Label 2 loss: 21.9071 ; P: 0.7809 ; R: 0.7961 ; F1: 0.7884 ; Acc: 0.7863\n",
      "2023-01-29 14:10:41.306715\n",
      "counter:  6\n",
      "2023-01-29 14:10:41.306715\n",
      "EPOCH 207\n",
      "TAG_LOSS_WEIGHT:  0.17299649606895656\n",
      "CLS_LOSS_WEIGHT:  0.8270035039310434\n",
      "tp:  1264\n",
      "fn:  58\n",
      "tn:  1265\n",
      "fp:  57\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2529\n",
      "tp:  451\n",
      "fn:  113\n",
      "tn:  437\n",
      "fp:  127\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  888\n",
      "EPOCH 207\n",
      "   TRAIN | Label 1 loss: 5.8185 ; P: 0.9411 ; R: 0.9416 ; F1: 0.9414 ; Acc: 0.9784\n",
      "           Label 2 loss: 23.9551 ; P: 0.9569 ; R: 0.9561 ; F1: 0.9565 ; Acc: 0.9565\n",
      "    TEST | Label 1 loss: 8.3237 ; P: 0.8241 ; R: 0.8564 ; F1: 0.84 ; Acc: 0.9359\n",
      "           Label 2 loss: 21.8834 ; P: 0.7803 ; R: 0.7996 ; F1: 0.7898 ; Acc: 0.7872\n",
      "2023-01-29 14:11:12.233233\n",
      "counter:  7\n",
      "2023-01-29 14:11:12.233233\n",
      "EPOCH 208\n",
      "TAG_LOSS_WEIGHT:  0.16701595685663223\n",
      "CLS_LOSS_WEIGHT:  0.8329840431433677\n",
      "tp:  1255\n",
      "fn:  67\n",
      "tn:  1264\n",
      "fp:  58\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2519\n",
      "tp:  451\n",
      "fn:  113\n",
      "tn:  440\n",
      "fp:  124\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  891\n",
      "EPOCH 208\n",
      "   TRAIN | Label 1 loss: 5.9157 ; P: 0.9402 ; R: 0.9418 ; F1: 0.941 ; Acc: 0.9782\n",
      "           Label 2 loss: 23.9464 ; P: 0.9558 ; R: 0.9493 ; F1: 0.9526 ; Acc: 0.9527\n",
      "    TEST | Label 1 loss: 8.3251 ; P: 0.8299 ; R: 0.8545 ; F1: 0.842 ; Acc: 0.937\n",
      "           Label 2 loss: 21.8462 ; P: 0.7843 ; R: 0.7996 ; F1: 0.7919 ; Acc: 0.7899\n",
      "2023-01-29 14:11:43.235527\n",
      "counter:  0\n",
      "2023-01-29 14:11:44.894705\n",
      "EPOCH 209\n",
      "TAG_LOSS_WEIGHT:  0.17178003812593842\n",
      "CLS_LOSS_WEIGHT:  0.8282199618740617\n",
      "tp:  1268\n",
      "fn:  54\n",
      "tn:  1255\n",
      "fp:  67\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2523\n",
      "tp:  445\n",
      "fn:  119\n",
      "tn:  446\n",
      "fp:  118\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  891\n",
      "EPOCH 209\n",
      "   TRAIN | Label 1 loss: 5.7774 ; P: 0.9397 ; R: 0.9419 ; F1: 0.9408 ; Acc: 0.9782\n",
      "           Label 2 loss: 23.7951 ; P: 0.9498 ; R: 0.9592 ; F1: 0.9545 ; Acc: 0.9542\n",
      "    TEST | Label 1 loss: 8.4882 ; P: 0.839 ; R: 0.8438 ; F1: 0.8414 ; Acc: 0.9375\n",
      "           Label 2 loss: 21.8104 ; P: 0.7904 ; R: 0.789 ; F1: 0.7897 ; Acc: 0.7899\n",
      "2023-01-29 14:12:17.286473\n",
      "counter:  1\n",
      "2023-01-29 14:12:17.286473\n",
      "EPOCH 210\n",
      "TAG_LOSS_WEIGHT:  0.16690825597246875\n",
      "CLS_LOSS_WEIGHT:  0.8330917440275313\n",
      "tp:  1269\n",
      "fn:  53\n",
      "tn:  1274\n",
      "fp:  48\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2543\n",
      "tp:  444\n",
      "fn:  120\n",
      "tn:  446\n",
      "fp:  118\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  890\n",
      "EPOCH 210\n",
      "   TRAIN | Label 1 loss: 5.4968 ; P: 0.944 ; R: 0.9439 ; F1: 0.944 ; Acc: 0.9793\n",
      "           Label 2 loss: 23.1505 ; P: 0.9636 ; R: 0.9599 ; F1: 0.9617 ; Acc: 0.9618\n",
      "    TEST | Label 1 loss: 8.6289 ; P: 0.8328 ; R: 0.8539 ; F1: 0.8432 ; Acc: 0.9376\n",
      "           Label 2 loss: 22.002 ; P: 0.79 ; R: 0.7872 ; F1: 0.7886 ; Acc: 0.789\n",
      "2023-01-29 14:12:48.945715\n",
      "counter:  2\n",
      "2023-01-29 14:12:48.947707\n",
      "EPOCH 211\n",
      "TAG_LOSS_WEIGHT:  0.16079183892412635\n",
      "CLS_LOSS_WEIGHT:  0.8392081610758736\n",
      "tp:  1273\n",
      "fn:  49\n",
      "tn:  1272\n",
      "fp:  50\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2545\n",
      "tp:  451\n",
      "fn:  113\n",
      "tn:  444\n",
      "fp:  120\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  895\n",
      "EPOCH 211\n",
      "   TRAIN | Label 1 loss: 5.3838 ; P: 0.9437 ; R: 0.9482 ; F1: 0.946 ; Acc: 0.98\n",
      "           Label 2 loss: 22.8603 ; P: 0.9622 ; R: 0.9629 ; F1: 0.9626 ; Acc: 0.9626\n",
      "    TEST | Label 1 loss: 8.4613 ; P: 0.8327 ; R: 0.8564 ; F1: 0.8444 ; Acc: 0.938\n",
      "           Label 2 loss: 21.6294 ; P: 0.7898 ; R: 0.7996 ; F1: 0.7947 ; Acc: 0.7934\n",
      "2023-01-29 14:13:20.074735\n",
      "counter:  0\n",
      "2023-01-29 14:13:21.787603\n",
      "EPOCH 212\n",
      "TAG_LOSS_WEIGHT:  0.15860260969919215\n",
      "CLS_LOSS_WEIGHT:  0.8413973903008078\n",
      "tp:  1271\n",
      "fn:  51\n",
      "tn:  1274\n",
      "fp:  48\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2545\n",
      "tp:  448\n",
      "fn:  116\n",
      "tn:  446\n",
      "fp:  118\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  894\n",
      "EPOCH 212\n",
      "   TRAIN | Label 1 loss: 5.4135 ; P: 0.9457 ; R: 0.9486 ; F1: 0.9472 ; Acc: 0.9805\n",
      "           Label 2 loss: 23.0068 ; P: 0.9636 ; R: 0.9614 ; F1: 0.9625 ; Acc: 0.9626\n",
      "    TEST | Label 1 loss: 8.4392 ; P: 0.8365 ; R: 0.8577 ; F1: 0.847 ; Acc: 0.9391\n",
      "           Label 2 loss: 21.8256 ; P: 0.7915 ; R: 0.7943 ; F1: 0.7929 ; Acc: 0.7926\n",
      "2023-01-29 14:13:53.960906\n",
      "counter:  1\n",
      "2023-01-29 14:13:53.960906\n",
      "EPOCH 213\n",
      "TAG_LOSS_WEIGHT:  0.15836610896988634\n",
      "CLS_LOSS_WEIGHT:  0.8416338910301137\n",
      "tp:  1273\n",
      "fn:  49\n",
      "tn:  1268\n",
      "fp:  54\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2541\n",
      "tp:  442\n",
      "fn:  122\n",
      "tn:  451\n",
      "fp:  113\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  893\n",
      "EPOCH 213\n",
      "   TRAIN | Label 1 loss: 5.4042 ; P: 0.9432 ; R: 0.9503 ; F1: 0.9467 ; Acc: 0.9803\n",
      "           Label 2 loss: 22.6931 ; P: 0.9593 ; R: 0.9629 ; F1: 0.9611 ; Acc: 0.961\n",
      "    TEST | Label 1 loss: 8.4106 ; P: 0.8409 ; R: 0.8526 ; F1: 0.8467 ; Acc: 0.9393\n",
      "           Label 2 loss: 21.8621 ; P: 0.7964 ; R: 0.7837 ; F1: 0.79 ; Acc: 0.7917\n",
      "2023-01-29 14:14:25.739068\n",
      "counter:  2\n",
      "2023-01-29 14:14:25.740069\n",
      "EPOCH 214\n",
      "TAG_LOSS_WEIGHT:  0.16159384455920728\n",
      "CLS_LOSS_WEIGHT:  0.8384061554407926\n",
      "tp:  1281\n",
      "fn:  41\n",
      "tn:  1270\n",
      "fp:  52\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2551\n",
      "tp:  445\n",
      "fn:  119\n",
      "tn:  448\n",
      "fp:  116\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  893\n",
      "EPOCH 214\n",
      "   TRAIN | Label 1 loss: 5.0339 ; P: 0.9485 ; R: 0.9544 ; F1: 0.9515 ; Acc: 0.9821\n",
      "           Label 2 loss: 22.4101 ; P: 0.961 ; R: 0.969 ; F1: 0.965 ; Acc: 0.9648\n",
      "    TEST | Label 1 loss: 8.5791 ; P: 0.8344 ; R: 0.8539 ; F1: 0.844 ; Acc: 0.938\n",
      "           Label 2 loss: 21.9089 ; P: 0.7932 ; R: 0.789 ; F1: 0.7911 ; Acc: 0.7917\n",
      "2023-01-29 14:14:56.861593\n",
      "counter:  3\n",
      "2023-01-29 14:14:56.861593\n",
      "EPOCH 215\n",
      "TAG_LOSS_WEIGHT:  0.14637988517167716\n",
      "CLS_LOSS_WEIGHT:  0.8536201148283229\n",
      "tp:  1284\n",
      "fn:  38\n",
      "tn:  1275\n",
      "fp:  47\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2559\n",
      "tp:  441\n",
      "fn:  123\n",
      "tn:  454\n",
      "fp:  110\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  895\n",
      "EPOCH 215\n",
      "   TRAIN | Label 1 loss: 4.9534 ; P: 0.9493 ; R: 0.9547 ; F1: 0.952 ; Acc: 0.9823\n",
      "           Label 2 loss: 22.1325 ; P: 0.9647 ; R: 0.9713 ; F1: 0.968 ; Acc: 0.9679\n",
      "    TEST | Label 1 loss: 8.7501 ; P: 0.8406 ; R: 0.8507 ; F1: 0.8456 ; Acc: 0.939\n",
      "           Label 2 loss: 21.8516 ; P: 0.8004 ; R: 0.7819 ; F1: 0.791 ; Acc: 0.7934\n",
      "2023-01-29 14:15:27.689201\n",
      "counter:  4\n",
      "2023-01-29 14:15:27.689201\n",
      "EPOCH 216\n",
      "TAG_LOSS_WEIGHT:  0.14546854369092235\n",
      "CLS_LOSS_WEIGHT:  0.8545314563090777\n",
      "tp:  1278\n",
      "fn:  44\n",
      "tn:  1277\n",
      "fp:  45\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2555\n",
      "tp:  443\n",
      "fn:  121\n",
      "tn:  450\n",
      "fp:  114\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  893\n",
      "EPOCH 216\n",
      "   TRAIN | Label 1 loss: 5.0849 ; P: 0.9463 ; R: 0.9468 ; F1: 0.9466 ; Acc: 0.9803\n",
      "           Label 2 loss: 22.4692 ; P: 0.966 ; R: 0.9667 ; F1: 0.9664 ; Acc: 0.9663\n",
      "    TEST | Label 1 loss: 8.7841 ; P: 0.8264 ; R: 0.8583 ; F1: 0.8421 ; Acc: 0.9367\n",
      "           Label 2 loss: 21.9482 ; P: 0.7953 ; R: 0.7855 ; F1: 0.7904 ; Acc: 0.7917\n",
      "2023-01-29 14:15:58.464869\n",
      "counter:  5\n",
      "2023-01-29 14:15:58.465868\n",
      "EPOCH 217\n",
      "TAG_LOSS_WEIGHT:  0.14825065019352496\n",
      "CLS_LOSS_WEIGHT:  0.8517493498064749\n",
      "tp:  1283\n",
      "fn:  39\n",
      "tn:  1286\n",
      "fp:  36\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2569\n",
      "tp:  446\n",
      "fn:  118\n",
      "tn:  445\n",
      "fp:  119\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  891\n",
      "EPOCH 217\n",
      "   TRAIN | Label 1 loss: 4.8494 ; P: 0.9497 ; R: 0.9559 ; F1: 0.9528 ; Acc: 0.9825\n",
      "           Label 2 loss: 22.0679 ; P: 0.9727 ; R: 0.9705 ; F1: 0.9716 ; Acc: 0.9716\n",
      "    TEST | Label 1 loss: 8.9244 ; P: 0.8261 ; R: 0.8564 ; F1: 0.841 ; Acc: 0.9364\n",
      "           Label 2 loss: 22.0194 ; P: 0.7894 ; R: 0.7908 ; F1: 0.7901 ; Acc: 0.7899\n",
      "2023-01-29 14:16:29.449852\n",
      "counter:  6\n",
      "2023-01-29 14:16:29.450852\n",
      "EPOCH 218\n",
      "TAG_LOSS_WEIGHT:  0.14097859283911915\n",
      "CLS_LOSS_WEIGHT:  0.8590214071608807\n",
      "tp:  1285\n",
      "fn:  37\n",
      "tn:  1276\n",
      "fp:  46\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2561\n",
      "tp:  445\n",
      "fn:  119\n",
      "tn:  446\n",
      "fp:  118\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  891\n",
      "EPOCH 218\n",
      "   TRAIN | Label 1 loss: 4.7678 ; P: 0.949 ; R: 0.9566 ; F1: 0.9528 ; Acc: 0.9825\n",
      "           Label 2 loss: 21.7356 ; P: 0.9654 ; R: 0.972 ; F1: 0.9687 ; Acc: 0.9686\n",
      "    TEST | Label 1 loss: 8.9657 ; P: 0.8393 ; R: 0.852 ; F1: 0.8456 ; Acc: 0.9389\n",
      "           Label 2 loss: 22.0207 ; P: 0.7904 ; R: 0.789 ; F1: 0.7897 ; Acc: 0.7899\n",
      "2023-01-29 14:17:00.324501\n",
      "counter:  7\n",
      "2023-01-29 14:17:00.325501\n",
      "EPOCH 219\n",
      "TAG_LOSS_WEIGHT:  0.14054380900460728\n",
      "CLS_LOSS_WEIGHT:  0.8594561909953927\n",
      "tp:  1283\n",
      "fn:  39\n",
      "tn:  1282\n",
      "fp:  40\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2565\n",
      "tp:  440\n",
      "fn:  124\n",
      "tn:  455\n",
      "fp:  109\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  895\n",
      "EPOCH 219\n",
      "   TRAIN | Label 1 loss: 4.8479 ; P: 0.9526 ; R: 0.953 ; F1: 0.9528 ; Acc: 0.9826\n",
      "           Label 2 loss: 21.8803 ; P: 0.9698 ; R: 0.9705 ; F1: 0.9701 ; Acc: 0.9701\n",
      "    TEST | Label 1 loss: 9.1128 ; P: 0.841 ; R: 0.8431 ; F1: 0.8421 ; Acc: 0.9379\n",
      "           Label 2 loss: 22.1418 ; P: 0.8015 ; R: 0.7801 ; F1: 0.7907 ; Acc: 0.7934\n",
      "2023-01-29 14:17:31.315401\n",
      "counter:  8\n",
      "2023-01-29 14:17:31.315401\n",
      "EPOCH 220\n",
      "TAG_LOSS_WEIGHT:  0.14298327534917357\n",
      "CLS_LOSS_WEIGHT:  0.8570167246508265\n",
      "tp:  1280\n",
      "fn:  42\n",
      "tn:  1285\n",
      "fp:  37\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2565\n",
      "tp:  448\n",
      "fn:  116\n",
      "tn:  447\n",
      "fp:  117\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  895\n",
      "EPOCH 220\n",
      "   TRAIN | Label 1 loss: 4.7189 ; P: 0.9525 ; R: 0.9545 ; F1: 0.9535 ; Acc: 0.9829\n",
      "           Label 2 loss: 21.6038 ; P: 0.9719 ; R: 0.9682 ; F1: 0.9701 ; Acc: 0.9701\n",
      "    TEST | Label 1 loss: 8.8499 ; P: 0.8418 ; R: 0.8514 ; F1: 0.8465 ; Acc: 0.9393\n",
      "           Label 2 loss: 21.8417 ; P: 0.7929 ; R: 0.7943 ; F1: 0.7936 ; Acc: 0.7934\n",
      "2023-01-29 14:18:02.088314\n",
      "counter:  9\n",
      "2023-01-29 14:18:02.088314\n",
      "EPOCH 221\n",
      "TAG_LOSS_WEIGHT:  0.13952573558109924\n",
      "CLS_LOSS_WEIGHT:  0.8604742644189006\n",
      "tp:  1288\n",
      "fn:  34\n",
      "tn:  1292\n",
      "fp:  30\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2580\n",
      "tp:  451\n",
      "fn:  113\n",
      "tn:  449\n",
      "fp:  115\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  900\n",
      "EPOCH 221\n",
      "   TRAIN | Label 1 loss: 4.6735 ; P: 0.9506 ; R: 0.9566 ; F1: 0.9536 ; Acc: 0.9829\n",
      "           Label 2 loss: 21.219 ; P: 0.9772 ; R: 0.9743 ; F1: 0.9758 ; Acc: 0.9758\n",
      "    TEST | Label 1 loss: 8.9586 ; P: 0.8329 ; R: 0.8545 ; F1: 0.8436 ; Acc: 0.9377\n",
      "           Label 2 loss: 21.7765 ; P: 0.7968 ; R: 0.7996 ; F1: 0.7982 ; Acc: 0.7979\n",
      "2023-01-29 14:18:33.066469\n",
      "counter:  0\n",
      "2023-01-29 14:18:34.762529\n",
      "EPOCH 222\n",
      "TAG_LOSS_WEIGHT:  0.14153180943185814\n",
      "CLS_LOSS_WEIGHT:  0.8584681905681418\n",
      "tp:  1286\n",
      "fn:  36\n",
      "tn:  1289\n",
      "fp:  33\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2575\n",
      "tp:  440\n",
      "fn:  124\n",
      "tn:  456\n",
      "fp:  108\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  896\n",
      "EPOCH 222\n",
      "   TRAIN | Label 1 loss: 4.7151 ; P: 0.9536 ; R: 0.9549 ; F1: 0.9543 ; Acc: 0.9831\n",
      "           Label 2 loss: 21.5473 ; P: 0.975 ; R: 0.9728 ; F1: 0.9739 ; Acc: 0.9739\n",
      "    TEST | Label 1 loss: 9.0196 ; P: 0.8411 ; R: 0.8501 ; F1: 0.8455 ; Acc: 0.939\n",
      "           Label 2 loss: 21.9728 ; P: 0.8029 ; R: 0.7801 ; F1: 0.7914 ; Acc: 0.7943\n",
      "2023-01-29 14:19:06.375394\n",
      "counter:  1\n",
      "2023-01-29 14:19:06.376394\n",
      "EPOCH 223\n",
      "TAG_LOSS_WEIGHT:  0.13996166266961868\n",
      "CLS_LOSS_WEIGHT:  0.8600383373303814\n",
      "tp:  1287\n",
      "fn:  35\n",
      "tn:  1283\n",
      "fp:  39\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2570\n",
      "tp:  453\n",
      "fn:  111\n",
      "tn:  449\n",
      "fp:  115\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  902\n",
      "EPOCH 223\n",
      "   TRAIN | Label 1 loss: 4.7092 ; P: 0.9524 ; R: 0.9556 ; F1: 0.954 ; Acc: 0.983\n",
      "           Label 2 loss: 21.6074 ; P: 0.9706 ; R: 0.9735 ; F1: 0.9721 ; Acc: 0.972\n",
      "    TEST | Label 1 loss: 8.8547 ; P: 0.8408 ; R: 0.852 ; F1: 0.8464 ; Acc: 0.9392\n",
      "           Label 2 loss: 21.6364 ; P: 0.7975 ; R: 0.8032 ; F1: 0.8004 ; Acc: 0.7996\n",
      "2023-01-29 14:19:38.016895\n",
      "counter:  0\n",
      "2023-01-29 14:19:39.835844\n",
      "EPOCH 224\n",
      "TAG_LOSS_WEIGHT:  0.1389924995068567\n",
      "CLS_LOSS_WEIGHT:  0.8610075004931433\n",
      "tp:  1286\n",
      "fn:  36\n",
      "tn:  1285\n",
      "fp:  37\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2571\n",
      "tp:  450\n",
      "fn:  114\n",
      "tn:  449\n",
      "fp:  115\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  899\n",
      "EPOCH 224\n",
      "   TRAIN | Label 1 loss: 4.6674 ; P: 0.9544 ; R: 0.9569 ; F1: 0.9556 ; Acc: 0.9836\n",
      "           Label 2 loss: 21.4685 ; P: 0.972 ; R: 0.9728 ; F1: 0.9724 ; Acc: 0.9724\n",
      "    TEST | Label 1 loss: 8.9217 ; P: 0.8411 ; R: 0.8501 ; F1: 0.8455 ; Acc: 0.939\n",
      "           Label 2 loss: 21.8586 ; P: 0.7965 ; R: 0.7979 ; F1: 0.7972 ; Acc: 0.797\n",
      "2023-01-29 14:20:12.454490\n",
      "counter:  1\n",
      "2023-01-29 14:20:12.454490\n",
      "EPOCH 225\n",
      "TAG_LOSS_WEIGHT:  0.13840313676190288\n",
      "CLS_LOSS_WEIGHT:  0.8615968632380971\n",
      "tp:  1290\n",
      "fn:  32\n",
      "tn:  1292\n",
      "fp:  30\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2582\n",
      "tp:  450\n",
      "fn:  114\n",
      "tn:  449\n",
      "fp:  115\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  899\n",
      "EPOCH 225\n",
      "   TRAIN | Label 1 loss: 4.5764 ; P: 0.9557 ; R: 0.9573 ; F1: 0.9565 ; Acc: 0.984\n",
      "           Label 2 loss: 20.8488 ; P: 0.9773 ; R: 0.9758 ; F1: 0.9765 ; Acc: 0.9766\n",
      "    TEST | Label 1 loss: 9.0954 ; P: 0.8362 ; R: 0.8495 ; F1: 0.8428 ; Acc: 0.9377\n",
      "           Label 2 loss: 21.8563 ; P: 0.7965 ; R: 0.7979 ; F1: 0.7972 ; Acc: 0.797\n",
      "2023-01-29 14:20:44.020564\n",
      "counter:  2\n",
      "2023-01-29 14:20:44.020564\n",
      "EPOCH 226\n",
      "TAG_LOSS_WEIGHT:  0.14070883210409008\n",
      "CLS_LOSS_WEIGHT:  0.8592911678959101\n",
      "tp:  1289\n",
      "fn:  33\n",
      "tn:  1283\n",
      "fp:  39\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2572\n",
      "tp:  446\n",
      "fn:  118\n",
      "tn:  452\n",
      "fp:  112\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  898\n",
      "EPOCH 226\n",
      "   TRAIN | Label 1 loss: 4.5342 ; P: 0.9507 ; R: 0.961 ; F1: 0.9558 ; Acc: 0.9836\n",
      "           Label 2 loss: 21.472 ; P: 0.9706 ; R: 0.975 ; F1: 0.9728 ; Acc: 0.9728\n",
      "    TEST | Label 1 loss: 9.0576 ; P: 0.8449 ; R: 0.8514 ; F1: 0.8481 ; Acc: 0.9401\n",
      "           Label 2 loss: 21.8454 ; P: 0.7993 ; R: 0.7908 ; F1: 0.795 ; Acc: 0.7961\n",
      "2023-01-29 14:21:14.826186\n",
      "counter:  3\n",
      "2023-01-29 14:21:14.826186\n",
      "EPOCH 227\n",
      "TAG_LOSS_WEIGHT:  0.13160406737398325\n",
      "CLS_LOSS_WEIGHT:  0.8683959326260167\n",
      "tp:  1294\n",
      "fn:  28\n",
      "tn:  1289\n",
      "fp:  33\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2583\n",
      "tp:  443\n",
      "fn:  121\n",
      "tn:  455\n",
      "fp:  109\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  898\n",
      "EPOCH 227\n",
      "   TRAIN | Label 1 loss: 4.627 ; P: 0.9547 ; R: 0.9584 ; F1: 0.9566 ; Acc: 0.984\n",
      "           Label 2 loss: 21.1879 ; P: 0.9751 ; R: 0.9788 ; F1: 0.977 ; Acc: 0.9769\n",
      "    TEST | Label 1 loss: 9.0622 ; P: 0.8445 ; R: 0.8482 ; F1: 0.8463 ; Acc: 0.9395\n",
      "           Label 2 loss: 21.8394 ; P: 0.8025 ; R: 0.7855 ; F1: 0.7939 ; Acc: 0.7961\n",
      "2023-01-29 14:21:46.362108\n",
      "counter:  4\n",
      "2023-01-29 14:21:46.362108\n",
      "EPOCH 228\n",
      "TAG_LOSS_WEIGHT:  0.13947098586111928\n",
      "CLS_LOSS_WEIGHT:  0.8605290141388806\n",
      "tp:  1289\n",
      "fn:  33\n",
      "tn:  1288\n",
      "fp:  34\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2577\n",
      "tp:  446\n",
      "fn:  118\n",
      "tn:  456\n",
      "fp:  108\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  902\n",
      "EPOCH 228\n",
      "   TRAIN | Label 1 loss: 4.4239 ; P: 0.9554 ; R: 0.9618 ; F1: 0.9586 ; Acc: 0.9847\n",
      "           Label 2 loss: 21.11 ; P: 0.9743 ; R: 0.975 ; F1: 0.9747 ; Acc: 0.9747\n",
      "    TEST | Label 1 loss: 9.1401 ; P: 0.8384 ; R: 0.8501 ; F1: 0.8442 ; Acc: 0.9384\n",
      "           Label 2 loss: 21.7437 ; P: 0.8051 ; R: 0.7908 ; F1: 0.7979 ; Acc: 0.7996\n",
      "2023-01-29 14:22:17.280180\n",
      "counter:  5\n",
      "2023-01-29 14:22:17.281180\n",
      "EPOCH 229\n",
      "TAG_LOSS_WEIGHT:  0.12987120238876865\n",
      "CLS_LOSS_WEIGHT:  0.8701287976112313\n",
      "tp:  1292\n",
      "fn:  30\n",
      "tn:  1286\n",
      "fp:  36\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2578\n",
      "tp:  449\n",
      "fn:  115\n",
      "tn:  455\n",
      "fp:  109\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  904\n",
      "EPOCH 229\n",
      "   TRAIN | Label 1 loss: 4.2902 ; P: 0.9559 ; R: 0.9605 ; F1: 0.9582 ; Acc: 0.9846\n",
      "           Label 2 loss: 20.8809 ; P: 0.9729 ; R: 0.9773 ; F1: 0.9751 ; Acc: 0.975\n",
      "    TEST | Label 1 loss: 9.1154 ; P: 0.84 ; R: 0.8501 ; F1: 0.845 ; Acc: 0.9387\n",
      "           Label 2 loss: 21.6609 ; P: 0.8047 ; R: 0.7961 ; F1: 0.8004 ; Acc: 0.8014\n",
      "2023-01-29 14:22:48.401112\n",
      "counter:  0\n",
      "2023-01-29 14:22:50.196684\n",
      "EPOCH 230\n",
      "TAG_LOSS_WEIGHT:  0.12546662636999975\n",
      "CLS_LOSS_WEIGHT:  0.8745333736300003\n",
      "tp:  1295\n",
      "fn:  27\n",
      "tn:  1285\n",
      "fp:  37\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2580\n",
      "tp:  445\n",
      "fn:  119\n",
      "tn:  461\n",
      "fp:  103\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  906\n",
      "EPOCH 230\n",
      "   TRAIN | Label 1 loss: 4.4188 ; P: 0.9558 ; R: 0.9593 ; F1: 0.9575 ; Acc: 0.9843\n",
      "           Label 2 loss: 21.0831 ; P: 0.9722 ; R: 0.9796 ; F1: 0.9759 ; Acc: 0.9758\n",
      "    TEST | Label 1 loss: 9.2337 ; P: 0.844 ; R: 0.8488 ; F1: 0.8464 ; Acc: 0.9395\n",
      "           Label 2 loss: 21.6456 ; P: 0.812 ; R: 0.789 ; F1: 0.8004 ; Acc: 0.8032\n",
      "2023-01-29 14:23:21.902909\n",
      "counter:  0\n",
      "2023-01-29 14:23:23.574429\n",
      "EPOCH 231\n",
      "TAG_LOSS_WEIGHT:  0.12989868674145968\n",
      "CLS_LOSS_WEIGHT:  0.8701013132585402\n",
      "tp:  1287\n",
      "fn:  35\n",
      "tn:  1296\n",
      "fp:  26\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2583\n",
      "tp:  450\n",
      "fn:  114\n",
      "tn:  453\n",
      "fp:  111\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  903\n",
      "EPOCH 231\n",
      "   TRAIN | Label 1 loss: 4.3514 ; P: 0.9545 ; R: 0.9625 ; F1: 0.9585 ; Acc: 0.9846\n",
      "           Label 2 loss: 20.707 ; P: 0.9802 ; R: 0.9735 ; F1: 0.9769 ; Acc: 0.9769\n",
      "    TEST | Label 1 loss: 9.0988 ; P: 0.8401 ; R: 0.8539 ; F1: 0.8469 ; Acc: 0.9393\n",
      "           Label 2 loss: 21.6678 ; P: 0.8021 ; R: 0.7979 ; F1: 0.8 ; Acc: 0.8005\n",
      "2023-01-29 14:23:55.742251\n",
      "counter:  1\n",
      "2023-01-29 14:23:55.742251\n",
      "EPOCH 232\n",
      "TAG_LOSS_WEIGHT:  0.1304942273834348\n",
      "CLS_LOSS_WEIGHT:  0.8695057726165653\n",
      "tp:  1291\n",
      "fn:  31\n",
      "tn:  1285\n",
      "fp:  37\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2576\n",
      "tp:  444\n",
      "fn:  120\n",
      "tn:  455\n",
      "fp:  109\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  899\n",
      "EPOCH 232\n",
      "   TRAIN | Label 1 loss: 4.3969 ; P: 0.9543 ; R: 0.9605 ; F1: 0.9574 ; Acc: 0.9842\n",
      "           Label 2 loss: 20.9896 ; P: 0.9721 ; R: 0.9766 ; F1: 0.9743 ; Acc: 0.9743\n",
      "    TEST | Label 1 loss: 9.0876 ; P: 0.8448 ; R: 0.8507 ; F1: 0.8478 ; Acc: 0.94\n",
      "           Label 2 loss: 21.7253 ; P: 0.8029 ; R: 0.7872 ; F1: 0.795 ; Acc: 0.797\n",
      "2023-01-29 14:24:27.208027\n",
      "counter:  2\n",
      "2023-01-29 14:24:27.208027\n",
      "EPOCH 233\n",
      "TAG_LOSS_WEIGHT:  0.12978034477109912\n",
      "CLS_LOSS_WEIGHT:  0.8702196552289009\n",
      "tp:  1292\n",
      "fn:  30\n",
      "tn:  1294\n",
      "fp:  28\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2586\n",
      "tp:  448\n",
      "fn:  116\n",
      "tn:  452\n",
      "fp:  112\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  900\n",
      "EPOCH 233\n",
      "   TRAIN | Label 1 loss: 4.2639 ; P: 0.9574 ; R: 0.9646 ; F1: 0.961 ; Acc: 0.9856\n",
      "           Label 2 loss: 20.7232 ; P: 0.9788 ; R: 0.9773 ; F1: 0.978 ; Acc: 0.9781\n",
      "    TEST | Label 1 loss: 9.0751 ; P: 0.8447 ; R: 0.8533 ; F1: 0.849 ; Acc: 0.9403\n",
      "           Label 2 loss: 21.7098 ; P: 0.8 ; R: 0.7943 ; F1: 0.7972 ; Acc: 0.7979\n",
      "2023-01-29 14:24:59.054211\n",
      "counter:  3\n",
      "2023-01-29 14:24:59.056211\n",
      "EPOCH 234\n",
      "TAG_LOSS_WEIGHT:  0.1257811938382624\n",
      "CLS_LOSS_WEIGHT:  0.8742188061617376\n",
      "tp:  1302\n",
      "fn:  20\n",
      "tn:  1294\n",
      "fp:  28\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2596\n",
      "tp:  451\n",
      "fn:  113\n",
      "tn:  451\n",
      "fp:  113\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  902\n",
      "EPOCH 234\n",
      "   TRAIN | Label 1 loss: 4.1387 ; P: 0.9584 ; R: 0.9638 ; F1: 0.9611 ; Acc: 0.9856\n",
      "           Label 2 loss: 20.1587 ; P: 0.9789 ; R: 0.9849 ; F1: 0.9819 ; Acc: 0.9818\n",
      "    TEST | Label 1 loss: 9.136 ; P: 0.8437 ; R: 0.8533 ; F1: 0.8484 ; Acc: 0.9401\n",
      "           Label 2 loss: 21.7623 ; P: 0.7996 ; R: 0.7996 ; F1: 0.7996 ; Acc: 0.7996\n",
      "2023-01-29 14:25:30.534414\n",
      "counter:  4\n",
      "2023-01-29 14:25:30.535424\n",
      "EPOCH 235\n",
      "TAG_LOSS_WEIGHT:  0.12530153666074653\n",
      "CLS_LOSS_WEIGHT:  0.8746984633392534\n",
      "tp:  1298\n",
      "fn:  24\n",
      "tn:  1293\n",
      "fp:  29\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2591\n",
      "tp:  447\n",
      "fn:  117\n",
      "tn:  456\n",
      "fp:  108\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  903\n",
      "EPOCH 235\n",
      "   TRAIN | Label 1 loss: 4.1619 ; P: 0.9593 ; R: 0.964 ; F1: 0.9617 ; Acc: 0.9858\n",
      "           Label 2 loss: 20.408 ; P: 0.9781 ; R: 0.9818 ; F1: 0.98 ; Acc: 0.98\n",
      "    TEST | Label 1 loss: 9.2912 ; P: 0.8436 ; R: 0.8526 ; F1: 0.8481 ; Acc: 0.94\n",
      "           Label 2 loss: 21.7302 ; P: 0.8054 ; R: 0.7926 ; F1: 0.7989 ; Acc: 0.8005\n",
      "2023-01-29 14:26:01.803537\n",
      "counter:  5\n",
      "2023-01-29 14:26:01.804537\n",
      "EPOCH 236\n",
      "TAG_LOSS_WEIGHT:  0.12384001312809004\n",
      "CLS_LOSS_WEIGHT:  0.8761599868719099\n",
      "tp:  1296\n",
      "fn:  26\n",
      "tn:  1291\n",
      "fp:  31\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2587\n",
      "tp:  450\n",
      "fn:  114\n",
      "tn:  458\n",
      "fp:  106\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  908\n",
      "EPOCH 236\n",
      "   TRAIN | Label 1 loss: 4.1388 ; P: 0.9586 ; R: 0.9646 ; F1: 0.9616 ; Acc: 0.9858\n",
      "           Label 2 loss: 20.5377 ; P: 0.9766 ; R: 0.9803 ; F1: 0.9785 ; Acc: 0.9784\n",
      "    TEST | Label 1 loss: 9.2889 ; P: 0.8465 ; R: 0.8514 ; F1: 0.8489 ; Acc: 0.9405\n",
      "           Label 2 loss: 21.6555 ; P: 0.8094 ; R: 0.7979 ; F1: 0.8036 ; Acc: 0.805\n",
      "2023-01-29 14:26:32.968575\n",
      "counter:  0\n",
      "2023-01-29 14:26:34.635023\n",
      "EPOCH 237\n",
      "TAG_LOSS_WEIGHT:  0.12128043564768869\n",
      "CLS_LOSS_WEIGHT:  0.8787195643523114\n",
      "tp:  1301\n",
      "fn:  21\n",
      "tn:  1296\n",
      "fp:  26\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2597\n",
      "tp:  450\n",
      "fn:  114\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  907\n",
      "EPOCH 237\n",
      "   TRAIN | Label 1 loss: 4.2383 ; P: 0.9561 ; R: 0.9611 ; F1: 0.9586 ; Acc: 0.9847\n",
      "           Label 2 loss: 20.3531 ; P: 0.9804 ; R: 0.9841 ; F1: 0.9823 ; Acc: 0.9822\n",
      "    TEST | Label 1 loss: 9.2557 ; P: 0.8423 ; R: 0.8545 ; F1: 0.8484 ; Acc: 0.94\n",
      "           Label 2 loss: 21.6957 ; P: 0.8079 ; R: 0.7979 ; F1: 0.8029 ; Acc: 0.8041\n",
      "2023-01-29 14:27:06.057253\n",
      "counter:  1\n",
      "2023-01-29 14:27:06.057253\n",
      "EPOCH 238\n",
      "TAG_LOSS_WEIGHT:  0.12844371997445908\n",
      "CLS_LOSS_WEIGHT:  0.8715562800255409\n",
      "tp:  1299\n",
      "fn:  23\n",
      "tn:  1294\n",
      "fp:  28\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2593\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  454\n",
      "fp:  110\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  906\n",
      "EPOCH 238\n",
      "   TRAIN | Label 1 loss: 4.1949 ; P: 0.9567 ; R: 0.9638 ; F1: 0.9602 ; Acc: 0.9853\n",
      "           Label 2 loss: 20.3847 ; P: 0.9789 ; R: 0.9826 ; F1: 0.9807 ; Acc: 0.9807\n",
      "    TEST | Label 1 loss: 9.2318 ; P: 0.8414 ; R: 0.8558 ; F1: 0.8485 ; Acc: 0.94\n",
      "           Label 2 loss: 21.6902 ; P: 0.8043 ; R: 0.8014 ; F1: 0.8028 ; Acc: 0.8032\n",
      "2023-01-29 14:27:38.046007\n",
      "counter:  2\n",
      "2023-01-29 14:27:38.046007\n",
      "EPOCH 239\n",
      "TAG_LOSS_WEIGHT:  0.12581517405765816\n",
      "CLS_LOSS_WEIGHT:  0.8741848259423417\n",
      "tp:  1292\n",
      "fn:  30\n",
      "tn:  1292\n",
      "fp:  30\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2584\n",
      "tp:  450\n",
      "fn:  114\n",
      "tn:  456\n",
      "fp:  108\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  906\n",
      "EPOCH 239\n",
      "   TRAIN | Label 1 loss: 4.1914 ; P: 0.957 ; R: 0.9631 ; F1: 0.96 ; Acc: 0.9852\n",
      "           Label 2 loss: 20.6354 ; P: 0.9773 ; R: 0.9773 ; F1: 0.9773 ; Acc: 0.9773\n",
      "    TEST | Label 1 loss: 9.2895 ; P: 0.8427 ; R: 0.8539 ; F1: 0.8483 ; Acc: 0.94\n",
      "           Label 2 loss: 21.6856 ; P: 0.8065 ; R: 0.7979 ; F1: 0.8021 ; Acc: 0.8032\n",
      "2023-01-29 14:28:09.394541\n",
      "counter:  3\n",
      "2023-01-29 14:28:09.394541\n",
      "EPOCH 240\n",
      "TAG_LOSS_WEIGHT:  0.12297071863093845\n",
      "CLS_LOSS_WEIGHT:  0.8770292813690616\n",
      "tp:  1302\n",
      "fn:  20\n",
      "tn:  1299\n",
      "fp:  23\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2601\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  456\n",
      "fp:  108\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  908\n",
      "EPOCH 240\n",
      "   TRAIN | Label 1 loss: 4.0058 ; P: 0.9589 ; R: 0.9687 ; F1: 0.9637 ; Acc: 0.9866\n",
      "           Label 2 loss: 19.9392 ; P: 0.9826 ; R: 0.9849 ; F1: 0.9838 ; Acc: 0.9837\n",
      "    TEST | Label 1 loss: 9.3114 ; P: 0.8467 ; R: 0.8526 ; F1: 0.8497 ; Acc: 0.9407\n",
      "           Label 2 loss: 21.7559 ; P: 0.8071 ; R: 0.8014 ; F1: 0.8043 ; Acc: 0.805\n",
      "2023-01-29 14:28:41.191429\n",
      "counter:  4\n",
      "2023-01-29 14:28:41.191429\n",
      "EPOCH 241\n",
      "TAG_LOSS_WEIGHT:  0.12062378773701443\n",
      "CLS_LOSS_WEIGHT:  0.8793762122629856\n",
      "tp:  1295\n",
      "fn:  27\n",
      "tn:  1297\n",
      "fp:  25\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2592\n",
      "tp:  451\n",
      "fn:  113\n",
      "tn:  455\n",
      "fp:  109\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  906\n",
      "EPOCH 241\n",
      "   TRAIN | Label 1 loss: 4.0187 ; P: 0.9609 ; R: 0.9638 ; F1: 0.9623 ; Acc: 0.9861\n",
      "           Label 2 loss: 20.2649 ; P: 0.9811 ; R: 0.9796 ; F1: 0.9803 ; Acc: 0.9803\n",
      "    TEST | Label 1 loss: 9.3126 ; P: 0.8442 ; R: 0.8533 ; F1: 0.8487 ; Acc: 0.9402\n",
      "           Label 2 loss: 21.7459 ; P: 0.8054 ; R: 0.7996 ; F1: 0.8025 ; Acc: 0.8032\n",
      "2023-01-29 14:29:12.217432\n",
      "counter:  5\n",
      "2023-01-29 14:29:12.218433\n",
      "EPOCH 242\n",
      "TAG_LOSS_WEIGHT:  0.11789555644240447\n",
      "CLS_LOSS_WEIGHT:  0.8821044435575955\n",
      "tp:  1298\n",
      "fn:  24\n",
      "tn:  1290\n",
      "fp:  32\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2588\n",
      "tp:  451\n",
      "fn:  113\n",
      "tn:  456\n",
      "fp:  108\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  907\n",
      "EPOCH 242\n",
      "   TRAIN | Label 1 loss: 4.0676 ; P: 0.9578 ; R: 0.9653 ; F1: 0.9615 ; Acc: 0.9858\n",
      "           Label 2 loss: 20.3313 ; P: 0.9759 ; R: 0.9818 ; F1: 0.9789 ; Acc: 0.9788\n",
      "    TEST | Label 1 loss: 9.3222 ; P: 0.8446 ; R: 0.8526 ; F1: 0.8486 ; Acc: 0.9402\n",
      "           Label 2 loss: 21.71 ; P: 0.8068 ; R: 0.7996 ; F1: 0.8032 ; Acc: 0.8041\n",
      "2023-01-29 14:29:43.490793\n",
      "counter:  6\n",
      "2023-01-29 14:29:43.490793\n",
      "EPOCH 243\n",
      "TAG_LOSS_WEIGHT:  0.11974317370579411\n",
      "CLS_LOSS_WEIGHT:  0.880256826294206\n",
      "tp:  1298\n",
      "fn:  24\n",
      "tn:  1294\n",
      "fp:  28\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2592\n",
      "tp:  451\n",
      "fn:  113\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  908\n",
      "EPOCH 243\n",
      "   TRAIN | Label 1 loss: 4.1029 ; P: 0.961 ; R: 0.9657 ; F1: 0.9634 ; Acc: 0.9865\n",
      "           Label 2 loss: 20.2994 ; P: 0.9789 ; R: 0.9818 ; F1: 0.9804 ; Acc: 0.9803\n",
      "    TEST | Label 1 loss: 9.341 ; P: 0.8449 ; R: 0.8514 ; F1: 0.8481 ; Acc: 0.9401\n",
      "           Label 2 loss: 21.7248 ; P: 0.8082 ; R: 0.7996 ; F1: 0.8039 ; Acc: 0.805\n",
      "2023-01-29 14:30:14.845425\n",
      "counter:  7\n",
      "2023-01-29 14:30:14.846425\n",
      "EPOCH 244\n",
      "TAG_LOSS_WEIGHT:  0.1219125497328875\n",
      "CLS_LOSS_WEIGHT:  0.8780874502671124\n",
      "tp:  1298\n",
      "fn:  24\n",
      "tn:  1297\n",
      "fp:  25\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2595\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  909\n",
      "EPOCH 244\n",
      "   TRAIN | Label 1 loss: 4.1146 ; P: 0.9581 ; R: 0.9643 ; F1: 0.9612 ; Acc: 0.9857\n",
      "           Label 2 loss: 20.2618 ; P: 0.9811 ; R: 0.9818 ; F1: 0.9815 ; Acc: 0.9815\n",
      "    TEST | Label 1 loss: 9.3337 ; P: 0.8443 ; R: 0.8507 ; F1: 0.8475 ; Acc: 0.9398\n",
      "           Label 2 loss: 21.6872 ; P: 0.8086 ; R: 0.8014 ; F1: 0.805 ; Acc: 0.8059\n",
      "2023-01-29 14:30:46.014809\n",
      "counter:  0\n",
      "2023-01-29 14:30:47.734254\n",
      "EPOCH 245\n",
      "TAG_LOSS_WEIGHT:  0.12292273924356324\n",
      "CLS_LOSS_WEIGHT:  0.8770772607564368\n",
      "tp:  1293\n",
      "fn:  29\n",
      "tn:  1296\n",
      "fp:  26\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2589\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  909\n",
      "EPOCH 245\n",
      "   TRAIN | Label 1 loss: 4.312 ; P: 0.9567 ; R: 0.9622 ; F1: 0.9595 ; Acc: 0.985\n",
      "           Label 2 loss: 20.3181 ; P: 0.9803 ; R: 0.9781 ; F1: 0.9792 ; Acc: 0.9792\n",
      "    TEST | Label 1 loss: 9.3073 ; P: 0.8435 ; R: 0.852 ; F1: 0.8477 ; Acc: 0.9398\n",
      "           Label 2 loss: 21.7094 ; P: 0.8086 ; R: 0.8014 ; F1: 0.805 ; Acc: 0.8059\n",
      "2023-01-29 14:31:19.743127\n",
      "counter:  1\n",
      "2023-01-29 14:31:19.743127\n",
      "EPOCH 246\n",
      "TAG_LOSS_WEIGHT:  0.13274901364250047\n",
      "CLS_LOSS_WEIGHT:  0.8672509863574995\n",
      "tp:  1298\n",
      "fn:  24\n",
      "tn:  1291\n",
      "fp:  31\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2589\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  909\n",
      "EPOCH 246\n",
      "   TRAIN | Label 1 loss: 4.1633 ; P: 0.9583 ; R: 0.9639 ; F1: 0.9611 ; Acc: 0.9856\n",
      "           Label 2 loss: 20.3757 ; P: 0.9767 ; R: 0.9818 ; F1: 0.9793 ; Acc: 0.9792\n",
      "    TEST | Label 1 loss: 9.2996 ; P: 0.8435 ; R: 0.852 ; F1: 0.8477 ; Acc: 0.9398\n",
      "           Label 2 loss: 21.6989 ; P: 0.8086 ; R: 0.8014 ; F1: 0.805 ; Acc: 0.8059\n",
      "2023-01-29 14:31:51.859702\n",
      "counter:  2\n",
      "2023-01-29 14:31:51.860714\n",
      "EPOCH 247\n",
      "TAG_LOSS_WEIGHT:  0.124257333538218\n",
      "CLS_LOSS_WEIGHT:  0.875742666461782\n",
      "tp:  1301\n",
      "fn:  21\n",
      "tn:  1294\n",
      "fp:  28\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2595\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  909\n",
      "EPOCH 247\n",
      "   TRAIN | Label 1 loss: 4.0463 ; P: 0.9594 ; R: 0.9666 ; F1: 0.963 ; Acc: 0.9863\n",
      "           Label 2 loss: 20.0618 ; P: 0.9789 ; R: 0.9841 ; F1: 0.9815 ; Acc: 0.9815\n",
      "    TEST | Label 1 loss: 9.2981 ; P: 0.843 ; R: 0.8526 ; F1: 0.8478 ; Acc: 0.9398\n",
      "           Label 2 loss: 21.7043 ; P: 0.8086 ; R: 0.8014 ; F1: 0.805 ; Acc: 0.8059\n",
      "2023-01-29 14:32:23.058168\n",
      "counter:  3\n",
      "2023-01-29 14:32:23.059158\n",
      "EPOCH 248\n",
      "TAG_LOSS_WEIGHT:  0.12145995353524534\n",
      "CLS_LOSS_WEIGHT:  0.8785400464647546\n",
      "tp:  1298\n",
      "fn:  24\n",
      "tn:  1294\n",
      "fp:  28\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2592\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  909\n",
      "EPOCH 248\n",
      "   TRAIN | Label 1 loss: 4.2199 ; P: 0.9574 ; R: 0.9615 ; F1: 0.9594 ; Acc: 0.985\n",
      "           Label 2 loss: 20.4358 ; P: 0.9789 ; R: 0.9818 ; F1: 0.9804 ; Acc: 0.9803\n",
      "    TEST | Label 1 loss: 9.295 ; P: 0.843 ; R: 0.8526 ; F1: 0.8478 ; Acc: 0.9398\n",
      "           Label 2 loss: 21.6882 ; P: 0.8086 ; R: 0.8014 ; F1: 0.805 ; Acc: 0.8059\n",
      "2023-01-29 14:32:54.488183\n",
      "counter:  4\n",
      "2023-01-29 14:32:54.488183\n",
      "EPOCH 249\n",
      "TAG_LOSS_WEIGHT:  0.1265734464504592\n",
      "CLS_LOSS_WEIGHT:  0.8734265535495408\n",
      "tp:  1302\n",
      "fn:  20\n",
      "tn:  1299\n",
      "fp:  23\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2601\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  909\n",
      "EPOCH 249\n",
      "   TRAIN | Label 1 loss: 4.1896 ; P: 0.9537 ; R: 0.9652 ; F1: 0.9594 ; Acc: 0.9849\n",
      "           Label 2 loss: 19.9058 ; P: 0.9826 ; R: 0.9849 ; F1: 0.9838 ; Acc: 0.9837\n",
      "    TEST | Label 1 loss: 9.2957 ; P: 0.843 ; R: 0.8526 ; F1: 0.8478 ; Acc: 0.9398\n",
      "           Label 2 loss: 21.6931 ; P: 0.8086 ; R: 0.8014 ; F1: 0.805 ; Acc: 0.8059\n",
      "2023-01-29 14:33:25.576082\n",
      "counter:  5\n",
      "2023-01-29 14:33:25.576082\n",
      "EPOCH 250\n",
      "TAG_LOSS_WEIGHT:  0.13085053415557943\n",
      "CLS_LOSS_WEIGHT:  0.8691494658444205\n",
      "tp:  1300\n",
      "fn:  22\n",
      "tn:  1302\n",
      "fp:  20\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2602\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  909\n",
      "EPOCH 250\n",
      "   TRAIN | Label 1 loss: 3.993 ; P: 0.9625 ; R: 0.9635 ; F1: 0.963 ; Acc: 0.9864\n",
      "           Label 2 loss: 19.9593 ; P: 0.9848 ; R: 0.9834 ; F1: 0.9841 ; Acc: 0.9841\n",
      "    TEST | Label 1 loss: 9.2947 ; P: 0.843 ; R: 0.8526 ; F1: 0.8478 ; Acc: 0.9398\n",
      "           Label 2 loss: 21.6971 ; P: 0.8086 ; R: 0.8014 ; F1: 0.805 ; Acc: 0.8059\n",
      "2023-01-29 14:33:56.351662\n",
      "counter:  6\n",
      "2023-01-29 14:33:56.352663\n",
      "EPOCH 251\n",
      "TAG_LOSS_WEIGHT:  0.11973390968093356\n",
      "CLS_LOSS_WEIGHT:  0.8802660903190663\n",
      "tp:  1301\n",
      "fn:  21\n",
      "tn:  1293\n",
      "fp:  29\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2594\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  909\n",
      "EPOCH 251\n",
      "   TRAIN | Label 1 loss: 4.0912 ; P: 0.9595 ; R: 0.9647 ; F1: 0.9621 ; Acc: 0.986\n",
      "           Label 2 loss: 19.9044 ; P: 0.9782 ; R: 0.9841 ; F1: 0.9811 ; Acc: 0.9811\n",
      "    TEST | Label 1 loss: 9.2947 ; P: 0.843 ; R: 0.8526 ; F1: 0.8478 ; Acc: 0.9398\n",
      "           Label 2 loss: 21.6971 ; P: 0.8086 ; R: 0.8014 ; F1: 0.805 ; Acc: 0.8059\n",
      "2023-01-29 14:34:27.440507\n",
      "counter:  7\n",
      "2023-01-29 14:34:27.442497\n",
      "EPOCH 252\n",
      "TAG_LOSS_WEIGHT:  0.12555421868566008\n",
      "CLS_LOSS_WEIGHT:  0.8744457813143399\n",
      "tp:  1304\n",
      "fn:  18\n",
      "tn:  1294\n",
      "fp:  28\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2598\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  909\n",
      "EPOCH 252\n",
      "   TRAIN | Label 1 loss: 4.0737 ; P: 0.9594 ; R: 0.965 ; F1: 0.9622 ; Acc: 0.986\n",
      "           Label 2 loss: 20.1701 ; P: 0.979 ; R: 0.9864 ; F1: 0.9827 ; Acc: 0.9826\n",
      "    TEST | Label 1 loss: 9.2942 ; P: 0.843 ; R: 0.8526 ; F1: 0.8478 ; Acc: 0.9398\n",
      "           Label 2 loss: 21.6972 ; P: 0.8086 ; R: 0.8014 ; F1: 0.805 ; Acc: 0.8059\n",
      "2023-01-29 14:34:58.547494\n",
      "counter:  8\n",
      "2023-01-29 14:34:58.549488\n",
      "EPOCH 253\n",
      "TAG_LOSS_WEIGHT:  0.1217515646328824\n",
      "CLS_LOSS_WEIGHT:  0.8782484353671176\n",
      "tp:  1301\n",
      "fn:  21\n",
      "tn:  1292\n",
      "fp:  30\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2593\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  909\n",
      "EPOCH 253\n",
      "   TRAIN | Label 1 loss: 4.0981 ; P: 0.9576 ; R: 0.9646 ; F1: 0.9611 ; Acc: 0.9856\n",
      "           Label 2 loss: 20.3558 ; P: 0.9775 ; R: 0.9841 ; F1: 0.9808 ; Acc: 0.9807\n",
      "    TEST | Label 1 loss: 9.2953 ; P: 0.843 ; R: 0.8526 ; F1: 0.8478 ; Acc: 0.9398\n",
      "           Label 2 loss: 21.6983 ; P: 0.8086 ; R: 0.8014 ; F1: 0.805 ; Acc: 0.8059\n",
      "2023-01-29 14:35:29.452760\n",
      "counter:  9\n",
      "2023-01-29 14:35:29.453756\n",
      "EPOCH 254\n",
      "TAG_LOSS_WEIGHT:  0.12107041206573015\n",
      "CLS_LOSS_WEIGHT:  0.8789295879342698\n",
      "tp:  1308\n",
      "fn:  14\n",
      "tn:  1299\n",
      "fp:  23\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2607\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  909\n",
      "EPOCH 254\n",
      "   TRAIN | Label 1 loss: 4.1315 ; P: 0.9585 ; R: 0.9635 ; F1: 0.961 ; Acc: 0.9856\n",
      "           Label 2 loss: 19.7769 ; P: 0.9827 ; R: 0.9894 ; F1: 0.9861 ; Acc: 0.986\n",
      "    TEST | Label 1 loss: 9.2951 ; P: 0.843 ; R: 0.8526 ; F1: 0.8478 ; Acc: 0.9398\n",
      "           Label 2 loss: 21.6986 ; P: 0.8086 ; R: 0.8014 ; F1: 0.805 ; Acc: 0.8059\n",
      "2023-01-29 14:36:00.409051\n",
      "counter:  10\n",
      "2023-01-29 14:36:00.409051\n",
      "EPOCH 255\n",
      "TAG_LOSS_WEIGHT:  0.12916119000927864\n",
      "CLS_LOSS_WEIGHT:  0.8708388099907215\n",
      "tp:  1301\n",
      "fn:  21\n",
      "tn:  1298\n",
      "fp:  24\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2599\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  909\n",
      "EPOCH 255\n",
      "   TRAIN | Label 1 loss: 4.1702 ; P: 0.955 ; R: 0.965 ; F1: 0.96 ; Acc: 0.9852\n",
      "           Label 2 loss: 20.1198 ; P: 0.9819 ; R: 0.9841 ; F1: 0.983 ; Acc: 0.983\n",
      "    TEST | Label 1 loss: 9.2942 ; P: 0.843 ; R: 0.8526 ; F1: 0.8478 ; Acc: 0.9398\n",
      "           Label 2 loss: 21.6987 ; P: 0.8086 ; R: 0.8014 ; F1: 0.805 ; Acc: 0.8059\n",
      "2023-01-29 14:36:31.621078\n",
      "counter:  11\n",
      "2023-01-29 14:36:31.622079\n",
      "EPOCH 256\n",
      "TAG_LOSS_WEIGHT:  0.12740189753677983\n",
      "CLS_LOSS_WEIGHT:  0.8725981024632201\n",
      "tp:  1301\n",
      "fn:  21\n",
      "tn:  1295\n",
      "fp:  27\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2596\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  909\n",
      "EPOCH 256\n",
      "   TRAIN | Label 1 loss: 4.0247 ; P: 0.9584 ; R: 0.9668 ; F1: 0.9626 ; Acc: 0.9862\n",
      "           Label 2 loss: 20.0453 ; P: 0.9797 ; R: 0.9841 ; F1: 0.9819 ; Acc: 0.9818\n",
      "    TEST | Label 1 loss: 9.2985 ; P: 0.8435 ; R: 0.852 ; F1: 0.8477 ; Acc: 0.9398\n",
      "           Label 2 loss: 21.6978 ; P: 0.8086 ; R: 0.8014 ; F1: 0.805 ; Acc: 0.8059\n",
      "2023-01-29 14:37:02.752446\n",
      "counter:  12\n",
      "2023-01-29 14:37:02.752446\n",
      "EPOCH 257\n",
      "TAG_LOSS_WEIGHT:  0.12049655599735472\n",
      "CLS_LOSS_WEIGHT:  0.8795034440026452\n",
      "tp:  1300\n",
      "fn:  22\n",
      "tn:  1296\n",
      "fp:  26\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2596\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  909\n",
      "EPOCH 257\n",
      "   TRAIN | Label 1 loss: 4.1818 ; P: 0.957 ; R: 0.9628 ; F1: 0.9599 ; Acc: 0.9852\n",
      "           Label 2 loss: 20.1714 ; P: 0.9804 ; R: 0.9834 ; F1: 0.9819 ; Acc: 0.9818\n",
      "    TEST | Label 1 loss: 9.304 ; P: 0.8444 ; R: 0.8514 ; F1: 0.8479 ; Acc: 0.94\n",
      "           Label 2 loss: 21.7088 ; P: 0.8086 ; R: 0.8014 ; F1: 0.805 ; Acc: 0.8059\n",
      "2023-01-29 14:37:33.473637\n",
      "counter:  13\n",
      "2023-01-29 14:37:33.473637\n",
      "EPOCH 258\n",
      "TAG_LOSS_WEIGHT:  0.12745002547473186\n",
      "CLS_LOSS_WEIGHT:  0.8725499745252682\n",
      "tp:  1302\n",
      "fn:  20\n",
      "tn:  1301\n",
      "fp:  21\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2603\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  909\n",
      "EPOCH 258\n",
      "   TRAIN | Label 1 loss: 3.9999 ; P: 0.963 ; R: 0.965 ; F1: 0.964 ; Acc: 0.9867\n",
      "           Label 2 loss: 19.9449 ; P: 0.9841 ; R: 0.9849 ; F1: 0.9845 ; Acc: 0.9845\n",
      "    TEST | Label 1 loss: 9.3021 ; P: 0.843 ; R: 0.8526 ; F1: 0.8478 ; Acc: 0.9398\n",
      "           Label 2 loss: 21.7113 ; P: 0.8086 ; R: 0.8014 ; F1: 0.805 ; Acc: 0.8059\n",
      "2023-01-29 14:38:04.403289\n",
      "counter:  14\n",
      "2023-01-29 14:38:04.403289\n",
      "EPOCH 259\n",
      "TAG_LOSS_WEIGHT:  0.12025095359630729\n",
      "CLS_LOSS_WEIGHT:  0.8797490464036928\n",
      "tp:  1304\n",
      "fn:  18\n",
      "tn:  1297\n",
      "fp:  25\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2601\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  909\n",
      "EPOCH 259\n",
      "   TRAIN | Label 1 loss: 4.1791 ; P: 0.9563 ; R: 0.9643 ; F1: 0.9603 ; Acc: 0.9853\n",
      "           Label 2 loss: 20.1686 ; P: 0.9812 ; R: 0.9864 ; F1: 0.9838 ; Acc: 0.9837\n",
      "    TEST | Label 1 loss: 9.3149 ; P: 0.845 ; R: 0.852 ; F1: 0.8485 ; Acc: 0.9402\n",
      "           Label 2 loss: 21.7257 ; P: 0.8086 ; R: 0.8014 ; F1: 0.805 ; Acc: 0.8059\n",
      "2023-01-29 14:38:35.658592\n",
      "counter:  15\n",
      "2023-01-29 14:38:35.659404\n",
      "EPOCH 260\n",
      "TAG_LOSS_WEIGHT:  0.12733729499639132\n",
      "CLS_LOSS_WEIGHT:  0.8726627050036087\n",
      "tp:  1290\n",
      "fn:  32\n",
      "tn:  1296\n",
      "fp:  26\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2586\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  456\n",
      "fp:  108\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  908\n",
      "EPOCH 260\n",
      "   TRAIN | Label 1 loss: 4.1361 ; P: 0.9592 ; R: 0.9611 ; F1: 0.9602 ; Acc: 0.9853\n",
      "           Label 2 loss: 20.4017 ; P: 0.9802 ; R: 0.9758 ; F1: 0.978 ; Acc: 0.9781\n",
      "    TEST | Label 1 loss: 9.3018 ; P: 0.8441 ; R: 0.8526 ; F1: 0.8483 ; Acc: 0.9401\n",
      "           Label 2 loss: 21.6934 ; P: 0.8071 ; R: 0.8014 ; F1: 0.8043 ; Acc: 0.805\n",
      "2023-01-29 14:39:06.507448\n",
      "counter:  16\n",
      "2023-01-29 14:39:06.507448\n",
      "EPOCH 261\n",
      "TAG_LOSS_WEIGHT:  0.12256327003678517\n",
      "CLS_LOSS_WEIGHT:  0.8774367299632146\n",
      "tp:  1301\n",
      "fn:  21\n",
      "tn:  1297\n",
      "fp:  25\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2598\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  909\n",
      "EPOCH 261\n",
      "   TRAIN | Label 1 loss: 4.0622 ; P: 0.9588 ; R: 0.9643 ; F1: 0.9616 ; Acc: 0.9858\n",
      "           Label 2 loss: 19.8945 ; P: 0.9811 ; R: 0.9841 ; F1: 0.9826 ; Acc: 0.9826\n",
      "    TEST | Label 1 loss: 9.3081 ; P: 0.8451 ; R: 0.8526 ; F1: 0.8489 ; Acc: 0.9403\n",
      "           Label 2 loss: 21.7125 ; P: 0.8086 ; R: 0.8014 ; F1: 0.805 ; Acc: 0.8059\n",
      "2023-01-29 14:39:37.486979\n",
      "counter:  17\n",
      "2023-01-29 14:39:37.488979\n",
      "EPOCH 262\n",
      "TAG_LOSS_WEIGHT:  0.12410862875302221\n",
      "CLS_LOSS_WEIGHT:  0.8758913712469777\n",
      "tp:  1304\n",
      "fn:  18\n",
      "tn:  1295\n",
      "fp:  27\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2599\n",
      "tp:  451\n",
      "fn:  113\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  908\n",
      "EPOCH 262\n",
      "   TRAIN | Label 1 loss: 4.0089 ; P: 0.9598 ; R: 0.9678 ; F1: 0.9638 ; Acc: 0.9866\n",
      "           Label 2 loss: 20.0594 ; P: 0.9797 ; R: 0.9864 ; F1: 0.983 ; Acc: 0.983\n",
      "    TEST | Label 1 loss: 9.3328 ; P: 0.8456 ; R: 0.852 ; F1: 0.8488 ; Acc: 0.9403\n",
      "           Label 2 loss: 21.7199 ; P: 0.8082 ; R: 0.7996 ; F1: 0.8039 ; Acc: 0.805\n",
      "2023-01-29 14:40:08.431729\n",
      "counter:  18\n",
      "2023-01-29 14:40:08.431729\n",
      "EPOCH 263\n",
      "TAG_LOSS_WEIGHT:  0.1195172529258205\n",
      "CLS_LOSS_WEIGHT:  0.8804827470741795\n",
      "tp:  1304\n",
      "fn:  18\n",
      "tn:  1296\n",
      "fp:  26\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2600\n",
      "tp:  450\n",
      "fn:  114\n",
      "tn:  454\n",
      "fp:  110\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  904\n",
      "EPOCH 263\n",
      "   TRAIN | Label 1 loss: 4.0361 ; P: 0.9608 ; R: 0.9649 ; F1: 0.9629 ; Acc: 0.9863\n",
      "           Label 2 loss: 20.0255 ; P: 0.9805 ; R: 0.9864 ; F1: 0.9834 ; Acc: 0.9834\n",
      "    TEST | Label 1 loss: 9.3429 ; P: 0.8451 ; R: 0.8526 ; F1: 0.8489 ; Acc: 0.9403\n",
      "           Label 2 loss: 21.7863 ; P: 0.8036 ; R: 0.7979 ; F1: 0.8007 ; Acc: 0.8014\n",
      "2023-01-29 14:40:39.290931\n",
      "counter:  19\n",
      "2023-01-29 14:40:39.290931\n",
      "EPOCH 264\n",
      "TAG_LOSS_WEIGHT:  0.12130788018684176\n",
      "CLS_LOSS_WEIGHT:  0.8786921198131582\n",
      "tp:  1297\n",
      "fn:  25\n",
      "tn:  1300\n",
      "fp:  22\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2597\n",
      "tp:  450\n",
      "fn:  114\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  907\n",
      "EPOCH 264\n",
      "   TRAIN | Label 1 loss: 4.2034 ; P: 0.9548 ; R: 0.9636 ; F1: 0.9592 ; Acc: 0.9849\n",
      "           Label 2 loss: 20.086 ; P: 0.9833 ; R: 0.9811 ; F1: 0.9822 ; Acc: 0.9822\n",
      "    TEST | Label 1 loss: 9.3477 ; P: 0.8452 ; R: 0.8495 ; F1: 0.8473 ; Acc: 0.9398\n",
      "           Label 2 loss: 21.7752 ; P: 0.8079 ; R: 0.7979 ; F1: 0.8029 ; Acc: 0.8041\n",
      "2023-01-29 14:41:10.225036\n",
      "counter:  20\n",
      "2023-01-29 14:41:10.225036\n",
      "EPOCH 265\n",
      "TAG_LOSS_WEIGHT:  0.1295541852713732\n",
      "CLS_LOSS_WEIGHT:  0.8704458147286267\n",
      "tp:  1299\n",
      "fn:  23\n",
      "tn:  1294\n",
      "fp:  28\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2593\n",
      "tp:  451\n",
      "fn:  113\n",
      "tn:  456\n",
      "fp:  108\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  907\n",
      "EPOCH 265\n",
      "   TRAIN | Label 1 loss: 4.0207 ; P: 0.9581 ; R: 0.9638 ; F1: 0.9609 ; Acc: 0.9856\n",
      "           Label 2 loss: 20.178 ; P: 0.9789 ; R: 0.9826 ; F1: 0.9807 ; Acc: 0.9807\n",
      "    TEST | Label 1 loss: 9.3715 ; P: 0.8428 ; R: 0.8514 ; F1: 0.8471 ; Acc: 0.9396\n",
      "           Label 2 loss: 21.7953 ; P: 0.8068 ; R: 0.7996 ; F1: 0.8032 ; Acc: 0.8041\n",
      "2023-01-29 14:41:41.220976\n",
      "counter:  21\n",
      "2023-01-29 14:41:41.221950\n",
      "EPOCH 266\n",
      "TAG_LOSS_WEIGHT:  0.11889653461228879\n",
      "CLS_LOSS_WEIGHT:  0.8811034653877112\n",
      "tp:  1302\n",
      "fn:  20\n",
      "tn:  1292\n",
      "fp:  30\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2594\n",
      "tp:  451\n",
      "fn:  113\n",
      "tn:  459\n",
      "fp:  105\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  910\n",
      "EPOCH 266\n",
      "   TRAIN | Label 1 loss: 4.0178 ; P: 0.9571 ; R: 0.9681 ; F1: 0.9626 ; Acc: 0.9861\n",
      "           Label 2 loss: 20.39 ; P: 0.9775 ; R: 0.9849 ; F1: 0.9812 ; Acc: 0.9811\n",
      "    TEST | Label 1 loss: 9.4138 ; P: 0.8469 ; R: 0.8501 ; F1: 0.8485 ; Acc: 0.9403\n",
      "           Label 2 loss: 21.7199 ; P: 0.8112 ; R: 0.7996 ; F1: 0.8054 ; Acc: 0.8067\n",
      "2023-01-29 14:42:12.013953\n",
      "counter:  0\n",
      "2023-01-29 14:42:13.569860\n",
      "EPOCH 267\n",
      "TAG_LOSS_WEIGHT:  0.11657538446978342\n",
      "CLS_LOSS_WEIGHT:  0.8834246155302166\n",
      "tp:  1304\n",
      "fn:  18\n",
      "tn:  1296\n",
      "fp:  26\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2600\n",
      "tp:  451\n",
      "fn:  113\n",
      "tn:  459\n",
      "fp:  105\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  910\n",
      "EPOCH 267\n",
      "   TRAIN | Label 1 loss: 3.9236 ; P: 0.961 ; R: 0.9682 ; F1: 0.9646 ; Acc: 0.9869\n",
      "           Label 2 loss: 20.0762 ; P: 0.9805 ; R: 0.9864 ; F1: 0.9834 ; Acc: 0.9834\n",
      "    TEST | Label 1 loss: 9.423 ; P: 0.8469 ; R: 0.8501 ; F1: 0.8485 ; Acc: 0.9403\n",
      "           Label 2 loss: 21.69 ; P: 0.8112 ; R: 0.7996 ; F1: 0.8054 ; Acc: 0.8067\n",
      "2023-01-29 14:42:45.848853\n",
      "counter:  1\n",
      "2023-01-29 14:42:45.848853\n",
      "EPOCH 268\n",
      "TAG_LOSS_WEIGHT:  0.1148938929806129\n",
      "CLS_LOSS_WEIGHT:  0.8851061070193871\n",
      "tp:  1302\n",
      "fn:  20\n",
      "tn:  1305\n",
      "fp:  17\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2607\n",
      "tp:  454\n",
      "fn:  110\n",
      "tn:  454\n",
      "fp:  110\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  908\n",
      "EPOCH 268\n",
      "   TRAIN | Label 1 loss: 4.0651 ; P: 0.9582 ; R: 0.9653 ; F1: 0.9617 ; Acc: 0.9858\n",
      "           Label 2 loss: 19.752 ; P: 0.9871 ; R: 0.9849 ; F1: 0.986 ; Acc: 0.986\n",
      "    TEST | Label 1 loss: 9.4323 ; P: 0.8447 ; R: 0.8533 ; F1: 0.849 ; Acc: 0.9403\n",
      "           Label 2 loss: 21.8529 ; P: 0.805 ; R: 0.805 ; F1: 0.805 ; Acc: 0.805\n",
      "2023-01-29 14:43:17.323569\n",
      "counter:  2\n",
      "2023-01-29 14:43:17.323569\n",
      "EPOCH 269\n",
      "TAG_LOSS_WEIGHT:  0.12583688873970306\n",
      "CLS_LOSS_WEIGHT:  0.874163111260297\n",
      "tp:  1305\n",
      "fn:  17\n",
      "tn:  1298\n",
      "fp:  24\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2603\n",
      "tp:  450\n",
      "fn:  114\n",
      "tn:  455\n",
      "fp:  109\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  905\n",
      "EPOCH 269\n",
      "   TRAIN | Label 1 loss: 3.8724 ; P: 0.9611 ; R: 0.9685 ; F1: 0.9648 ; Acc: 0.987\n",
      "           Label 2 loss: 19.6731 ; P: 0.9819 ; R: 0.9871 ; F1: 0.9845 ; Acc: 0.9845\n",
      "    TEST | Label 1 loss: 9.5068 ; P: 0.8471 ; R: 0.8514 ; F1: 0.8492 ; Acc: 0.9406\n",
      "           Label 2 loss: 21.8443 ; P: 0.805 ; R: 0.7979 ; F1: 0.8014 ; Acc: 0.8023\n",
      "2023-01-29 14:43:48.776715\n",
      "counter:  3\n",
      "2023-01-29 14:43:48.777721\n",
      "EPOCH 270\n",
      "TAG_LOSS_WEIGHT:  0.11635565832698423\n",
      "CLS_LOSS_WEIGHT:  0.8836443416730158\n",
      "tp:  1299\n",
      "fn:  23\n",
      "tn:  1301\n",
      "fp:  21\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2600\n",
      "tp:  454\n",
      "fn:  110\n",
      "tn:  452\n",
      "fp:  112\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  906\n",
      "EPOCH 270\n",
      "   TRAIN | Label 1 loss: 3.9256 ; P: 0.9599 ; R: 0.9656 ; F1: 0.9627 ; Acc: 0.9862\n",
      "           Label 2 loss: 19.59 ; P: 0.9841 ; R: 0.9826 ; F1: 0.9833 ; Acc: 0.9834\n",
      "    TEST | Label 1 loss: 9.4347 ; P: 0.8452 ; R: 0.8533 ; F1: 0.8492 ; Acc: 0.9405\n",
      "           Label 2 loss: 21.7455 ; P: 0.8021 ; R: 0.805 ; F1: 0.8035 ; Acc: 0.8032\n",
      "2023-01-29 14:44:19.955244\n",
      "counter:  4\n",
      "2023-01-29 14:44:19.955244\n",
      "EPOCH 271\n",
      "TAG_LOSS_WEIGHT:  0.12008265453142838\n",
      "CLS_LOSS_WEIGHT:  0.8799173454685716\n",
      "tp:  1305\n",
      "fn:  17\n",
      "tn:  1299\n",
      "fp:  23\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2604\n",
      "tp:  445\n",
      "fn:  119\n",
      "tn:  460\n",
      "fp:  104\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  905\n",
      "EPOCH 271\n",
      "   TRAIN | Label 1 loss: 3.9313 ; P: 0.9597 ; R: 0.9673 ; F1: 0.9635 ; Acc: 0.9865\n",
      "           Label 2 loss: 19.7215 ; P: 0.9827 ; R: 0.9871 ; F1: 0.9849 ; Acc: 0.9849\n",
      "    TEST | Label 1 loss: 9.5923 ; P: 0.85 ; R: 0.8495 ; F1: 0.8497 ; Acc: 0.941\n",
      "           Label 2 loss: 21.7995 ; P: 0.8106 ; R: 0.789 ; F1: 0.7996 ; Acc: 0.8023\n",
      "2023-01-29 14:44:51.047464\n",
      "counter:  5\n",
      "2023-01-29 14:44:51.047464\n",
      "EPOCH 272\n",
      "TAG_LOSS_WEIGHT:  0.11897987225072641\n",
      "CLS_LOSS_WEIGHT:  0.8810201277492735\n",
      "tp:  1297\n",
      "fn:  25\n",
      "tn:  1297\n",
      "fp:  25\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2594\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  458\n",
      "fp:  106\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  910\n",
      "EPOCH 272\n",
      "   TRAIN | Label 1 loss: 3.913 ; P: 0.9617 ; R: 0.9659 ; F1: 0.9638 ; Acc: 0.9866\n",
      "           Label 2 loss: 20.0184 ; P: 0.9811 ; R: 0.9811 ; F1: 0.9811 ; Acc: 0.9811\n",
      "    TEST | Label 1 loss: 9.514 ; P: 0.8461 ; R: 0.852 ; F1: 0.849 ; Acc: 0.9405\n",
      "           Label 2 loss: 21.678 ; P: 0.81 ; R: 0.8014 ; F1: 0.8057 ; Acc: 0.8067\n",
      "2023-01-29 14:45:22.077835\n",
      "counter:  6\n",
      "2023-01-29 14:45:22.079835\n",
      "EPOCH 273\n",
      "TAG_LOSS_WEIGHT:  0.11493008586093041\n",
      "CLS_LOSS_WEIGHT:  0.8850699141390694\n",
      "tp:  1298\n",
      "fn:  24\n",
      "tn:  1298\n",
      "fp:  24\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2596\n",
      "tp:  454\n",
      "fn:  110\n",
      "tn:  455\n",
      "fp:  109\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  909\n",
      "EPOCH 273\n",
      "   TRAIN | Label 1 loss: 4.0045 ; P: 0.9588 ; R: 0.967 ; F1: 0.9629 ; Acc: 0.9863\n",
      "           Label 2 loss: 20.0378 ; P: 0.9818 ; R: 0.9818 ; F1: 0.9818 ; Acc: 0.9818\n",
      "    TEST | Label 1 loss: 9.4244 ; P: 0.8463 ; R: 0.8533 ; F1: 0.8498 ; Acc: 0.9407\n",
      "           Label 2 loss: 21.6699 ; P: 0.8064 ; R: 0.805 ; F1: 0.8057 ; Acc: 0.8059\n",
      "2023-01-29 14:45:53.182696\n",
      "counter:  7\n",
      "2023-01-29 14:45:53.182696\n",
      "EPOCH 274\n",
      "TAG_LOSS_WEIGHT:  0.11951287980582811\n",
      "CLS_LOSS_WEIGHT:  0.880487120194172\n",
      "tp:  1301\n",
      "fn:  21\n",
      "tn:  1297\n",
      "fp:  25\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2598\n",
      "tp:  455\n",
      "fn:  109\n",
      "tn:  451\n",
      "fp:  113\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  906\n",
      "EPOCH 274\n",
      "   TRAIN | Label 1 loss: 3.8452 ; P: 0.9629 ; R: 0.9673 ; F1: 0.9651 ; Acc: 0.9871\n",
      "           Label 2 loss: 19.7964 ; P: 0.9811 ; R: 0.9841 ; F1: 0.9826 ; Acc: 0.9826\n",
      "    TEST | Label 1 loss: 9.4021 ; P: 0.8457 ; R: 0.8564 ; F1: 0.851 ; Acc: 0.9411\n",
      "           Label 2 loss: 21.6544 ; P: 0.8011 ; R: 0.8067 ; F1: 0.8039 ; Acc: 0.8032\n",
      "2023-01-29 14:46:24.634627\n",
      "counter:  8\n",
      "2023-01-29 14:46:24.634627\n",
      "EPOCH 275\n",
      "TAG_LOSS_WEIGHT:  0.11364916924314913\n",
      "CLS_LOSS_WEIGHT:  0.886350830756851\n",
      "tp:  1306\n",
      "fn:  16\n",
      "tn:  1300\n",
      "fp:  22\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2606\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  461\n",
      "fp:  103\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  913\n",
      "EPOCH 275\n",
      "   TRAIN | Label 1 loss: 3.8473 ; P: 0.9596 ; R: 0.9677 ; F1: 0.9636 ; Acc: 0.9865\n",
      "           Label 2 loss: 19.7413 ; P: 0.9834 ; R: 0.9879 ; F1: 0.9857 ; Acc: 0.9856\n",
      "    TEST | Label 1 loss: 9.5781 ; P: 0.8489 ; R: 0.8526 ; F1: 0.8507 ; Acc: 0.9412\n",
      "           Label 2 loss: 21.6067 ; P: 0.8144 ; R: 0.8014 ; F1: 0.8079 ; Acc: 0.8094\n",
      "2023-01-29 14:46:55.900512\n",
      "counter:  0\n",
      "2023-01-29 14:46:57.514748\n",
      "EPOCH 276\n",
      "TAG_LOSS_WEIGHT:  0.11432242776179502\n",
      "CLS_LOSS_WEIGHT:  0.8856775722382051\n",
      "tp:  1308\n",
      "fn:  14\n",
      "tn:  1299\n",
      "fp:  23\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2607\n",
      "tp:  450\n",
      "fn:  114\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  907\n",
      "EPOCH 276\n",
      "   TRAIN | Label 1 loss: 3.8802 ; P: 0.9621 ; R: 0.967 ; F1: 0.9645 ; Acc: 0.9869\n",
      "           Label 2 loss: 19.6721 ; P: 0.9827 ; R: 0.9894 ; F1: 0.9861 ; Acc: 0.986\n",
      "    TEST | Label 1 loss: 9.5895 ; P: 0.8483 ; R: 0.8526 ; F1: 0.8505 ; Acc: 0.9411\n",
      "           Label 2 loss: 21.7217 ; P: 0.8079 ; R: 0.7979 ; F1: 0.8029 ; Acc: 0.8041\n",
      "2023-01-29 14:47:29.731202\n",
      "counter:  1\n",
      "2023-01-29 14:47:29.731202\n",
      "EPOCH 277\n",
      "TAG_LOSS_WEIGHT:  0.11678056589279777\n",
      "CLS_LOSS_WEIGHT:  0.8832194341072022\n",
      "tp:  1303\n",
      "fn:  19\n",
      "tn:  1295\n",
      "fp:  27\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2598\n",
      "tp:  446\n",
      "fn:  118\n",
      "tn:  462\n",
      "fp:  102\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  908\n",
      "EPOCH 277\n",
      "   TRAIN | Label 1 loss: 4.0241 ; P: 0.9606 ; R: 0.9626 ; F1: 0.9616 ; Acc: 0.9858\n",
      "           Label 2 loss: 19.8675 ; P: 0.9797 ; R: 0.9856 ; F1: 0.9827 ; Acc: 0.9826\n",
      "    TEST | Label 1 loss: 9.5262 ; P: 0.8478 ; R: 0.8488 ; F1: 0.8483 ; Acc: 0.9403\n",
      "           Label 2 loss: 21.6941 ; P: 0.8139 ; R: 0.7908 ; F1: 0.8022 ; Acc: 0.805\n",
      "2023-01-29 14:48:01.517705\n",
      "counter:  2\n",
      "2023-01-29 14:48:01.517705\n",
      "EPOCH 278\n",
      "TAG_LOSS_WEIGHT:  0.12236573902886569\n",
      "CLS_LOSS_WEIGHT:  0.8776342609711343\n",
      "tp:  1298\n",
      "fn:  24\n",
      "tn:  1301\n",
      "fp:  21\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2599\n",
      "tp:  455\n",
      "fn:  109\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  912\n",
      "EPOCH 278\n",
      "   TRAIN | Label 1 loss: 3.8726 ; P: 0.9606 ; R: 0.9684 ; F1: 0.9645 ; Acc: 0.9869\n",
      "           Label 2 loss: 19.9071 ; P: 0.9841 ; R: 0.9818 ; F1: 0.983 ; Acc: 0.983\n",
      "    TEST | Label 1 loss: 9.3165 ; P: 0.8529 ; R: 0.8583 ; F1: 0.8556 ; Acc: 0.9431\n",
      "           Label 2 loss: 21.3593 ; P: 0.8096 ; R: 0.8067 ; F1: 0.8082 ; Acc: 0.8085\n",
      "2023-01-29 14:48:33.095052\n",
      "counter:  3\n",
      "2023-01-29 14:48:33.097044\n",
      "EPOCH 279\n",
      "TAG_LOSS_WEIGHT:  0.11395659554671794\n",
      "CLS_LOSS_WEIGHT:  0.8860434044532821\n",
      "tp:  1301\n",
      "fn:  21\n",
      "tn:  1296\n",
      "fp:  26\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2597\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  458\n",
      "fp:  106\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  910\n",
      "EPOCH 279\n",
      "   TRAIN | Label 1 loss: 3.8111 ; P: 0.9631 ; R: 0.9689 ; F1: 0.966 ; Acc: 0.9874\n",
      "           Label 2 loss: 19.8969 ; P: 0.9804 ; R: 0.9841 ; F1: 0.9823 ; Acc: 0.9822\n",
      "    TEST | Label 1 loss: 9.3992 ; P: 0.8529 ; R: 0.8545 ; F1: 0.8537 ; Acc: 0.9425\n",
      "           Label 2 loss: 21.3567 ; P: 0.81 ; R: 0.8014 ; F1: 0.8057 ; Acc: 0.8067\n",
      "2023-01-29 14:49:04.384113\n",
      "counter:  4\n",
      "2023-01-29 14:49:04.384113\n",
      "EPOCH 280\n",
      "TAG_LOSS_WEIGHT:  0.11086461011715279\n",
      "CLS_LOSS_WEIGHT:  0.8891353898828471\n",
      "tp:  1304\n",
      "fn:  18\n",
      "tn:  1299\n",
      "fp:  23\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2603\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  462\n",
      "fp:  102\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  914\n",
      "EPOCH 280\n",
      "   TRAIN | Label 1 loss: 3.7394 ; P: 0.9643 ; R: 0.9684 ; F1: 0.9663 ; Acc: 0.9876\n",
      "           Label 2 loss: 19.6233 ; P: 0.9827 ; R: 0.9864 ; F1: 0.9845 ; Acc: 0.9845\n",
      "    TEST | Label 1 loss: 9.6163 ; P: 0.8492 ; R: 0.8552 ; F1: 0.8522 ; Acc: 0.9417\n",
      "           Label 2 loss: 21.5028 ; P: 0.8159 ; R: 0.8014 ; F1: 0.8086 ; Acc: 0.8103\n",
      "2023-01-29 14:49:35.347438\n",
      "counter:  0\n",
      "2023-01-29 14:49:37.093922\n",
      "EPOCH 281\n",
      "TAG_LOSS_WEIGHT:  0.10985407051727049\n",
      "CLS_LOSS_WEIGHT:  0.8901459294827295\n",
      "tp:  1305\n",
      "fn:  17\n",
      "tn:  1302\n",
      "fp:  20\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2607\n",
      "tp:  443\n",
      "fn:  121\n",
      "tn:  463\n",
      "fp:  101\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  906\n",
      "EPOCH 281\n",
      "   TRAIN | Label 1 loss: 3.8269 ; P: 0.963 ; R: 0.9682 ; F1: 0.9656 ; Acc: 0.9873\n",
      "           Label 2 loss: 19.4368 ; P: 0.9849 ; R: 0.9871 ; F1: 0.986 ; Acc: 0.986\n",
      "    TEST | Label 1 loss: 9.5596 ; P: 0.8543 ; R: 0.8533 ; F1: 0.8538 ; Acc: 0.9426\n",
      "           Label 2 loss: 21.4984 ; P: 0.8143 ; R: 0.7855 ; F1: 0.7996 ; Acc: 0.8032\n",
      "2023-01-29 14:50:08.950377\n",
      "counter:  1\n",
      "2023-01-29 14:50:08.950377\n",
      "EPOCH 282\n",
      "TAG_LOSS_WEIGHT:  0.11641009044170422\n",
      "CLS_LOSS_WEIGHT:  0.8835899095582959\n",
      "tp:  1307\n",
      "fn:  15\n",
      "tn:  1301\n",
      "fp:  21\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2608\n",
      "tp:  458\n",
      "fn:  106\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  915\n",
      "EPOCH 282\n",
      "   TRAIN | Label 1 loss: 3.763 ; P: 0.9613 ; R: 0.9667 ; F1: 0.964 ; Acc: 0.9867\n",
      "           Label 2 loss: 19.4789 ; P: 0.9842 ; R: 0.9887 ; F1: 0.9864 ; Acc: 0.9864\n",
      "    TEST | Label 1 loss: 9.5414 ; P: 0.8438 ; R: 0.8577 ; F1: 0.8507 ; Acc: 0.9408\n",
      "           Label 2 loss: 21.3804 ; P: 0.8106 ; R: 0.8121 ; F1: 0.8113 ; Acc: 0.8112\n",
      "2023-01-29 14:50:40.481603\n",
      "counter:  0\n",
      "2023-01-29 14:50:42.235040\n",
      "EPOCH 283\n",
      "TAG_LOSS_WEIGHT:  0.11255762615603102\n",
      "CLS_LOSS_WEIGHT:  0.8874423738439691\n",
      "tp:  1307\n",
      "fn:  15\n",
      "tn:  1297\n",
      "fp:  25\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2604\n",
      "tp:  450\n",
      "fn:  114\n",
      "tn:  463\n",
      "fp:  101\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  913\n",
      "EPOCH 283\n",
      "   TRAIN | Label 1 loss: 3.9103 ; P: 0.9612 ; R: 0.9682 ; F1: 0.9647 ; Acc: 0.987\n",
      "           Label 2 loss: 19.5749 ; P: 0.9812 ; R: 0.9887 ; F1: 0.9849 ; Acc: 0.9849\n",
      "    TEST | Label 1 loss: 9.6098 ; P: 0.8514 ; R: 0.8514 ; F1: 0.8514 ; Acc: 0.9416\n",
      "           Label 2 loss: 21.4473 ; P: 0.8167 ; R: 0.7979 ; F1: 0.8072 ; Acc: 0.8094\n",
      "2023-01-29 14:51:14.357890\n",
      "counter:  1\n",
      "2023-01-29 14:51:14.358889\n",
      "EPOCH 284\n",
      "TAG_LOSS_WEIGHT:  0.11942193353212757\n",
      "CLS_LOSS_WEIGHT:  0.8805780664678724\n",
      "tp:  1305\n",
      "fn:  17\n",
      "tn:  1301\n",
      "fp:  21\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2606\n",
      "tp:  453\n",
      "fn:  111\n",
      "tn:  463\n",
      "fp:  101\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  916\n",
      "EPOCH 284\n",
      "   TRAIN | Label 1 loss: 3.6984 ; P: 0.9645 ; R: 0.9687 ; F1: 0.9666 ; Acc: 0.9877\n",
      "           Label 2 loss: 19.575 ; P: 0.9842 ; R: 0.9871 ; F1: 0.9856 ; Acc: 0.9856\n",
      "    TEST | Label 1 loss: 9.5358 ; P: 0.8558 ; R: 0.8558 ; F1: 0.8558 ; Acc: 0.9433\n",
      "           Label 2 loss: 21.1739 ; P: 0.8177 ; R: 0.8032 ; F1: 0.8104 ; Acc: 0.8121\n",
      "2023-01-29 14:51:46.071419\n",
      "counter:  0\n",
      "2023-01-29 14:51:48.141236\n",
      "EPOCH 285\n",
      "TAG_LOSS_WEIGHT:  0.10819102628014243\n",
      "CLS_LOSS_WEIGHT:  0.8918089737198575\n",
      "tp:  1303\n",
      "fn:  19\n",
      "tn:  1305\n",
      "fp:  17\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2608\n",
      "tp:  456\n",
      "fn:  108\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  913\n",
      "EPOCH 285\n",
      "   TRAIN | Label 1 loss: 3.7689 ; P: 0.9634 ; R: 0.9677 ; F1: 0.9655 ; Acc: 0.9873\n",
      "           Label 2 loss: 19.4223 ; P: 0.9871 ; R: 0.9856 ; F1: 0.9864 ; Acc: 0.9864\n",
      "    TEST | Label 1 loss: 9.6582 ; P: 0.8464 ; R: 0.8577 ; F1: 0.852 ; Acc: 0.9415\n",
      "           Label 2 loss: 21.4473 ; P: 0.8099 ; R: 0.8085 ; F1: 0.8092 ; Acc: 0.8094\n",
      "2023-01-29 14:52:20.523303\n",
      "counter:  1\n",
      "2023-01-29 14:52:20.524303\n",
      "EPOCH 286\n",
      "TAG_LOSS_WEIGHT:  0.11345505571354406\n",
      "CLS_LOSS_WEIGHT:  0.886544944286456\n",
      "tp:  1307\n",
      "fn:  15\n",
      "tn:  1307\n",
      "fp:  15\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2614\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  459\n",
      "fp:  105\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  911\n",
      "EPOCH 286\n",
      "   TRAIN | Label 1 loss: 3.696 ; P: 0.9624 ; R: 0.9673 ; F1: 0.9648 ; Acc: 0.987\n",
      "           Label 2 loss: 19.0659 ; P: 0.9887 ; R: 0.9887 ; F1: 0.9887 ; Acc: 0.9887\n",
      "    TEST | Label 1 loss: 9.813 ; P: 0.8497 ; R: 0.8545 ; F1: 0.8521 ; Acc: 0.9417\n",
      "           Label 2 loss: 21.7915 ; P: 0.8115 ; R: 0.8014 ; F1: 0.8064 ; Acc: 0.8076\n",
      "2023-01-29 14:52:52.830828\n",
      "counter:  2\n",
      "2023-01-29 14:52:52.830828\n",
      "EPOCH 287\n",
      "TAG_LOSS_WEIGHT:  0.11325172800663229\n",
      "CLS_LOSS_WEIGHT:  0.8867482719933677\n",
      "tp:  1312\n",
      "fn:  10\n",
      "tn:  1309\n",
      "fp:  13\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2621\n",
      "tp:  456\n",
      "fn:  108\n",
      "tn:  459\n",
      "fp:  105\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  915\n",
      "EPOCH 287\n",
      "   TRAIN | Label 1 loss: 3.5846 ; P: 0.963 ; R: 0.9691 ; F1: 0.966 ; Acc: 0.9874\n",
      "           Label 2 loss: 19.0045 ; P: 0.9902 ; R: 0.9924 ; F1: 0.9913 ; Acc: 0.9913\n",
      "    TEST | Label 1 loss: 10.028 ; P: 0.8534 ; R: 0.8545 ; F1: 0.854 ; Acc: 0.9426\n",
      "           Label 2 loss: 21.6819 ; P: 0.8128 ; R: 0.8085 ; F1: 0.8107 ; Acc: 0.8112\n",
      "2023-01-29 14:53:23.789228\n",
      "counter:  3\n",
      "2023-01-29 14:53:23.791227\n",
      "EPOCH 288\n",
      "TAG_LOSS_WEIGHT:  0.10786803962808054\n",
      "CLS_LOSS_WEIGHT:  0.8921319603719194\n",
      "tp:  1307\n",
      "fn:  15\n",
      "tn:  1307\n",
      "fp:  15\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2614\n",
      "tp:  456\n",
      "fn:  108\n",
      "tn:  458\n",
      "fp:  106\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  914\n",
      "EPOCH 288\n",
      "   TRAIN | Label 1 loss: 3.4327 ; P: 0.9686 ; R: 0.9716 ; F1: 0.9701 ; Acc: 0.989\n",
      "           Label 2 loss: 19.1567 ; P: 0.9887 ; R: 0.9887 ; F1: 0.9887 ; Acc: 0.9887\n",
      "    TEST | Label 1 loss: 10.1683 ; P: 0.8524 ; R: 0.8545 ; F1: 0.8534 ; Acc: 0.9423\n",
      "           Label 2 loss: 21.6578 ; P: 0.8114 ; R: 0.8085 ; F1: 0.8099 ; Acc: 0.8103\n",
      "2023-01-29 14:53:54.830748\n",
      "counter:  4\n",
      "2023-01-29 14:53:54.831747\n",
      "EPOCH 289\n",
      "TAG_LOSS_WEIGHT:  0.09838862046859374\n",
      "CLS_LOSS_WEIGHT:  0.9016113795314062\n",
      "tp:  1312\n",
      "fn:  10\n",
      "tn:  1301\n",
      "fp:  21\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2613\n",
      "tp:  455\n",
      "fn:  109\n",
      "tn:  455\n",
      "fp:  109\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  910\n",
      "EPOCH 289\n",
      "   TRAIN | Label 1 loss: 3.4554 ; P: 0.9673 ; R: 0.9733 ; F1: 0.9703 ; Acc: 0.989\n",
      "           Label 2 loss: 19.1869 ; P: 0.9842 ; R: 0.9924 ; F1: 0.9883 ; Acc: 0.9883\n",
      "    TEST | Label 1 loss: 10.2463 ; P: 0.8496 ; R: 0.8577 ; F1: 0.8536 ; Acc: 0.9422\n",
      "           Label 2 loss: 21.7527 ; P: 0.8067 ; R: 0.8067 ; F1: 0.8067 ; Acc: 0.8067\n",
      "2023-01-29 14:54:26.269645\n",
      "counter:  5\n",
      "2023-01-29 14:54:26.269645\n",
      "EPOCH 290\n",
      "TAG_LOSS_WEIGHT:  0.09928211143558226\n",
      "CLS_LOSS_WEIGHT:  0.9007178885644177\n",
      "tp:  1306\n",
      "fn:  16\n",
      "tn:  1302\n",
      "fp:  20\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2608\n",
      "tp:  460\n",
      "fn:  104\n",
      "tn:  458\n",
      "fp:  106\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  918\n",
      "EPOCH 290\n",
      "   TRAIN | Label 1 loss: 3.5653 ; P: 0.9645 ; R: 0.9724 ; F1: 0.9684 ; Acc: 0.9883\n",
      "           Label 2 loss: 19.1276 ; P: 0.9849 ; R: 0.9879 ; F1: 0.9864 ; Acc: 0.9864\n",
      "    TEST | Label 1 loss: 10.035 ; P: 0.8507 ; R: 0.8653 ; F1: 0.8579 ; Acc: 0.9437\n",
      "           Label 2 loss: 21.474 ; P: 0.8127 ; R: 0.8156 ; F1: 0.8142 ; Acc: 0.8138\n",
      "2023-01-29 14:54:57.144591\n",
      "counter:  0\n",
      "2023-01-29 14:54:58.833333\n",
      "EPOCH 291\n",
      "TAG_LOSS_WEIGHT:  0.1056074490807365\n",
      "CLS_LOSS_WEIGHT:  0.8943925509192635\n",
      "tp:  1304\n",
      "fn:  18\n",
      "tn:  1299\n",
      "fp:  23\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2603\n",
      "tp:  462\n",
      "fn:  102\n",
      "tn:  461\n",
      "fp:  103\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  923\n",
      "EPOCH 291\n",
      "   TRAIN | Label 1 loss: 3.5538 ; P: 0.9662 ; R: 0.971 ; F1: 0.9686 ; Acc: 0.9884\n",
      "           Label 2 loss: 19.5075 ; P: 0.9827 ; R: 0.9864 ; F1: 0.9845 ; Acc: 0.9845\n",
      "    TEST | Label 1 loss: 10.0003 ; P: 0.8562 ; R: 0.859 ; F1: 0.8576 ; Acc: 0.9439\n",
      "           Label 2 loss: 21.0887 ; P: 0.8177 ; R: 0.8191 ; F1: 0.8184 ; Acc: 0.8183\n",
      "2023-01-29 14:55:30.830425\n",
      "counter:  0\n",
      "2023-01-29 14:55:32.565252\n",
      "EPOCH 292\n",
      "TAG_LOSS_WEIGHT:  0.1013593837735948\n",
      "CLS_LOSS_WEIGHT:  0.8986406162264051\n",
      "tp:  1306\n",
      "fn:  16\n",
      "tn:  1305\n",
      "fp:  17\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2611\n",
      "tp:  459\n",
      "fn:  105\n",
      "tn:  460\n",
      "fp:  104\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  919\n",
      "EPOCH 292\n",
      "   TRAIN | Label 1 loss: 3.3683 ; P: 0.9678 ; R: 0.9751 ; F1: 0.9714 ; Acc: 0.9894\n",
      "           Label 2 loss: 19.108 ; P: 0.9872 ; R: 0.9879 ; F1: 0.9875 ; Acc: 0.9875\n",
      "    TEST | Label 1 loss: 10.1118 ; P: 0.8552 ; R: 0.859 ; F1: 0.8571 ; Acc: 0.9437\n",
      "           Label 2 loss: 21.2325 ; P: 0.8153 ; R: 0.8138 ; F1: 0.8146 ; Acc: 0.8147\n",
      "2023-01-29 14:56:04.175204\n",
      "counter:  1\n",
      "2023-01-29 14:56:04.175204\n",
      "EPOCH 293\n",
      "TAG_LOSS_WEIGHT:  0.09551819024778067\n",
      "CLS_LOSS_WEIGHT:  0.9044818097522194\n",
      "tp:  1308\n",
      "fn:  14\n",
      "tn:  1301\n",
      "fp:  21\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2609\n",
      "tp:  456\n",
      "fn:  108\n",
      "tn:  462\n",
      "fp:  102\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  918\n",
      "EPOCH 293\n",
      "   TRAIN | Label 1 loss: 3.4526 ; P: 0.9662 ; R: 0.9733 ; F1: 0.9697 ; Acc: 0.9888\n",
      "           Label 2 loss: 19.144 ; P: 0.9842 ; R: 0.9894 ; F1: 0.9868 ; Acc: 0.9868\n",
      "    TEST | Label 1 loss: 10.0071 ; P: 0.8551 ; R: 0.8621 ; F1: 0.8586 ; Acc: 0.9442\n",
      "           Label 2 loss: 21.342 ; P: 0.8172 ; R: 0.8085 ; F1: 0.8128 ; Acc: 0.8138\n",
      "2023-01-29 14:56:36.034688\n",
      "counter:  2\n",
      "2023-01-29 14:56:36.035688\n",
      "EPOCH 294\n",
      "TAG_LOSS_WEIGHT:  0.09953775728525723\n",
      "CLS_LOSS_WEIGHT:  0.9004622427147427\n",
      "tp:  1302\n",
      "fn:  20\n",
      "tn:  1308\n",
      "fp:  14\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2610\n",
      "tp:  461\n",
      "fn:  103\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  918\n",
      "EPOCH 294\n",
      "   TRAIN | Label 1 loss: 3.4066 ; P: 0.9679 ; R: 0.9696 ; F1: 0.9688 ; Acc: 0.9885\n",
      "           Label 2 loss: 18.7764 ; P: 0.9894 ; R: 0.9849 ; F1: 0.9871 ; Acc: 0.9871\n",
      "    TEST | Label 1 loss: 9.9034 ; P: 0.8518 ; R: 0.8615 ; F1: 0.8566 ; Acc: 0.9433\n",
      "           Label 2 loss: 21.1367 ; P: 0.8116 ; R: 0.8174 ; F1: 0.8145 ; Acc: 0.8138\n",
      "2023-01-29 14:57:07.477323\n",
      "counter:  3\n",
      "2023-01-29 14:57:07.477323\n",
      "EPOCH 295\n",
      "TAG_LOSS_WEIGHT:  0.10061410788843726\n",
      "CLS_LOSS_WEIGHT:  0.8993858921115628\n",
      "tp:  1308\n",
      "fn:  14\n",
      "tn:  1304\n",
      "fp:  18\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2612\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  464\n",
      "fp:  100\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  916\n",
      "EPOCH 295\n",
      "   TRAIN | Label 1 loss: 3.2983 ; P: 0.9662 ; R: 0.9727 ; F1: 0.9695 ; Acc: 0.9887\n",
      "           Label 2 loss: 18.9818 ; P: 0.9864 ; R: 0.9894 ; F1: 0.9879 ; Acc: 0.9879\n",
      "    TEST | Label 1 loss: 10.1784 ; P: 0.8553 ; R: 0.8564 ; F1: 0.8559 ; Acc: 0.9433\n",
      "           Label 2 loss: 21.2049 ; P: 0.8188 ; R: 0.8014 ; F1: 0.81 ; Acc: 0.8121\n",
      "2023-01-29 14:57:39.150497\n",
      "counter:  4\n",
      "2023-01-29 14:57:39.150497\n",
      "EPOCH 296\n",
      "TAG_LOSS_WEIGHT:  0.09306315114949353\n",
      "CLS_LOSS_WEIGHT:  0.9069368488505065\n",
      "tp:  1307\n",
      "fn:  15\n",
      "tn:  1309\n",
      "fp:  13\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2616\n",
      "tp:  454\n",
      "fn:  110\n",
      "tn:  460\n",
      "fp:  104\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  914\n",
      "EPOCH 296\n",
      "   TRAIN | Label 1 loss: 3.224 ; P: 0.9691 ; R: 0.974 ; F1: 0.9715 ; Acc: 0.9895\n",
      "           Label 2 loss: 18.7656 ; P: 0.9902 ; R: 0.9887 ; F1: 0.9894 ; Acc: 0.9894\n",
      "    TEST | Label 1 loss: 10.1741 ; P: 0.8478 ; R: 0.8596 ; F1: 0.8536 ; Acc: 0.9421\n",
      "           Label 2 loss: 21.4089 ; P: 0.8136 ; R: 0.805 ; F1: 0.8093 ; Acc: 0.8103\n",
      "2023-01-29 14:58:11.058042\n",
      "counter:  5\n",
      "2023-01-29 14:58:11.059042\n",
      "EPOCH 297\n",
      "TAG_LOSS_WEIGHT:  0.09116829040400871\n",
      "CLS_LOSS_WEIGHT:  0.9088317095959912\n",
      "tp:  1312\n",
      "fn:  10\n",
      "tn:  1309\n",
      "fp:  13\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2621\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  460\n",
      "fp:  104\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  912\n",
      "EPOCH 297\n",
      "   TRAIN | Label 1 loss: 3.2237 ; P: 0.9687 ; R: 0.9751 ; F1: 0.9719 ; Acc: 0.9896\n",
      "           Label 2 loss: 18.6414 ; P: 0.9902 ; R: 0.9924 ; F1: 0.9913 ; Acc: 0.9913\n",
      "    TEST | Label 1 loss: 10.3816 ; P: 0.851 ; R: 0.8526 ; F1: 0.8518 ; Acc: 0.9417\n",
      "           Label 2 loss: 21.8211 ; P: 0.8129 ; R: 0.8014 ; F1: 0.8071 ; Acc: 0.8085\n",
      "2023-01-29 14:58:42.182922\n",
      "counter:  6\n",
      "2023-01-29 14:58:42.184921\n",
      "EPOCH 298\n",
      "TAG_LOSS_WEIGHT:  0.09225911169680319\n",
      "CLS_LOSS_WEIGHT:  0.9077408883031968\n",
      "tp:  1317\n",
      "fn:  5\n",
      "tn:  1312\n",
      "fp:  10\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2629\n",
      "tp:  449\n",
      "fn:  115\n",
      "tn:  467\n",
      "fp:  97\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  916\n",
      "EPOCH 298\n",
      "   TRAIN | Label 1 loss: 3.2771 ; P: 0.9675 ; R: 0.9747 ; F1: 0.9711 ; Acc: 0.9893\n",
      "           Label 2 loss: 18.265 ; P: 0.9925 ; R: 0.9962 ; F1: 0.9943 ; Acc: 0.9943\n",
      "    TEST | Label 1 loss: 10.5181 ; P: 0.8557 ; R: 0.8514 ; F1: 0.8535 ; Acc: 0.9426\n",
      "           Label 2 loss: 21.7549 ; P: 0.8223 ; R: 0.7961 ; F1: 0.809 ; Acc: 0.8121\n",
      "2023-01-29 14:59:13.390766\n",
      "counter:  7\n",
      "2023-01-29 14:59:13.391763\n",
      "EPOCH 299\n",
      "TAG_LOSS_WEIGHT:  0.09861552509520005\n",
      "CLS_LOSS_WEIGHT:  0.9013844749047999\n",
      "tp:  1307\n",
      "fn:  15\n",
      "tn:  1311\n",
      "fp:  11\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2618\n",
      "tp:  457\n",
      "fn:  107\n",
      "tn:  456\n",
      "fp:  108\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  913\n",
      "EPOCH 299\n",
      "   TRAIN | Label 1 loss: 3.2107 ; P: 0.9671 ; R: 0.9745 ; F1: 0.9708 ; Acc: 0.9892\n",
      "           Label 2 loss: 18.6454 ; P: 0.9917 ; R: 0.9887 ; F1: 0.9902 ; Acc: 0.9902\n",
      "    TEST | Label 1 loss: 10.2231 ; P: 0.8488 ; R: 0.8627 ; F1: 0.8557 ; Acc: 0.9428\n",
      "           Label 2 loss: 21.5748 ; P: 0.8088 ; R: 0.8103 ; F1: 0.8096 ; Acc: 0.8094\n",
      "2023-01-29 14:59:44.735759\n",
      "counter:  8\n",
      "2023-01-29 14:59:44.736759\n",
      "EPOCH 300\n",
      "TAG_LOSS_WEIGHT:  0.0915488337997065\n",
      "CLS_LOSS_WEIGHT:  0.9084511662002934\n",
      "tp:  1311\n",
      "fn:  11\n",
      "tn:  1308\n",
      "fp:  14\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2619\n",
      "tp:  451\n",
      "fn:  113\n",
      "tn:  460\n",
      "fp:  104\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  911\n",
      "EPOCH 300\n",
      "   TRAIN | Label 1 loss: 3.2724 ; P: 0.9696 ; R: 0.9727 ; F1: 0.9711 ; Acc: 0.9894\n",
      "           Label 2 loss: 18.5463 ; P: 0.9894 ; R: 0.9917 ; F1: 0.9906 ; Acc: 0.9905\n",
      "    TEST | Label 1 loss: 10.4714 ; P: 0.8497 ; R: 0.8545 ; F1: 0.8521 ; Acc: 0.9417\n",
      "           Label 2 loss: 21.9043 ; P: 0.8126 ; R: 0.7996 ; F1: 0.8061 ; Acc: 0.8076\n",
      "2023-01-29 15:00:15.747520\n",
      "counter:  9\n",
      "2023-01-29 15:00:15.749512\n",
      "EPOCH 301\n",
      "TAG_LOSS_WEIGHT:  0.09568286082476979\n",
      "CLS_LOSS_WEIGHT:  0.9043171391752303\n",
      "tp:  1315\n",
      "fn:  7\n",
      "tn:  1309\n",
      "fp:  13\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2624\n",
      "tp:  445\n",
      "fn:  119\n",
      "tn:  465\n",
      "fp:  99\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  910\n",
      "EPOCH 301\n",
      "   TRAIN | Label 1 loss: 2.9929 ; P: 0.9698 ; R: 0.9758 ; F1: 0.9728 ; Acc: 0.9899\n",
      "           Label 2 loss: 18.3562 ; P: 0.9902 ; R: 0.9947 ; F1: 0.9925 ; Acc: 0.9924\n",
      "    TEST | Label 1 loss: 10.9115 ; P: 0.8547 ; R: 0.8482 ; F1: 0.8514 ; Acc: 0.9418\n",
      "           Label 2 loss: 22.0635 ; P: 0.818 ; R: 0.789 ; F1: 0.8032 ; Acc: 0.8067\n",
      "2023-01-29 15:00:46.603148\n",
      "counter:  10\n",
      "2023-01-29 15:00:46.603148\n",
      "EPOCH 302\n",
      "TAG_LOSS_WEIGHT:  0.08286082939477252\n",
      "CLS_LOSS_WEIGHT:  0.9171391706052274\n",
      "tp:  1313\n",
      "fn:  9\n",
      "tn:  1314\n",
      "fp:  8\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2627\n",
      "tp:  451\n",
      "fn:  113\n",
      "tn:  459\n",
      "fp:  105\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  910\n",
      "EPOCH 302\n",
      "   TRAIN | Label 1 loss: 3.1283 ; P: 0.9692 ; R: 0.9734 ; F1: 0.9713 ; Acc: 0.9894\n",
      "           Label 2 loss: 18.1483 ; P: 0.9939 ; R: 0.9932 ; F1: 0.9936 ; Acc: 0.9936\n",
      "    TEST | Label 1 loss: 10.916 ; P: 0.8543 ; R: 0.8495 ; F1: 0.8519 ; Acc: 0.942\n",
      "           Label 2 loss: 21.9729 ; P: 0.8112 ; R: 0.7996 ; F1: 0.8054 ; Acc: 0.8067\n",
      "2023-01-29 15:01:17.593132\n",
      "counter:  11\n",
      "2023-01-29 15:01:17.595132\n",
      "EPOCH 303\n",
      "TAG_LOSS_WEIGHT:  0.09171919014052002\n",
      "CLS_LOSS_WEIGHT:  0.9082808098594798\n",
      "tp:  1311\n",
      "fn:  11\n",
      "tn:  1310\n",
      "fp:  12\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2621\n",
      "tp:  456\n",
      "fn:  108\n",
      "tn:  462\n",
      "fp:  102\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  918\n",
      "EPOCH 303\n",
      "   TRAIN | Label 1 loss: 3.1127 ; P: 0.973 ; R: 0.9737 ; F1: 0.9734 ; Acc: 0.9902\n",
      "           Label 2 loss: 18.3886 ; P: 0.9909 ; R: 0.9917 ; F1: 0.9913 ; Acc: 0.9913\n",
      "    TEST | Label 1 loss: 10.6261 ; P: 0.8489 ; R: 0.8564 ; F1: 0.8526 ; Acc: 0.9418\n",
      "           Label 2 loss: 21.6392 ; P: 0.8172 ; R: 0.8085 ; F1: 0.8128 ; Acc: 0.8138\n",
      "2023-01-29 15:01:48.577964\n",
      "counter:  12\n",
      "2023-01-29 15:01:48.579963\n",
      "EPOCH 304\n",
      "TAG_LOSS_WEIGHT:  0.08873911843483429\n",
      "CLS_LOSS_WEIGHT:  0.9112608815651658\n",
      "tp:  1308\n",
      "fn:  14\n",
      "tn:  1310\n",
      "fp:  12\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2618\n",
      "tp:  456\n",
      "fn:  108\n",
      "tn:  459\n",
      "fp:  105\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  915\n",
      "EPOCH 304\n",
      "   TRAIN | Label 1 loss: 3.0116 ; P: 0.9686 ; R: 0.9764 ; F1: 0.9725 ; Acc: 0.9898\n",
      "           Label 2 loss: 18.4024 ; P: 0.9909 ; R: 0.9894 ; F1: 0.9902 ; Acc: 0.9902\n",
      "    TEST | Label 1 loss: 10.6408 ; P: 0.8473 ; R: 0.8596 ; F1: 0.8534 ; Acc: 0.942\n",
      "           Label 2 loss: 21.8687 ; P: 0.8128 ; R: 0.8085 ; F1: 0.8107 ; Acc: 0.8112\n",
      "2023-01-29 15:02:19.426769\n",
      "counter:  13\n",
      "2023-01-29 15:02:19.427769\n",
      "EPOCH 305\n",
      "TAG_LOSS_WEIGHT:  0.08342722186800272\n",
      "CLS_LOSS_WEIGHT:  0.9165727781319973\n",
      "tp:  1314\n",
      "fn:  8\n",
      "tn:  1310\n",
      "fp:  12\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2624\n",
      "tp:  444\n",
      "fn:  120\n",
      "tn:  472\n",
      "fp:  92\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  916\n",
      "EPOCH 305\n",
      "   TRAIN | Label 1 loss: 3.0547 ; P: 0.9718 ; R: 0.9754 ; F1: 0.9736 ; Acc: 0.9903\n",
      "           Label 2 loss: 18.2595 ; P: 0.991 ; R: 0.9939 ; F1: 0.9924 ; Acc: 0.9924\n",
      "    TEST | Label 1 loss: 10.9011 ; P: 0.8594 ; R: 0.8469 ; F1: 0.8531 ; Acc: 0.9427\n",
      "           Label 2 loss: 21.6955 ; P: 0.8284 ; R: 0.7872 ; F1: 0.8073 ; Acc: 0.8121\n",
      "2023-01-29 15:02:50.627469\n",
      "counter:  14\n",
      "2023-01-29 15:02:50.627469\n",
      "EPOCH 306\n",
      "TAG_LOSS_WEIGHT:  0.08685490347921794\n",
      "CLS_LOSS_WEIGHT:  0.9131450965207821\n",
      "tp:  1312\n",
      "fn:  10\n",
      "tn:  1311\n",
      "fp:  11\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2623\n",
      "tp:  455\n",
      "fn:  109\n",
      "tn:  462\n",
      "fp:  102\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  917\n",
      "EPOCH 306\n",
      "   TRAIN | Label 1 loss: 2.9972 ; P: 0.9697 ; R: 0.9772 ; F1: 0.9734 ; Acc: 0.9902\n",
      "           Label 2 loss: 18.2858 ; P: 0.9917 ; R: 0.9924 ; F1: 0.9921 ; Acc: 0.9921\n",
      "    TEST | Label 1 loss: 10.6783 ; P: 0.8547 ; R: 0.852 ; F1: 0.8533 ; Acc: 0.9425\n",
      "           Label 2 loss: 21.5557 ; P: 0.8169 ; R: 0.8067 ; F1: 0.8118 ; Acc: 0.8129\n",
      "2023-01-29 15:03:21.567703\n",
      "counter:  15\n",
      "2023-01-29 15:03:21.568698\n",
      "EPOCH 307\n",
      "TAG_LOSS_WEIGHT:  0.08366661695992708\n",
      "CLS_LOSS_WEIGHT:  0.9163333830400728\n",
      "tp:  1314\n",
      "fn:  8\n",
      "tn:  1313\n",
      "fp:  9\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2627\n",
      "tp:  456\n",
      "fn:  108\n",
      "tn:  461\n",
      "fp:  103\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  917\n",
      "EPOCH 307\n",
      "   TRAIN | Label 1 loss: 3.1402 ; P: 0.9702 ; R: 0.9765 ; F1: 0.9734 ; Acc: 0.9902\n",
      "           Label 2 loss: 17.9868 ; P: 0.9932 ; R: 0.9939 ; F1: 0.9936 ; Acc: 0.9936\n",
      "    TEST | Label 1 loss: 10.5131 ; P: 0.8573 ; R: 0.8552 ; F1: 0.8562 ; Acc: 0.9436\n",
      "           Label 2 loss: 21.4932 ; P: 0.8157 ; R: 0.8085 ; F1: 0.8121 ; Acc: 0.8129\n",
      "2023-01-29 15:03:52.349659\n",
      "counter:  16\n",
      "2023-01-29 15:03:52.351661\n",
      "EPOCH 308\n",
      "TAG_LOSS_WEIGHT:  0.09386327879707565\n",
      "CLS_LOSS_WEIGHT:  0.9061367212029242\n",
      "tp:  1310\n",
      "fn:  12\n",
      "tn:  1308\n",
      "fp:  14\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2618\n",
      "tp:  459\n",
      "fn:  105\n",
      "tn:  455\n",
      "fp:  109\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  914\n",
      "EPOCH 308\n",
      "   TRAIN | Label 1 loss: 3.1117 ; P: 0.9681 ; R: 0.9776 ; F1: 0.9728 ; Acc: 0.9899\n",
      "           Label 2 loss: 18.3812 ; P: 0.9894 ; R: 0.9909 ; F1: 0.9902 ; Acc: 0.9902\n",
      "    TEST | Label 1 loss: 10.6153 ; P: 0.8513 ; R: 0.8583 ; F1: 0.8548 ; Acc: 0.9427\n",
      "           Label 2 loss: 21.6694 ; P: 0.8081 ; R: 0.8138 ; F1: 0.811 ; Acc: 0.8103\n",
      "2023-01-29 15:04:23.857142\n",
      "counter:  17\n",
      "2023-01-29 15:04:23.857142\n",
      "EPOCH 309\n",
      "TAG_LOSS_WEIGHT:  0.08875224978324467\n",
      "CLS_LOSS_WEIGHT:  0.9112477502167554\n",
      "tp:  1313\n",
      "fn:  9\n",
      "tn:  1307\n",
      "fp:  15\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2620\n",
      "tp:  454\n",
      "fn:  110\n",
      "tn:  465\n",
      "fp:  99\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  919\n",
      "EPOCH 309\n",
      "   TRAIN | Label 1 loss: 3.003 ; P: 0.9732 ; R: 0.9771 ; F1: 0.9751 ; Acc: 0.9908\n",
      "           Label 2 loss: 18.3913 ; P: 0.9887 ; R: 0.9932 ; F1: 0.9909 ; Acc: 0.9909\n",
      "    TEST | Label 1 loss: 10.7321 ; P: 0.8595 ; R: 0.8552 ; F1: 0.8573 ; Acc: 0.9441\n",
      "           Label 2 loss: 21.3397 ; P: 0.821 ; R: 0.805 ; F1: 0.8129 ; Acc: 0.8147\n",
      "2023-01-29 15:04:55.041308\n",
      "counter:  18\n",
      "2023-01-29 15:04:55.043309\n",
      "EPOCH 310\n",
      "TAG_LOSS_WEIGHT:  0.08308279738965246\n",
      "CLS_LOSS_WEIGHT:  0.9169172026103475\n",
      "tp:  1317\n",
      "fn:  5\n",
      "tn:  1313\n",
      "fp:  9\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2630\n",
      "tp:  448\n",
      "fn:  116\n",
      "tn:  466\n",
      "fp:  98\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  914\n",
      "EPOCH 310\n",
      "   TRAIN | Label 1 loss: 2.797 ; P: 0.9728 ; R: 0.98 ; F1: 0.9764 ; Acc: 0.9913\n",
      "           Label 2 loss: 17.832 ; P: 0.9932 ; R: 0.9962 ; F1: 0.9947 ; Acc: 0.9947\n",
      "    TEST | Label 1 loss: 11.2059 ; P: 0.8558 ; R: 0.8558 ; F1: 0.8558 ; Acc: 0.9433\n",
      "           Label 2 loss: 21.7545 ; P: 0.8205 ; R: 0.7943 ; F1: 0.8072 ; Acc: 0.8103\n",
      "2023-01-29 15:05:25.906960\n",
      "counter:  19\n",
      "2023-01-29 15:05:25.908968\n",
      "EPOCH 311\n",
      "TAG_LOSS_WEIGHT:  0.07716232764189451\n",
      "CLS_LOSS_WEIGHT:  0.9228376723581054\n",
      "tp:  1314\n",
      "fn:  8\n",
      "tn:  1314\n",
      "fp:  8\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2628\n",
      "tp:  459\n",
      "fn:  105\n",
      "tn:  460\n",
      "fp:  104\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  919\n",
      "EPOCH 311\n",
      "   TRAIN | Label 1 loss: 2.9007 ; P: 0.9709 ; R: 0.9791 ; F1: 0.975 ; Acc: 0.9907\n",
      "           Label 2 loss: 17.9709 ; P: 0.9939 ; R: 0.9939 ; F1: 0.9939 ; Acc: 0.9939\n",
      "    TEST | Label 1 loss: 10.8634 ; P: 0.8537 ; R: 0.8602 ; F1: 0.857 ; Acc: 0.9436\n",
      "           Label 2 loss: 21.4893 ; P: 0.8153 ; R: 0.8138 ; F1: 0.8146 ; Acc: 0.8147\n",
      "2023-01-29 15:05:56.617304\n",
      "counter:  20\n",
      "2023-01-29 15:05:56.617304\n",
      "EPOCH 312\n",
      "TAG_LOSS_WEIGHT:  0.08134202972310951\n",
      "CLS_LOSS_WEIGHT:  0.9186579702768904\n",
      "tp:  1316\n",
      "fn:  6\n",
      "tn:  1312\n",
      "fp:  10\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2628\n",
      "tp:  454\n",
      "fn:  110\n",
      "tn:  461\n",
      "fp:  103\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  915\n",
      "EPOCH 312\n",
      "   TRAIN | Label 1 loss: 2.8098 ; P: 0.9722 ; R: 0.9791 ; F1: 0.9757 ; Acc: 0.991\n",
      "           Label 2 loss: 18.0771 ; P: 0.9925 ; R: 0.9955 ; F1: 0.994 ; Acc: 0.9939\n",
      "    TEST | Label 1 loss: 11.1399 ; P: 0.8596 ; R: 0.8558 ; F1: 0.8577 ; Acc: 0.9442\n",
      "           Label 2 loss: 21.2695 ; P: 0.8151 ; R: 0.805 ; F1: 0.81 ; Acc: 0.8112\n",
      "2023-01-29 15:06:27.642518\n",
      "counter:  21\n",
      "2023-01-29 15:06:27.643984\n",
      "EPOCH 313\n",
      "TAG_LOSS_WEIGHT:  0.07587830878932886\n",
      "CLS_LOSS_WEIGHT:  0.924121691210671\n",
      "tp:  1315\n",
      "fn:  7\n",
      "tn:  1313\n",
      "fp:  9\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2628\n",
      "tp:  453\n",
      "fn:  111\n",
      "tn:  464\n",
      "fp:  100\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  917\n",
      "EPOCH 313\n",
      "   TRAIN | Label 1 loss: 2.8536 ; P: 0.9709 ; R: 0.9773 ; F1: 0.9741 ; Acc: 0.9904\n",
      "           Label 2 loss: 17.9214 ; P: 0.9932 ; R: 0.9947 ; F1: 0.994 ; Acc: 0.9939\n",
      "    TEST | Label 1 loss: 11.1487 ; P: 0.8571 ; R: 0.8571 ; F1: 0.8571 ; Acc: 0.9438\n",
      "           Label 2 loss: 21.4493 ; P: 0.8192 ; R: 0.8032 ; F1: 0.8111 ; Acc: 0.8129\n",
      "2023-01-29 15:06:58.919460\n",
      "counter:  22\n",
      "2023-01-29 15:06:58.920460\n",
      "EPOCH 314\n",
      "TAG_LOSS_WEIGHT:  0.07933068055819655\n",
      "CLS_LOSS_WEIGHT:  0.9206693194418034\n",
      "tp:  1316\n",
      "fn:  6\n",
      "tn:  1310\n",
      "fp:  12\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2626\n",
      "tp:  453\n",
      "fn:  111\n",
      "tn:  466\n",
      "fp:  98\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  919\n",
      "EPOCH 314\n",
      "   TRAIN | Label 1 loss: 2.8784 ; P: 0.9717 ; R: 0.9786 ; F1: 0.9751 ; Acc: 0.9908\n",
      "           Label 2 loss: 17.9905 ; P: 0.991 ; R: 0.9955 ; F1: 0.9932 ; Acc: 0.9932\n",
      "    TEST | Label 1 loss: 11.2821 ; P: 0.8602 ; R: 0.8526 ; F1: 0.8564 ; Acc: 0.9438\n",
      "           Label 2 loss: 21.4262 ; P: 0.8221 ; R: 0.8032 ; F1: 0.8126 ; Acc: 0.8147\n",
      "2023-01-29 15:07:29.729616\n",
      "counter:  23\n",
      "2023-01-29 15:07:29.731617\n",
      "EPOCH 315\n",
      "TAG_LOSS_WEIGHT:  0.08003540069126862\n",
      "CLS_LOSS_WEIGHT:  0.9199645993087313\n",
      "tp:  1317\n",
      "fn:  5\n",
      "tn:  1312\n",
      "fp:  10\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2629\n",
      "tp:  457\n",
      "fn:  107\n",
      "tn:  461\n",
      "fp:  103\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  918\n",
      "EPOCH 315\n",
      "   TRAIN | Label 1 loss: 2.9696 ; P: 0.9704 ; R: 0.9782 ; F1: 0.9743 ; Acc: 0.9905\n",
      "           Label 2 loss: 18.1185 ; P: 0.9925 ; R: 0.9962 ; F1: 0.9943 ; Acc: 0.9943\n",
      "    TEST | Label 1 loss: 10.7707 ; P: 0.8619 ; R: 0.8564 ; F1: 0.8591 ; Acc: 0.9448\n",
      "           Label 2 loss: 21.4364 ; P: 0.8161 ; R: 0.8103 ; F1: 0.8132 ; Acc: 0.8138\n",
      "2023-01-29 15:08:00.710029\n",
      "counter:  24\n",
      "2023-01-29 15:08:00.712029\n",
      "EPOCH 316\n",
      "TAG_LOSS_WEIGHT:  0.08365742214833945\n",
      "CLS_LOSS_WEIGHT:  0.9163425778516605\n",
      "tp:  1316\n",
      "fn:  6\n",
      "tn:  1311\n",
      "fp:  11\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2627\n",
      "tp:  453\n",
      "fn:  111\n",
      "tn:  464\n",
      "fp:  100\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  917\n",
      "EPOCH 316\n",
      "   TRAIN | Label 1 loss: 2.7727 ; P: 0.9734 ; R: 0.9798 ; F1: 0.9766 ; Acc: 0.9914\n",
      "           Label 2 loss: 18.0736 ; P: 0.9917 ; R: 0.9955 ; F1: 0.9936 ; Acc: 0.9936\n",
      "    TEST | Label 1 loss: 11.0601 ; P: 0.862 ; R: 0.8533 ; F1: 0.8576 ; Acc: 0.9443\n",
      "           Label 2 loss: 21.3456 ; P: 0.8192 ; R: 0.8032 ; F1: 0.8111 ; Acc: 0.8129\n",
      "2023-01-29 15:08:31.262137\n",
      "counter:  25\n",
      "2023-01-29 15:08:31.263137\n",
      "EPOCH 317\n",
      "TAG_LOSS_WEIGHT:  0.07406169793512253\n",
      "CLS_LOSS_WEIGHT:  0.9259383020648774\n",
      "tp:  1315\n",
      "fn:  7\n",
      "tn:  1316\n",
      "fp:  6\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2631\n",
      "tp:  450\n",
      "fn:  114\n",
      "tn:  470\n",
      "fp:  94\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  920\n",
      "EPOCH 317\n",
      "   TRAIN | Label 1 loss: 2.7119 ; P: 0.9742 ; R: 0.981 ; F1: 0.9775 ; Acc: 0.9917\n",
      "           Label 2 loss: 17.7558 ; P: 0.9955 ; R: 0.9947 ; F1: 0.9951 ; Acc: 0.9951\n",
      "    TEST | Label 1 loss: 11.1358 ; P: 0.8625 ; R: 0.8533 ; F1: 0.8579 ; Acc: 0.9444\n",
      "           Label 2 loss: 21.3849 ; P: 0.8272 ; R: 0.7979 ; F1: 0.8123 ; Acc: 0.8156\n",
      "2023-01-29 15:09:02.413050\n",
      "counter:  26\n",
      "2023-01-29 15:09:02.414050\n",
      "EPOCH 318\n",
      "TAG_LOSS_WEIGHT:  0.07345612674303016\n",
      "CLS_LOSS_WEIGHT:  0.9265438732569699\n",
      "tp:  1313\n",
      "fn:  9\n",
      "tn:  1316\n",
      "fp:  6\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2629\n",
      "tp:  458\n",
      "fn:  106\n",
      "tn:  463\n",
      "fp:  101\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  921\n",
      "EPOCH 318\n",
      "   TRAIN | Label 1 loss: 2.7327 ; P: 0.974 ; R: 0.9794 ; F1: 0.9767 ; Acc: 0.9914\n",
      "           Label 2 loss: 17.8404 ; P: 0.9955 ; R: 0.9932 ; F1: 0.9943 ; Acc: 0.9943\n",
      "    TEST | Label 1 loss: 11.2546 ; P: 0.8645 ; R: 0.8514 ; F1: 0.8579 ; Acc: 0.9446\n",
      "           Label 2 loss: 21.3097 ; P: 0.8193 ; R: 0.8121 ; F1: 0.8157 ; Acc: 0.8165\n",
      "2023-01-29 15:09:33.260114\n",
      "counter:  27\n",
      "2023-01-29 15:09:33.261113\n",
      "EPOCH 319\n",
      "TAG_LOSS_WEIGHT:  0.07385011859370567\n",
      "CLS_LOSS_WEIGHT:  0.9261498814062944\n",
      "tp:  1317\n",
      "fn:  5\n",
      "tn:  1314\n",
      "fp:  8\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2631\n",
      "tp:  451\n",
      "fn:  113\n",
      "tn:  466\n",
      "fp:  98\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  917\n",
      "EPOCH 319\n",
      "   TRAIN | Label 1 loss: 2.7112 ; P: 0.9744 ; R: 0.9789 ; F1: 0.9766 ; Acc: 0.9914\n",
      "           Label 2 loss: 17.6613 ; P: 0.994 ; R: 0.9962 ; F1: 0.9951 ; Acc: 0.9951\n",
      "    TEST | Label 1 loss: 11.4246 ; P: 0.8566 ; R: 0.8577 ; F1: 0.8571 ; Acc: 0.9438\n",
      "           Label 2 loss: 21.4481 ; P: 0.8215 ; R: 0.7996 ; F1: 0.8104 ; Acc: 0.8129\n",
      "2023-01-29 15:10:05.132342\n",
      "counter:  28\n",
      "2023-01-29 15:10:05.132342\n",
      "EPOCH 320\n",
      "TAG_LOSS_WEIGHT:  0.07415038489899105\n",
      "CLS_LOSS_WEIGHT:  0.9258496151010089\n",
      "tp:  1316\n",
      "fn:  6\n",
      "tn:  1315\n",
      "fp:  7\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2631\n",
      "tp:  457\n",
      "fn:  107\n",
      "tn:  461\n",
      "fp:  103\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  918\n",
      "EPOCH 320\n",
      "   TRAIN | Label 1 loss: 2.6339 ; P: 0.9736 ; R: 0.9794 ; F1: 0.9765 ; Acc: 0.9913\n",
      "           Label 2 loss: 17.7074 ; P: 0.9947 ; R: 0.9955 ; F1: 0.9951 ; Acc: 0.9951\n",
      "    TEST | Label 1 loss: 11.6195 ; P: 0.858 ; R: 0.8558 ; F1: 0.8569 ; Acc: 0.9438\n",
      "           Label 2 loss: 21.5163 ; P: 0.8161 ; R: 0.8103 ; F1: 0.8132 ; Acc: 0.8138\n",
      "2023-01-29 15:10:36.446547\n",
      "counter:  29\n",
      "2023-01-29 15:10:36.446547\n",
      "EPOCH 321\n",
      "TAG_LOSS_WEIGHT:  0.0699354304435592\n",
      "CLS_LOSS_WEIGHT:  0.9300645695564408\n",
      "tp:  1314\n",
      "fn:  8\n",
      "tn:  1315\n",
      "fp:  7\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2629\n",
      "tp:  448\n",
      "fn:  116\n",
      "tn:  467\n",
      "fp:  97\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  915\n",
      "EPOCH 321\n",
      "   TRAIN | Label 1 loss: 2.6381 ; P: 0.9733 ; R: 0.9797 ; F1: 0.9765 ; Acc: 0.9913\n",
      "           Label 2 loss: 17.7513 ; P: 0.9947 ; R: 0.9939 ; F1: 0.9943 ; Acc: 0.9943\n",
      "    TEST | Label 1 loss: 11.9239 ; P: 0.8635 ; R: 0.8482 ; F1: 0.8558 ; Acc: 0.9438\n",
      "           Label 2 loss: 21.6817 ; P: 0.822 ; R: 0.7943 ; F1: 0.8079 ; Acc: 0.8112\n",
      "2023-01-29 15:11:07.289322\n",
      "counter:  30\n",
      "2023-01-29 15:11:07.289322\n",
      "EPOCH 322\n",
      "TAG_LOSS_WEIGHT:  0.06982067538399186\n",
      "CLS_LOSS_WEIGHT:  0.9301793246160082\n",
      "tp:  1317\n",
      "fn:  5\n",
      "tn:  1312\n",
      "fp:  10\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2629\n",
      "tp:  453\n",
      "fn:  111\n",
      "tn:  464\n",
      "fp:  100\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  917\n",
      "EPOCH 322\n",
      "   TRAIN | Label 1 loss: 2.7894 ; P: 0.9726 ; R: 0.9779 ; F1: 0.9752 ; Acc: 0.9908\n",
      "           Label 2 loss: 17.809 ; P: 0.9925 ; R: 0.9962 ; F1: 0.9943 ; Acc: 0.9943\n",
      "    TEST | Label 1 loss: 11.6509 ; P: 0.8578 ; R: 0.8545 ; F1: 0.8561 ; Acc: 0.9436\n",
      "           Label 2 loss: 21.6139 ; P: 0.8192 ; R: 0.8032 ; F1: 0.8111 ; Acc: 0.8129\n",
      "2023-01-29 15:11:38.144708\n",
      "counter:  31\n",
      "2023-01-29 15:11:38.145712\n",
      "EPOCH 323\n",
      "TAG_LOSS_WEIGHT:  0.07695888297337203\n",
      "CLS_LOSS_WEIGHT:  0.923041117026628\n",
      "tp:  1313\n",
      "fn:  9\n",
      "tn:  1309\n",
      "fp:  13\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2622\n",
      "tp:  451\n",
      "fn:  113\n",
      "tn:  464\n",
      "fp:  100\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  915\n",
      "EPOCH 323\n",
      "   TRAIN | Label 1 loss: 2.7187 ; P: 0.9713 ; R: 0.9796 ; F1: 0.9754 ; Acc: 0.9909\n",
      "           Label 2 loss: 18.0401 ; P: 0.9902 ; R: 0.9932 ; F1: 0.9917 ; Acc: 0.9917\n",
      "    TEST | Label 1 loss: 11.5854 ; P: 0.8665 ; R: 0.8501 ; F1: 0.8582 ; Acc: 0.9448\n",
      "           Label 2 loss: 21.4336 ; P: 0.8185 ; R: 0.7996 ; F1: 0.809 ; Acc: 0.8112\n",
      "2023-01-29 15:12:08.927692\n",
      "counter:  32\n",
      "2023-01-29 15:12:08.929692\n",
      "EPOCH 324\n",
      "TAG_LOSS_WEIGHT:  0.07165542558548237\n",
      "CLS_LOSS_WEIGHT:  0.9283445744145175\n",
      "tp:  1317\n",
      "fn:  5\n",
      "tn:  1316\n",
      "fp:  6\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2633\n",
      "tp:  451\n",
      "fn:  113\n",
      "tn:  461\n",
      "fp:  103\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  912\n",
      "EPOCH 324\n",
      "   TRAIN | Label 1 loss: 2.5852 ; P: 0.9768 ; R: 0.9798 ; F1: 0.9783 ; Acc: 0.992\n",
      "           Label 2 loss: 17.5711 ; P: 0.9955 ; R: 0.9962 ; F1: 0.9958 ; Acc: 0.9958\n",
      "    TEST | Label 1 loss: 11.5715 ; P: 0.8663 ; R: 0.8526 ; F1: 0.8594 ; Acc: 0.9452\n",
      "           Label 2 loss: 21.69 ; P: 0.8141 ; R: 0.7996 ; F1: 0.8068 ; Acc: 0.8085\n",
      "2023-01-29 15:12:40.013299\n",
      "counter:  33\n",
      "2023-01-29 15:12:40.013299\n",
      "EPOCH 325\n",
      "TAG_LOSS_WEIGHT:  0.06852613695389083\n",
      "CLS_LOSS_WEIGHT:  0.9314738630461092\n",
      "tp:  1314\n",
      "fn:  8\n",
      "tn:  1319\n",
      "fp:  3\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2633\n",
      "tp:  462\n",
      "fn:  102\n",
      "tn:  457\n",
      "fp:  107\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  919\n",
      "EPOCH 325\n",
      "   TRAIN | Label 1 loss: 2.6828 ; P: 0.9736 ; R: 0.9791 ; F1: 0.9763 ; Acc: 0.9913\n",
      "           Label 2 loss: 17.6573 ; P: 0.9977 ; R: 0.9939 ; F1: 0.9958 ; Acc: 0.9958\n",
      "    TEST | Label 1 loss: 11.3986 ; P: 0.8576 ; R: 0.8608 ; F1: 0.8592 ; Acc: 0.9446\n",
      "           Label 2 loss: 21.5019 ; P: 0.812 ; R: 0.8191 ; F1: 0.8155 ; Acc: 0.8147\n",
      "2023-01-29 15:13:10.979630\n",
      "counter:  34\n",
      "2023-01-29 15:13:10.979630\n",
      "EPOCH 326\n",
      "TAG_LOSS_WEIGHT:  0.07274798560510039\n",
      "CLS_LOSS_WEIGHT:  0.9272520143948997\n",
      "tp:  1318\n",
      "fn:  4\n",
      "tn:  1316\n",
      "fp:  6\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2634\n",
      "tp:  455\n",
      "fn:  109\n",
      "tn:  466\n",
      "fp:  98\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  921\n",
      "EPOCH 326\n",
      "   TRAIN | Label 1 loss: 2.6936 ; P: 0.9751 ; R: 0.9801 ; F1: 0.9776 ; Acc: 0.9917\n",
      "           Label 2 loss: 17.6082 ; P: 0.9955 ; R: 0.997 ; F1: 0.9962 ; Acc: 0.9962\n",
      "    TEST | Label 1 loss: 11.7514 ; P: 0.8608 ; R: 0.8564 ; F1: 0.8586 ; Acc: 0.9446\n",
      "           Label 2 loss: 21.4948 ; P: 0.8228 ; R: 0.8067 ; F1: 0.8147 ; Acc: 0.8165\n",
      "2023-01-29 15:13:42.064174\n",
      "counter:  35\n",
      "2023-01-29 15:13:42.065174\n",
      "EPOCH 327\n",
      "TAG_LOSS_WEIGHT:  0.07367102519848853\n",
      "CLS_LOSS_WEIGHT:  0.9263289748015114\n",
      "tp:  1318\n",
      "fn:  4\n",
      "tn:  1314\n",
      "fp:  8\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2632\n",
      "tp:  456\n",
      "fn:  108\n",
      "tn:  463\n",
      "fp:  101\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  919\n",
      "EPOCH 327\n",
      "   TRAIN | Label 1 loss: 2.4754 ; P: 0.9759 ; R: 0.9807 ; F1: 0.9783 ; Acc: 0.992\n",
      "           Label 2 loss: 17.6231 ; P: 0.994 ; R: 0.997 ; F1: 0.9955 ; Acc: 0.9955\n",
      "    TEST | Label 1 loss: 11.623 ; P: 0.8616 ; R: 0.8583 ; F1: 0.8599 ; Acc: 0.9451\n",
      "           Label 2 loss: 21.4832 ; P: 0.8187 ; R: 0.8085 ; F1: 0.8136 ; Acc: 0.8147\n",
      "2023-01-29 15:14:13.339509\n",
      "counter:  36\n",
      "2023-01-29 15:14:13.340504\n",
      "EPOCH 328\n",
      "TAG_LOSS_WEIGHT:  0.0628398525148551\n",
      "CLS_LOSS_WEIGHT:  0.9371601474851449\n",
      "tp:  1319\n",
      "fn:  3\n",
      "tn:  1316\n",
      "fp:  6\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2635\n",
      "tp:  452\n",
      "fn:  112\n",
      "tn:  465\n",
      "fp:  99\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  917\n",
      "EPOCH 328\n",
      "   TRAIN | Label 1 loss: 2.5347 ; P: 0.9741 ; R: 0.9804 ; F1: 0.9773 ; Acc: 0.9916\n",
      "           Label 2 loss: 17.4502 ; P: 0.9955 ; R: 0.9977 ; F1: 0.9966 ; Acc: 0.9966\n",
      "    TEST | Label 1 loss: 11.6882 ; P: 0.8626 ; R: 0.8577 ; F1: 0.8601 ; Acc: 0.9452\n",
      "           Label 2 loss: 21.4994 ; P: 0.8203 ; R: 0.8014 ; F1: 0.8108 ; Acc: 0.8129\n",
      "2023-01-29 15:14:45.167281\n",
      "counter:  37\n",
      "2023-01-29 15:14:45.167281\n",
      "EPOCH 329\n",
      "TAG_LOSS_WEIGHT:  0.06690712492902216\n",
      "CLS_LOSS_WEIGHT:  0.9330928750709778\n",
      "tp:  1319\n",
      "fn:  3\n",
      "tn:  1316\n",
      "fp:  6\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2635\n",
      "tp:  459\n",
      "fn:  105\n",
      "tn:  462\n",
      "fp:  102\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  921\n",
      "EPOCH 329\n",
      "   TRAIN | Label 1 loss: 2.4924 ; P: 0.9742 ; R: 0.9815 ; F1: 0.9778 ; Acc: 0.9918\n",
      "           Label 2 loss: 17.5356 ; P: 0.9955 ; R: 0.9977 ; F1: 0.9966 ; Acc: 0.9966\n",
      "    TEST | Label 1 loss: 11.5603 ; P: 0.8643 ; R: 0.8583 ; F1: 0.8613 ; Acc: 0.9457\n",
      "           Label 2 loss: 21.4895 ; P: 0.8182 ; R: 0.8138 ; F1: 0.816 ; Acc: 0.8165\n",
      "2023-01-29 15:15:15.448760\n",
      "counter:  38\n",
      "2023-01-29 15:15:15.449751\n",
      "EPOCH 330\n",
      "TAG_LOSS_WEIGHT:  0.06424669301914808\n",
      "CLS_LOSS_WEIGHT:  0.935753306980852\n",
      "tp:  1318\n",
      "fn:  4\n",
      "tn:  1316\n",
      "fp:  6\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2634\n",
      "tp:  456\n",
      "fn:  108\n",
      "tn:  463\n",
      "fp:  101\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  919\n",
      "EPOCH 330\n",
      "   TRAIN | Label 1 loss: 2.5094 ; P: 0.9747 ; R: 0.9822 ; F1: 0.9785 ; Acc: 0.992\n",
      "           Label 2 loss: 17.5352 ; P: 0.9955 ; R: 0.997 ; F1: 0.9962 ; Acc: 0.9962\n",
      "    TEST | Label 1 loss: 11.7018 ; P: 0.8626 ; R: 0.8577 ; F1: 0.8601 ; Acc: 0.9452\n",
      "           Label 2 loss: 21.5318 ; P: 0.8187 ; R: 0.8085 ; F1: 0.8136 ; Acc: 0.8147\n",
      "2023-01-29 15:15:46.260475\n",
      "counter:  39\n",
      "2023-01-29 15:15:46.262476\n",
      "EPOCH 331\n",
      "TAG_LOSS_WEIGHT:  0.0650716546275053\n",
      "CLS_LOSS_WEIGHT:  0.9349283453724947\n",
      "tp:  1317\n",
      "fn:  5\n",
      "tn:  1314\n",
      "fp:  8\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2631\n",
      "tp:  456\n",
      "fn:  108\n",
      "tn:  463\n",
      "fp:  101\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  919\n",
      "EPOCH 331\n",
      "   TRAIN | Label 1 loss: 2.5901 ; P: 0.9757 ; R: 0.9824 ; F1: 0.979 ; Acc: 0.9922\n",
      "           Label 2 loss: 17.5644 ; P: 0.994 ; R: 0.9962 ; F1: 0.9951 ; Acc: 0.9951\n",
      "    TEST | Label 1 loss: 11.6557 ; P: 0.8582 ; R: 0.8615 ; F1: 0.8598 ; Acc: 0.9448\n",
      "           Label 2 loss: 21.6111 ; P: 0.8187 ; R: 0.8085 ; F1: 0.8136 ; Acc: 0.8147\n",
      "2023-01-29 15:16:16.913284\n",
      "counter:  40\n",
      "2023-01-29 15:16:16.914284\n",
      "EPOCH 332\n",
      "TAG_LOSS_WEIGHT:  0.06881713451184646\n",
      "CLS_LOSS_WEIGHT:  0.9311828654881535\n",
      "tp:  1317\n",
      "fn:  5\n",
      "tn:  1316\n",
      "fp:  6\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2633\n",
      "tp:  456\n",
      "fn:  108\n",
      "tn:  461\n",
      "fp:  103\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  917\n",
      "EPOCH 332\n",
      "   TRAIN | Label 1 loss: 2.5142 ; P: 0.9744 ; R: 0.9812 ; F1: 0.9778 ; Acc: 0.9918\n",
      "           Label 2 loss: 17.5305 ; P: 0.9955 ; R: 0.9962 ; F1: 0.9958 ; Acc: 0.9958\n",
      "    TEST | Label 1 loss: 11.7047 ; P: 0.8604 ; R: 0.8577 ; F1: 0.859 ; Acc: 0.9447\n",
      "           Label 2 loss: 21.549 ; P: 0.8157 ; R: 0.8085 ; F1: 0.8121 ; Acc: 0.8129\n",
      "2023-01-29 15:16:48.016310\n",
      "counter:  41\n",
      "2023-01-29 15:16:48.016310\n",
      "EPOCH 333\n",
      "TAG_LOSS_WEIGHT:  0.06533729277690534\n",
      "CLS_LOSS_WEIGHT:  0.9346627072230946\n",
      "tp:  1317\n",
      "fn:  5\n",
      "tn:  1316\n",
      "fp:  6\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2633\n",
      "tp:  451\n",
      "fn:  113\n",
      "tn:  464\n",
      "fp:  100\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  915\n",
      "EPOCH 333\n",
      "   TRAIN | Label 1 loss: 2.5667 ; P: 0.9754 ; R: 0.9818 ; F1: 0.9786 ; Acc: 0.9921\n",
      "           Label 2 loss: 17.4982 ; P: 0.9955 ; R: 0.9962 ; F1: 0.9958 ; Acc: 0.9958\n",
      "    TEST | Label 1 loss: 11.6454 ; P: 0.861 ; R: 0.8577 ; F1: 0.8593 ; Acc: 0.9448\n",
      "           Label 2 loss: 21.4628 ; P: 0.8185 ; R: 0.7996 ; F1: 0.809 ; Acc: 0.8112\n",
      "2023-01-29 15:17:18.925718\n",
      "counter:  42\n",
      "2023-01-29 15:17:18.927718\n",
      "EPOCH 334\n",
      "TAG_LOSS_WEIGHT:  0.06814105165222177\n",
      "CLS_LOSS_WEIGHT:  0.9318589483477784\n",
      "tp:  1313\n",
      "fn:  9\n",
      "tn:  1319\n",
      "fp:  3\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2632\n",
      "tp:  457\n",
      "fn:  107\n",
      "tn:  462\n",
      "fp:  102\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  919\n",
      "EPOCH 334\n",
      "   TRAIN | Label 1 loss: 2.6339 ; P: 0.9759 ; R: 0.9807 ; F1: 0.9783 ; Acc: 0.992\n",
      "           Label 2 loss: 17.6256 ; P: 0.9977 ; R: 0.9932 ; F1: 0.9955 ; Acc: 0.9955\n",
      "    TEST | Label 1 loss: 11.6237 ; P: 0.8572 ; R: 0.8583 ; F1: 0.8578 ; Acc: 0.9441\n",
      "           Label 2 loss: 21.4553 ; P: 0.8175 ; R: 0.8103 ; F1: 0.8139 ; Acc: 0.8147\n",
      "2023-01-29 15:17:49.721594\n",
      "counter:  43\n",
      "2023-01-29 15:17:49.721594\n",
      "EPOCH 335\n",
      "TAG_LOSS_WEIGHT:  0.07054017764996211\n",
      "CLS_LOSS_WEIGHT:  0.9294598223500378\n",
      "tp:  1318\n",
      "fn:  4\n",
      "tn:  1316\n",
      "fp:  6\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2634\n",
      "tp:  456\n",
      "fn:  108\n",
      "tn:  462\n",
      "fp:  102\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  918\n",
      "EPOCH 335\n",
      "   TRAIN | Label 1 loss: 2.5712 ; P: 0.9723 ; R: 0.9817 ; F1: 0.977 ; Acc: 0.9915\n",
      "           Label 2 loss: 17.3319 ; P: 0.9955 ; R: 0.997 ; F1: 0.9962 ; Acc: 0.9962\n",
      "    TEST | Label 1 loss: 11.618 ; P: 0.8577 ; R: 0.8577 ; F1: 0.8577 ; Acc: 0.9441\n",
      "           Label 2 loss: 21.5811 ; P: 0.8172 ; R: 0.8085 ; F1: 0.8128 ; Acc: 0.8138\n",
      "2023-01-29 15:18:20.827027\n",
      "counter:  44\n",
      "2023-01-29 15:18:20.828028\n",
      "EPOCH 336\n",
      "TAG_LOSS_WEIGHT:  0.06959031093574965\n",
      "CLS_LOSS_WEIGHT:  0.9304096890642503\n",
      "tp:  1317\n",
      "fn:  5\n",
      "tn:  1315\n",
      "fp:  7\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2632\n",
      "tp:  451\n",
      "fn:  113\n",
      "tn:  463\n",
      "fp:  101\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  914\n",
      "EPOCH 336\n",
      "   TRAIN | Label 1 loss: 2.5798 ; P: 0.9749 ; R: 0.9829 ; F1: 0.9789 ; Acc: 0.9922\n",
      "           Label 2 loss: 17.4929 ; P: 0.9947 ; R: 0.9962 ; F1: 0.9955 ; Acc: 0.9955\n",
      "    TEST | Label 1 loss: 11.6655 ; P: 0.8624 ; R: 0.8564 ; F1: 0.8594 ; Acc: 0.9449\n",
      "           Label 2 loss: 21.5597 ; P: 0.817 ; R: 0.7996 ; F1: 0.8082 ; Acc: 0.8103\n",
      "2023-01-29 15:18:52.402892\n",
      "counter:  45\n",
      "2023-01-29 15:18:52.402892\n",
      "EPOCH 337\n",
      "TAG_LOSS_WEIGHT:  0.0688292383499125\n",
      "CLS_LOSS_WEIGHT:  0.9311707616500876\n",
      "tp:  1317\n",
      "fn:  5\n",
      "tn:  1318\n",
      "fp:  4\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2635\n",
      "tp:  449\n",
      "fn:  115\n",
      "tn:  466\n",
      "fp:  98\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  915\n",
      "EPOCH 337\n",
      "   TRAIN | Label 1 loss: 2.465 ; P: 0.9759 ; R: 0.981 ; F1: 0.9784 ; Acc: 0.992\n",
      "           Label 2 loss: 17.4193 ; P: 0.997 ; R: 0.9962 ; F1: 0.9966 ; Acc: 0.9966\n",
      "    TEST | Label 1 loss: 11.7109 ; P: 0.8659 ; R: 0.8539 ; F1: 0.8599 ; Acc: 0.9453\n",
      "           Label 2 loss: 21.6097 ; P: 0.8208 ; R: 0.7961 ; F1: 0.8083 ; Acc: 0.8112\n",
      "2023-01-29 15:19:23.277804\n",
      "counter:  46\n",
      "2023-01-29 15:19:23.278805\n",
      "EPOCH 338\n",
      "TAG_LOSS_WEIGHT:  0.06371967195897864\n",
      "CLS_LOSS_WEIGHT:  0.9362803280410213\n",
      "tp:  1318\n",
      "fn:  4\n",
      "tn:  1317\n",
      "fp:  5\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2635\n",
      "tp:  450\n",
      "fn:  114\n",
      "tn:  468\n",
      "fp:  96\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  918\n",
      "EPOCH 338\n",
      "   TRAIN | Label 1 loss: 2.4646 ; P: 0.9758 ; R: 0.9807 ; F1: 0.9782 ; Acc: 0.992\n",
      "           Label 2 loss: 17.4678 ; P: 0.9962 ; R: 0.997 ; F1: 0.9966 ; Acc: 0.9966\n",
      "    TEST | Label 1 loss: 11.6845 ; P: 0.8645 ; R: 0.8558 ; F1: 0.8601 ; Acc: 0.9453\n",
      "           Label 2 loss: 21.4706 ; P: 0.8242 ; R: 0.7979 ; F1: 0.8108 ; Acc: 0.8138\n",
      "2023-01-29 15:19:54.192824\n",
      "counter:  47\n",
      "2023-01-29 15:19:54.192824\n",
      "EPOCH 339\n",
      "TAG_LOSS_WEIGHT:  0.06336945423407252\n",
      "CLS_LOSS_WEIGHT:  0.9366305457659275\n",
      "tp:  1317\n",
      "fn:  5\n",
      "tn:  1315\n",
      "fp:  7\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2632\n",
      "tp:  453\n",
      "fn:  111\n",
      "tn:  465\n",
      "fp:  99\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  918\n",
      "EPOCH 339\n",
      "   TRAIN | Label 1 loss: 2.4296 ; P: 0.9765 ; R: 0.9839 ; F1: 0.9802 ; Acc: 0.9927\n",
      "           Label 2 loss: 17.5608 ; P: 0.9947 ; R: 0.9962 ; F1: 0.9955 ; Acc: 0.9955\n",
      "    TEST | Label 1 loss: 11.5571 ; P: 0.8637 ; R: 0.8577 ; F1: 0.8607 ; Acc: 0.9454\n",
      "           Label 2 loss: 21.4161 ; P: 0.8207 ; R: 0.8032 ; F1: 0.8118 ; Acc: 0.8138\n",
      "2023-01-29 15:20:25.557629\n",
      "counter:  48\n",
      "2023-01-29 15:20:25.557629\n",
      "EPOCH 340\n",
      "TAG_LOSS_WEIGHT:  0.06108075388897062\n",
      "CLS_LOSS_WEIGHT:  0.9389192461110294\n",
      "tp:  1315\n",
      "fn:  7\n",
      "tn:  1316\n",
      "fp:  6\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2631\n",
      "tp:  454\n",
      "fn:  110\n",
      "tn:  465\n",
      "fp:  99\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  919\n",
      "EPOCH 340\n",
      "   TRAIN | Label 1 loss: 2.4869 ; P: 0.9774 ; R: 0.9822 ; F1: 0.9798 ; Acc: 0.9925\n",
      "           Label 2 loss: 17.5559 ; P: 0.9955 ; R: 0.9947 ; F1: 0.9951 ; Acc: 0.9951\n",
      "    TEST | Label 1 loss: 11.5065 ; P: 0.8624 ; R: 0.8564 ; F1: 0.8594 ; Acc: 0.9449\n",
      "           Label 2 loss: 21.3379 ; P: 0.821 ; R: 0.805 ; F1: 0.8129 ; Acc: 0.8147\n",
      "2023-01-29 15:20:56.431118\n",
      "counter:  49\n",
      "2023-01-29 15:20:56.432109\n",
      "EPOCH 341\n",
      "TAG_LOSS_WEIGHT:  0.06384314222135162\n",
      "CLS_LOSS_WEIGHT:  0.9361568577786483\n",
      "tp:  1318\n",
      "fn:  4\n",
      "tn:  1313\n",
      "fp:  9\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2631\n",
      "tp:  451\n",
      "fn:  113\n",
      "tn:  466\n",
      "fp:  98\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  917\n",
      "EPOCH 341\n",
      "   TRAIN | Label 1 loss: 2.4976 ; P: 0.9774 ; R: 0.9815 ; F1: 0.9795 ; Acc: 0.9924\n",
      "           Label 2 loss: 17.5676 ; P: 0.9932 ; R: 0.997 ; F1: 0.9951 ; Acc: 0.9951\n",
      "    TEST | Label 1 loss: 11.5694 ; P: 0.8656 ; R: 0.8558 ; F1: 0.8607 ; Acc: 0.9456\n",
      "           Label 2 loss: 21.3283 ; P: 0.8215 ; R: 0.7996 ; F1: 0.8104 ; Acc: 0.8129\n",
      "2023-01-29 15:21:27.233531\n",
      "counter:  50\n",
      "2023-01-29 15:21:27.233531\n",
      "EPOCH 342\n",
      "TAG_LOSS_WEIGHT:  0.06427807905497573\n",
      "CLS_LOSS_WEIGHT:  0.9357219209450243\n",
      "tp:  1318\n",
      "fn:  4\n",
      "tn:  1316\n",
      "fp:  6\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2634\n",
      "tp:  451\n",
      "fn:  113\n",
      "tn:  465\n",
      "fp:  99\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  916\n",
      "EPOCH 342\n",
      "   TRAIN | Label 1 loss: 2.5452 ; P: 0.9727 ; R: 0.9811 ; F1: 0.9769 ; Acc: 0.9914\n",
      "           Label 2 loss: 17.5032 ; P: 0.9955 ; R: 0.997 ; F1: 0.9962 ; Acc: 0.9962\n",
      "    TEST | Label 1 loss: 11.5522 ; P: 0.865 ; R: 0.8552 ; F1: 0.8601 ; Acc: 0.9453\n",
      "           Label 2 loss: 21.3392 ; P: 0.82 ; R: 0.7996 ; F1: 0.8097 ; Acc: 0.8121\n",
      "2023-01-29 15:21:58.401508\n",
      "counter:  51\n",
      "2023-01-29 15:21:58.403500\n",
      "EPOCH 343\n",
      "TAG_LOSS_WEIGHT:  0.06704476999097093\n",
      "CLS_LOSS_WEIGHT:  0.932955230009029\n",
      "tp:  1317\n",
      "fn:  5\n",
      "tn:  1319\n",
      "fp:  3\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2636\n",
      "tp:  453\n",
      "fn:  111\n",
      "tn:  466\n",
      "fp:  98\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  919\n",
      "EPOCH 343\n",
      "   TRAIN | Label 1 loss: 2.313 ; P: 0.9762 ; R: 0.9815 ; F1: 0.9789 ; Acc: 0.9922\n",
      "           Label 2 loss: 17.3332 ; P: 0.9977 ; R: 0.9962 ; F1: 0.997 ; Acc: 0.997\n",
      "    TEST | Label 1 loss: 11.533 ; P: 0.8643 ; R: 0.8583 ; F1: 0.8613 ; Acc: 0.9457\n",
      "           Label 2 loss: 21.328 ; P: 0.8221 ; R: 0.8032 ; F1: 0.8126 ; Acc: 0.8147\n",
      "2023-01-29 15:22:29.494240\n",
      "counter:  52\n",
      "2023-01-29 15:22:29.495239\n",
      "EPOCH 344\n",
      "TAG_LOSS_WEIGHT:  0.05706510987485296\n",
      "CLS_LOSS_WEIGHT:  0.9429348901251472\n",
      "tp:  1317\n",
      "fn:  5\n",
      "tn:  1316\n",
      "fp:  6\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2633\n",
      "tp:  454\n",
      "fn:  110\n",
      "tn:  463\n",
      "fp:  101\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  917\n",
      "EPOCH 344\n",
      "   TRAIN | Label 1 loss: 2.4101 ; P: 0.9757 ; R: 0.9812 ; F1: 0.9784 ; Acc: 0.992\n",
      "           Label 2 loss: 17.4441 ; P: 0.9955 ; R: 0.9962 ; F1: 0.9958 ; Acc: 0.9958\n",
      "    TEST | Label 1 loss: 11.5061 ; P: 0.8623 ; R: 0.8596 ; F1: 0.8609 ; Acc: 0.9454\n",
      "           Label 2 loss: 21.3419 ; P: 0.818 ; R: 0.805 ; F1: 0.8114 ; Acc: 0.8129\n",
      "2023-01-29 15:23:00.476241\n",
      "counter:  53\n",
      "2023-01-29 15:23:00.477235\n",
      "EPOCH 345\n",
      "TAG_LOSS_WEIGHT:  0.06092143186642432\n",
      "CLS_LOSS_WEIGHT:  0.9390785681335757\n",
      "tp:  1317\n",
      "fn:  5\n",
      "tn:  1317\n",
      "fp:  5\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2634\n",
      "tp:  454\n",
      "fn:  110\n",
      "tn:  464\n",
      "fp:  100\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  918\n",
      "EPOCH 345\n",
      "   TRAIN | Label 1 loss: 2.4345 ; P: 0.9776 ; R: 0.9826 ; F1: 0.9801 ; Acc: 0.9927\n",
      "           Label 2 loss: 17.4783 ; P: 0.9962 ; R: 0.9962 ; F1: 0.9962 ; Acc: 0.9962\n",
      "    TEST | Label 1 loss: 11.5144 ; P: 0.8633 ; R: 0.859 ; F1: 0.8611 ; Acc: 0.9456\n",
      "           Label 2 loss: 21.3335 ; P: 0.8195 ; R: 0.805 ; F1: 0.8122 ; Acc: 0.8138\n",
      "2023-01-29 15:23:31.644125\n",
      "counter:  54\n",
      "2023-01-29 15:23:31.645125\n",
      "EPOCH 346\n",
      "TAG_LOSS_WEIGHT:  0.06185653915293058\n",
      "CLS_LOSS_WEIGHT:  0.9381434608470693\n",
      "tp:  1315\n",
      "fn:  7\n",
      "tn:  1317\n",
      "fp:  5\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2632\n",
      "tp:  454\n",
      "fn:  110\n",
      "tn:  463\n",
      "fp:  101\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  917\n",
      "EPOCH 346\n",
      "   TRAIN | Label 1 loss: 2.4065 ; P: 0.9753 ; R: 0.9836 ; F1: 0.9794 ; Acc: 0.9924\n",
      "           Label 2 loss: 17.4538 ; P: 0.9962 ; R: 0.9947 ; F1: 0.9955 ; Acc: 0.9955\n",
      "    TEST | Label 1 loss: 11.5175 ; P: 0.864 ; R: 0.8602 ; F1: 0.8621 ; Acc: 0.9459\n",
      "           Label 2 loss: 21.3323 ; P: 0.818 ; R: 0.805 ; F1: 0.8114 ; Acc: 0.8129\n",
      "2023-01-29 15:24:02.735527\n",
      "counter:  55\n",
      "2023-01-29 15:24:02.737521\n",
      "EPOCH 347\n",
      "TAG_LOSS_WEIGHT:  0.06068720850823031\n",
      "CLS_LOSS_WEIGHT:  0.9393127914917697\n",
      "tp:  1318\n",
      "fn:  4\n",
      "tn:  1319\n",
      "fp:  3\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2637\n",
      "tp:  454\n",
      "fn:  110\n",
      "tn:  463\n",
      "fp:  101\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  917\n",
      "EPOCH 347\n",
      "   TRAIN | Label 1 loss: 2.449 ; P: 0.9776 ; R: 0.9828 ; F1: 0.9802 ; Acc: 0.9927\n",
      "           Label 2 loss: 17.3217 ; P: 0.9977 ; R: 0.997 ; F1: 0.9974 ; Acc: 0.9974\n",
      "    TEST | Label 1 loss: 11.5314 ; P: 0.8635 ; R: 0.8602 ; F1: 0.8619 ; Acc: 0.9458\n",
      "           Label 2 loss: 21.3372 ; P: 0.818 ; R: 0.805 ; F1: 0.8114 ; Acc: 0.8129\n",
      "2023-01-29 15:24:33.490512\n",
      "counter:  56\n",
      "2023-01-29 15:24:33.491512\n",
      "EPOCH 348\n",
      "TAG_LOSS_WEIGHT:  0.06361316817708551\n",
      "CLS_LOSS_WEIGHT:  0.9363868318229145\n",
      "tp:  1318\n",
      "fn:  4\n",
      "tn:  1317\n",
      "fp:  5\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2635\n",
      "tp:  454\n",
      "fn:  110\n",
      "tn:  464\n",
      "fp:  100\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  918\n",
      "EPOCH 348\n",
      "   TRAIN | Label 1 loss: 2.494 ; P: 0.9756 ; R: 0.9804 ; F1: 0.978 ; Acc: 0.9919\n",
      "           Label 2 loss: 17.4553 ; P: 0.9962 ; R: 0.997 ; F1: 0.9966 ; Acc: 0.9966\n",
      "    TEST | Label 1 loss: 11.5372 ; P: 0.8638 ; R: 0.8583 ; F1: 0.861 ; Acc: 0.9456\n",
      "           Label 2 loss: 21.3245 ; P: 0.8195 ; R: 0.805 ; F1: 0.8122 ; Acc: 0.8138\n",
      "2023-01-29 15:25:04.774035\n",
      "counter:  57\n",
      "2023-01-29 15:25:04.776035\n",
      "EPOCH 349\n",
      "TAG_LOSS_WEIGHT:  0.06487859618122693\n",
      "CLS_LOSS_WEIGHT:  0.935121403818773\n",
      "tp:  1317\n",
      "fn:  5\n",
      "tn:  1314\n",
      "fp:  8\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2631\n",
      "tp:  454\n",
      "fn:  110\n",
      "tn:  463\n",
      "fp:  101\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  917\n",
      "EPOCH 349\n",
      "   TRAIN | Label 1 loss: 2.3792 ; P: 0.9777 ; R: 0.9829 ; F1: 0.9803 ; Acc: 0.9927\n",
      "           Label 2 loss: 17.6132 ; P: 0.994 ; R: 0.9962 ; F1: 0.9951 ; Acc: 0.9951\n",
      "    TEST | Label 1 loss: 11.5329 ; P: 0.8631 ; R: 0.8577 ; F1: 0.8604 ; Acc: 0.9453\n",
      "           Label 2 loss: 21.3183 ; P: 0.818 ; R: 0.805 ; F1: 0.8114 ; Acc: 0.8129\n",
      "2023-01-29 15:25:36.106772\n",
      "counter:  58\n",
      "2023-01-29 15:25:36.106772\n",
      "EPOCH 350\n",
      "TAG_LOSS_WEIGHT:  0.05839166338907212\n",
      "CLS_LOSS_WEIGHT:  0.9416083366109279\n",
      "tp:  1318\n",
      "fn:  4\n",
      "tn:  1316\n",
      "fp:  6\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2634\n",
      "tp:  454\n",
      "fn:  110\n",
      "tn:  464\n",
      "fp:  100\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  918\n",
      "EPOCH 350\n",
      "   TRAIN | Label 1 loss: 2.4867 ; P: 0.9758 ; R: 0.9801 ; F1: 0.9779 ; Acc: 0.9919\n",
      "           Label 2 loss: 17.5279 ; P: 0.9955 ; R: 0.997 ; F1: 0.9962 ; Acc: 0.9962\n",
      "    TEST | Label 1 loss: 11.5247 ; P: 0.8632 ; R: 0.8583 ; F1: 0.8608 ; Acc: 0.9454\n",
      "           Label 2 loss: 21.3157 ; P: 0.8195 ; R: 0.805 ; F1: 0.8122 ; Acc: 0.8138\n",
      "2023-01-29 15:26:07.038455\n",
      "counter:  59\n",
      "2023-01-29 15:26:07.039446\n",
      "EPOCH 351\n",
      "TAG_LOSS_WEIGHT:  0.06402456669402383\n",
      "CLS_LOSS_WEIGHT:  0.9359754333059763\n",
      "tp:  1319\n",
      "fn:  3\n",
      "tn:  1319\n",
      "fp:  3\n",
      "train set pred label2 length:  2644\n",
      "train set true label2 length:  2644\n",
      "match number:  2638\n",
      "tp:  454\n",
      "fn:  110\n",
      "tn:  464\n",
      "fp:  100\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "match number:  918\n",
      "EPOCH 351\n",
      "   TRAIN | Label 1 loss: 2.3491 ; P: 0.9768 ; R: 0.9856 ; F1: 0.9812 ; Acc: 0.993\n",
      "           Label 2 loss: 17.3108 ; P: 0.9977 ; R: 0.9977 ; F1: 0.9977 ; Acc: 0.9977\n",
      "    TEST | Label 1 loss: 11.5273 ; P: 0.8633 ; R: 0.859 ; F1: 0.8611 ; Acc: 0.9456\n",
      "           Label 2 loss: 21.3185 ; P: 0.8195 ; R: 0.805 ; F1: 0.8122 ; Acc: 0.8138\n",
      "2023-01-29 15:26:38.121424\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os, shutil\n",
    "import datetime\n",
    "\n",
    "OUTPUT_PATH = './checkpoint'\n",
    "OUTPUT_PATH =os.path.join(OUTPUT_PATH, BERT_PATH[2:])\n",
    "\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)\n",
    "\n",
    "\n",
    "label1_loss_train_list=[]\n",
    "# label1_loss_validation_list=[]\n",
    "label1_loss_test_list=[]\n",
    "\n",
    "label2_loss_train_list=[]\n",
    "# label2_loss_validation_list=[]\n",
    "label2_loss_test_list=[]\n",
    "\n",
    "label1_f1_train_list=[]\n",
    "# label1_f1_validation_list=[]\n",
    "label1_f1_test_list=[]\n",
    "\n",
    "label2_f1_train_list=[]\n",
    "# label2_f1_validation_list=[]\n",
    "label2_f1_test_list=[]\n",
    "\n",
    "label1_acc_train_list=[]\n",
    "# label1_acc_validation_list=[]\n",
    "label1_acc_test_list=[]\n",
    "\n",
    "label2_acc_train_list=[]\n",
    "# label2_acc_validation_list=[]\n",
    "label2_acc_test_list=[]\n",
    "\n",
    "label1_weight_list=[]\n",
    "# label2_acc_validation_list=[]\n",
    "label2_weight_list=[]\n",
    "\n",
    "best_label2_acc_va=-1\n",
    "best_label2_acc_te=-1\n",
    "\n",
    "epoch_num = 0\n",
    "min_validation_loss = np.inf\n",
    "max_validation_acc = 0\n",
    "patience = 60\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(datetime.datetime.now())\n",
    "    print('EPOCH', epoch_num)\n",
    "    print('TAG_LOSS_WEIGHT: ', TAG_LOSS_WEIGTH)\n",
    "    print('CLS_LOSS_WEIGHT: ', CLS_LOSS_WEIGTH)\n",
    "    \n",
    "    loss_label1_tr, loss_label2_tr, p_label1_tr, r_label1_tr, f_label1_tr, acc_label1_tr, p_label2_tr,\\\n",
    "    r_label2_tr, f_label2_tr, acc_label2_tr = \\\n",
    "    train(model, train_iterator, optimizer, scheduler, criterion_tag, criterion_cls, \n",
    "          TAG_PAD_IDX, TAG_LOSS_WEIGTH, CLS_LOSS_WEIGTH)\n",
    "    # ######## for softmax trust level ###########\n",
    "    # loss_label1_tr, loss_label2_tr, p_label1_tr, r_label1_tr, f_label1_tr, acc_label1_tr, p_label2_tr,\\\n",
    "    # r_label2_tr, f_label2_tr, acc_label2_tr, rmsd_tag_signal, rmsd_cls_signal = \\\n",
    "    # train(model, train_iterator, optimizer, scheduler, criterion_tag, criterion_cls, \n",
    "    #       TAG_PAD_IDX, TAG_LOSS_WEIGTH, CLS_LOSS_WEIGTH)\n",
    "    if epoch_num==0:\n",
    "        first_epoch_loss_tag = loss_label1_tr\n",
    "        first_epoch_loss_cls = loss_label2_tr\n",
    "    if epoch_num != 0:\n",
    "        TAG_LOSS_WEIGTH = (loss_label1_tr/first_epoch_loss_tag)**2\n",
    "        CLS_LOSS_WEIGTH = (loss_label2_tr/first_epoch_loss_cls)**2\n",
    "    # TAG_LOSS_WEIGTH = TAG_LOSS_WEIGTH/(rmsd_tag_signal+1e-9)\n",
    "    # CLS_LOSS_WEIGTH = CLS_LOSS_WEIGTH/(rmsd_cls_signal+1e-9)\n",
    "    coef=1/(TAG_LOSS_WEIGTH+CLS_LOSS_WEIGTH)\n",
    "    TAG_LOSS_WEIGTH = coef*TAG_LOSS_WEIGTH\n",
    "    CLS_LOSS_WEIGTH = coef*CLS_LOSS_WEIGTH\n",
    "    # loss_label1_va, loss_label2_va, p_label1_va, r_label1_va, f_label1_va, acc_label1_va, p_label2_va, r_label2_va, f_label2_va, acc_label2_va = evaluate(model, valid_iterator, criterion_tag, criterion_cls, TAG_PAD_IDX)\n",
    "    loss_label1_te, loss_label2_te, p_label1_te, r_label1_te, f_label1_te, acc_label1_te, p_label2_te, \\\n",
    "    r_label2_te, f_label2_te, acc_label2_te = evaluate(model, test_iterator, criterion_tag, \n",
    "                                                       criterion_cls, TAG_PAD_IDX)\n",
    "    print('EPOCH', epoch)\n",
    "    print('   TRAIN | Label 1 loss:', loss_label1_tr, '; P:', p_label1_tr, '; R:', r_label1_tr, '; F1:', f_label1_tr, '; Acc:', acc_label1_tr)\n",
    "    print('           Label 2 loss:', loss_label2_tr, '; P:', p_label2_tr, '; R:', r_label2_tr, '; F1:', f_label2_tr, '; Acc:', acc_label2_tr)\n",
    "    # print('   VALID | Label 1 loss:', loss_label1_va, '; P:', p_label1_va, '; R:', r_label1_va, '; F1:', f_label1_va, '; Acc:', acc_label1_va)\n",
    "    # print('           Label 2 loss:', loss_label2_va, '; P:', p_label2_va, '; R:', r_label2_va, '; F1:', f_label2_va, '; Acc:', acc_label2_va)\n",
    "    print('    TEST | Label 1 loss:', loss_label1_te, '; P:', p_label1_te, '; R:', r_label1_te, '; F1:', f_label1_te, '; Acc:', acc_label1_te)\n",
    "    print('           Label 2 loss:', loss_label2_te, '; P:', p_label2_te, '; R:', r_label2_te, '; F1:', f_label2_te, '; Acc:', acc_label2_te)\n",
    "    print(datetime.datetime.now())\n",
    "    epoch_num +=1\n",
    "    # if loss_label1_tr < 180:\n",
    "    #     TAG_LOSS_WEIGTH =0.1*TAG_LOSS_WEIGTH\n",
    "    \n",
    "    #print(\"Tag loss weight: \", TAG_LOSS_WEIGTH)\n",
    "    \n",
    "    label1_loss_train_list.append(loss_label1_tr)\n",
    "    # label1_loss_validation_list.append(loss_label1_va)\n",
    "    label1_loss_test_list.append(loss_label1_te)\n",
    "    \n",
    "    label2_loss_train_list.append(loss_label2_tr)\n",
    "    # label2_loss_validation_list.append(loss_label2_va)\n",
    "    label2_loss_test_list.append(loss_label2_te)\n",
    "    \n",
    "    label1_f1_train_list.append(f_label1_tr)\n",
    "    # label1_f1_validation_list.append(f_label1_va)\n",
    "    label1_f1_test_list.append(f_label1_te)\n",
    "    \n",
    "    label2_f1_train_list.append(f_label2_tr)\n",
    "    # label2_f1_validation_list.append(f_label2_va)\n",
    "    label2_f1_test_list.append(f_label2_te)\n",
    "    \n",
    "    label1_acc_train_list.append(acc_label1_tr)\n",
    "    # label1_f1_validation_list.append(f_label1_va)\n",
    "    label1_acc_test_list.append(acc_label1_te)\n",
    "    \n",
    "    label2_acc_train_list.append(acc_label2_tr)\n",
    "    # label2_f1_validation_list.append(f_label2_va)\n",
    "    label2_acc_test_list.append(acc_label2_te)\n",
    "    \n",
    "    label1_weight_list.append(TAG_LOSS_WEIGTH)\n",
    "    # label2_f1_validation_list.append(f_label2_va)\n",
    "    label2_weight_list.append(CLS_LOSS_WEIGTH)\n",
    "    \n",
    "    \n",
    "    # OUTPUT_PATH_validation =os.path.join(OUTPUT_PATH, 'validation')\n",
    "    # if not os.path.exists(OUTPUT_PATH_validation):\n",
    "    #     os.makedirs(OUTPUT_PATH_validation)\n",
    "    # if f_label2_va>best_label2_f1_va:\n",
    "    #     best_label2_f1_va=f_label2_va\n",
    "    #     output_dir_validation = os.path.join(OUTPUT_PATH_validation, 'checkpoint_epoch{}.pt'.format(epoch))\n",
    "    #     # clear the content of folder\n",
    "    #     for files in os.listdir(OUTPUT_PATH_validation):\n",
    "    #         path = os.path.join(OUTPUT_PATH_validation, files)\n",
    "    #         try:\n",
    "    #             shutil.rmtree(path)\n",
    "    #         except OSError:\n",
    "    #             os.remove(path)\n",
    "    #     # if not os.path.exists(output_dir):\n",
    "    #     #     os.makedirs(output_dir)\n",
    "    #     torch.save(model.state_dict(), output_dir_validation)\n",
    "        \n",
    "    OUTPUT_PATH_test =os.path.join(OUTPUT_PATH, 'test/')\n",
    "    if not os.path.exists(OUTPUT_PATH_test):\n",
    "        os.makedirs(OUTPUT_PATH_test)\n",
    "    if acc_label2_te>best_label2_acc_te:\n",
    "        best_label2_acc_te=acc_label2_te\n",
    "        output_dir_test = os.path.join(OUTPUT_PATH_test, 'checkpoint_epoch{}.pt'.format(epoch))\n",
    "        # clear the content of folder\n",
    "        for files in os.listdir(OUTPUT_PATH_test):\n",
    "            path = os.path.join(OUTPUT_PATH_test, files)\n",
    "            try:\n",
    "                shutil.rmtree(path)\n",
    "            except OSError:\n",
    "                os.remove(path)\n",
    "        # if not os.path.exists(output_dir):\n",
    "        #     os.makedirs(output_dir)\n",
    "        torch.save(model.state_dict(), output_dir_test)\n",
    "    # early stop\n",
    "    if acc_label2_te <0.75:\n",
    "        continue\n",
    "    elif acc_label2_te > max_validation_acc:\n",
    "        max_validation_acc = acc_label2_te\n",
    "        counter = 0\n",
    "    elif acc_label2_te <= max_validation_acc:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            break\n",
    "    print('counter: ',counter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "798ea626-65be-4f9d-8b05-e87eba8a4665",
   "metadata": {},
   "outputs": [],
   "source": [
    "label1_loss_df = pd.DataFrame(\n",
    "    {'label1_loss_train': label1_loss_train_list,\n",
    "     # 'label1_loss_validation': label1_loss_validation_list,\n",
    "     'label1_loss_test': label1_loss_test_list\n",
    "    })\n",
    "label2_loss_df = pd.DataFrame(\n",
    "    {'label2_loss_train': label2_loss_train_list,\n",
    "     # 'label2_loss_validation': label2_loss_validation_list,\n",
    "     'label2_loss_test': label2_loss_test_list\n",
    "    })\n",
    "label1_f1_df = pd.DataFrame(\n",
    "    {'label1_f1_train': label1_f1_train_list,\n",
    "     # 'label1_f1_validation': label1_f1_validation_list,\n",
    "     'label1_f1_test': label1_f1_test_list\n",
    "    })\n",
    "label2_f1_df = pd.DataFrame(\n",
    "    {'label2_f1_train': label2_f1_train_list,\n",
    "     # 'label2_f1_validation': label2_f1_validation_list,\n",
    "     'label2_f1_test': label2_f1_test_list\n",
    "    })\n",
    "label1_acc_df = pd.DataFrame(\n",
    "    {'label1_f1_train': label1_acc_train_list,\n",
    "     # 'label1_f1_validation': label1_f1_validation_list,\n",
    "     'label1_f1_test': label1_acc_test_list\n",
    "    })\n",
    "label2_acc_df = pd.DataFrame(\n",
    "    {'label2_f1_train': label2_acc_train_list,\n",
    "     # 'label2_f1_validation': label2_f1_validation_list,\n",
    "     'label2_f1_test': label2_acc_test_list\n",
    "    })\n",
    "train_loss_df = pd.DataFrame(\n",
    "    {'label1_loss_train': label1_loss_train_list,\n",
    "     # 'label1_loss_validation': label1_loss_validation_list,\n",
    "     'label2_loss_train': label2_loss_train_list\n",
    "    })\n",
    "weight_df = pd.DataFrame(\n",
    "    {'label1_weight_train': label1_weight_list,\n",
    "     # 'label2_f1_validation': label2_f1_validation_list,\n",
    "     'label2_weight_train': label2_weight_list\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "777e5eb2-8d49-46c7-9d9e-7d9ce323fc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./checkpoint\\\\bert-large-uncased\\\\test/checkpoint_epoch291.pt'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5918fbda-c096-42f6-b749-32b7c14a9176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'weights'}, xlabel='epochs', ylabel='weight'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label1_loss_df.plot(title=\"label1 losses\",xlabel=\"epochs\",ylabel=\"loss\")\n",
    "label2_loss_df.plot(title=\"label2 losses\",xlabel=\"epochs\",ylabel=\"loss\")\n",
    "label1_f1_df.plot(title=\"label1 f1\",xlabel=\"epochs\",ylabel=\"f1\")\n",
    "label2_f1_df.plot(title=\"label2 f1\",xlabel=\"epochs\",ylabel=\"f1\")\n",
    "label1_acc_df.plot(title=\"label1 acc\",xlabel=\"epochs\",ylabel=\"acc\")\n",
    "label2_acc_df.plot(title=\"label2 acc\",xlabel=\"epochs\",ylabel=\"acc\")\n",
    "train_loss_df.plot(title=\"train losses\",xlabel=\"epochs\",ylabel=\"loss\")\n",
    "weight_df.plot(title=\"weights\",xlabel=\"epochs\",ylabel=\"weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6faa13c9-8697-4d0b-a206-67cbd793d1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(output_dir_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5949ff83-b9fd-4fab-b7d5-d09d6a6005b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./dpr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d2b04a4-5588-4975-85dd-7a62121596f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruicheng\\anaconda3\\lib\\site-packages\\fontTools\\misc\\py23.py:11: DeprecationWarning: The py23 module has been deprecated and will be removed in a future release. Please update your code.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_df.plot(title=\"train losses\",xlabel=\"epochs\",ylabel=\"loss\")\n",
    "plt.savefig(\"train losses.pdf\", bbox_inches='tight')\n",
    "\n",
    "weight_df.plot(title=\"weights\",xlabel=\"epochs\",ylabel=\"weight\")\n",
    "plt.savefig(\"weights.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc71c2e2-0faf-4ca8-959d-7c5abd455812",
   "metadata": {},
   "outputs": [],
   "source": [
    "label1_loss_df.to_csv(\"label1 losses.csv\", index=False,encoding='utf-8-sig')\n",
    "label2_loss_df.to_csv(\"label2 losses.csv\", index=False,encoding='utf-8-sig')\n",
    "label1_f1_df.to_csv(\"label1 f1.csv\", index=False,encoding='utf-8-sig')\n",
    "label2_f1_df.to_csv(\"label2 f1.csv\", index=False,encoding='utf-8-sig')\n",
    "label1_acc_df.to_csv(\"label1 acc.csv\", index=False,encoding='utf-8-sig')\n",
    "label2_acc_df.to_csv(\"label2 acc.csv\", index=False,encoding='utf-8-sig')\n",
    "train_loss_df.to_csv(\"train losses.csv\", index=False,encoding='utf-8-sig')\n",
    "weight_df.to_csv(\"weight_df.csv\", index=False,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6591fe4a-1a14-41c6-a43d-563c0b1d6af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8184"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(label2_f1_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2629b306-c507-4e4e-bb1a-b671725d8a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8183"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(label2_acc_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73adc569-a586-4b78-9f1e-81189c911538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoint\\bert-large-uncased\\test/checkpoint_epoch291.pt\n"
     ]
    }
   ],
   "source": [
    "print(output_dir_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6186dc67-83c0-45c0-84e6-a9a15a0f633a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp:  462\n",
      "fn:  102\n",
      "tn:  461\n",
      "fp:  103\n",
      "pred label2 length:  1128\n",
      "true label2 length:  1128\n",
      "token_idx_list length:  1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match number:  923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n",
      "C:\\Users\\Ruicheng\\AppData\\Local\\Temp\\ipykernel_22488\\3303094034.py:69: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append(df2, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "loss_label1_te, loss_label2_te, p_label1_te, r_label1_te, f_label1_te, acc_label1_te, p_label2_te, r_label2_te, f_label2_te, acc_label2_te, comparison_df_te = evaluate_output_difference(model, test_iterator, criterion_tag, criterion_cls, TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c234d212-0030-4137-9cf5-102091a1845d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8184"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_label2_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a2b8ddc-2236-4252-b626-e33e9a136bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_female = data.TabularDataset(\n",
    "#                                     path = DATA_PATH+'gap_test_female_bert_2mask.csv',\n",
    "#                                     format = 'csv',\n",
    "#                                     fields = fields,\n",
    "#                                     skip_header = True)\n",
    "# test_data_male = data.TabularDataset(\n",
    "#                                     path = DATA_PATH+'gap_test_male_bert_2mask.csv',\n",
    "#                                     format = 'csv',\n",
    "#                                     fields = fields,\n",
    "#                                     skip_header = True)\n",
    "\n",
    "# TOKEN.build_vocab(test_data_female, test_data_male)\n",
    "# LABEL1.build_vocab(test_data_female, test_data_male)\n",
    "# FT_TAGS.build_vocab(test_data_female, test_data_male)\n",
    "# SEQ.build_vocab(test_data_female, test_data_male)\n",
    "# LABEL2.build_vocab(test_data_female, test_data_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "085e0238-ff9d-4246-a09b-ad82ea7b64b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_data_female)\n",
    "# print(test_data_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3e2cd5d-8249-4d15-a23e-adc3dd70d0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_female_iterator = data.BucketIterator(\n",
    "#     test_data_female, \n",
    "#     batch_size = BATCH_SIZE,\n",
    "#     device = device,\n",
    "#     shuffle = True,\n",
    "#     sort=False)\n",
    "# test_male_iterator = data.BucketIterator(\n",
    "#     test_data_male, \n",
    "#     batch_size = BATCH_SIZE,\n",
    "#     device = device,\n",
    "#     shuffle = True,\n",
    "#     sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef1828bb-eebc-4cb9-96fb-5cd6e6a17b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(test_female_iterator))\n",
    "# print(type(test_male_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bfb5a8fd-6148-4f46-9478-a6b9f9097b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_label1_te_female, loss_label2_te_female, p_label1_te_female, r_label1_te_female,f_label1_te_female, acc_label1_te_female, p_label2_te_female,r_label2_te_female, f_label2_te_female, acc_label2_te_female = evaluate(model, test_female_iterator, criterion_tag, criterion_cls, TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0f30f234-6a37-450c-b514-82621b4b3e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_label2_te_female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b4fe4f6-5eeb-4f6d-a2ef-8e50fcc8583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_label1_te_male, loss_label2_te_male, p_label1_te_male, r_label1_te_male, f_label1_te_male, acc_label1_te_male, p_label2_te_male, r_label2_te_male, f_label2_te_male, acc_label2_te_male = evaluate(model, test_male_iterator, criterion_tag, criterion_cls, TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7f9457b3-9a99-44d9-b44e-4e566f215340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_label2_te_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "652e6a64-be35-4f00-8428-286b53ed653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias=f_label2_te_female/f_label2_te_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f8a37c55-6239-4224-813e-18d15af07b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "225b213f-7eca-4114-9072-7e0d776ee4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('E:/Google Drive/Continental/coref-multitask/winogender')\n",
    "#os.chdir('./dpr')\n",
    "comparison_df_te.to_csv(\"comparison_dpr_bert_multitask_lbwb.csv\", index=False,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f2fe52-6690-49fc-995a-411cacc054b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "53560c29-27ac-4364-9fd9-95dd05de2cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('E:/Google Drive/Continental/coref-multitask')\n",
    "# DATA_PATH = './winogender/'\n",
    "# winogender_df = data.TabularDataset(\n",
    "#                                     path = DATA_PATH+'winogender_df_new_spanbert.csv',\n",
    "#                                     format = 'csv',\n",
    "#                                     fields = fields,\n",
    "#                                     skip_header = True)\n",
    "\n",
    "# TOKEN.build_vocab(winogender_df)\n",
    "# LABEL1.build_vocab(winogender_df)\n",
    "# FT_TAGS.build_vocab(winogender_df)\n",
    "# SEQ.build_vocab(winogender_df)\n",
    "# LABEL2.build_vocab(winogender_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b2106030-16b4-437b-b1be-1e3ba48ff0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(winogender_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "93cc74f5-808b-468c-b2f6-debac9c7dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# winogender_iterator = data.BucketIterator(\n",
    "#     winogender_df, \n",
    "#     batch_size = BATCH_SIZE,\n",
    "#     device = device,\n",
    "#     shuffle = True,\n",
    "#     sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b7fa9392-49c1-48db-bfda-4e751e79a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_label1_winogender, loss_label2_winogender, p_label1_winogender, r_label1_winogender,f_label1_winogender, acc_label1_winogender, p_label2_winogender,r_label2_winogender, f_label2_winogender, acc_label2_winogender = evaluate(model, winogender_iterator, criterion_tag, criterion_cls, TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ed9234cf-f68d-43a6-965e-9dcd1e721bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_label2_winogender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649a08e4-fef1-4930-923a-5b6ee6f83b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
